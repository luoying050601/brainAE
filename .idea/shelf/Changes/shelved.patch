Index: .idea/inspectionProfiles/profiles_settings.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/inspectionProfiles/profiles_settings.xml b/.idea/inspectionProfiles/profiles_settings.xml
new file mode 100644
--- /dev/null	(date 1672825716000)
+++ b/.idea/inspectionProfiles/profiles_settings.xml	(date 1672825716000)
@@ -0,0 +1,6 @@
+<component name="InspectionProjectProfileManager">
+  <settings>
+    <option name="USE_PROJECT_PROFILE" value="false" />
+    <version value="1.0" />
+  </settings>
+</component>
\ No newline at end of file
Index: .idea/inspectionProfiles/Project_Default.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/inspectionProfiles/Project_Default.xml b/.idea/inspectionProfiles/Project_Default.xml
new file mode 100644
--- /dev/null	(date 1672825715000)
+++ b/.idea/inspectionProfiles/Project_Default.xml	(date 1672825715000)
@@ -0,0 +1,12 @@
+<component name="InspectionProjectProfileManager">
+  <profile version="1.0">
+    <option name="myName" value="Project Default" />
+    <inspection_tool class="PyPep8NamingInspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
+      <option name="ignoredErrors">
+        <list>
+          <option value="N806" />
+        </list>
+      </option>
+    </inspection_tool>
+  </profile>
+</component>
\ No newline at end of file
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
new file mode 100644
--- /dev/null	(date 1695637415000)
+++ b/.idea/misc.xml	(date 1695637415000)
@@ -0,0 +1,4 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="ProjectRootManager" version="2" project-jdk-name="laplace_local" project-jdk-type="Python SDK" />
+</project>
\ No newline at end of file
Index: src/com/model/run_auto_encoder_shell.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/run_auto_encoder_shell.py b/src/com/model/run_auto_encoder_shell.py
new file mode 100644
--- /dev/null	(date 1674104775000)
+++ b/src/com/model/run_auto_encoder_shell.py	(date 1674104775000)
@@ -0,0 +1,651 @@
+import os
+import random
+
+# cherry 的 GPU跑不动 死心吧
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "."))  # TODO script
+import sys
+from transformers import AlbertTokenizer, AlbertModel
+
+sys.path.append(Proj_dir)
+import json
+import time
+import transformers
+import torch
+import pandas as pd
+from torch import nn
+import torch.nn.functional as F
+import numpy as np
+from transformers import BertModel
+from sentence_transformers import SentenceTransformer
+from simcse import SimCSE
+from src.com.util.data_format import normalization, standardization
+from transformers import AdamW
+from tqdm import tqdm
+
+os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"  # GPU
+
+lr = 1e-5
+
+corr_list = []
+
+
+def get_albert_embedding_tensor(sentence, tokenizer, model):
+    encoded_input = tokenizer(sentence, return_tensors='pt')
+    output = model(**encoded_input)
+    return output[-1].detach().squeeze(0)
+
+
+def get_sentence_embedding(sentence, tokenizer, option):
+    # if YOU NEED [cls] and [seq] PRESENTATION：True
+    # print(_config.MODEL)
+    if _config.MODEL == 'bert-large-uncased':
+        input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=False)).unsqueeze(0)  # Batch size 1
+        text_model = BertModel.from_pretrained(_config.MODEL, output_hidden_states=True)
+        outputs = text_model(input_ids)
+        all_layers_output = outputs[2]
+        if option == "last_layer":
+            sent_embeddings = all_layers_output[-1]  # last layer
+        elif option == "second_to_last_layer":
+            sent_embeddings = all_layers_output[-2]  # second to last layer
+        else:
+            sent_embeddings = all_layers_output[-1]  # last layer
+
+        sent_embeddings = torch.squeeze(sent_embeddings, dim=0)
+        sentence_embedding_avg = torch.mean(sent_embeddings, dim=0)
+        return sentence_embedding_avg
+
+    elif _config.MODEL == 'sentence-camembert-large':
+        text_model = SentenceTransformer("dangvantuan/sentence-camembert-large")
+        embeddings = text_model.encode(sentence)
+        return embeddings
+    elif _config.MODEL == 'SimCSE':
+
+        text_model = SimCSE("princeton-nlp/sup-simcse-bert-base-uncased")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_large':
+
+        text_model = SimCSE("princeton-nlp/sup-simcse-bert-large-uncased")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_roberta_large':
+        text_model = SimCSE("princeton-nlp/sup-simcse-roberta-large")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_roberta_large_sup':
+        text_model = SimCSE("princeton-nlp/unsup-simcse-roberta-large")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_bert_large_unsup':
+        text_model = SimCSE("princeton-nlp/unsup-simcse-bert-large-uncased")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL in ['albert-xlarge-v1', 'albert-xlarge-v2']:
+        text_model = AlbertModel.from_pretrained(_config.MODEL)
+        tokenizer = AlbertTokenizer.from_pretrained(_config.MODEL)
+        # text_model = AlbertModel("princeton-nlp/unsup-simcse-bert-large-uncased")
+        embeddings = get_albert_embedding_tensor(sentence, tokenizer, text_model)
+        # embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+        #                                batch_size=64,
+        #                                max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+
+
+def seed_all(seed=42):
+    """
+  Fix seed for reproducibility
+  """
+    # python RNG
+    import random
+    random.seed(seed)
+
+    # pytorch RNGs
+    torch.manual_seed(seed)
+    torch.backends.cudnn.deterministic = True
+    if torch.cuda.is_available():
+        torch.cuda.manual_seed_all(seed)
+    np.random.seed(seed)
+
+
+def preprocess(text):
+    # text = html.unescape(text)
+    # text = text.translate(transl_table)
+    # text = text.replace('…', '...')
+    # text = re.sub(control_char_regex, ' ', text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')
+    text = ' '.join(text.split())
+    text = text.lower()
+    text = text.strip()
+
+    # text = text.replace('HTTPURL', 'URL')
+    # text = emoji.demojize(text)
+
+    # text = unidecode.unidecode(text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'So')
+
+    return text
+
+
+def process_data(data, tokenizer, max_len):
+    text = preprocess(data['label'])
+    embeding = get_sentence_embedding(sentence=text, tokenizer=tokenizer, option="last_layer")
+
+    return {
+        'ids': data['index'],
+        'brain': data['brain'],
+        # 'mask': mask,
+        'label': embeding
+    }
+
+
+class Dataset:
+    def __init__(self, dataList):
+        self.dataList = dataList
+        # self.label = label
+        self.tokenizer = _config.TOKENIZER
+        self.max_len = _config.MAX_LEN
+
+    def __len__(self):
+        return len(self.dataList)
+
+    def __getitem__(self, item):
+        data = process_data(
+            self.dataList[item],
+            self.tokenizer,
+            self.max_len,
+            # self.label[item],
+        )
+
+        return {
+            'ids': torch.tensor(data["ids"], dtype=torch.long),
+            # 'mask': torch.tensor(data["mask"], dtype=torch.long),
+            'brain': data['brain'],
+            'label': torch.tensor(data["label"], dtype=torch.long)  # data['label'],
+        }
+
+
+class EarlyStopping:
+    """
+    Early stopping utility
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self, patience=7, mode="max", delta=0.001, optimizer=None):
+        self.patience = patience
+        self.counter = 0
+        self.mode = mode
+        self.best_score = None
+        self.early_stop = False
+        self.delta = delta
+        self.optimizer = optimizer
+        if self.mode == "min":
+            self.val_score = np.Inf
+        else:
+            self.val_score = -np.Inf
+
+    def __call__(self, epoch_score, model, model_path):
+        if self.mode == "min":
+            score = -1.0 * epoch_score
+            self.delta = -1.0 * self.delta
+        else:
+            score = np.copy(epoch_score)
+        if self.best_score is None:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+        elif score < self.best_score + self.delta:
+            self.counter += 1
+            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))
+            if self.counter >= self.patience:
+                self.early_stop = True
+        else:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+            self.counter = 0
+
+    def save_checkpoint(self, epoch_score, model, model_path):
+        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:
+            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))
+            torch.save(model.state_dict(), model_path)
+            # torch.save({'state_dict': model.state_dict(),
+            #             'optimizer_state_dict': self.optimizer.state_dict()},
+            #            model_path)
+        self.val_score = epoch_score
+
+
+class AverageMeter:
+    """
+    Computes and stores the average and current value
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self):
+        self.reset()
+
+    def reset(self):
+        self.val = 0
+        self.avg = 0
+        self.sum = 0
+        self.count = 0
+
+    def update(self, val, n=1):
+        self.val = val
+        self.sum += val * n
+        self.count += n
+        self.avg = self.sum / self.count
+
+
+def train_fn(data_loader, model, optimizer):
+    model.train()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    # optimizer.zero_grad()
+
+    for bi, d in enumerate(tk0):
+        optimizer.zero_grad()
+        x = d['brain']
+        t = d['label']
+
+        x = standardization(x, 'train')
+        t = standardization(t, 'train')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+
+        # model.zero_grad()
+        # with torch.no_grad():
+        x = torch.autograd.Variable(x).to(_config.DEVICE, dtype=torch.float)
+        t = torch.autograd.Variable(t).to(_config.DEVICE, dtype=torch.float)
+        # x = x.to(_config.DEVICE, dtype=torch.float)
+        # t = t.to(_config.DEVICE, dtype=torch.float)
+        y, z = model(x)
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        # corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        # corr_list.append(corr)
+        # loss.requres_grad = True
+        loss.backward()
+        optimizer.step()
+        tk0.set_postfix(loss=losses.avg)
+
+
+# %%
+def eval_fn(data_loader, model):
+    model.eval()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    x_list = []
+    y_list = []
+    for bi, d in enumerate(tk0):
+        x = d['brain']
+        t = d['label']
+        x = standardization(x, 'valid')
+        t = standardization(t, 'valid')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+        x = x.to(_config.DEVICE, dtype=torch.float)
+        t = t.to(_config.DEVICE, dtype=torch.float)
+        # model.zero_grad()
+        y, z = model(x.float())
+        # loss = criterion(y.float(), x.float())
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        # corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        # corr_list.append(corr)
+        print(loss)
+        loss.backward()
+        tk0.set_postfix(loss=losses.avg)
+        x_list.append(x)
+        y_list.append(y)
+
+        losses.update(loss.item(), d['ids'].size(0))
+        tk0.set_postfix(loss=losses.avg)
+    return losses.avg
+    # return mean_squared_error(x_list, y_list)
+
+
+def run(train, val, fold=None):
+    train_dataset = Dataset(
+        dataList=train
+        # brain=train['brain'],
+        # label='',
+    )
+
+    valid_dataset = Dataset(
+        dataList=val
+        # brain=val['brain'],
+        # label='',
+    )
+
+    train_data_loader = torch.utils.data.DataLoader(
+        train_dataset,
+        batch_size=_config.TRAIN_BATCH_SIZE,
+        num_workers=8,
+        drop_last=True,
+        shuffle=True
+    )
+
+    valid_data_loader = torch.utils.data.DataLoader(
+        valid_dataset,
+        batch_size=_config.VALID_BATCH_SIZE,
+        num_workers=8,
+        drop_last=True,
+        shuffle=True
+    )
+    # with torch.no_grad():
+    model = Autoencoder()
+    # checkpoint_file = os.path.join(_config.SAVE_DIR, 'sentence-camembert-large_1024_vanilla-AE_0.27176549285650253.bin')
+    # checkpoint = torch.load(checkpoint_file)
+    # model.load_state_dict(checkpoint, False)
+    # laplace 0~7
+    model = nn.DataParallel(model, device_ids=[0, 1, 2, 3])  # multi- GPU
+    model = model.module.to(_config.DEVICE)
+
+    # cudnn.benchmark = True
+
+    # model.to(device)
+    # criterion = nn.MSELoss()2
+    param_optimizer = list(model.named_parameters())
+    no_decay = ['bias', 'gamma', 'beta']
+    optimizer_grouped_parameters = [
+        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.01},
+        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.0}
+    ]
+    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)
+    # scheduler = ReduceLROnPlateau(optimizer, 'min')  # set up scheduler
+
+    es = EarlyStopping(patience=10, mode="min", optimizer=optimizer)
+    # es = EarlyStopping(patience=3, mode="max")
+
+    print('Starting training....')
+    losses = []
+    for epoch in range(_config.EPOCHS):
+        print(epoch)
+        train_fn(train_data_loader, model, optimizer)
+        valid_loss = eval_fn(valid_data_loader, model)
+        losses.append(valid_loss)
+        # scheduler.step(valid_loss, epoch)  # update lr if needed
+        print(f'Epoch :{epoch + 1} | Validation Loss :{valid_loss}')
+        if fold is None:
+            es(valid_loss, model, model_path=os.path.join(_config.SAVE_DIR,
+                                                          _config.MODEL + '_' + str(
+                                                              _config.LATENT_SIZE) + '_' + _config._type + '-AE_' + str(
+                                                              valid_loss) + '.bin'))
+        else:
+            es(valid_loss, model, model_path=os.path.join(_config.SAVE_DIR,
+                                                          _config.MODEL + '_' + str(
+                                                              _config.LATENT_SIZE) + f'-AE_{fold}.bin'))
+        if es.early_stop:
+            print('Early stopping')
+            break
+
+    print('Predicting for OOF')
+    print(losses)
+
+
+def dataloader_alice():
+    brain2txt = json.load(open(Proj_dir + f'/src/com/model/brain2txt.json', 'r'))
+    sentence_df = pd.read_csv(Proj_dir + f'/src/com/model/alice_sentence.tsv', sep='\t', header=0)
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/alice/ae_npy/'  # laplace
+    files = os.listdir(brain_path)
+    # i = 0
+    train_data = []
+    val_data = []
+    # min_size = 10000000
+    for file in files:  # 遍历文件夹
+        file_spilt = file.replace('.npy', '').split('_')
+        index = int(file_spilt[2])
+        user = file_spilt[1]
+        brain_data = np.load(brain_path + file)
+        name = 'alice_' + str(user) + '_' + str(index) + '.npz'
+        sentence_id = int(brain2txt[name].split('-')[2])
+        if index < 362 * 0.8:
+            train_data.append({
+                'index': index,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['sentences'][sentence_id]
+            })
+        else:
+            val_data.append({
+                'index': index,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['sentences'][sentence_id]
+            })
+
+        # (372, 199662)
+    # print("min_size:", min_size)
+    return train_data, val_data
+
+
+def dataloader_pereira():
+    train_data = []
+    val_data = []
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/'  # laplace
+    files = os.listdir(brain_path)
+    i = 0
+    for file in files:  # 遍历文件夹
+        # print(file.replace('.npy', '').split('_'))
+        file_spilt = file.replace('.npy', '').split('_')
+        index = int(file_spilt[3])
+        user = file_spilt[1]
+        exp_index = file_spilt[2]
+        brain_data = np.load(brain_path + file)
+        if exp_index == 'exp1':
+            # 180 ->144 train; ->36 val
+
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp1_text.tsv', sep='\t', header=0)
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp1_text.tsv', sep='\t', header=0)
+            group_boundary = 144
+        elif exp_index == 'exp2':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp2_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp2_text.tsv', sep='\t', header=0)
+            # 384 ->308 train; ->76 val
+            group_boundary = 308
+        elif exp_index == 'exp3':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp3_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp3_text.tsv', sep='\t', header=0)
+            # 243 ->195 train; ->48 val
+            group_boundary = 195
+        if index < group_boundary:
+            train_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['text'][index]})
+            i = i + 1
+        else:
+            val_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['text'][index]
+            })
+            i = i + 1
+
+    # print("min_size:", min_size)
+    return train_data, val_data
+
+
+def dataloader_switch(type):
+    if type == 'alice':
+        train_, val_ = dataloader_alice()
+    elif type == 'pereira':
+        train_, val_ = dataloader_pereira()
+    return train_, val_
+
+
+def run_fold(type, fold_idx=None):
+    """
+      Perform k-fold cross-validation
+    """
+    seed_all(seed=_config.SEED)
+    train_, val_ = dataloader_switch(type=type)
+
+    run(train_, val_, fold_idx)
+
+
+def make_print_to_file(path='.'):
+    '''
+    path， it is a path for save your log about fuction print
+    example:
+    use  make_print_to_file()   and the   all the information of funtion print , will be write in to a log file
+    :return:
+    '''
+    import os
+    # import config_file as cfg_file
+    import sys
+    import datetime
+
+    class Logger(object):
+        def __init__(self, filename="Default.log", path="./"):
+            self.terminal = sys.stdout
+            self.log = open(os.path.join(path, filename), "a", encoding='utf8', )
+
+        def write(self, message):
+            self.terminal.write(message)
+            self.log.write(message)
+
+        def flush(self):
+            pass
+
+    fileName = datetime.datetime.now().strftime('day and time:' + '%Y_%m_%d')
+    sys.stdout = Logger(fileName + '.out', path=path)
+
+    #############################################################
+    # print -> log
+    #############################################################
+    print(fileName.center(60, '*'))
+
+
+class config:
+    SEED = random.randint(0, 100)
+    _type = "vanilla"
+    # KFOLD = 5
+    SAVE_DIR = Proj_dir + '/output'  # laplace
+    MAX_LEN = 2048
+    MODEL = sys.argv[2]  # default
+    TOKENIZER = ''  # default
+    LATENT_SIZE = 1024  # default
+
+    EPOCHS = 75
+    TRAIN_BATCH_SIZE = 32
+    VALID_BATCH_SIZE = 32
+    DEVICE = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+
+    @property
+    def type(self):
+        return self._type
+
+
+class Autoencoder(nn.Module):
+    def __init__(self):
+        super(Autoencoder, self).__init__()
+        self.dense_enc1 = nn.Linear(46840, 8192)  # [batch*size]->[batch*size]
+        self.bn1 = nn.BatchNorm1d(8192)
+        self.dense_enc2 = nn.Linear(8192, 4096)
+        self.bn2 = nn.BatchNorm1d(4096)
+        # 3l
+        self.dense_enc3 = nn.Linear(4096, _config.LATENT_SIZE)
+        # self.dense_enc3 = nn.Linear(8192, 1024)
+        # vanilla
+        self.dense_enc4 = nn.Linear(8192, _config.LATENT_SIZE)
+
+        self.dense_dec0 = nn.Linear(_config.LATENT_SIZE, 8192)
+
+        self.dense_dec1 = nn.Linear(_config.LATENT_SIZE, 4096)
+        self.bn4 = nn.BatchNorm1d(4096)
+        self.dense_dec2 = nn.Linear(4096, 8192)
+        self.bn5 = nn.BatchNorm1d(8192)
+        self.drop1 = nn.Dropout(p=0.2)
+        self.dense_dec3 = nn.Linear(8192, 46840)
+
+    def encoder(self, x):
+        x = F.relu(self.dense_enc1(x))
+        x = self.bn1(x)
+        # vanilla
+        x = F.relu(self.dense_enc4(x))
+        # 3 layer
+        # x = F.relu(self.dense_enc2(x))
+        # x = self.bn2(x)
+        # x = F.relu(self.dense_enc3(x))
+        return x
+
+    def decoder(self, x):
+        # 3 layer
+        # x = F.relu(self.dense_dec1(x))
+        # x = self.bn4(x)
+        # x = F.relu(self.dense_dec2(x))
+        # vanilla
+        x = F.relu(self.dense_dec0(x))
+        x = self.bn5(x)
+        x = self.drop1(x)
+        x = F.relu(self.dense_dec3(x))
+        return x
+
+    def forward(self, x):
+        z = self.encoder(x)
+        x = self.decoder(z)
+        return x, z
+
+_config = config()
+
+if __name__ == "__main__":
+    torch.multiprocessing.set_start_method('spawn')
+    start = time.perf_counter()
+    make_print_to_file('.')
+
+    # print(sys.argv)
+    # SimCSE_bert_large_unsup
+    criterion_l2 = nn.MSELoss().to(_config.DEVICE)
+    criterion_l1 = nn.L1Loss().to(_config.DEVICE)
+
+    _config.MODEL = sys.argv[2]  # TODO shell
+    if _config.MODEL == 'bert-large-uncased':
+        _config.TOKENIZER = transformers.AutoTokenizer.from_pretrained(_config.MODEL)
+        _config.LATENT_SIZE = 1024
+    elif _config.MODEL == 'sentence-camembert-large':
+        _config.TOKENIZER = SentenceTransformer("dangvantuan/sentence-camembert-large")
+        _config.LATENT_SIZE = 1024
+    elif _config.MODEL == 'SimCSE_large':
+        _config.TOKENIZER = SimCSE("princeton-nlp/sup-simcse-bert-large-uncased")
+        _config.LATENT_SIZE = 1024
+    elif _config.MODEL == 'SimCSE':
+        _config.TOKENIZER = SimCSE("princeton-nlp/sup-simcse-bert-base-uncased")
+        _config.LATENT_SIZE = 768
+    elif _config.MODEL == 'SimCSE_roberta_large':
+        _config.TOKENIZER = SimCSE("princeton-nlp/unsup-simcse-roberta-large")
+        _config.LATENT_SIZE = 1024
+    elif _config.MODEL == 'SimCSE_bert_large_unsup':
+        _config.TOKENIZER = SimCSE("princeton-nlp/unsup-simcse-bert-large-uncased")
+        _config.LATENT_SIZE = 1024
+
+    elif _config.MODEL == 'SimCSE_roberta_large_sup':
+        _config.TOKENIZER = SimCSE("princeton-nlp/sup-simcse-roberta-large")
+        _config.LATENT_SIZE = 1024
+    elif _config.MODEL in ['albert-xlarge-v1', 'albert-xlarge-v2']:
+
+        _config.TOKENIZER = AlbertTokenizer.from_pretrained(_config.MODEL)
+        _config.LATENT_SIZE = 2048
+
+    run_fold(type='pereira', fold_idx=None)
+
+    print(corr_list)
+    end = time.perf_counter()
+    time_cost = str((end - start) / 60)
+    print("time-cost:", time_cost)
Index: src/com/model/run_auto_encoder_prince.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/run_auto_encoder_prince.py b/src/com/model/run_auto_encoder_prince.py
new file mode 100644
--- /dev/null	(date 1695461615000)
+++ b/src/com/model/run_auto_encoder_prince.py	(date 1695461615000)
@@ -0,0 +1,573 @@
+import os
+
+os.environ["CUDA_VISIBLE_DEVICES"] = "2,3,4,5,6"  # GPU
+
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "."))  # TODO script
+# Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "../../../"))  # TODO debug
+# print(Proj_dir)
+import sys
+
+# cherry 的 GPU跑不动 死心吧
+sys.path.append(Proj_dir)
+import random
+# from tqdm import
+import h5py
+import json
+import time
+import torch
+from torch import nn
+import torch.nn.functional as F
+import numpy as np
+from src.com.util.data_format import normalization, standardization
+from tqdm import tqdm, trange
+from transformers import BertModel, BertTokenizer
+
+MODEL = 'bert-large-uncased'
+TOKENIZER = BertTokenizer.from_pretrained(MODEL)  # default
+text_model = BertModel.from_pretrained(MODEL, output_hidden_states=True)
+# 必须使用laplace多服务器
+lr = 1e-5
+
+corr_list = []
+
+
+def get_albert_embedding_tensor(sentence, tokenizer, model):
+    encoded_input = tokenizer(sentence, return_tensors='pt')
+    output = model(**encoded_input)
+    return output[-1].detach().squeeze(0)
+
+
+class config:
+    SEED = random.randint(0, 100)
+    # print("seed:", SEED)
+    _type = "vanilla"
+    # KFOLD = 5
+    SAVE_DIR = '/Storage2/ying/project/brainAE/output/'  # laplace
+    MAX_LEN = 2048
+
+    # default
+
+    LATENT_SIZE = 1024  # default
+
+    EPOCHS = 75
+    TRAIN_BATCH_SIZE = 32
+    VALID_BATCH_SIZE = 32
+    DEVICE = torch.device("cuda" if (torch.cuda.is_available()) else "cpu")
+
+    # print(DEVICE)
+
+    # num_gpus = torch.cuda.device_count()
+    # print("Number of available GPUs:", num_gpus)
+
+    @property
+    def type(self):
+        return self._type
+
+
+class Autoencoder(nn.Module):
+    def __init__(self):
+        super(Autoencoder, self).__init__()
+        self.dense_enc1 = nn.Linear(46840, 8192)  # TODO [batch*size]->[batch*size]
+        self.bn1 = nn.BatchNorm1d(8192)
+        self.dense_enc2 = nn.Linear(8192, 4096)
+        self.bn2 = nn.BatchNorm1d(4096)
+        # 3l
+        self.dense_enc3 = nn.Linear(4096, _config.LATENT_SIZE)
+        # self.dense_enc3 = nn.Linear(8192, 1024)
+        # vanilla
+        self.dense_enc4 = nn.Linear(8192, _config.LATENT_SIZE)
+
+        self.dense_dec0 = nn.Linear(_config.LATENT_SIZE, 8192)
+
+        self.dense_dec1 = nn.Linear(_config.LATENT_SIZE, 4096)
+        self.bn4 = nn.BatchNorm1d(4096)
+        self.dense_dec2 = nn.Linear(4096, 8192)
+        self.bn5 = nn.BatchNorm1d(8192)
+        self.drop1 = nn.Dropout(p=0.2)
+        self.dense_dec3 = nn.Linear(8192, 46840)
+
+    def encoder(self, x):
+        x = F.relu(self.dense_enc1(x))
+        x = self.bn1(x)
+        # vanilla
+        x = F.relu(self.dense_enc4(x))
+        # 3 layer
+        # x = F.relu(self.dense_enc2(x))
+        # x = self.bn2(x)
+        # x = F.relu(self.dense_enc3(x))
+        return x
+
+    def decoder(self, x):
+        # 3 layer
+        # x = F.relu(self.dense_dec1(x))
+        # x = self.bn4(x)
+        # x = F.relu(self.dense_dec2(x))
+        # vanilla
+        x = F.relu(self.dense_dec0(x))
+        x = self.bn5(x)
+        x = self.drop1(x)
+        x = F.relu(self.dense_dec3(x))
+        return x
+
+    def forward(self, x):
+        z = self.encoder(x)
+        x = self.decoder(z)
+        return x, z
+
+
+def seed_all(seed=42):
+    """
+  Fix seed for reproducibility
+  """
+    # python RNG
+    import random
+    random.seed(seed)
+
+    # pytorch RNGs
+    torch.manual_seed(seed)
+    # torch.backends.cudnn.deterministic = True
+    if torch.cuda.is_available():
+        torch.cuda.manual_seed_all(seed)
+    np.random.seed(seed)
+
+
+# def is_string(input):
+#     return isinstance(input, str)
+
+# 判断输入参数是否是字符串数组
+def is_string_array(input):
+    return isinstance(input, list) and all(isinstance(item, str) for item in input)
+
+
+def preprocess(text):
+    if is_string_array(text):
+        process_list = []
+        for i in trange(len(text)):
+            _text = ' '.join(text[i].split())
+            _text = _text.lower()
+            _text = _text.strip()
+            process_list.append(_text)
+        return process_list
+    else:
+        _text = ' '.join(text.split())
+        _text = _text.lower()
+        _text = _text.strip()
+        return text
+        # process_list.append(_text)
+    # text = html.unescape(text)
+    # text = text.translate(transl_table)
+    # text = text.replace('…', '...')
+    # text = re.sub(control_char_regex, ' ', text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')
+
+    # text = text.replace('HTTPURL', 'URL')
+    # text = emoji.demojize(text)
+
+    # text = unidecode.unidecode(text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'So')
+
+
+def process_data(data, _is_eval=False):
+    # text = preprocess(data['label'])
+    # embeding = get_sentence_embedding(sentence=text, option="last_layer")
+    if _is_eval:
+        return {
+            'ids': data['index'],
+            'brain': data['brain'],
+
+        }
+    else:
+        return {
+            'ids': data['index'],
+            'brain': data['brain'],
+            'label': data['elabel']
+        }
+
+
+class Dataset:
+    def __init__(self, dataList, _is_eval):
+        self.dataList = dataList
+        self._is_eval = _is_eval
+        # self.tokenizer = _config.TOKENIZER
+        self.max_len = _config.MAX_LEN
+
+    def __len__(self):
+        return len(self.dataList)
+
+    def __getitem__(self, item):
+        data = process_data(
+            self.dataList[item],
+            self._is_eval
+            # self.tokenizer,
+            # self.max_len,
+            # self.label[item],
+        )
+        if self._is_eval:
+            return {
+                'ids': torch.tensor(data["ids"], dtype=torch.long),
+                'brain': data['brain']
+            }
+        else:
+            return {
+                'ids': torch.tensor(data["ids"], dtype=torch.long),
+                # 'mask': torch.tensor(data["mask"], dtype=torch.long),
+                'brain': data['brain'],
+                'label': torch.tensor(data["label"], dtype=torch.float),  # data['label'],
+                # 'elabel': torch.tensor(data["elabel"], dtype=torch.long)  # data['label'],
+            }
+
+
+
+
+
+class EarlyStopping:
+    """
+    Early stopping utility
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self, patience=7, mode="max", delta=0.001, optimizer=None):
+        self.patience = patience
+        self.counter = 0
+        self.mode = mode
+        self.best_score = None
+        self.early_stop = False
+        self.delta = delta
+        self.optimizer = optimizer
+        if self.mode == "min":
+            self.val_score = np.Inf
+        else:
+            self.val_score = -np.Inf
+
+    def __call__(self, epoch_score, model, model_path):
+        if self.mode == "min":
+            score = -1.0 * epoch_score
+            self.delta = -1.0 * self.delta
+        else:
+            score = np.copy(epoch_score)
+        if self.best_score is None:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+        elif score < self.best_score + self.delta:
+            self.counter += 1
+            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))
+            if self.counter >= self.patience:
+                self.early_stop = True
+        else:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+            self.counter = 0
+
+    def save_checkpoint(self, epoch_score, model, model_path):
+        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:
+            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))
+            torch.save(model.state_dict(), model_path)
+            # torch.save({'state_dict': model.state_dict(),
+            #             'optimizer_state_dict': self.optimizer.state_dict()},
+            #            model_path)
+        self.val_score = epoch_score
+
+
+class AverageMeter:
+    """
+    Computes and stores the average and current value
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self):
+        self.reset()
+
+    def reset(self):
+        self.val = 0
+        self.avg = 0
+        self.sum = 0
+        self.count = 0
+
+    def update(self, val, n=1):
+        self.val = val
+        self.sum += val * n
+        self.count += n
+        self.avg = self.sum / self.count
+
+
+def train_fn(data_loader, model, optimizer):
+    model.train()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    # optimizer.zero_grad()
+
+    for bi, d in enumerate(tk0):
+        optimizer.zero_grad()
+        x = d['brain']
+        t = d['label']
+
+        x = standardization(x, 'train')
+        t = standardization(t, 'train')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+
+        # model.zero_grad()
+        # with torch.no_grad():
+        x = torch.autograd.Variable(x).to(_config.DEVICE, dtype=torch.float)
+        t = torch.autograd.Variable(t).to(_config.DEVICE, dtype=torch.float)
+        # x = x.to(_config.DEVICE, dtype=torch.float)
+        # t = t.to(_config.DEVICE, dtype=torch.float)
+        y, z = model(x)
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        # corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        # corr_list.append(corr)
+        # loss.requres_grad = True
+        loss.backward()
+        optimizer.step()
+        tk0.set_postfix(loss=losses.avg)
+
+
+# %%
+def eval_fn(data_loader, model):
+    model.eval()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    x_list = []
+    y_list = []
+    for bi, d in enumerate(tk0):
+        x = d['brain']
+        t = d['label']
+        x = standardization(x, 'valid')
+        t = standardization(t, 'valid')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+        x = x.to(_config.DEVICE, dtype=torch.float)
+        t = t.to(_config.DEVICE, dtype=torch.float)
+        # model.zero_grad()
+        y, z = model(x.float())
+        # loss = criterion(y.float(), x.float())
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        # corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        # corr_list.append(corr)
+        print(loss)
+        loss.backward()
+        tk0.set_postfix(loss=losses.avg)
+        x_list.append(x)
+        y_list.append(y)
+
+        losses.update(loss.item(), d['ids'].size(0))
+        tk0.set_postfix(loss=losses.avg)
+    return losses.avg
+    # return mean_squared_error(x_list, y_list)
+
+
+def run(train, val, fold=None):
+    train_dataset = Dataset(
+        dataList=train,
+        _is_eval=False
+        # brain=train['brain'],
+        # label='',
+    )
+
+    valid_dataset = Dataset(
+        dataList=val,
+        _is_eval=False
+        # brain=val['brain'],
+        # label='',
+    )
+
+    train_data_loader = torch.utils.data.DataLoader(
+        train_dataset,
+        batch_size=_config.TRAIN_BATCH_SIZE,
+        num_workers=5,
+        drop_last=True,
+        shuffle=True, pin_memory=True
+    )
+
+    valid_data_loader = torch.utils.data.DataLoader(
+        valid_dataset,
+        batch_size=_config.VALID_BATCH_SIZE,
+        num_workers=5,
+        drop_last=True,
+        shuffle=True, pin_memory=True
+    )
+    # with torch.no_grad():
+    model = Autoencoder()
+    # checkpoint_file = os.path.join(_config.SAVE_DIR, 'model_sentenceBERT_' + _config._type + '.bin')
+    # checkpoint = torch.load(checkpoint_file)
+    # model.load_state_dict(checkpoint,False)
+    # laplace 0~7
+    model = nn.DataParallel(model, device_ids=[0, 1, 2, 3, 4])  # multi- GPU
+    model = model.module.to(_config.DEVICE)
+
+    # cudnn.benchmark = True
+
+    # model.to(device)
+    # criterion = nn.MSELoss()2
+    param_optimizer = list(model.named_parameters())
+    no_decay = ['bias', 'gamma', 'beta']
+    optimizer_grouped_parameters = [
+        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.01},
+        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.0}
+    ]
+    from transformers import AdamW
+    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)
+
+    es = EarlyStopping(patience=10, mode="min", optimizer=optimizer)
+
+    print('Starting training....')
+    losses = []
+    for epoch in trange(_config.EPOCHS):
+        print(epoch)
+        train_fn(train_data_loader, model, optimizer)
+        valid_loss = eval_fn(valid_data_loader, model)
+        losses.append(valid_loss)
+        # scheduler.step(valid_loss, epoch)  # update lr if needed
+        print(f'Epoch :{epoch + 1} | Validation Loss :{valid_loss}')
+        if fold is None:
+            es(valid_loss, model, model_path=os.path.join(_config.SAVE_DIR,
+                                                          _config.MODEL + '_' + str(
+                                                              _config.LATENT_SIZE) + '_' + _config._type + '-p-AE_' + str(
+                                                              valid_loss) + '.bin'))
+        else:
+            es(valid_loss, model, model_path=os.path.join(_config.SAVE_DIR,
+                                                          _config.MODEL + '_' + str(
+                                                              _config.LATENT_SIZE) + f'-p-AE_{fold}.bin'))
+        if es.early_stop:
+            print('Early stopping')
+            break
+
+    print('Predicting for OOF')
+    print(losses)
+
+
+def dataloader_prince():
+    prince_proj_path = "/home/ying/project/littlePrinceDatasetProj/"  # laplace  home local
+
+    sentence_df = json.load(open(prince_proj_path + f'resources/section_word_segment_dict_id.json', 'r'))
+    brain_path = prince_proj_path + 'resources/preprocessed/AE/'  #
+    files = os.listdir(brain_path)
+    # i = 0
+    train_data = []
+    val_data = []
+    for file in files:  # 遍历文件夹
+        subj = 'sub-' + file.split('_')[1]
+        # print(file)
+        if subj in ['sub-EN058', 'sub-EN062', 'sub-EN063', 'sub-EN064', 'sub-EN068', 'sub-EN075', 'sub-EN076',
+                    'sub-EN077', 'sub-EN086', 'sub-EN087', 'sub-EN067', 'sub-EN069', 'sub-EN072', 'sub-EN073',
+                    'sub-EN074', 'sub-EN078', 'sub-EN079', 'sub-EN081', 'sub-EN083', 'sub-EN084']:
+            with h5py.File(brain_path + file, "r") as file:
+                dataset = file["brain"]
+                brain_data = dataset[:46840]
+                data_size = dataset.shape[1]
+                s_list = sentence_df[str(data_size)]
+                s_list = preprocess(s_list)
+                # s_embedding = get_sentence_embedding(s_list, "last_layer").tolist()
+                # 要嵌入的字符串数组
+                # 标记化和编码字符串数组
+                inputs = TOKENIZER(s_list, padding=True, truncation=True, return_tensors="pt")
+                # 获取嵌入向量
+                with torch.no_grad():
+                    outputs = text_model(**inputs)
+                    s_embedding = outputs.last_hidden_state[:, -1, :]
+                # print(data_size)
+                for i in trange(data_size):
+                    if i < int(data_size * 0.8):
+                        train_data.append({
+                            'index': i,
+                            'participant': subj,
+                            'brain': brain_data[:, i],
+                            'label': sentence_df[str(data_size)][i],
+                            'elabel': s_embedding[i, :].tolist()
+                        })
+                    else:
+                        val_data.append({
+                            'index': i,
+                            'participant': subj,
+                            'brain': brain_data[:, i],
+                            'label': sentence_df[str(data_size)][i],
+                            'elabel': s_embedding[i, :].tolist()
+                        })
+        # break # TODO debug model
+
+    return train_data, val_data
+
+
+def dataloader_switch(type):
+    if type == 'prince':
+        train_, val_ = dataloader_prince()
+    # elif type == 'pereira':
+    #     train_, val_ = dataloader_pereira()
+    return train_, val_
+
+
+def run_fold(type, fold_idx=None):
+    """
+      Perform k-fold cross-validation
+    """
+    seed_all(seed=_config.SEED)
+    print("data loading")
+
+    train_, val_ = dataloader_switch(type=type)
+    print("data loaded")
+    print("model training")
+
+    run(train_, val_, fold_idx)
+    print("modeling finished")
+
+
+def make_print_to_file(path='.'):
+    '''
+    path， it is a path for save your log about fuction print
+    example:
+    use  make_print_to_file()   and the   all the information of funtion print , will be write in to a log file
+    :return:
+    '''
+    import os
+    # import config_file as cfg_file
+    import sys
+    import datetime
+
+    class Logger(object):
+        def __init__(self, filename="Default.log", path="./"):
+            self.terminal = sys.stdout
+            self.log = open(os.path.join(path, filename), "a", encoding='utf8', )
+
+        def write(self, message):
+            self.terminal.write(message)
+            self.log.write(message)
+
+        def flush(self):
+            pass
+
+    fileName = datetime.datetime.now().strftime('day and time:' + '%Y_%m_%d')
+    sys.stdout = Logger(fileName + '.log', path=path)
+
+    #############################################################
+    # print -> log
+    #############################################################
+    print(fileName.center(60, '*'))
+
+
+_config = config()
+if __name__ == "__main__":
+    # 检查GPU是否可用
+    print("GPU available:", torch.cuda.is_available())
+
+    # 检查Transformers库是否使用了GPU
+    # print("Transformers using GPU:", torch.backends.cudnn.enabled)
+
+    torch.multiprocessing.set_start_method('spawn')
+    start = time.perf_counter()
+    make_print_to_file('.')
+
+    criterion_l2 = nn.MSELoss().to(_config.DEVICE)
+    criterion_l1 = nn.L1Loss().to(_config.DEVICE)
+    _config.MODEL = 'bert-large-uncased'  # local running
+
+    run_fold(type='prince', fold_idx=None)
+    # print(corr_list)
+    end = time.perf_counter()
+    time_cost = str((end - start) / 60)
+    print("time-cost:", time_cost)
Index: alice_feature_extraction.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/alice_feature_extraction.py b/alice_feature_extraction.py
new file mode 100644
--- /dev/null	(date 1695532734000)
+++ b/alice_feature_extraction.py	(date 1695532734000)
@@ -0,0 +1,255 @@
+# prince dataset extraction
+import os
+
+os.environ["CUDA_VISIBLE_DEVICES"] = "2,3,4,5,6"  # GPU
+
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "../../../"))
+import sys
+import time
+import h5py
+
+sys.path.append(Proj_dir)
+# print(sys.path)
+# import json
+import torch
+from tqdm import tqdm, trange
+
+print(torch.__version__)
+print(torch.version.cuda)
+print(torch.cuda.is_available())
+import scipy.io as scio
+import numpy as np
+from tqdm import tqdm
+from src.com.util.data_format import make_print_to_file
+from src.com.util.data_format import normalization
+from transformers import BertModel, BertTokenizer
+from src.com.model.run_auto_encoder_prince import Autoencoder, config, Dataset
+# import pandas as pd
+
+_config = config()
+tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')
+bert_model = BertModel.from_pretrained('bert-large-uncased', output_hidden_states=True)
+PROJ_DIR = os.path.abspath(os.path.join(os.getcwd(), "."))
+# 这里调整模型
+# 768
+# participants = {'18', '22', '23', '24', '26', '28', '30', '31', '35', '36', '37',
+#                 '39', '41', '42', '43', '44', '45', '47', '48', '49', '50', '51', '53'}
+AE_participants = ['sub-EN058', 'sub-EN062', 'sub-EN063', 'sub-EN064', 'sub-EN068', 'sub-EN075', 'sub-EN076',
+                   'sub-EN077', 'sub-EN086', 'sub-EN087', 'sub-EN067', 'sub-EN069', 'sub-EN072', 'sub-EN073',
+                   'sub-EN074', 'sub-EN078', 'sub-EN079', 'sub-EN081', 'sub-EN083', 'sub-EN084']
+participants = [
+    'sub_EN057', 'sub_EN058', 'sub_EN059', 'sub_EN061', 'sub_EN062',
+    'sub_EN063', 'sub_EN064',
+    'sub_EN065', 'sub_EN067', 'sub_EN068', 'sub_EN069', 'sub_EN070', 'sub_EN072', 'sub_EN073', 'sub_EN074', 'sub_EN075',
+    'sub_EN076', 'sub_EN077', 'sub_EN078', 'sub_EN079', 'sub_EN081', 'sub_EN082', 'sub_EN083', 'sub_EN084', 'sub_EN086',
+    'sub_EN087', 'sub_EN088', 'sub_EN089', 'sub_EN091', 'sub_EN092', 'sub_EN094', 'sub_EN095', 'sub_EN096', 'sub_EN097',
+    'sub_EN098', 'sub_EN099', 'sub_EN100', 'sub_EN101', 'sub_EN103', 'sub_EN104', 'sub_EN105', 'sub_EN106', 'sub_EN108',
+    'sub_EN109', 'sub_EN110', 'sub_EN113', 'sub_EN114', 'sub_EN115']
+
+
+def get_sentence_embedding(sentence, option, z_size):
+    bert_version = 'bert-base-uncased'
+    if z_size == 1024:
+        bert_version = 'bert-large-uncased'
+    # elif z_size == 768:
+    tokenizer = BertTokenizer.from_pretrained(bert_version)
+    bert_model = BertModel.from_pretrained(bert_version, output_hidden_states=True)
+    # if YOU NEED [cls] and [seq] PRESENTATION：True
+    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)  # Batch size 1
+    outputs = bert_model(input_ids)
+
+    all_layers_output = outputs[2]
+    # list of torch.FloatTensor (one for the output of each layer + the output of the embeddings) of shape (batch_size, sequence_length, hidden_size): Hidden-states of the model at the output of each layer plus the initial embedding outputs.
+
+    if option == "last_layer":
+        sent_embeddings = all_layers_output[-1]  # last layer
+    elif option == "second_to_last_layer":
+        sent_embeddings = all_layers_output[-2]  # second to last layer
+    else:
+        sent_embeddings = all_layers_output[-1]  # last layer
+
+    sent_embeddings = torch.squeeze(sent_embeddings, dim=0)
+
+    # Calculate the average of all token vectors.
+    sentence_embedding_avg = torch.mean(sent_embeddings, dim=0)
+
+    return sent_embeddings.detach(), sentence_embedding_avg.detach()
+
+
+# %%
+def eval(data_loader, model):
+    model.eval()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    z_list = []
+    for bi, d in enumerate(tk0):
+        x = d['brain']
+        # x = standardization(x, 'valid')
+        x, _, _ = normalization(x)
+        x = torch.Tensor(x).float()
+        x = x.to(_config.DEVICE, dtype=torch.float)
+        y, z = model(x.float())
+        z_list.append(z.T.tolist())
+    return np.concatenate(z_list, axis=1)
+
+
+def load_brain_data(dataset, _type, user):  # user "sub_EN070"
+    a = []
+    if dataset == 'pereira':
+        paticipants_1 = ['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07',
+                         'M08', 'M09', 'M10', 'M13', 'M14', 'M15', 'M16', 'M17', 'P01']
+        paticipants_2 = ['M02', 'M04', 'M07', 'M08', 'M09', 'M14', 'M15', 'P01']
+        paticipants_3 = ['M02', 'M03', 'M04', 'M07', 'M15', 'P01']
+        # dataset_path = "/Storage/ying/resources/pereira2018/'+user+'/data_180concepts_wordclouds.mat"
+        if user in paticipants_1:
+            exp1_path = '/Storage/ying/resources/pereira2018/' + user + '/data_180concepts_wordclouds.mat'
+            exp1_data = scio.loadmat(exp1_path)
+            examples = exp1_data['examples']
+
+            ROI_path = '../../../resource/' + user + '_roi.mat'
+            data = scio.loadmat(ROI_path)
+            roi = data['index']
+
+            for i in range((examples.shape[0])):
+                b = []
+                for index in roi[0]:
+                    b.append(examples[i][index])
+                a.append(b[:46840])
+            if user in paticipants_2:
+                exp2_path = '/Storage/ying/resources/pereira2018/' + user + '/data_384sentences.mat'
+                exp2_data = scio.loadmat(exp2_path)
+                examples = exp2_data['examples_passagesentences']
+                # b = []
+                for i in range((examples.shape[0])):
+
+                    b = []
+                    for index in roi[0]:
+                        b.append(examples[i][index])
+
+                    a.append(b[:46840])
+            if user in paticipants_3:
+                exp3_path = '/Storage/ying/resources/pereira2018/' + user + '/data_243sentences.mat'
+                exp3_data = scio.loadmat(exp3_path)
+                examples = exp3_data['examples_passagesentences']
+                for i in range((examples.shape[0])):
+
+                    b = []
+                    for index in roi[0]:
+                        b.append(examples[i][index])
+                    a.append(b[:46840])
+    elif dataset == 'alice_ae' or dataset == 'alice':
+
+        brain_path = '/Storage/ying/resources/BrainBertTorch/brain/' + dataset + '/ae_npy/'
+        files = sorted(os.listdir(brain_path))
+        for file in files:  # 遍历文件夹
+            file_spilt = file.replace('.npy', '').split('_')
+            sub = file_spilt[1]
+            if sub == user:
+                brain_data = np.load(brain_path + file)
+                a.append(brain_data[:46840])
+    else:  # prince
+        prince_proj_path = "/Storage2/ying/project/littlePrinceDatasetProj/"  # laplace  home local
+
+        # sentence_df = json.load(open(prince_proj_path + f'resources/section_word_segment_dict_id.json', 'r'))
+        brain_path = prince_proj_path + 'resources/preprocessed/downstreamTask/'  #
+        files = sorted(os.listdir(brain_path))
+        # i = 0
+        a = []
+        for file in files:  # 遍历文件夹
+            subj = 'sub-' + file.split('_')[1]
+            if subj == user.replace('_', '-'):
+                with h5py.File(brain_path + file, "r") as file:
+                    dataset = file["brain"]
+                    brain_data = dataset[:46840]
+                    data_size = dataset.shape[1]
+
+                    for i in trange(data_size):
+                        a.append({
+                            'index': i,
+                            'participant': subj,
+                            'brain': brain_data[:, i],
+                            #
+                        })
+            #
+
+            # break # TODO debug model
+    return a
+
+
+def create_brain_npz(_type, dataset):
+    # print(_type)
+    if _type == 'bert-large-uncased':
+        model_file = '/Storage2/ying/project/brainAE/benchmark/prince_1024_AE_0.04.bin'
+        config.LATENT_SIZE = 1024
+    elif _type == 'sentence-camembert-large':
+        model_file = '/Storage/ying/project/brainAE/output/sentence-camembert-large_768_0.083.bin'
+        config.LATENT_SIZE = 1024
+    elif _type == 'SimCSE':
+        model_file = '/Storage/ying/project/brainAE/output/SimCSE_768_0.076.bin'
+        config.LATENT_SIZE = 768
+    elif _type == 'SimCSE_bert_large_unsup':
+        model_file = '/Storage/ying/project/brainAE/output/SimCSE_bert_large_unsup_1024_0.10.bin'
+        config.LATENT_SIZE = 1024
+    elif _type == 'SimCSE_large':
+        model_file = '/Storage/ying/project/brainAE/output/SimCSE_large_1024_0.09.bin'
+        config.LATENT_SIZE = 1024
+    elif _type == 'SimCSE_roberta_large':
+        model_file = '/Storage/ying/project/brainAE/output/SimCSE_roberta_large_1024_0.072.bin'
+        config.LATENT_SIZE = 1024
+    elif _type == 'SimCSE_roberta_large_sup':
+        model_file = '/Storage/ying/project/brainAE/output/SimCSE_roberta_large_sup_1024_0.078.bin'
+        config.LATENT_SIZE = 1024
+    # model_file = '/Storage/ying/project/brainAE/output/model_1e-05.bin'
+    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+    pre_trained_model = Autoencoder()
+    pre_trained_model.load_state_dict(
+        {k.replace('module.', ''): v for k, v in torch.load(os.path.join(model_file)).items()})
+    pre_trained_model.to(device)
+
+    norm_path = '/Storage2/ying/project/brainLMProj/dataset/' + dataset + '/' + _type + '/norm/'
+    feature_path = '/Storage2/ying/project/brainLMProj/dataset/' + dataset + '/' + _type + '/features/'
+    feature_data = {}
+    norm_data = {}
+    for user in tqdm(sorted(participants)):
+        if user.replace('_', '-') not in AE_participants:
+            print(user)
+            brain_data = load_brain_data(dataset, _type, user)
+            valid_dataset = Dataset(
+                dataList=brain_data,
+                _is_eval=True
+
+            )
+            valid_data_loader = torch.utils.data.DataLoader(
+                valid_dataset,
+                batch_size=32,
+                num_workers=5,
+                drop_last=True,
+                shuffle=True, pin_memory=True
+            )
+            z = eval(valid_data_loader, pre_trained_model)
+
+            z = z.transpose()  # 2816 1024
+            # feature_shape = z[0]
+            for index in trange(len(z)):
+                npz_filename = dataset + '_' + user + '_' + str(index) + '.npz'
+                norm_data['norm'] = {'data': z[index].tolist(),
+                                     'shape': [1024],
+                                     'type': None,
+                                     'kind': None}
+                feature_data['features'] = {'data': z[index].tolist(),
+                                            'shape': [1024],
+                                            'type': None,
+                                            'kind': None}
+                np.savez(feature_path + npz_filename, features=feature_data['features'])
+                np.savez(norm_path + npz_filename, features=norm_data['norm'])
+            print(user, "finished")
+
+
+if __name__ == "__main__":
+    start = time.perf_counter()
+    make_print_to_file('.')
+    # _type = ''
+    create_brain_npz(_type='bert-large-uncased', dataset='prince')
+
+    end = time.perf_counter()
+    time_cost = str((end - start) / 60)
+    print("time-cost:", time_cost)
Index: train_ae_nohup.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/train_ae_nohup.sh b/train_ae_nohup.sh
new file mode 100644
--- /dev/null	(date 1695105346000)
+++ b/train_ae_nohup.sh	(date 1695105346000)
@@ -0,0 +1,8 @@
+#!/bin/bash
+cur_date="$(date "+%Y-%m-%d-%H:%M:%S")"
+
+str=$"\n"
+nohup /usr/bin/python3 -u src/com/model/run_auto_encoder_prince.py \
+>>"train_prince_ae_${cur_date}".out 2>&1 &
+sstr=$(echo -e $str)
+echo $sstr
\ No newline at end of file
Index: pereira_corr_user.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pereira_corr_user.json b/pereira_corr_user.json
new file mode 100644
--- /dev/null	(date 1615275370000)
+++ b/pereira_corr_user.json	(date 1615275370000)
@@ -0,0 +1,7444 @@
+{
+  "M17": [
+    0.24944727990182272,
+    0.3840158055593228,
+    0.29072542923904793,
+    0.19943033740240287,
+    0.4184206531001369,
+    0.27423324809962674,
+    0.3944085384335331,
+    0.2798419391696119,
+    0.3068833662745092,
+    0.3111732695320577,
+    0.26134640357594957,
+    0.3331644214517081,
+    0.3175807643622356,
+    0.3401290142831152,
+    0.29918330294358997,
+    0.33439660787772124,
+    0.5557549295087428,
+    0.2780206853092402,
+    0.48395379807818956,
+    0.3326350798798185,
+    0.2302248620255942,
+    0.35722879417153014,
+    0.22054885040569147,
+    0.3567448318666549,
+    0.30223000069784933,
+    0.4485637638922808,
+    0.1481771493212575,
+    0.21429788826481083,
+    0.47758426739889304,
+    0.30211305493479684,
+    0.36361004598550684,
+    0.3696364176286909,
+    0.2517831445319903,
+    0.1973805111214017,
+    0.3412538993228185,
+    0.46996199435476105,
+    0.2621418767683127,
+    0.41965616141327317,
+    0.3405089034508947,
+    0.3964396189790363,
+    0.4207468415039142,
+    0.454281738706861,
+    0.6761739932088262,
+    0.34063573844533535,
+    0.2850990923632082,
+    0.3815279838270045,
+    0.22491789491764327,
+    0.21316377343767412,
+    0.2691790202751049,
+    0.29878602871546134,
+    0.26405644434604464,
+    0.36517005291276716,
+    0.2436846183850611,
+    0.262148375557246,
+    0.3415055892087942,
+    0.4194117336766842,
+    0.25907871560705464,
+    0.345894735310825,
+    0.4586742012128329,
+    0.3699306482997623,
+    0.2929573957096777,
+    0.29595695071094996,
+    0.25243166302270725,
+    0.3177097687964698,
+    0.29433917818573485,
+    0.2048087287427308,
+    0.3441544096214622,
+    0.28340177736073274,
+    0.195433972201761,
+    0.5573352528612076,
+    0.32276393848713947,
+    0.29759208312590446,
+    0.3883050295149854,
+    0.31083536879466356,
+    0.42020650815010635,
+    0.4676703269824257,
+    0.4361516538466915,
+    0.28341089538465997,
+    0.2885428440846427,
+    0.27813993355488054,
+    0.30729460495135585,
+    0.29446535476382446,
+    0.2975504566193643,
+    0.3083722847542599,
+    0.25731033690566846,
+    0.43733799055030376,
+    0.31950752796044257,
+    0.13595342218057535,
+    0.35645389647290926,
+    0.28210404019353713,
+    0.30756970300542646,
+    0.5189990290844708,
+    0.37499166863798744,
+    0.33433342729282994,
+    0.31371829237990695,
+    0.32008784396961304,
+    0.3960690619206419,
+    0.3833445665191322,
+    0.2959090887497597,
+    0.4109408111606502,
+    0.35844920777050815,
+    0.3272324872656865,
+    0.24398352617582106,
+    0.2742627750449467,
+    0.4270789562437032,
+    0.35618823959211293,
+    0.3756155834255873,
+    0.28087094724985995,
+    0.1928753942277218,
+    0.4165735553458573,
+    0.2822761786364875,
+    0.43302300856883363,
+    0.22070327628477934,
+    0.3726049541973752,
+    0.1692530007146098,
+    0.383778248702326,
+    0.296724321022121,
+    0.3734433151960217,
+    0.18117460992165987,
+    0.381659376588853,
+    0.39305682459143987,
+    0.3545419908331869,
+    0.5136081083567812,
+    0.2975820897812276,
+    0.33872647280238977,
+    0.3303650792505354,
+    0.32054487408836857,
+    0.2775032454798178,
+    0.3047124295252864,
+    0.24129276368969052,
+    0.4458773087880101,
+    0.20180089525334596,
+    0.39353793044197877,
+    0.34773534774204473,
+    0.3360452799541122,
+    0.47685027907873917,
+    0.38252417496041585,
+    0.4688923140549807,
+    0.5033048402070308,
+    0.3438982316676296,
+    0.29298144093739964,
+    0.40898386020130356,
+    0.18910996488019932,
+    0.36947755617746897,
+    0.23775082126187697,
+    0.22521906624571258,
+    0.4763376174969928,
+    0.2894692760803135,
+    0.22801530913809853,
+    0.27071595738073695,
+    0.4663376022121787,
+    0.28882482314272134,
+    0.24262660741330563,
+    0.28756560844722984,
+    0.4617774541066357,
+    0.4203975875392663,
+    0.4169793611234197,
+    0.32012769075318076,
+    0.40065436180547187,
+    0.39439883481308596,
+    0.38558172701667315,
+    0.30254038337594524,
+    0.3410041010096098,
+    0.27879320941413493,
+    0.17374951289319118,
+    0.3010471518354748,
+    0.3106726219969848,
+    0.2069721922532401,
+    0.2181428461415371,
+    0.27808198860277644,
+    0.2873255577475027,
+    0.3584026579495706,
+    0.30151476989404496,
+    0.32389840752592836,
+    0.46649028429117717,
+    0.570491192674748,
+    0.2596767369256839,
+    0.39128274284517656,
+    0.28090530137920244,
+    0.38992925901533176
+  ],
+  "M14": [
+    0.2751182820439386,
+    0.4014041617422875,
+    0.4049822311237352,
+    0.24772639642647462,
+    0.4399790041534241,
+    0.3037999478270987,
+    0.43138073135201693,
+    0.4224945803724446,
+    0.36976739743125164,
+    0.34051934496961955,
+    0.3150814311724969,
+    0.3786731698573569,
+    0.3575638179975769,
+    0.3392929583488531,
+    0.32739544601608134,
+    0.4467676010052748,
+    0.43423587767764893,
+    0.42273152358071425,
+    0.4569743812899282,
+    0.42052108970417323,
+    0.32678514115654056,
+    0.3936926805119227,
+    0.2499720056469181,
+    0.3863131702204356,
+    0.3585541635362801,
+    0.4092196935847812,
+    0.24648238788714277,
+    0.23191792659725644,
+    0.5143070635506329,
+    0.4099570543183031,
+    0.3571993752382218,
+    0.502188886228425,
+    0.3620893738330757,
+    0.24417509698900228,
+    0.3965974576168244,
+    0.5130356916259277,
+    0.29700620726799487,
+    0.4970553048761178,
+    0.38451745791685676,
+    0.3546541659717476,
+    0.42607040804830215,
+    0.4281655440366817,
+    0.6738065364363909,
+    0.29231062115781214,
+    0.34748745057119695,
+    0.4044686892537759,
+    0.35415154682967215,
+    0.24628290526307067,
+    0.34674979090984565,
+    0.3913351900024112,
+    0.29493271429171963,
+    0.40001969925438385,
+    0.31026243359745054,
+    0.3356433872060299,
+    0.37025531542211226,
+    0.47094146809168513,
+    0.30093876491616556,
+    0.37463357822960286,
+    0.5282664301946186,
+    0.4043304180420859,
+    0.3332103457354959,
+    0.3012436839722026,
+    0.4134896213313675,
+    0.3595233268147126,
+    0.2954953543992494,
+    0.34266791767993793,
+    0.3698954275409047,
+    0.3227148012330787,
+    0.28963331858574504,
+    0.5765022761622872,
+    0.47092427519358754,
+    0.34354862444684653,
+    0.43127477422706734,
+    0.4031677447374678,
+    0.38941989147357275,
+    0.5397333231558928,
+    0.4673906930786499,
+    0.31174470845451785,
+    0.3534247777316456,
+    0.29740363796545816,
+    0.29867819313747285,
+    0.3069697268797361,
+    0.28432325561730526,
+    0.27873751045760137,
+    0.23453869487761406,
+    0.4552278478665006,
+    0.392835289330043,
+    0.33145876325248336,
+    0.4826786931931859,
+    0.37764732829030756,
+    0.36701612736105127,
+    0.5526467092035009,
+    0.4176772789751417,
+    0.4408169852966484,
+    0.5505572071911304,
+    0.3403441519999204,
+    0.5439100886868258,
+    0.3904328803002611,
+    0.29256651370036857,
+    0.4167336481036299,
+    0.3712300720748887,
+    0.326779160380318,
+    0.26381667154313676,
+    0.32325142071000246,
+    0.4896502759582434,
+    0.3394507641074592,
+    0.386042490198767,
+    0.244973909865317,
+    0.22551316933570706,
+    0.500199328914844,
+    0.3110497411528758,
+    0.3882370771721175,
+    0.30039085051376063,
+    0.3469870503551809,
+    0.3173200235325873,
+    0.4426658812592302,
+    0.4858244275740228,
+    0.37209409262081344,
+    0.23500240149358345,
+    0.3706887002939023,
+    0.5187211234748795,
+    0.44098097117971613,
+    0.5813234966244114,
+    0.3504567265922499,
+    0.3637472256490926,
+    0.2838762436665264,
+    0.4235808639858795,
+    0.22967674429214208,
+    0.4573125310270086,
+    0.41628132138253143,
+    0.448047146438711,
+    0.239700494911012,
+    0.4694565179933276,
+    0.3450801907501135,
+    0.38880397528489485,
+    0.4896307442229502,
+    0.3966784676199384,
+    0.5663628916516439,
+    0.48399598309319025,
+    0.34607084368675917,
+    0.35735967134007723,
+    0.3747230312893856,
+    0.3694705144050571,
+    0.41469748173108373,
+    0.3205884777425089,
+    0.3115667341422033,
+    0.4980265903526801,
+    0.3687167258188705,
+    0.23132920149709316,
+    0.31643863491663005,
+    0.4455046687798623,
+    0.34129485850026225,
+    0.36682291292850344,
+    0.28894832459068664,
+    0.4331342657819811,
+    0.506373199975206,
+    0.4487985377229917,
+    0.36802742118631726,
+    0.4103703182163815,
+    0.38668821795961983,
+    0.5580757859063125,
+    0.31849979933495587,
+    0.34617758055545816,
+    0.3140353213828249,
+    0.2788821650916385,
+    0.39493283359877507,
+    0.29105322919770943,
+    0.23508387670174252,
+    0.2797919488859176,
+    0.29555626467887397,
+    0.30711822603888567,
+    0.3465299748829216,
+    0.42559770022659543,
+    0.3753206890008222,
+    0.4947323447327985,
+    0.580949323114591,
+    0.31256568977238114,
+    0.5014046328188487,
+    0.3021695709613227,
+    0.3654670092137076,
+    0.6078680434615682,
+    0.35656749913916186,
+    0.4318758252582662,
+    0.47535218139708213,
+    0.7177704561447193,
+    0.6306773983574125,
+    0.4738628242562359,
+    0.5358212548471314,
+    0.5965986619859989,
+    0.5461787874788679,
+    0.6516005829534652,
+    0.6041839114174765,
+    0.6596383712549007,
+    0.6377122955791197,
+    0.5548743176277758,
+    0.6240172710481101,
+    0.6621917778582223,
+    0.682785297289175,
+    0.6344771716853048,
+    0.6696643844573148,
+    0.5092162976680829,
+    0.384417109279932,
+    0.3238000123536286,
+    0.4339967552906021,
+    0.5815427348879935,
+    0.6443328173264328,
+    0.5912884055487584,
+    0.4920225293826486,
+    0.5510092670877067,
+    0.5944300398755784,
+    0.4810629273352603,
+    0.4845585907236088,
+    0.5862446857772796,
+    0.6078759424737722,
+    0.5644218974147468,
+    0.6196364493504632,
+    0.5513992396593895,
+    0.5176278608031478,
+    0.6264423077212113,
+    0.49258361951677854,
+    0.5645467421776152,
+    0.5642298784517631,
+    0.41508136345017554,
+    0.4500795314940711,
+    0.5253097015452244,
+    0.45920085820800655,
+    0.5231082095765194,
+    0.28640736552522783,
+    0.6331401320332134,
+    0.5494337553747364,
+    0.4328890045659194,
+    0.43339836503718404,
+    0.34580456403294363,
+    0.4564478001916855,
+    0.5035669556698166,
+    0.6335645894453642,
+    0.6647495889191958,
+    0.5998228891962913,
+    0.6719086735204973,
+    0.7543808687061369,
+    0.5455224822373672,
+    0.7283523238909885,
+    0.7097637045206364,
+    0.6433855828657027,
+    0.6656613952191762,
+    0.6217189576159604,
+    0.5635910998272563,
+    0.5907036163742915,
+    0.6878267168187591,
+    0.5591664462538806,
+    0.5396554120343182,
+    0.39680500897926724,
+    0.47164298336912946,
+    0.3157507609032123,
+    0.5263828840552996,
+    0.4805985070217568,
+    0.567676385079369,
+    0.5718511807776178,
+    0.4519221746190991,
+    0.6617829849420629,
+    0.5470604745698728,
+    0.6304086750424462,
+    0.7469845117730095,
+    0.6509538965855911,
+    0.6558223260078313,
+    0.5116323712567058,
+    0.6300629580916516,
+    0.6392234859630802,
+    0.5656192803752269,
+    0.6191154393297633,
+    0.5333142034594509,
+    0.5997809027189995,
+    0.6682850368856412,
+    0.6406486110041868,
+    0.5412346692354564,
+    0.5433017658700531,
+    0.6227201329540903,
+    0.6138635729801875,
+    0.5789763736891524,
+    0.5987505172548371,
+    0.5949443909735215,
+    0.5103839464523832,
+    0.533151129405984,
+    0.5877016646096805,
+    0.580649044484478,
+    0.537089055185218,
+    0.5526426480133505,
+    0.6277637032310713,
+    0.6383407816934202,
+    0.6729254066716146,
+    0.5839277253432338,
+    0.6601825478755353,
+    0.6892157980968273,
+    0.432493797420861,
+    0.536330149799362,
+    0.650708623551717,
+    0.6189023454215646,
+    0.6984262263609622,
+    0.6890309736184635,
+    0.5185549209073517,
+    0.573886979604277,
+    0.5791419247107226,
+    0.497790221962923,
+    0.5244798194807816,
+    0.6761366973261789,
+    0.7196159973322935,
+    0.5787120671247551,
+    0.6374279435408412,
+    0.6145384694618421,
+    0.6414611067129778,
+    0.43826335738544464,
+    0.4830475789209669,
+    0.6363227164471864,
+    0.5639636053187207,
+    0.6574242484663027,
+    0.607935318706178,
+    0.5423007157704324,
+    0.4978589295641357,
+    0.6320122171221669,
+    0.6016174632746085,
+    0.5782627613207397,
+    0.6838434299970644,
+    0.6265000074465967,
+    0.49948395660418665,
+    0.37483086735684956,
+    0.19828686992878577,
+    0.2892760015178254,
+    0.3431653988034035,
+    0.6362177128528889,
+    0.5206133767368746,
+    0.6914878347244617,
+    0.6883607209786237,
+    0.5837505137637414,
+    0.5665701197824985,
+    0.5627671463200845,
+    0.6417781720341299,
+    0.40706113769513913,
+    0.5510333163594473,
+    0.5693756202091516,
+    0.6582003124838062,
+    0.5924682283756023,
+    0.5436487188977853,
+    0.6684298171782289,
+    0.5640923575585864,
+    0.6664202630138405,
+    0.4982800172894626,
+    0.5065607573792102,
+    0.5327608514857213,
+    0.6325411326431899,
+    0.3567696925767533,
+    0.5083545945610121,
+    0.6886982073680387,
+    0.7116072963620516,
+    0.6449876461652434,
+    0.49965224827219573,
+    0.4120274869766076,
+    0.6250386747324946,
+    0.5895528847206056,
+    0.49139011693435075,
+    0.6048960401159231,
+    0.5678291165364788,
+    0.6053716114969044,
+    0.5335754686089981,
+    0.6876323724256947,
+    0.6863397715107799,
+    0.7584468033047284,
+    0.7007511120077496,
+    0.5788688729780078,
+    0.6714365035340627,
+    0.6466334282792443,
+    0.6332583278892804,
+    0.6218318400760041,
+    0.6289804706270893,
+    0.5926813554052939,
+    0.6395722683101678,
+    0.6197851857505658,
+    0.5066243539421323,
+    0.46337078747945526,
+    0.4645976578946315,
+    0.6075622051462785,
+    0.5171437645519946,
+    0.6318422944266782,
+    0.6149415028464921,
+    0.6005343161600917,
+    0.5245040270383714,
+    0.39208038345123086,
+    0.33453406258509355,
+    0.5096582408928156,
+    0.5397753986875167,
+    0.6461534401781119,
+    0.6244390590203095,
+    0.527696888138206,
+    0.7107834879966319,
+    0.6175275662184992,
+    0.6457135246303141,
+    0.5912367164330022,
+    0.6465155034604995,
+    0.7156687092396685,
+    0.6578875897965659,
+    0.6558868097637981,
+    0.7262857881184847,
+    0.6700585877266815,
+    0.5793806832065039,
+    0.6815994902683582,
+    0.6119980531964633,
+    0.5524319517116532,
+    0.5920127596869496,
+    0.6113398996469204,
+    0.5509811179809512,
+    0.6003151174394405,
+    0.5100315924306507,
+    0.5408286667669678,
+    0.4227386487416668,
+    0.5051811225538928,
+    0.44848663971652736,
+    0.5860331937976706,
+    0.22824828832478186,
+    0.5496203969506016,
+    0.3844918855341389,
+    0.4439783281097385,
+    0.6381021967794044,
+    0.5943121770034191,
+    0.5045558249256676,
+    0.5127855129899049,
+    0.6042128378871294,
+    0.6344382097053906,
+    0.6252756375521935,
+    0.46796474177414826,
+    0.6068302879377927,
+    0.6109492462258166,
+    0.3840245859805644,
+    0.36044757284185835,
+    0.6082103988581006,
+    0.7090431888806924,
+    0.7417915443591128,
+    0.7100543211497445,
+    0.6802272426777191,
+    0.6507834127123968,
+    0.6307955170135896,
+    0.6260509809235815,
+    0.5924348727946707,
+    0.5599411857296238,
+    0.6824683061336756,
+    0.6584083109990505,
+    0.5094791841752453,
+    0.5408334847080333,
+    0.6550510622668133,
+    0.723606502661627,
+    0.6443376286636655,
+    0.6393686774526023,
+    0.5763218203172474,
+    0.5178855343762976,
+    0.6206669151671881,
+    0.5344139566287301,
+    0.40480540766896667,
+    0.5713186800279766,
+    0.6045889973009054,
+    0.608890008012478,
+    0.5383831637766295,
+    0.6352656912031514,
+    0.6600408977164325,
+    0.7347382770118421,
+    0.5863417587949923,
+    0.6788988190781283,
+    0.6386822687869089,
+    0.593709760380748,
+    0.6456872501307631,
+    0.6239080482994426,
+    0.6661838393110061,
+    0.5738033767458762,
+    0.5702386121001649,
+    0.49693802463668413,
+    0.7052825600311791,
+    0.4550523866573632,
+    0.44674398062658816,
+    0.6905563984086316,
+    0.5884055271659969,
+    0.5177265096435212,
+    0.5524044611422421,
+    0.634993211948785,
+    0.45643985041574414,
+    0.3947874570366121,
+    0.5876834147107614,
+    0.5187249196645426,
+    0.5655961982328074,
+    0.6479591697398157,
+    0.5099234152637816,
+    0.5132983453778721,
+    0.5963561997859663,
+    0.5369722847714741,
+    0.6187775754757487,
+    0.6365829757127722,
+    0.6264871340172735,
+    0.5648048892689453,
+    0.5129815702722453,
+    0.4450000889601722,
+    0.6154941493281548,
+    0.582479510708933,
+    0.5557267532931971,
+    0.6382449285879628,
+    0.4437546743014057,
+    0.5895412570064849,
+    0.634695581141148,
+    0.561128452743052,
+    0.6861105551682773,
+    0.5873473297817037,
+    0.5612535041569955,
+    0.552935186817238,
+    0.7013004885920202,
+    0.5739911289054153,
+    0.5143635611458433,
+    0.5856772907945376,
+    0.6179576498433079,
+    0.6676510811072329,
+    0.5850822971924594,
+    0.631903160625866,
+    0.5939741670980592,
+    0.5837411255401154,
+    0.5541740725089213,
+    0.51066160177735,
+    0.5882131905299884,
+    0.6961851427318099,
+    0.5493860302283039,
+    0.5660793859205284,
+    0.6372137211733784,
+    0.5684071427401284,
+    0.6176048904432716,
+    0.7181481516906342,
+    0.3563176193639477,
+    0.5334222098053953,
+    0.4930335006764827,
+    0.5511599634069143,
+    0.48596757121315626,
+    0.5631152987608452,
+    0.571941940534343,
+    0.5363254154982141,
+    0.2883718155546029,
+    0.5160253446377379,
+    0.5936993531048762,
+    0.5289454584302926,
+    0.6160417699201907,
+    0.5602915261867414,
+    0.6879718740801706,
+    0.5236947954863687,
+    0.559933933507971,
+    0.6723863959228875,
+    0.5800393328163652,
+    0.6211151351197376,
+    0.6186513148078856,
+    0.6803949034500821,
+    0.49515479402397183,
+    0.5724272795373065,
+    0.6671942533395733,
+    0.6728971015168911,
+    0.5497984227171528,
+    0.5449842071464454,
+    0.6863630095720383,
+    0.6439850997915051,
+    0.6299689961854442,
+    0.5784428707702406,
+    0.5028734407158926,
+    0.6437706056788174,
+    0.6151452877871069,
+    0.6393964128514892
+  ],
+  "M07": [
+    0.27916855513991207,
+    0.3928630409814095,
+    0.3224835772589223,
+    0.19474970758718455,
+    0.4121434740093282,
+    0.2666399458873877,
+    0.40729422102757734,
+    0.36685267447210523,
+    0.3203464173721704,
+    0.33783869842669734,
+    0.29394923967459646,
+    0.3634058757644211,
+    0.31504823113507663,
+    0.39778038148882056,
+    0.32870933222443816,
+    0.38556504988811535,
+    0.6024682432620903,
+    0.41343079673480904,
+    0.4079340764058678,
+    0.41254983167374415,
+    0.30756851714503747,
+    0.3752709283027045,
+    0.27867050420113226,
+    0.3659125487569061,
+    0.34342817194347564,
+    0.43948113682173084,
+    0.1871388947487155,
+    0.2970021525461069,
+    0.440655649849915,
+    0.4107571032140596,
+    0.4016794439794489,
+    0.4397286459457103,
+    0.3376700192496525,
+    0.17367193870730957,
+    0.3015681772540989,
+    0.49292420178445195,
+    0.24895451055871737,
+    0.5050661694166938,
+    0.3705626147664511,
+    0.3941034486091308,
+    0.390320246022181,
+    0.4207761974205337,
+    0.6930188219238156,
+    0.35024166616112795,
+    0.37666978588983324,
+    0.42814082002405446,
+    0.3503941467335661,
+    0.2792909762574903,
+    0.3410591637206025,
+    0.3717826243101556,
+    0.28159823175785537,
+    0.37559479307247506,
+    0.2050078608820983,
+    0.28658964693987155,
+    0.37324322417915534,
+    0.4718209028923157,
+    0.3045145507067633,
+    0.3638116204234681,
+    0.5347672578379689,
+    0.3793912874754796,
+    0.2964232475991735,
+    0.29146486439249275,
+    0.40446139351608085,
+    0.2779702352605047,
+    0.2950453686526795,
+    0.33672040344102405,
+    0.2255988829800851,
+    0.31035580815903285,
+    0.2530049503272425,
+    0.5833154328990491,
+    0.4009633322509633,
+    0.31895671563106637,
+    0.42817592864425835,
+    0.39553845672789467,
+    0.3911180336807624,
+    0.5378984595662624,
+    0.3701113928136205,
+    0.16332172282395496,
+    0.356227139101324,
+    0.3117367187100771,
+    0.35995758292247343,
+    0.24555213297838338,
+    0.3250657205555079,
+    0.27131512689974857,
+    0.2804640954946734,
+    0.33727568817080367,
+    0.2910955419194714,
+    0.27826168002777046,
+    0.4955128744497724,
+    0.25000164234545735,
+    0.29151247801102054,
+    0.5527651939033646,
+    0.32838509498988455,
+    0.4396725178121541,
+    0.5390690401672378,
+    0.3293328335457989,
+    0.5345782824159672,
+    0.40312461040770775,
+    0.33330623984493685,
+    0.33186125830693913,
+    0.3200716816475165,
+    0.30256706455249854,
+    0.2345216352947095,
+    0.3027775899835281,
+    0.5571130025470166,
+    0.23975152037687614,
+    0.3390909961337291,
+    0.28437353626361733,
+    0.2599562369124482,
+    0.5025803557110832,
+    0.3123800525146624,
+    0.42525201827216547,
+    0.24871874643696898,
+    0.2712037053489082,
+    0.33971001983391114,
+    0.4537889177987998,
+    0.3383035006915588,
+    0.4036839809698001,
+    0.17366076026490732,
+    0.3751261137594897,
+    0.49516343570679483,
+    0.33757317356850053,
+    0.5383763523254457,
+    0.23269492219782623,
+    0.33066792183793664,
+    0.2750370099788786,
+    0.4096927285339761,
+    0.2759628718652344,
+    0.41346505423677726,
+    0.43132368305396024,
+    0.38856827580017195,
+    0.20785440644110528,
+    0.40606670932003763,
+    0.3607139419421913,
+    0.35707944734844466,
+    0.49532471041751047,
+    0.34246139357118566,
+    0.5450213064209489,
+    0.3727849681461478,
+    0.34143816851753395,
+    0.36658184464751886,
+    0.3941401849723023,
+    0.26339987705881035,
+    0.2847881628606268,
+    0.33871387708393796,
+    0.3193693290824137,
+    0.49600189361895103,
+    0.4088112805257996,
+    0.20500000772023677,
+    0.31759612927227315,
+    0.46256630174732594,
+    0.3282408157227428,
+    0.25609663692474477,
+    0.2732342983173176,
+    0.4230712864412404,
+    0.39785239581321236,
+    0.43352379339504243,
+    0.31175891385368426,
+    0.3960228393119459,
+    0.38336171417055503,
+    0.5300017168341205,
+    0.22045208412979467,
+    0.3314098637121851,
+    0.30138405347879005,
+    0.27106643467512853,
+    0.3969157992240506,
+    0.19522920409612265,
+    0.2045058540254212,
+    0.25045328794914756,
+    0.21822711775641465,
+    0.187034146939423,
+    0.37731560664714153,
+    0.44934736827425104,
+    0.32214409020131207,
+    0.4452690703734051,
+    0.566186119818431,
+    0.3315858037584437,
+    0.44701316537981123,
+    0.28652802195364807,
+    0.4281627108931032,
+    0.5482657983466835,
+    0.5346042383647079,
+    0.6476611606282252,
+    0.4329263356282713,
+    0.5854464934573979,
+    0.5264856962848595,
+    0.342517121266252,
+    0.6360758602760865,
+    0.6428126554393845,
+    0.5086253594722484,
+    0.6502160085216623,
+    0.5752110625854275,
+    0.634710523148354,
+    0.6144371663607625,
+    0.546447783395519,
+    0.518546811657355,
+    0.5324651901144646,
+    0.4721795329751724,
+    0.4861834098631379,
+    0.4824313750254064,
+    0.6556173883956814,
+    0.46954340285688645,
+    0.49487535502251057,
+    0.5388717426974445,
+    0.6272865527865542,
+    0.5973900524329039,
+    0.4388701316938789,
+    0.6789862392715937,
+    0.6010764511147384,
+    0.38457932815077017,
+    0.4533799326607757,
+    0.632476352469011,
+    0.6391437590824641,
+    0.43984011765468767,
+    0.43261465283211414,
+    0.5498737792076756,
+    0.6685672797239283,
+    0.6667510928301745,
+    0.6076836804318119,
+    0.641003798357673,
+    0.6493171823790166,
+    0.7091337845075223,
+    0.4895196600815759,
+    0.6552063117782075,
+    0.623682105036739,
+    0.5406223387104049,
+    0.5572034968330383,
+    0.5989066123055344,
+    0.6135821658316477,
+    0.5961567112218167,
+    0.4851246753636942,
+    0.5984337009578432,
+    0.667727237583712,
+    0.6557126246254856,
+    0.6260146771887488,
+    0.6178729469905768,
+    0.6301864817468863,
+    0.5189115991078421,
+    0.5102134158218833,
+    0.585712659850915,
+    0.626977731575529,
+    0.6292153375142199,
+    0.7206214131963943,
+    0.6511043140340803,
+    0.6564870373438557,
+    0.5223127345552127,
+    0.5897808236705683,
+    0.6215826588911048,
+    0.5148402908266546,
+    0.6596288403048157,
+    0.6259943872659834,
+    0.5062162614608533,
+    0.5366720026347261,
+    0.4877364076121448,
+    0.5999249427422036,
+    0.6317338246878126,
+    0.5460795314576791,
+    0.4564470449301971,
+    0.4511461417841442,
+    0.5201140334031729,
+    0.5607756663040813,
+    0.7050025525555538,
+    0.7596752769373104,
+    0.6948619350277093,
+    0.7097752355809452,
+    0.579145204413971,
+    0.691859520869421,
+    0.620300892512286,
+    0.6641903857495394,
+    0.6980309432857902,
+    0.6722445109262367,
+    0.45771761005735967,
+    0.6565106947800392,
+    0.5922529560733553,
+    0.5570729365813032,
+    0.480429472019217,
+    0.5807487525510808,
+    0.6323732422852273,
+    0.6002737463478477,
+    0.6579781509968304,
+    0.4643599839184507,
+    0.6898517551594455,
+    0.6096999614306041,
+    0.4750435698701595,
+    0.6531252737395432,
+    0.7044132143124472,
+    0.6300096180252823,
+    0.550415160241865,
+    0.665014738237147,
+    0.5491715140056034,
+    0.4533991584267736,
+    0.6446753999492144,
+    0.6708700776538696,
+    0.5505481824498346,
+    0.6002206316145828,
+    0.6623759166727964,
+    0.5727157749816001,
+    0.5560858381696373,
+    0.36588839007941276,
+    0.5212658540409292,
+    0.542215414709948,
+    0.5228775948639068,
+    0.6278433345559933,
+    0.6548529669583584,
+    0.6584472961284971,
+    0.6744700478194461,
+    0.53235457973197,
+    0.4906617511731761,
+    0.6662832081070644,
+    0.6286952022395659,
+    0.6151707757757471,
+    0.5960555655631602,
+    0.5763685636411565,
+    0.5217614025462177,
+    0.6508390199083106,
+    0.5402078744102671,
+    0.6124379773342469,
+    0.452096864179601,
+    0.6961259723644249,
+    0.4367392072717517,
+    0.4169940347638956,
+    0.6434576678371524,
+    0.4848562254719121,
+    0.5810505112965626,
+    0.6340701390836958,
+    0.5180043909500356,
+    0.649639673365984,
+    0.5663153974210825,
+    0.7080306441098367,
+    0.610104225261553,
+    0.6734139652866209,
+    0.567841004123781,
+    0.5508373262484825,
+    0.572865972021026,
+    0.4875565689213298,
+    0.4804171826499896,
+    0.5940025144526386,
+    0.6512343483543188,
+    0.4682116107106699,
+    0.5166488904897905,
+    0.5960485795297463,
+    0.30633299513196055,
+    0.5735275726259228,
+    0.6087204191868453,
+    0.4952646122750063,
+    0.38851731518891064,
+    0.4793384664832072,
+    0.46339453767524486,
+    0.6265153710021145,
+    0.5540487379937297,
+    0.37524796816833567,
+    0.5839042503266009,
+    0.7034233571770641,
+    0.6867610055604245,
+    0.5751610669950556,
+    0.4984066052475092,
+    0.5795297141150453,
+    0.6279019498927125,
+    0.5329799135126836,
+    0.616905388246925,
+    0.5480338998753579,
+    0.5567135593549503,
+    0.5608435137239187,
+    0.5609563365017302,
+    0.6829763206090428,
+    0.7268031122875604,
+    0.6746047299161045,
+    0.5868635252021799,
+    0.5830378802933127,
+    0.5666090167909386,
+    0.6379552348688577,
+    0.5414563615739879,
+    0.5456680618055658,
+    0.5004260634466648,
+    0.6053349442756142,
+    0.6712908907557279,
+    0.6629776346376183,
+    0.6290371579022582,
+    0.605372825009938,
+    0.6164618754441068,
+    0.6580543162728048,
+    0.6070215718679922,
+    0.5981927899631347,
+    0.4124290796836144,
+    0.5968047127325122,
+    0.609443818469925,
+    0.4906675906116765,
+    0.5593280536973527,
+    0.3773198665808032,
+    0.6956978257133309,
+    0.5306619342017149,
+    0.7133503159698398,
+    0.684708699295843,
+    0.5307878492981105,
+    0.6246816035417196,
+    0.6073212500314272,
+    0.4949519780130013,
+    0.6804336438737109,
+    0.5472959808575546,
+    0.48851936535633395,
+    0.709050166585025,
+    0.6905619401879683,
+    0.6154197191639578,
+    0.5816921469840991,
+    0.6474049388242566,
+    0.5617656803045286,
+    0.5622537670957055,
+    0.6308486557292796,
+    0.5424553726296957,
+    0.6124100151500952,
+    0.5536109719303444,
+    0.5827477095089966,
+    0.5855664325574803,
+    0.4973233618186854,
+    0.5425299864371014,
+    0.5008095465927733,
+    0.3780400375626926,
+    0.7461249962954835,
+    0.5619878935959124,
+    0.45789505839459294,
+    0.6321015196482234,
+    0.6780058807131009,
+    0.6497789136406891,
+    0.43962533763047196,
+    0.651894155356819,
+    0.7075160204607657,
+    0.5581896012181466,
+    0.6302566466259018,
+    0.6124879489931138,
+    0.6603866645331986,
+    0.4237446769523166,
+    0.5257361140312485,
+    0.6461758788942239,
+    0.7224953198894956,
+    0.4848324829073117,
+    0.6305650952319157,
+    0.6846391063098963,
+    0.5643727054386398,
+    0.5368248918836279,
+    0.6274550459434549,
+    0.6136649870080467,
+    0.6260759290498653,
+    0.6392533710207382,
+    0.6287154393374287,
+    0.6522416060971569,
+    0.5289850569066264,
+    0.5798652757445403,
+    0.6590745258205118,
+    0.630790638140317,
+    0.6002196290131024,
+    0.5518013148474848,
+    0.5093901804168977,
+    0.3904886353509517,
+    0.6263539953844456,
+    0.5481721584253438,
+    0.6835932529841275,
+    0.6410072030247295,
+    0.41561387062329314,
+    0.4915849047377866,
+    0.7151169006147475,
+    0.6465797765036473,
+    0.5470055326932792,
+    0.5674123030800644,
+    0.6683814107066937,
+    0.6290119567054252,
+    0.5950271835403464,
+    0.66911654912279,
+    0.6183397670133493,
+    0.6550577405845869,
+    0.46888146659439406,
+    0.5867020046548403,
+    0.6077613888648441,
+    0.5913949560089978,
+    0.5510950941927101,
+    0.5243368859605967,
+    0.5606461125239837,
+    0.6684760255995599,
+    0.6372671499781188,
+    0.5605717787817447,
+    0.6181948100482857,
+    0.55363451817446,
+    0.49177328892745,
+    0.6461437129263603,
+    0.5466527690503479,
+    0.5864523713426871,
+    0.662647261041337,
+    0.6155866807642372,
+    0.6381687501728884,
+    0.5989820790818686,
+    0.5269821298538889,
+    0.5484266890162919,
+    0.6336864099806683,
+    0.596119334218288,
+    0.5642327310706489,
+    0.4818846650989704,
+    0.6671506998280082,
+    0.6260330968074294,
+    0.5890460445993613,
+    0.561140528793009,
+    0.49128221668444355,
+    0.6158230393222667,
+    0.585920349987846,
+    0.6364160041664411,
+    0.4760869429474578,
+    0.6733334285158101,
+    0.6049057153158357,
+    0.5715967941771679,
+    0.6115036536075825,
+    0.7164699902852419,
+    0.6117959198588473,
+    0.48704940926046175,
+    0.6149232042221201,
+    0.6559326976138639,
+    0.5892010491511391,
+    0.5765384149028511,
+    0.652184043038357,
+    0.596834230211454,
+    0.5734700952397898,
+    0.5762802969240916,
+    0.36508737379169043,
+    0.5066077339128837,
+    0.6947897272235318,
+    0.5503740374680094,
+    0.5566974851869948,
+    0.6549237459899324,
+    0.5285370737212319,
+    0.6309742963596837,
+    0.5439091119288564,
+    0.6241728250655647,
+    0.437445320015512,
+    0.597707035725538,
+    0.5639067402051046,
+    0.4164173253648783,
+    0.6060008010886796,
+    0.5743967719228642,
+    0.5591719655200315,
+    0.4944216889955411,
+    0.5697709609455596,
+    0.6276121311769547,
+    0.4680049160901988,
+    0.5311870290099938,
+    0.5558811323894401,
+    0.6245154159694172,
+    0.4997584083675347,
+    0.5867889062637283,
+    0.5567287677274733,
+    0.594778196784284,
+    0.6133488608873807,
+    0.39270535710416726,
+    0.721263207368416,
+    0.6098705779644856,
+    0.652442517802945,
+    0.6427978084917647,
+    0.6791300136634406,
+    0.49876317638855094,
+    0.5442834631419954,
+    0.4957978465061689,
+    0.4243834588170172,
+    0.6033106991543089,
+    0.5272238410668114,
+    0.5358550240748496,
+    0.6663611152006537,
+    0.6323591691548358,
+    0.6447284559052286,
+    0.724835886785933,
+    0.6544401331718382,
+    0.5795662556752961,
+    0.7033702720172703,
+    0.6565720711210399,
+    0.6439400687340522,
+    0.5454278153577188,
+    0.6152345361786383,
+    0.6896688665555136,
+    0.5328629819290914,
+    0.6478650900459603,
+    0.7543500533941012,
+    0.6370044547579408,
+    0.5529187551305418,
+    0.6513174328835585,
+    0.6332472361504408,
+    0.5175243467583538,
+    0.6344474901940061,
+    0.7109107788024871,
+    0.6619283443705322,
+    0.7030046431298178,
+    0.652619470293436,
+    0.7266630004547174,
+    0.7554217535785492,
+    0.7016045837609731,
+    0.6857963137327192,
+    0.6486476127873277,
+    0.5894523792102583,
+    0.5559296658263877,
+    0.6345389011941488,
+    0.6326955652166337,
+    0.6726422160564046,
+    0.6522068083038354,
+    0.6773991938417083,
+    0.7198047524951766,
+    0.6098641115958277,
+    0.5700007575481655,
+    0.6376503225510133,
+    0.5597003562298264,
+    0.5943762418496518,
+    0.5747730356976319,
+    0.7134205158670271,
+    0.5626429829544152,
+    0.6405521217691302,
+    0.6260654841688311,
+    0.6107878861647512,
+    0.7011341914963488,
+    0.6000141320035621,
+    0.49203412007337716,
+    0.591072159729638,
+    0.5856613271524105,
+    0.6371883780636325,
+    0.5284993328956299,
+    0.7262890509527479,
+    0.6883033672794245,
+    0.656659921988142,
+    0.5531678089288877,
+    0.4652284599617668,
+    0.7077212716260375,
+    0.5895825652693225,
+    0.6671370478566011,
+    0.631160182260226,
+    0.6130488972898003,
+    0.5570568445391398,
+    0.6085248267710653,
+    0.6252751554398117,
+    0.5963833365229279,
+    0.6167173969114516,
+    0.5530726659122729,
+    0.6208931989231138,
+    0.6721266877369018,
+    0.5843638170250575,
+    0.7566731380786592,
+    0.5031344185428016,
+    0.567170062737934,
+    0.5956135413700223,
+    0.6090630084089701,
+    0.6466134650250028,
+    0.6548743149347838,
+    0.6352591338677621,
+    0.6242496341460855,
+    0.6347546329586218,
+    0.6906743956069148,
+    0.5328321406599956,
+    0.6275655516051021,
+    0.7387429661211842,
+    0.6697760069643383,
+    0.6882683662333426,
+    0.6113024501160618,
+    0.6245346844967,
+    0.5618234252370373,
+    0.5751496265937956,
+    0.6092447557843836,
+    0.5714158972040215,
+    0.68894895506089,
+    0.7009550703520279,
+    0.6332409763045329,
+    0.5819192767030831,
+    0.6627020358727674,
+    0.7240513397211097,
+    0.6897975129997059,
+    0.6996308766286459,
+    0.6461990232260969,
+    0.7181224839514263,
+    0.6050907815001141,
+    0.46465091041898315,
+    0.629197103092967,
+    0.5905489291290316,
+    0.6950721591112027,
+    0.741571902274331,
+    0.6845491977216012,
+    0.5728352230819959,
+    0.349437548681594,
+    0.4718416374077193,
+    0.612909722982211,
+    0.541956955764221,
+    0.5656654287773073,
+    0.5456739377065714,
+    0.456087246681771,
+    0.6430537551853805,
+    0.6052417433802789,
+    0.5977253947513594,
+    0.6214088793126136,
+    0.4729484531554352,
+    0.6667483268835017,
+    0.6866106749984111,
+    0.561579386110347,
+    0.5805425174768225,
+    0.67237928640976,
+    0.5257866805117405,
+    0.6076095988231957,
+    0.7360085790784611,
+    0.5943173554772411,
+    0.6116221192254884,
+    0.6640129234677774,
+    0.6543216889465311,
+    0.6129709050067786,
+    0.652115728328559,
+    0.5900340036772594,
+    0.4987873109717782,
+    0.6822993245432597,
+    0.6049573952112934,
+    0.5957326724456964,
+    0.5832992609425177,
+    0.7249748911085699,
+    0.6718955149632191,
+    0.6817524109172602,
+    0.6742853004036781,
+    0.6167201413618729,
+    0.5517904302489818,
+    0.350329690355999,
+    0.6564848592585337,
+    0.6483558532124941,
+    0.5695626600232566,
+    0.6549878640306432,
+    0.5957781637384314,
+    0.590507328542133,
+    0.6022528753626638,
+    0.6934468964837818,
+    0.6026544595363806,
+    0.6625872236709924,
+    0.42576182917583577,
+    0.5935618926102043,
+    0.6268603661088923,
+    0.5444884626426568,
+    0.5886068486098528,
+    0.5878391050553131,
+    0.6347777575473383,
+    0.6432289038132637,
+    0.7386682800217067,
+    0.6217448056914368,
+    0.6280037005546639,
+    0.6930322893705606,
+    0.4476863964886562,
+    0.49986622215164134,
+    0.6459148328506877,
+    0.5311551985732015,
+    0.4437755017271391,
+    0.5266328319062074,
+    0.7083318996099013,
+    0.6854621625701153,
+    0.7233303324680652,
+    0.5820405767528275,
+    0.6409923634179685,
+    0.7149490685923571,
+    0.6213758115228752,
+    0.6594884500131087,
+    0.6541510030793061,
+    0.5719267107187417,
+    0.5460582253194645,
+    0.648904985740503,
+    0.6180407926999146,
+    0.5795601106616066,
+    0.6448832441192923,
+    0.4596726774639844,
+    0.5804905428639406,
+    0.49769553595414917,
+    0.7058706822798586,
+    0.6619347658205597,
+    0.6003213831377558,
+    0.585107033499849,
+    0.5473939993233982,
+    0.6885797119205526,
+    0.4120613148946239,
+    0.5383810559993066,
+    0.5406567364066781,
+    0.6180800406451735,
+    0.5761766303940676,
+    0.5866738679859095,
+    0.49158842140896386,
+    0.6389888814403695,
+    0.6535418918384397,
+    0.6537231532946417,
+    0.6183013133812323,
+    0.5927788109586554,
+    0.7192971118822986,
+    0.6663503691204311,
+    0.5752120344007523,
+    0.6575266629522153,
+    0.6292776375659932,
+    0.6234865165540083,
+    0.5648309057703805,
+    0.6654239755911018,
+    0.5715034062652004,
+    0.5647180583041624,
+    0.6455111669630411,
+    0.6932821230698357,
+    0.4907236298618335,
+    0.4585993644621977,
+    0.5137542996959571,
+    0.5851387909456351,
+    0.4756969075664387,
+    0.5425287807781928,
+    0.5982710389725452,
+    0.6782423861317335,
+    0.6224605398046216,
+    0.6194432037724321,
+    0.3454447179872686,
+    0.5902105723647635,
+    0.5755992238126048,
+    0.5871327481997549,
+    0.6374775478108884,
+    0.5192036406793389
+  ],
+  "M13": [
+    0.26506805710249903,
+    0.3350516026993205,
+    0.3917540878470851,
+    0.2250589822968088,
+    0.3728000402929125,
+    0.2570191384164338,
+    0.3358746805268379,
+    0.3899979806136367,
+    0.3280535194261888,
+    0.34822368534781367,
+    0.15993968875488396,
+    0.3410591322652972,
+    0.3618899199423839,
+    0.35954455179870815,
+    0.2932855170787875,
+    0.35623897232908824,
+    0.5445034251688111,
+    0.40491355950480223,
+    0.49481936236514995,
+    0.38415914101707616,
+    0.28912350873611425,
+    0.3517961941895967,
+    0.3091056716125643,
+    0.29782626370861687,
+    0.28154308404331413,
+    0.4288492226654737,
+    0.2562439514889684,
+    0.2533032989041815,
+    0.48091012075481737,
+    0.41426957593905256,
+    0.39114750219867894,
+    0.3926657280690049,
+    0.3345065432587763,
+    0.17054016660546645,
+    0.3417564150601133,
+    0.44341874597161235,
+    0.20929024081688172,
+    0.4045569224986387,
+    0.3495838186614148,
+    0.4141056658584666,
+    0.41740604422256505,
+    0.4284142577665858,
+    0.5362129719488883,
+    0.36720127705246447,
+    0.21361739073697233,
+    0.33890851314972553,
+    0.2917729067640071,
+    0.2395304239083888,
+    0.2595448189628769,
+    0.4452611135143668,
+    0.2747718984835511,
+    0.26533037526337533,
+    0.28578639063251,
+    0.13060769895797283,
+    0.3571737249788815,
+    0.39157043389744123,
+    0.27516649261864995,
+    0.31686232327478786,
+    0.349027954730361,
+    0.3479602859717787,
+    0.2698311202831907,
+    0.31622140925413206,
+    0.3995672260785833,
+    0.3529526420020781,
+    0.29673051481036167,
+    0.26596528364999444,
+    0.32526368246388865,
+    0.2832442155006301,
+    0.2829687985145854,
+    0.5668469656047339,
+    0.391579147134477,
+    0.32896117635103056,
+    0.4095669146410338,
+    0.3376712016969973,
+    0.36542232904835986,
+    0.41876741349378466,
+    0.3244959570001126,
+    0.2943217304363838,
+    0.37318088392725635,
+    0.2872622403833553,
+    0.29146451735809553,
+    0.3076593666097598,
+    0.29488926286805994,
+    0.25561486161512775,
+    0.24826135860103585,
+    0.4204753377293775,
+    0.3290015792401911,
+    0.27538092515257406,
+    0.418049774791297,
+    0.34280982354480405,
+    0.29717503899979464,
+    0.48932402768150246,
+    0.3933404936820787,
+    0.43401834840729847,
+    0.49364956917345704,
+    0.27491232931032183,
+    0.5433187081491685,
+    0.34742660945041387,
+    0.33556441339939147,
+    0.3366328888354184,
+    0.34561958649447977,
+    0.3035693334865046,
+    0.22590680751332318,
+    0.32637716327548383,
+    0.5001729304513701,
+    0.24256234432470714,
+    0.3046870374931726,
+    0.23066972204955577,
+    0.2098224513219232,
+    0.4675038269689362,
+    0.30034841897707004,
+    0.37929154255959746,
+    0.20288981099032993,
+    0.3195489764317324,
+    0.34412614300184174,
+    0.4006147070883144,
+    0.38281484163585106,
+    0.3238427027492125,
+    0.19768756982632837,
+    0.332584812412696,
+    0.4792926056179419,
+    0.38016168828958646,
+    0.416555899329418,
+    0.3868391634437192,
+    0.32812812252020446,
+    0.3142030363931806,
+    0.40140118255809676,
+    0.2943350615666481,
+    0.36098132543722294,
+    0.32198353684954434,
+    0.3777712784116528,
+    0.17035814494901436,
+    0.4436255725489352,
+    0.40304426688997264,
+    0.3020313369646479,
+    0.4542572598543938,
+    0.387477654593537,
+    0.38181229932586597,
+    0.47462559244713554,
+    0.28358444767434093,
+    0.28937873473757086,
+    0.4113356705946231,
+    0.32889458534947397,
+    0.21664537169583847,
+    0.34589990735218284,
+    0.33625903950677016,
+    0.4450184145737232,
+    0.3342330748993504,
+    0.27055219038414746,
+    0.29035325898573683,
+    0.442587506508579,
+    0.294590277093511,
+    0.31298447601082535,
+    0.25856988540455106,
+    0.42603141831852065,
+    0.4213462130478231,
+    0.36363777800732383,
+    0.36395273794507205,
+    0.21729113959599633,
+    0.45809322304727307,
+    0.46212591298238137,
+    0.3161627907474575,
+    0.22743428002175958,
+    0.22284567499336158,
+    0.2600122872703078,
+    0.31622556991665557,
+    0.20352305051427635,
+    0.20350386282312116,
+    0.22213932073913656,
+    0.26977755440306006,
+    0.26720411957454815,
+    0.36336956323250014,
+    0.2674099193995188,
+    0.3467051155778361,
+    0.45514506690134643,
+    0.5421297409633455,
+    0.3091393777480495,
+    0.4649367300869201,
+    0.2727930920075072,
+    0.390406143254379
+  ],
+  "P01": [
+    0.25105219701277176,
+    0.3731760287432486,
+    0.35396874281374063,
+    0.24614763701886763,
+    0.4208979186429121,
+    0.2563224085088228,
+    0.39804144631606014,
+    0.342729772438143,
+    0.34027555263331566,
+    0.34913588777107313,
+    0.2996963264268632,
+    0.34139707869818514,
+    0.33160018499002053,
+    0.33327489988830467,
+    0.30134686074029055,
+    0.4139700850030028,
+    0.5753746904940104,
+    0.3273531806772124,
+    0.4413013933418964,
+    0.3387716016590725,
+    0.2931192556146389,
+    0.3022220764104768,
+    0.30003335954704546,
+    0.34415187896963156,
+    0.29989390566920465,
+    0.31900399689228104,
+    0.23347703036978537,
+    0.2742315774682564,
+    0.3792848395632444,
+    0.4386651172762229,
+    0.3520542630540213,
+    0.4890964681783579,
+    0.32781065909610935,
+    0.22256668178249067,
+    0.39196471424070994,
+    0.45940856014244963,
+    0.26416510443895674,
+    0.4763186447408344,
+    0.38700010679349006,
+    0.3254016274228711,
+    0.38961887405623863,
+    0.38424256862339706,
+    0.6309884608424305,
+    0.3522025878014956,
+    0.33716283766537775,
+    0.3573592979597335,
+    0.31952204631431175,
+    0.2800929691788154,
+    0.30069306121780165,
+    0.3885773868743226,
+    0.31030695947019926,
+    0.3586721636979141,
+    0.2966816135356434,
+    0.2941406451053645,
+    0.3653818914624142,
+    0.3879096074732568,
+    0.30510954511231186,
+    0.3697704862878155,
+    0.4997273568077155,
+    0.4090161188729098,
+    0.30479162033884966,
+    0.2867665405057399,
+    0.3157229905416928,
+    0.2777081872137583,
+    0.26818269277744095,
+    0.3473716387820756,
+    0.3512345542301887,
+    0.286429928067299,
+    0.2712409485944612,
+    0.5611122636636908,
+    0.3990311670406597,
+    0.3123526854142391,
+    0.36505933376321575,
+    0.385899586667026,
+    0.4207577965725838,
+    0.48428429603077505,
+    0.43003244280243946,
+    0.25017137264382977,
+    0.3212123436294096,
+    0.28693874454799995,
+    0.3129731290557745,
+    0.31306422615280044,
+    0.3045972376573217,
+    0.2523331593435751,
+    0.2880612854673108,
+    0.4267858146338487,
+    0.31091254057529905,
+    0.2912681184576645,
+    0.45751124666688253,
+    0.33324102039396486,
+    0.2935142107337996,
+    0.51365883495951,
+    0.34751606775764055,
+    0.4218230019267317,
+    0.5365059548576026,
+    0.2892646367844984,
+    0.5080306493420392,
+    0.33817459592908344,
+    0.33306040771141615,
+    0.2912435855431608,
+    0.34505208752011646,
+    0.29776968760135253,
+    0.26700375971182594,
+    0.3169556414888369,
+    0.4095470863832975,
+    0.30903486319578044,
+    0.37607536522782065,
+    0.27564480405394937,
+    0.22915901223417678,
+    0.39980841426576114,
+    0.2550919274958809,
+    0.4213049088019032,
+    0.2936428253704326,
+    0.3004856941851986,
+    0.3244825750226138,
+    0.40522913663967863,
+    0.4469970333527181,
+    0.3143761646813669,
+    0.19605961326147367,
+    0.3925641600629026,
+    0.3878686675871826,
+    0.40547157591548316,
+    0.5129790390477407,
+    0.3531847481208235,
+    0.34177762456858496,
+    0.3551779031117135,
+    0.3991853769893605,
+    0.25386714849536307,
+    0.41633745754670115,
+    0.4015937606737241,
+    0.4022637600590555,
+    0.2166666605187761,
+    0.4196337753853399,
+    0.39741162810208863,
+    0.33658020759850626,
+    0.4168108092765942,
+    0.3501262768150227,
+    0.5139208890998184,
+    0.4638591691471118,
+    0.323422776439906,
+    0.3403769118564617,
+    0.38680954765848974,
+    0.31670230196708293,
+    0.37578898329995597,
+    0.38930971117542174,
+    0.31698168411453786,
+    0.3736375556199111,
+    0.37225568504148737,
+    0.272232215941715,
+    0.287301033150851,
+    0.4036408618957277,
+    0.33074640808989786,
+    0.33843626307198915,
+    0.2725367875318847,
+    0.447133456578337,
+    0.4618383745291599,
+    0.3693487772206533,
+    0.38126092232570885,
+    0.43093927219146594,
+    0.4098767496385072,
+    0.43724784196820476,
+    0.2758273094728163,
+    0.31538137905822494,
+    0.29517341619776266,
+    0.2625541502295622,
+    0.30779344268905673,
+    0.28185060515345606,
+    0.2240255324149891,
+    0.24418213298352376,
+    0.2605927265639896,
+    0.2976082108493593,
+    0.2687218809236972,
+    0.4299918576707297,
+    0.3375429070798391,
+    0.3692874181599207,
+    0.5519354905524984,
+    0.26766896337400026,
+    0.4062615902095982,
+    0.2891821838913971,
+    0.39544328736448053,
+    0.6601719470912428,
+    0.5647731152506436,
+    0.6510005022086648,
+    0.6265989252657381,
+    0.7001524087429136,
+    0.6263742180116694,
+    0.5612170524769471,
+    0.6039933944406785,
+    0.6076617768638909,
+    0.546481556189276,
+    0.5734090482136233,
+    0.5837011941627531,
+    0.5557494775525844,
+    0.6044939779134922,
+    0.6042340001941033,
+    0.59879656565433,
+    0.6802623085562793,
+    0.6477470247344779,
+    0.6169747722949422,
+    0.6397523388668546,
+    0.5791503585592709,
+    0.46453530390094855,
+    0.5626140917483285,
+    0.5774665676381603,
+    0.6189316814384475,
+    0.5438428229814447,
+    0.5815138286412261,
+    0.5933251407066134,
+    0.6521630938909879,
+    0.6791803803147652,
+    0.5265308317362853,
+    0.6185833448925557,
+    0.671478471159737,
+    0.5863949076096189,
+    0.5933524786409838,
+    0.5862241762196214,
+    0.6878031808827235,
+    0.6423982176214922,
+    0.5757247300901086,
+    0.5394439176314851,
+    0.6324726462413534,
+    0.6447533554731011,
+    0.5228874579696909,
+    0.6293652623877256,
+    0.39969698206404713,
+    0.6342082998546142,
+    0.5596487665805843,
+    0.5883069682456755,
+    0.6203398859803203,
+    0.583367276861045,
+    0.5090143731353975,
+    0.6608886623627415,
+    0.5261159210945359,
+    0.6136475359479014,
+    0.6133046006714098,
+    0.5407769669009586,
+    0.6085277746597496,
+    0.6021261529721804,
+    0.6591071868689309,
+    0.7251763102113586,
+    0.6419350253567032,
+    0.569251590836578,
+    0.573403605612664,
+    0.6270810367634368,
+    0.6542249847834528,
+    0.5692718675544339,
+    0.5825631510237043,
+    0.44958183243851,
+    0.7009064916554747,
+    0.6209509178950288,
+    0.6044104949751604,
+    0.45372963396326665,
+    0.5539854386679424,
+    0.5450032489848048,
+    0.6039138454936592,
+    0.6144695844393495,
+    0.48284991410559647,
+    0.6546936784271681,
+    0.546216324767738,
+    0.6630836014607921,
+    0.6198444392113844,
+    0.6888051612358519,
+    0.7201213844880752,
+    0.3816916071589175,
+    0.5959334330418502,
+    0.5341487275758103,
+    0.6574636246213179,
+    0.5886254239708243,
+    0.47804312100198393,
+    0.664989376837645,
+    0.5792481791810915,
+    0.6388992416527675,
+    0.6642277375888371,
+    0.6463317456542723,
+    0.6290590026897867,
+    0.43791550461395123,
+    0.5945858017993426,
+    0.6126716450984749,
+    0.5972935946725172,
+    0.647831552050427,
+    0.5742921036085679,
+    0.6224284588584165,
+    0.5899125563007105,
+    0.5613388280427624,
+    0.6156184974946933,
+    0.6316540072743304,
+    0.6234322656763102,
+    0.637097074800719,
+    0.5331614443771727,
+    0.627150915922206,
+    0.5883643763481445,
+    0.7029279303768848,
+    0.6866504368712988,
+    0.5394164900698155,
+    0.5127668098373228,
+    0.6256776628053166,
+    0.6629538401047007,
+    0.640748261283038,
+    0.45403796277855263,
+    0.5988061425642196,
+    0.4547709569829914,
+    0.6158552253995923,
+    0.5760979070449688,
+    0.517318358117003,
+    0.6698497645691852,
+    0.7102901960916801,
+    0.5879994673206711,
+    0.6290836917174716,
+    0.4800252118740859,
+    0.6334636811061733,
+    0.4970238265902228,
+    0.5794301592704499,
+    0.6486006459194952,
+    0.545163735856519,
+    0.5983453894377526,
+    0.5329700099694985,
+    0.6322018659842206,
+    0.628508170527111,
+    0.6563573053316185,
+    0.40305220704469336,
+    0.5891836471056869,
+    0.6779425047204564,
+    0.6610115031446628,
+    0.6210128437462494,
+    0.6177363798759816,
+    0.5046940758695685,
+    0.5533217485587438,
+    0.6541326110675653,
+    0.40324145421305263,
+    0.6513326347915378,
+    0.5538104462677702,
+    0.590924733745761,
+    0.5214591999730418,
+    0.563279226109945,
+    0.47718630965777276,
+    0.526498694291153,
+    0.5645975436530233,
+    0.6261590316009049,
+    0.6053647081063762,
+    0.6450059670781203,
+    0.4976918374448445,
+    0.5423983452337456,
+    0.6713845177094553,
+    0.6142141781554813,
+    0.6442815459292675,
+    0.6052669502070616,
+    0.5634564822685603,
+    0.5793062571085899,
+    0.5718297143452744,
+    0.6043307809605297,
+    0.5458832072093592,
+    0.6833772799772336,
+    0.6158757360159144,
+    0.5793361647361374,
+    0.49778973276480626,
+    0.5608574769480135,
+    0.6206894725707881,
+    0.6226703504158349,
+    0.4637348784051873,
+    0.48864984535525685,
+    0.6800093909097279,
+    0.6033527761550321,
+    0.5825028308809144,
+    0.6373532318430629,
+    0.6577236896480282,
+    0.6461943029853233,
+    0.6771194305305143,
+    0.5879831518883747,
+    0.679819776637162,
+    0.6210200786498691,
+    0.5653568131014013,
+    0.5281380169091202,
+    0.5396252581524384,
+    0.596884324266289,
+    0.610899469254364,
+    0.41695378379771514,
+    0.638040364568222,
+    0.5957906087226303,
+    0.6742562496080101,
+    0.6234105330348794,
+    0.6228608773622191,
+    0.6333065096118679,
+    0.6076917864596789,
+    0.5644834895702058,
+    0.6092652157433561,
+    0.6360808627896722,
+    0.47632859759553026,
+    0.563187536643553,
+    0.40058422705256785,
+    0.7314165474637495,
+    0.6137385447988134,
+    0.6404768216330083,
+    0.575696714218079,
+    0.6402765681199956,
+    0.5981797586191232,
+    0.5760045017478648,
+    0.5374548595191481,
+    0.6980146490629333,
+    0.7011465649737774,
+    0.6604683074204943,
+    0.5005954319506893,
+    0.5842937480414063,
+    0.5839660162564405,
+    0.6595340682802342,
+    0.6337216043078135,
+    0.5954154598727825,
+    0.5504838958134348,
+    0.5840160962951694,
+    0.5633105479752125,
+    0.43978901787403085,
+    0.5882747978695545,
+    0.6143299834008829,
+    0.5615536739293685,
+    0.5926298570871767,
+    0.5935855447697804,
+    0.6257548555760265,
+    0.43313093766455957,
+    0.7103494805563406,
+    0.5532497130864673,
+    0.606862348609859,
+    0.5977413776829099,
+    0.5053672334539229,
+    0.5602271778907207,
+    0.5488571814611278,
+    0.5479836607656977,
+    0.6739623827824545,
+    0.6197450203230133,
+    0.579141663399538,
+    0.5910507171046864,
+    0.6098551096409692,
+    0.41033786184708454,
+    0.49250608098697435,
+    0.5361741158232411,
+    0.6847949473905086,
+    0.6189114117326021,
+    0.5708194854857829,
+    0.44117968133034186,
+    0.6044270696258165,
+    0.4846553316730948,
+    0.5723047143232605,
+    0.5911545143901903,
+    0.4732089074966045,
+    0.6756446439541656,
+    0.6753307270932787,
+    0.6257954989842677,
+    0.477115416636084,
+    0.6494273300407383,
+    0.5792699314610071,
+    0.5968891981535916,
+    0.6233074522235823,
+    0.5661164808877625,
+    0.5580980968301176,
+    0.619810771493437,
+    0.6625508371113121,
+    0.5872268592733081,
+    0.6410081290219065,
+    0.49810399640533887,
+    0.5935705374504675,
+    0.6400170640285816,
+    0.6753855551965618,
+    0.5807035919812554,
+    0.7356213765384659,
+    0.5614143320204065,
+    0.6351228118515383,
+    0.3952543382094402,
+    0.4598281622401461,
+    0.5870765628549488,
+    0.39025360898570255,
+    0.6351205951482951,
+    0.5771508757611675,
+    0.5302461180664118,
+    0.5079949575997988,
+    0.6407858881369141,
+    0.6118523568356025,
+    0.49350183163880373,
+    0.5662356653057806,
+    0.40608172516768754,
+    0.6511663043204804,
+    0.5396120130177857,
+    0.4212105854021708,
+    0.5760124166373158,
+    0.5701602861881271,
+    0.5937791883007311,
+    0.48747511560076673,
+    0.5696196915452048,
+    0.6308386493918874,
+    0.5968237362221519,
+    0.5369396370085437,
+    0.6089569617858882,
+    0.516165354954607,
+    0.5204790141008331,
+    0.5370338958858161,
+    0.6017767454467516,
+    0.6333174832622919,
+    0.5798713991628456,
+    0.5396105268728467,
+    0.5734608367097788,
+    0.550970087186307,
+    0.5691810121050436,
+    0.5773910865906325,
+    0.6175006391573493,
+    0.569879978628378,
+    0.6179555002605871,
+    0.5995535004410086,
+    0.5777452295190778,
+    0.5831964224489884,
+    0.5843847726424894,
+    0.5715883645066351,
+    0.4922649892033769,
+    0.6188593730790432,
+    0.3076294397906161,
+    0.2297462385689643,
+    0.4676727975143541,
+    0.6740989112529642,
+    0.6018409249007575,
+    0.6286576673707683,
+    0.5299855014898981,
+    0.6082224846980528,
+    0.5704774234124601,
+    0.4693238019983192,
+    0.5531747747549371,
+    0.6596429667711445,
+    0.6260473722984058,
+    0.5193657628669237,
+    0.636676779621188,
+    0.5442313536987595,
+    0.5871189996728897,
+    0.6108206993375671,
+    0.4350740294489798,
+    0.6055245620123413,
+    0.5111717415594563,
+    0.47895766653676175,
+    0.5030943982930811,
+    0.5704002186214377,
+    0.5425720495898357,
+    0.5566725738497299,
+    0.5588212796745003,
+    0.5699651009348168,
+    0.6169257637501242,
+    0.4958201384537383,
+    0.6112414484666769,
+    0.537174856856538,
+    0.6084752737117329,
+    0.4846081930182863,
+    0.6525614816225372,
+    0.6463969727471053,
+    0.6333907283967557,
+    0.6125762667879847,
+    0.554044825417564,
+    0.697478719593601,
+    0.568263069515125,
+    0.5702122842312238,
+    0.5626033693211666,
+    0.6137872170316933,
+    0.5903266721798772,
+    0.559574602202537,
+    0.6483075736806041,
+    0.6218836669702473,
+    0.5878726166575408,
+    0.544475044672459,
+    0.49529034626761703,
+    0.6517181349839692,
+    0.6319495723704291,
+    0.6458786246647563,
+    0.5880097205397605,
+    0.6060447619958356,
+    0.6908234010401944,
+    0.660218761286703,
+    0.6006312928184402,
+    0.5081178664182517,
+    0.6057382206906042,
+    0.6018649395925778,
+    0.49493550679278736,
+    0.6224033810360936,
+    0.7073226483539122,
+    0.548711244038992,
+    0.5121933562274584,
+    0.6457584150179625,
+    0.6670150558930712,
+    0.37314788247325065,
+    0.40545391811178905,
+    0.51081220634402,
+    0.5544479377296625,
+    0.6522623263895007,
+    0.6278584762010864,
+    0.6146640298125697,
+    0.5917292793302854,
+    0.5987600543579836,
+    0.6960229149761056,
+    0.40887388431101035,
+    0.5434755093778464,
+    0.5238022899660315,
+    0.5815821965061834,
+    0.6143526369710863,
+    0.4726335057746732,
+    0.6144171008252083,
+    0.6475143332437214,
+    0.5706096296451313,
+    0.5856033129094609,
+    0.660990072070924,
+    0.4319173340826772,
+    0.491671052510089,
+    0.49902608240365925,
+    0.5145461689696856,
+    0.6850153031239932,
+    0.7192510880787144,
+    0.6289021383814327,
+    0.5896307099393084,
+    0.5006834143525395,
+    0.6054982021408526,
+    0.7135575567148024,
+    0.6320870320099009,
+    0.5534510282755336,
+    0.5706976953425579,
+    0.6104664836304379,
+    0.5859903046457289,
+    0.6502590378532834,
+    0.6386204727973878,
+    0.6498514482325528,
+    0.6396186647481577,
+    0.5555166606001097,
+    0.5294266995103865,
+    0.6111892205762864,
+    0.5689261921083199,
+    0.6665337827100005,
+    0.4913411094629861,
+    0.6081108680020273,
+    0.5755224396484513,
+    0.5546608427703806,
+    0.4446998918281129,
+    0.5552050263149793,
+    0.36847008976913465,
+    0.5875289204050149,
+    0.6467291694144272,
+    0.5361404758737196,
+    0.6325411165746097,
+    0.7523348880607895,
+    0.6088271497970139,
+    0.636223875857533,
+    0.5561660900176898,
+    0.5666210844202502,
+    0.6878142907603602,
+    0.5076833559298017,
+    0.6570281361650029,
+    0.43809804856074586,
+    0.5094140079100956,
+    0.6190978857796171,
+    0.321627915236842,
+    0.6006124319304642,
+    0.6012784818591772,
+    0.539606191607012,
+    0.556478929049308,
+    0.6355947812796027,
+    0.5977771247931338,
+    0.3907094710013061,
+    0.5424508406749381,
+    0.5534688110555656,
+    0.6742645755718963,
+    0.7117687507384305,
+    0.47736598960025783,
+    0.5023346065610534,
+    0.5843094331685712,
+    0.6590013765902464,
+    0.7154953435462099,
+    0.6780981461164393,
+    0.6473215238670338,
+    0.5136698750048049,
+    0.5265279280073796,
+    0.5953315265533033,
+    0.636970183945484,
+    0.6704343543642238,
+    0.6036505847010885,
+    0.5146835273911107,
+    0.5759875078867176,
+    0.644302630911966,
+    0.6202381473874791,
+    0.4041081751755117,
+    0.42348871137914185,
+    0.4587543796338395,
+    0.36289337809123023,
+    0.3863411516991247,
+    0.4779984343267111,
+    0.5822307234337871,
+    0.46710403022104474,
+    0.4751990181220927,
+    0.5897093596122057,
+    0.5648667341886234,
+    0.47594477563848797,
+    0.6739831651956288,
+    0.6637821088602907,
+    0.5581656208862054,
+    0.562222230015385,
+    0.6792761246420979,
+    0.6005027908500167,
+    0.7018577008675756,
+    0.5298148898705463,
+    0.4418067874070642,
+    0.6228623827037338,
+    0.6215706113901118,
+    0.5677701776592319,
+    0.6420705838345334,
+    0.4923127720068693,
+    0.48426072881222776,
+    0.6575389890730622,
+    0.6376751739688942,
+    0.610181814190906,
+    0.663679149346272,
+    0.5183922410897757,
+    0.6828478408889153,
+    0.6752937775847276,
+    0.5646672894673433,
+    0.6042757248396049,
+    0.35386117377898385,
+    0.5294584893016429,
+    0.47635264218645096,
+    0.6300049212976493,
+    0.6808987827227024,
+    0.6677058629407869,
+    0.6669059027565025,
+    0.5609760647011446,
+    0.4933423944716599,
+    0.5009066675975589,
+    0.5074963676609636,
+    0.6062648745950768,
+    0.5082936362381825,
+    0.4349300229876559,
+    0.5932900783427643,
+    0.47655912168760295,
+    0.4659691721985616,
+    0.5416101459586583,
+    0.49387410873585275,
+    0.5714380852207288,
+    0.42318622369792797,
+    0.7184015343928589,
+    0.4374013395136424,
+    0.6101292726861719,
+    0.5795233696683934,
+    0.548833102054793,
+    0.5131882507679624,
+    0.5492382760441367,
+    0.5975873445707702,
+    0.4594886056046263,
+    0.6254491958539097,
+    0.5866800186924277,
+    0.6030117746506722,
+    0.5372229346089213,
+    0.5193553398270615,
+    0.411709429831858,
+    0.6686130525548926,
+    0.5461638131197285,
+    0.6222990689817703,
+    0.6340429813932352,
+    0.528748223498568,
+    0.46673248937038475,
+    0.5641724357676635,
+    0.5299544208814257,
+    0.62220295566492,
+    0.5744524518582665,
+    0.5548110914291831,
+    0.5125442207799523,
+    0.4789213480668698,
+    0.6571461007695556,
+    0.38918417096337266,
+    0.4562366890263343,
+    0.41658549430873654,
+    0.3949618276614367,
+    0.48748424575659977,
+    0.41303839190590147,
+    0.6535060760093558,
+    0.4867983327343679,
+    0.6318906834927074,
+    0.658571113118646,
+    0.5908367397004385,
+    0.5402187712488629,
+    0.48010553252414895,
+    0.45471891172756235,
+    0.5480693921610975,
+    0.5413265649915593,
+    0.6000458822161698,
+    0.6511010376092915,
+    0.7282287428945123,
+    0.660272702185567,
+    0.6750731191637596,
+    0.6079094224553302,
+    0.6166702724546739,
+    0.515122228834549,
+    0.566567871081954,
+    0.5704297656373589,
+    0.5173579652236253,
+    0.4381737387184256,
+    0.6910183724974583,
+    0.5507942832239545,
+    0.320722612040568,
+    0.3232018032194244,
+    0.5388903128009883,
+    0.41490950347269673,
+    0.4807045671253887,
+    0.6021143391791741,
+    0.6615379957537165,
+    0.579943478973324,
+    0.6342417983608963,
+    0.6005132211462098,
+    0.5790361770004991,
+    0.514131993573404,
+    0.6181038774163401,
+    0.5936873759276573,
+    0.5530197000276883
+  ],
+  "M05": [
+    0.12437105039030232,
+    0.3713968603299406,
+    0.34146178482578804,
+    0.21805194373037176,
+    0.40328747672207804,
+    0.2463454284026971,
+    0.4000260623324485,
+    0.36996154172496826,
+    0.32823964136970135,
+    0.3200373738859929,
+    0.27024759180441693,
+    0.35432703162054474,
+    0.3687157308101388,
+    0.38234899078870493,
+    0.2472450231467731,
+    0.34326895279929154,
+    0.5756691263493664,
+    0.40134690331518597,
+    0.49374167018508036,
+    0.3899581923208109,
+    0.25354902520118944,
+    0.37312316224186887,
+    0.28217537948647237,
+    0.3442144240073885,
+    0.3016809838191968,
+    0.42411567053298715,
+    0.14167838493611318,
+    0.2903587381805263,
+    0.49294064146470745,
+    0.39451265827327087,
+    0.3988532992607498,
+    0.49778458929224406,
+    0.25406740737360956,
+    0.23518291322833598,
+    0.39153773250412116,
+    0.47267299061568196,
+    0.22250259884963486,
+    0.44263701143645395,
+    0.35869751392210075,
+    0.42431580942638036,
+    0.391051258848816,
+    0.44276065946337073,
+    0.597086760822846,
+    0.35639059120180955,
+    0.3464820704179877,
+    0.3624931489633015,
+    0.2664930227639297,
+    0.28347855331039234,
+    0.30023530880586224,
+    0.4368987601893091,
+    0.19376134779039597,
+    0.3788024159025251,
+    0.30652602958287245,
+    0.2749302848664608,
+    0.28385118407851445,
+    0.4420060634938988,
+    0.28885350416336214,
+    0.3423066146580849,
+    0.49971918499096607,
+    0.32599826802574905,
+    0.22757166044358737,
+    0.21813141891035906,
+    0.3345701344827709,
+    0.35541865059999406,
+    0.270971114960686,
+    0.27025475792739784,
+    0.34851303189697913,
+    0.27387852815460423,
+    0.2768398697097442,
+    0.5702347725719864,
+    0.4314610265957999,
+    0.3015211791056406,
+    0.4118679310822599,
+    0.3846662157792497,
+    0.33948217438805695,
+    0.5036437392024743,
+    0.43060561986763246,
+    0.2756810704120543,
+    0.3036426429554448,
+    0.21579116328047504,
+    0.32470998210001434,
+    0.3012717243672842,
+    0.2762440895555053,
+    0.16447257166243343,
+    0.25115067653912854,
+    0.3826339972002254,
+    0.3603373166414731,
+    0.20789317142784788,
+    0.4423327973792476,
+    0.3596631480283729,
+    0.1854046333172662,
+    0.5451862302363394,
+    0.39256641952656385,
+    0.3500913094273406,
+    0.5277703900217023,
+    0.3045785228152397,
+    0.5375354355292584,
+    0.3781292658982921,
+    0.2616765458339711,
+    0.4312276981790385,
+    0.3089002026919814,
+    0.2598849212092998,
+    0.22016472678088173,
+    0.19083969644840676,
+    0.4276539005604374,
+    0.34513086182121117,
+    0.38212959789284234,
+    0.2547456929190882,
+    0.24014361161866613,
+    0.46073244337810887,
+    0.3202247364792987,
+    0.35848293183179164,
+    0.2351468942719298,
+    0.3524432025992692,
+    0.34057934429234327,
+    0.4257359998587213,
+    0.3910134712055609,
+    0.35703383318598403,
+    0.2160352664721442,
+    0.31675547421028194,
+    0.47868438025624516,
+    0.4187881161505707,
+    0.5626735929068931,
+    0.3435520999689808,
+    0.3087255171474393,
+    0.263889904767294,
+    0.28666016502899405,
+    0.253709515014595,
+    0.45772497304679327,
+    0.3721466823344431,
+    0.3165666098775275,
+    0.17152532215976612,
+    0.3845977762836517,
+    0.3600147629588509,
+    0.33521101052624197,
+    0.3546611704287122,
+    0.36114145924281094,
+    0.5042266686909894,
+    0.5068160122088206,
+    0.29967145416463575,
+    0.3521223655742513,
+    0.4199234282767006,
+    0.31455909424447387,
+    0.3948223625925589,
+    0.3665252283111955,
+    0.29156423806758747,
+    0.3793422198808042,
+    0.3856490889151811,
+    0.20253137041861013,
+    0.21178240019462655,
+    0.3993496710357751,
+    0.29873050584568284,
+    0.3318154653400915,
+    0.18712800528229992,
+    0.4336135159865458,
+    0.4218693854350871,
+    0.40662910687338444,
+    0.362228950292385,
+    0.3206546776286491,
+    0.31285252372966604,
+    0.4862982106486561,
+    0.28926776561305295,
+    0.3454502129144921,
+    0.2609122357599443,
+    0.23780930420598242,
+    0.30911394941635423,
+    0.28710677750194663,
+    0.17122929557859545,
+    0.12504248355860628,
+    0.2927117975635105,
+    0.3063121271680999,
+    0.38906504907732514,
+    0.36885983526505806,
+    0.34866916865450254,
+    0.4507491356472665,
+    0.5339306236592423,
+    0.29637170479655,
+    0.44985055764116266,
+    0.26711347810327557,
+    0.4115524925170839
+  ],
+  "M08": [
+    0.2024057268338106,
+    0.3441924190229762,
+    0.38962034667819145,
+    0.1958059116553032,
+    0.4427492314435855,
+    0.3155359588693787,
+    0.4311988604056919,
+    0.4273608151935077,
+    0.38304541403721687,
+    0.35662217506099975,
+    0.30279514032792715,
+    0.3714426511643578,
+    0.3767519303136164,
+    0.25937093523337257,
+    0.3383633843202722,
+    0.37724649833779894,
+    0.5875969262284123,
+    0.40965679144478384,
+    0.5480595901339691,
+    0.39892311096190264,
+    0.30855077371448325,
+    0.3790374863383777,
+    0.32384932795034355,
+    0.3736112117130564,
+    0.293399119973384,
+    0.39434271880143684,
+    0.23312292672481244,
+    0.2719315826448931,
+    0.43305350675257015,
+    0.4465740175047285,
+    0.4036386475752638,
+    0.5178115586800535,
+    0.3428621946706455,
+    0.24968968183361454,
+    0.37936236318820077,
+    0.4758365151582697,
+    0.25213042704717104,
+    0.4891078787288122,
+    0.324696042569088,
+    0.4239860165643779,
+    0.44718037961315243,
+    0.463842715671812,
+    0.7067006420201661,
+    0.3747645378353649,
+    0.3021934235256673,
+    0.33403198783033966,
+    0.34325501246015755,
+    0.26677813429530833,
+    0.27400079554778034,
+    0.4766211963925701,
+    0.2808535365896357,
+    0.3898572989526565,
+    0.3405382734752402,
+    0.33492677635403323,
+    0.19630560305209147,
+    0.4432983401408453,
+    0.3235868547663888,
+    0.19553719797260158,
+    0.5396245862752974,
+    0.33358829155930764,
+    0.3195105060053186,
+    0.2967649905467577,
+    0.41959720903036407,
+    0.34827774855834914,
+    0.2985433156582106,
+    0.3181223390877426,
+    0.33246155602354877,
+    0.3265741870682948,
+    0.23615582544845135,
+    0.5867937608259357,
+    0.46856955435636855,
+    0.3002938779881158,
+    0.38048916111978537,
+    0.4099734709066085,
+    0.43573913704364053,
+    0.5107394777516097,
+    0.4463473212765833,
+    0.3121332420588117,
+    0.4146774903495448,
+    0.2698713573868294,
+    0.3364130258619847,
+    0.3048703693104418,
+    0.2980952416974927,
+    0.29530413058384514,
+    0.23926265417744833,
+    0.4549873581635165,
+    0.3741064030939587,
+    0.3166964413468684,
+    0.4531905768286461,
+    0.3741760271829474,
+    0.355349796042545,
+    0.5713789569162003,
+    0.3877952890830251,
+    0.3654376282072817,
+    0.5546673626241824,
+    0.2937998953676942,
+    0.4967366250498425,
+    0.37553717327208175,
+    0.3369773903354285,
+    0.2985945276908842,
+    0.27397606820870346,
+    0.2911226387629664,
+    0.18849806628426435,
+    0.31537792096164546,
+    0.5457329909728745,
+    0.2678084068846512,
+    0.38850464399095913,
+    0.26679962893631365,
+    0.2565177070757927,
+    0.5107314282321077,
+    0.3348333173534065,
+    0.37094173009547154,
+    0.29372773058463386,
+    0.3873880602715438,
+    0.3296803796461837,
+    0.36701291545579157,
+    0.44565289544240905,
+    0.3765972271787647,
+    0.15586177091221712,
+    0.39856089385472937,
+    0.529448875094499,
+    0.41551412945864385,
+    0.48844168123067216,
+    0.3722736838334668,
+    0.3598836434492628,
+    0.32653088909213646,
+    0.40348368716925753,
+    0.2982529877686199,
+    0.42131538116200734,
+    0.37758298851461913,
+    0.43808234366962157,
+    0.2311841906148159,
+    0.3568130595305432,
+    0.4166476796546445,
+    0.27114320376644807,
+    0.45447355807588485,
+    0.3540113417253259,
+    0.5474550306773498,
+    0.5354202013768471,
+    0.32097676227976407,
+    0.31056235057694614,
+    0.4328513709892141,
+    0.359290950849763,
+    0.29093949847356015,
+    0.3359657147534832,
+    0.31303629237194364,
+    0.4618838674357844,
+    0.4117802658222774,
+    0.22492602695674985,
+    0.31797392811885117,
+    0.3052280290278862,
+    0.35377036827273656,
+    0.41317869165293797,
+    0.2812843154870618,
+    0.4482405464368827,
+    0.42852238695110634,
+    0.44355128395849835,
+    0.36626913209602424,
+    0.4667214106533094,
+    0.34442260228344906,
+    0.47164835582204373,
+    0.27369981773023716,
+    0.3542598843325294,
+    0.29999763368322563,
+    0.29428924501008785,
+    0.39181971061224863,
+    0.2988235934731251,
+    0.1962968988733985,
+    0.2645530614399597,
+    0.2931301785224546,
+    0.3565830205951734,
+    0.3821128779690078,
+    0.36334309134794235,
+    0.32080350890622433,
+    0.40232588288143456,
+    0.5898282153695802,
+    0.2222409362644549,
+    0.45931406965716537,
+    0.3138876856207284,
+    0.3208440731642957,
+    0.6782822768863259,
+    0.490908969786216,
+    0.6631832515624849,
+    0.6412879089527198,
+    0.6863672542613903,
+    0.6808442785250405,
+    0.5788124403766066,
+    0.6405838832611406,
+    0.5622763887257106,
+    0.41416771160724214,
+    0.605975369146987,
+    0.5910339580345861,
+    0.508204340382441,
+    0.5012338809901323,
+    0.46627684728844526,
+    0.6277803873181829,
+    0.5591293437575552,
+    0.6720912464102683,
+    0.632716771890748,
+    0.5440439133976711,
+    0.6685737570964132,
+    0.43541639648127506,
+    0.5295451755491312,
+    0.39714687515409325,
+    0.6391131626027178,
+    0.6443964989694211,
+    0.45162382591380357,
+    0.6010445666423088,
+    0.531686473832323,
+    0.661585151706791,
+    0.5571224587556126,
+    0.5731746470081462,
+    0.6591080735813947,
+    0.4107241485757666,
+    0.4821084195868006,
+    0.6212544731733557,
+    0.6974534117751809,
+    0.6003937741139007,
+    0.5992995151055163,
+    0.6047838197987129,
+    0.6321179230591801,
+    0.6751981210465907,
+    0.5197348934826674,
+    0.5376752880993948,
+    0.6526141335491994,
+    0.6251512820117979,
+    0.5774481956028763,
+    0.6105827597789881,
+    0.6625467597702038,
+    0.6139921195743248,
+    0.5767560053270537,
+    0.5978462472654239,
+    0.678737934031422,
+    0.6306394343640213,
+    0.39040131941962275,
+    0.5566785247027998,
+    0.6428749561195539,
+    0.603492597584479,
+    0.6563241570648788,
+    0.641295877494566,
+    0.6927479010473623,
+    0.5969531095296593,
+    0.5913790330978146,
+    0.5774608846272021,
+    0.6569207938869909,
+    0.6011989095023966,
+    0.5936687864324889,
+    0.6192027336482683,
+    0.43467835005083155,
+    0.6442087330463426,
+    0.5954004336049512,
+    0.22528757262089363,
+    0.6431619298277945,
+    0.6046455980540882,
+    0.5400718676313426,
+    0.6491859164038322,
+    0.5387388515924418,
+    0.6628484071891022,
+    0.33973175981117737,
+    0.6766387982937895,
+    0.6234703500046258,
+    0.6414183410480793,
+    0.7037687347698718,
+    0.6276161710282278,
+    0.7092917699228951,
+    0.4692520024101358,
+    0.43493003754382537,
+    0.6418205058056328,
+    0.5784587403698945,
+    0.6792662823564826,
+    0.6059333690780068,
+    0.682919578976283,
+    0.6783481360148962,
+    0.5608061255190729,
+    0.3806965207810177,
+    0.199990689985694,
+    0.556609292016561,
+    0.36876371835676786,
+    0.4919328738624835,
+    0.6455341747069254,
+    0.5363109901581918,
+    0.6619673285957067,
+    0.593260576277707,
+    0.5204788224541296,
+    0.6897822040811378,
+    0.7140068277713849,
+    0.5346203971487639,
+    0.6002612942029938,
+    0.5935309928744557,
+    0.6185517532631013,
+    0.5819319380272585,
+    0.5837906251139707,
+    0.647286491061691,
+    0.5705536698482149,
+    0.6157179515777291,
+    0.5702266073708347,
+    0.6756377861513283,
+    0.679751813037546,
+    0.5653891167521186,
+    0.5155185798840398,
+    0.6468181994650123,
+    0.5944788148261232,
+    0.48723448760982613,
+    0.641477515347083,
+    0.6804027307354246,
+    0.6530623333735168,
+    0.5725220146668826,
+    0.6403774655603968,
+    0.6689080110665274,
+    0.5820020055976375,
+    0.6107021613680556,
+    0.4648384252837202,
+    0.6746841291727084,
+    0.5567102138958868,
+    0.6547370996122767,
+    0.5751680338373154,
+    0.6519530426286582,
+    0.6694545389508414,
+    0.7150153713124461,
+    0.5415005338784089,
+    0.4148762695917165,
+    0.6153802630787956,
+    0.6009637498352344,
+    0.5480375363748422,
+    0.693636887405821,
+    0.532592340809089,
+    0.6786020261001047,
+    0.46514648795763924,
+    0.6738455100659141,
+    0.6508918743066902,
+    0.6758166526593435,
+    0.6867481765021974,
+    0.6547138458498596,
+    0.523691812597478,
+    0.6144290043870569,
+    0.6049093481597944,
+    0.6348669112797363,
+    0.6231767785207071,
+    0.6192962359997416,
+    0.7258045873879824,
+    0.4817281275133185,
+    0.47465823195950657,
+    0.6472753372243732,
+    0.5870099940108353,
+    0.6898201023674968,
+    0.6544749988949041,
+    0.5471480764799848,
+    0.5391800973320078,
+    0.6669665064005297,
+    0.5184140550947833,
+    0.5908908400627642,
+    0.6024609807547542,
+    0.6544981019067347,
+    0.6790626138991146,
+    0.5656114697331452,
+    0.3797501281777845,
+    0.6667475927032223,
+    0.6002181973374925,
+    0.4494031551183409,
+    0.36571475443387275,
+    0.6506409922053388,
+    0.6886681790834523,
+    0.6055992433647401,
+    0.5058557607043812,
+    0.5769757543801289,
+    0.6507102238388907,
+    0.7310396844596938,
+    0.5351312890415706,
+    0.7199021265464488,
+    0.6594998542571269,
+    0.6404858681980092,
+    0.5909915803699073,
+    0.6165066811865075,
+    0.6206729524706647,
+    0.4647749866983587,
+    0.5179321785131509,
+    0.6750869315969309,
+    0.5512652203571891,
+    0.5921586773320767,
+    0.6481226360109317,
+    0.5573377001189481,
+    0.570925134348758,
+    0.4965972197983562,
+    0.5381715500902914,
+    0.597880951441604,
+    0.5171165326985097,
+    0.29994348162636353,
+    0.5262486555465142,
+    0.5044274675520231,
+    0.7204429354103419,
+    0.6135006253192293,
+    0.7128778452322199,
+    0.6822996734485051,
+    0.6263099072709333,
+    0.5597189021580645,
+    0.46276208089725435,
+    0.6620601627318291,
+    0.6557463233178229,
+    0.7153994188977494,
+    0.6097070270524368,
+    0.6629544609977454,
+    0.47644668194353107,
+    0.30987933393250466,
+    0.5224365465536758,
+    0.6743543202901079,
+    0.5808822374077564,
+    0.4429342352437822,
+    0.574703281333497,
+    0.49451030960830356,
+    0.5387878241634072,
+    0.549654934060824,
+    0.6039570955004961,
+    0.6065571917175648,
+    0.5227270145403721,
+    0.5834946858870744,
+    0.615702037272213,
+    0.4210272055675747,
+    0.7245564792724778,
+    0.5838678593703408,
+    0.6034346234292677,
+    0.548797719708782,
+    0.6158659067648824,
+    0.5383982461209155,
+    0.5425487666906746,
+    0.6401386407885185,
+    0.6965907179756483,
+    0.5625289379679024,
+    0.6043058835295441,
+    0.4915679880113526,
+    0.6204674417300365,
+    0.3926127375441499,
+    0.46320994058957793,
+    0.6692245376952592,
+    0.7369932933754765,
+    0.674718250749168,
+    0.5723473290286387,
+    0.5884864534979404,
+    0.6298166970372542,
+    0.5793053015549967,
+    0.6517299784290754,
+    0.5167180927954136,
+    0.6009029331484067,
+    0.6568652083193897,
+    0.6106249669228175,
+    0.6454873082357648,
+    0.5014133375168895,
+    0.6115657322786522,
+    0.5934268711043182,
+    0.6527014797530309,
+    0.6439822471791938,
+    0.423730110423649,
+    0.5734520522277882,
+    0.6413038497245365,
+    0.6050819772510272,
+    0.5282864453550892,
+    0.6727075270004673,
+    0.5399065578487273,
+    0.6206835231341198,
+    0.6367573500087806,
+    0.5979547482041048,
+    0.6726077777618961,
+    0.5385141304723724,
+    0.5742077860191297,
+    0.6057317848778231,
+    0.6074599606268506,
+    0.5068015200889775,
+    0.658218532083704,
+    0.5703747787450529,
+    0.7104363024575882,
+    0.6116315280018693,
+    0.6463758926780134,
+    0.522459115272225,
+    0.6903230071528741,
+    0.6255788816889701,
+    0.49297868097567915,
+    0.5550678589298554,
+    0.6608942392362493,
+    0.6614215195690952,
+    0.5942024502916683,
+    0.658296108512796,
+    0.5944674434218213,
+    0.56283220077597,
+    0.6490191386884466,
+    0.640871615677247,
+    0.5866862537509102,
+    0.5895289491633494,
+    0.57319309458995,
+    0.5412379394499217,
+    0.568967692714052,
+    0.48569714481605814,
+    0.5451329933406222,
+    0.6374879179790748,
+    0.622150024353383,
+    0.5959072236959309,
+    0.4712517983653638,
+    0.5736936621300889,
+    0.6039175086453521,
+    0.6080408827554781,
+    0.4564924474455062,
+    0.5907810812265323,
+    0.5909331175008128,
+    0.5892757488946365,
+    0.6129761537525099,
+    0.6240083844664163,
+    0.6488392502520808,
+    0.5619440386667289,
+    0.5989235622576318,
+    0.5656007552932044,
+    0.7230838469277733,
+    0.627522733060962,
+    0.5227432634451722,
+    0.6012850156264598,
+    0.5824665873209033,
+    0.6883600509727759,
+    0.6204871604858654,
+    0.625317706414758,
+    0.527515110707467,
+    0.5508723283945565,
+    0.5922163537788057,
+    0.4024821893875098,
+    0.619017986508359,
+    0.6828244330446266,
+    0.6480066259926486,
+    0.5735915141947838,
+    0.6770018321910554,
+    0.4825032483984771,
+    0.704588883829091,
+    0.6188816834188874,
+    0.6467442619512663,
+    0.6206496511250479,
+    0.5605938361663658,
+    0.5410085221544572,
+    0.3907385625743566,
+    0.5682821262511062,
+    0.5595883329838242,
+    0.580932307167642,
+    0.5338849746194174,
+    0.5830223402727728,
+    0.6160577488238271,
+    0.5214125879939486,
+    0.5686247640702202,
+    0.4518898953428198,
+    0.525508902225189,
+    0.41227739720082895,
+    0.667502118424473,
+    0.6508657505158438,
+    0.6372241107164766,
+    0.5704067914345308,
+    0.6735855356535849,
+    0.681652190412013,
+    0.4511137130088902,
+    0.6452300563200045,
+    0.6979149874953537,
+    0.6571191685677616,
+    0.6022486744988446,
+    0.5925876109800968,
+    0.6335322521790514,
+    0.6390671232513155,
+    0.63869517211287,
+    0.5436854286871423,
+    0.34703480032758505,
+    0.6509208913950558,
+    0.6263912068302503,
+    0.513643962421305
+  ],
+  "M16": [
+    0.24559854808045636,
+    0.36889516779149506,
+    0.3722248226468796,
+    0.1343572516342854,
+    0.3772817325048669,
+    0.28451940947033594,
+    0.41788314091416623,
+    0.3600947255100485,
+    0.3348134561052426,
+    0.3107709936422017,
+    0.2937240499010467,
+    0.2761709873183967,
+    0.3625090856709777,
+    0.2902277429071791,
+    0.3053832590897105,
+    0.27221767253470436,
+    0.4106194070235196,
+    0.3617991351769279,
+    0.4935635117323147,
+    0.34644806752005347,
+    0.30140922137495985,
+    0.351546543927618,
+    0.3008072179065003,
+    0.3165708525911809,
+    0.32486821927180076,
+    0.4226576760869853,
+    0.14851125015945993,
+    0.2779065461758939,
+    0.3418981333280923,
+    0.40788752208687373,
+    0.3388596696914611,
+    0.37713663161653277,
+    0.28669124323643547,
+    0.23750722574461838,
+    0.3043101744630667,
+    0.47546137918823955,
+    0.2859502517827552,
+    0.4624769470804351,
+    0.3012458548033251,
+    0.280986772244138,
+    0.3472100075485469,
+    0.4295935523478827,
+    0.6892383140765298,
+    0.3578383138201525,
+    0.32119512190853017,
+    0.34293463036360494,
+    0.24769730575174073,
+    0.2697045526108808,
+    0.26614834537637,
+    0.4366379864066644,
+    0.28998350079077495,
+    0.26700993373649695,
+    0.27438620451733536,
+    0.17145260105755494,
+    0.3396920032917318,
+    0.4277720399533116,
+    0.21815785111813307,
+    0.19878493050840101,
+    0.46102123244748616,
+    0.4198771455655124,
+    0.213612824718664,
+    0.29279589405848505,
+    0.3447017613926692,
+    0.33094731344210193,
+    0.2272599508344678,
+    0.2998913541376938,
+    0.31211457448828456,
+    0.2863161609197477,
+    0.27879194170079424,
+    0.5572976132286779,
+    0.4215108704719171,
+    0.28313340034289514,
+    0.38741902952422747,
+    0.37806581664408806,
+    0.32886604736478886,
+    0.5476814445313526,
+    0.4029637544445844,
+    0.26180173724041433,
+    0.3205628993183914,
+    0.2591692746147817,
+    0.2385740671967572,
+    0.3151989279600188,
+    0.3101019886468593,
+    0.11442855106443857,
+    0.2377726778990688,
+    0.33443653487799974,
+    0.3609351229020093,
+    0.28284100832221254,
+    0.41363874025639963,
+    0.3407253837404883,
+    0.26795039013114424,
+    0.3941939859581481,
+    0.41098922936892,
+    0.3742791208065366,
+    0.45169094412629146,
+    0.26619590970515045,
+    0.4726260089517479,
+    0.33552591316959346,
+    0.33602666809266524,
+    0.25459574167501,
+    0.3269623800448926,
+    0.1640493539939473,
+    0.25936811667599013,
+    0.25777388430182857,
+    0.5173115823002188,
+    0.16435031119324525,
+    0.3689021332555746,
+    0.2556194375986256,
+    0.25075969336843257,
+    0.4191988605262225,
+    0.25984840750621585,
+    0.41296127991345744,
+    0.280591831004086,
+    0.35570545749194454,
+    0.34605257126695044,
+    0.41192426545844757,
+    0.44008383776257237,
+    0.3475369960417463,
+    0.14507264747241969,
+    0.37374363912287456,
+    0.4077538374850213,
+    0.37788217748372666,
+    0.5423307322011282,
+    0.35378851295289887,
+    0.3211032350048388,
+    0.287899558051686,
+    0.3411686104356778,
+    0.24241782080087995,
+    0.3870761781856999,
+    0.30541138387751426,
+    0.4299015565373666,
+    0.21326941080186113,
+    0.38344234711011355,
+    0.37263203632538927,
+    0.3137424334374392,
+    0.3764738302112773,
+    0.29157958329346106,
+    0.5151321097921688,
+    0.4414425546402371,
+    0.3350654286220695,
+    0.3350665453941376,
+    0.34321460712679797,
+    0.34288658782989806,
+    0.3677396316538385,
+    0.3390508217492833,
+    0.31471375995599865,
+    0.4087320351181847,
+    0.3842445688166222,
+    0.19714985775373403,
+    0.24608366564918932,
+    0.451026633928712,
+    0.2797293199929661,
+    0.21635277847198292,
+    0.25608616153446506,
+    0.4315933545806275,
+    0.467624824102055,
+    0.37915624485788896,
+    0.3453134913911158,
+    0.3960249116285141,
+    0.4126815735521172,
+    0.4313523301584386,
+    0.2842569213461532,
+    0.31835123342935273,
+    0.2716573481890679,
+    0.26067269672837756,
+    0.3486458815093957,
+    0.24839648414014132,
+    0.1454015632246238,
+    0.22659620554986865,
+    0.2726534720287703,
+    0.2851194659857768,
+    0.3445254741046277,
+    0.42357688682617844,
+    0.3393914432212559,
+    0.4261413191800939,
+    0.56846667519333,
+    0.2833535843690655,
+    0.4120938337764317,
+    0.2611648919319179,
+    0.3557961243863275
+  ],
+  "M03": [
+    0.21061811022493282,
+    0.2851749701818295,
+    0.37724287573443227,
+    0.17074102932809612,
+    0.4281108113224036,
+    0.29633261040628317,
+    0.4053579926894068,
+    0.3455649478594779,
+    0.3669283898755192,
+    0.266340499781367,
+    0.2589537610248358,
+    0.37570392250925205,
+    0.3850816116799112,
+    0.3847169331241772,
+    0.2863493004876322,
+    0.4560976367360769,
+    0.4808689834363382,
+    0.4286171199480147,
+    0.4961403741232553,
+    0.4251008806779355,
+    0.27973851883935896,
+    0.29466241998877213,
+    0.31624945126920717,
+    0.3736880600353068,
+    0.26266262520134587,
+    0.46498435546440325,
+    0.2628676781556644,
+    0.28703171964284163,
+    0.5196056114963468,
+    0.39696563374903526,
+    0.375350182272588,
+    0.5365847955105624,
+    0.33250189331415575,
+    0.22088697663768672,
+    0.40322793407102914,
+    0.49766727624014406,
+    0.3039503173875011,
+    0.47400468496410453,
+    0.2593650590142597,
+    0.4082338255941298,
+    0.4394975079111227,
+    0.3582708668506466,
+    0.6889756899952764,
+    0.4032282631014676,
+    0.3305770353412347,
+    0.43522439619339337,
+    0.34980681762222154,
+    0.2255047725356273,
+    0.33116108444724895,
+    0.32777469153606237,
+    0.28386026201628856,
+    0.3225058261228883,
+    0.27107551139648944,
+    0.33386303391463584,
+    0.3880941753834651,
+    0.4653080993017285,
+    0.26780885449342906,
+    0.3146989280789106,
+    0.5283683134635125,
+    0.43157709684014745,
+    0.31892070756218244,
+    0.30975642889524346,
+    0.37317981740287726,
+    0.2670716962342278,
+    0.3237220357468844,
+    0.31665074250017655,
+    0.3731984794726475,
+    0.2922363740449288,
+    0.28606718356085764,
+    0.5299138942505508,
+    0.35349620759539163,
+    0.3436866776538976,
+    0.34730881032018185,
+    0.38226041088446233,
+    0.4094491101856277,
+    0.5809182389101927,
+    0.4655628380448651,
+    0.3074118446147375,
+    0.39510697393998007,
+    0.3007264508184661,
+    0.32720627706879823,
+    0.3289965495677367,
+    0.31532545918385607,
+    0.2684076634906617,
+    0.25148748988693914,
+    0.4467995595173286,
+    0.3768392031467792,
+    0.3255468494711656,
+    0.4581959093593773,
+    0.35401712530137,
+    0.35536866193589145,
+    0.4025226069397994,
+    0.41452439320215906,
+    0.4058135955696804,
+    0.4759155008119471,
+    0.24545747800699466,
+    0.5790616240484284,
+    0.4051876703287796,
+    0.33457172942767605,
+    0.4162559189535069,
+    0.34076482506326966,
+    0.30542704022616785,
+    0.25120615450703276,
+    0.3549126852968024,
+    0.5473278673338908,
+    0.34112303173332975,
+    0.3644678940596407,
+    0.289684736080765,
+    0.26214845563921846,
+    0.5238027710554023,
+    0.25462536316957485,
+    0.3384389746655403,
+    0.14833929101999047,
+    0.38069014873624485,
+    0.335636468253029,
+    0.4368969082524826,
+    0.4633756175780339,
+    0.38116916969852727,
+    0.23788176761253343,
+    0.3622192981675603,
+    0.5235132910536661,
+    0.46366765608503213,
+    0.47082133729918724,
+    0.352049702419319,
+    0.34316531570840725,
+    0.3025726083398,
+    0.3545471835673699,
+    0.2835467333906316,
+    0.4503209650676607,
+    0.4321371499497518,
+    0.4580629313411919,
+    0.2247345960091919,
+    0.4151154899396002,
+    0.30954420759480267,
+    0.3563052626710376,
+    0.4842851153919581,
+    0.3179770946199796,
+    0.5732202124245163,
+    0.5207854812014919,
+    0.3779057847263672,
+    0.37860212671899823,
+    0.4378115512270953,
+    0.3271169613982536,
+    0.39793837263354936,
+    0.32930249772612824,
+    0.2730334143782824,
+    0.4694959566328743,
+    0.3487962915480526,
+    0.2772788299339163,
+    0.2539045838174168,
+    0.48282373667802,
+    0.3167345241506125,
+    0.3462233984601908,
+    0.2904421090619352,
+    0.4762488373607247,
+    0.5233805859127508,
+    0.39584893973656077,
+    0.347264855820184,
+    0.3096100079154091,
+    0.48400956857637795,
+    0.5492735782427643,
+    0.30100036758528864,
+    0.3690981770455593,
+    0.27816052954674036,
+    0.25179906626779497,
+    0.37238723292101317,
+    0.30584530254906456,
+    0.20043011865025367,
+    0.2749598040230471,
+    0.24686687899340093,
+    0.34795811225314877,
+    0.39234018085398914,
+    0.47038902900580076,
+    0.36331446698959335,
+    0.4959251477583112,
+    0.6233919793070778,
+    0.3269323720201891,
+    0.32561368166880206,
+    0.2787617591690825,
+    0.40968838453350914,
+    0.6428995353772645,
+    0.6908899300325487,
+    0.6091473300019595,
+    0.6703643975205631,
+    0.7147197419035117,
+    0.6901878652063317,
+    0.43588694829699115,
+    0.41142966190892843,
+    0.6923247364718527,
+    0.4990901017217193,
+    0.5664559978146229,
+    0.7559283808489898,
+    0.6760666990774816,
+    0.6515257927973298,
+    0.6468822175361167,
+    0.6630980114951031,
+    0.6006839028226821,
+    0.7204494894047346,
+    0.6382467786701065,
+    0.5935312986517058,
+    0.6535438356218962,
+    0.5614694540214661,
+    0.7315330103705261,
+    0.6976393478345266,
+    0.6759254128442735,
+    0.6251441850956457,
+    0.6375863988981546,
+    0.5833223117057654,
+    0.7217936037852557,
+    0.49825874640963214,
+    0.5774166647604129,
+    0.6900989134636598,
+    0.6399910496198468,
+    0.7207459456883784,
+    0.6487256153496378,
+    0.6656903120042146,
+    0.5587857875017954,
+    0.6750485646963729,
+    0.4872148229961766,
+    0.2627030555015891,
+    0.4412185450853599,
+    0.7320350169933767,
+    0.6232152722733876,
+    0.6004310350096812,
+    0.7514097553186324,
+    0.6136021056746074,
+    0.6563819920821138,
+    0.6580423870158213,
+    0.3802626558848262,
+    0.5608675734754872,
+    0.5449730900182655,
+    0.7041362388539683,
+    0.5929582665518689,
+    0.7013788916011171,
+    0.7414135636813551,
+    0.72114399429232,
+    0.5192814500142924,
+    0.47967985777362565,
+    0.5504654086973358,
+    0.47076921055933546,
+    0.5633375047545235,
+    0.6811506523630496,
+    0.5532099890250067,
+    0.397819356566716,
+    0.6596596157801499,
+    0.6427927231939986,
+    0.5974413109175825,
+    0.6200298333787416,
+    0.6338469609435493,
+    0.6576725349164843,
+    0.6067198484116002,
+    0.5151005138516858,
+    0.6476704737471894,
+    0.5246653913801727,
+    0.33471552870306176,
+    0.5008328032800397,
+    0.6149252880100518,
+    0.6159238554574111,
+    0.6621793004330958,
+    0.6568039922221555,
+    0.6150767097763629,
+    0.6980986254034537,
+    0.6621608736102288,
+    0.5781365385347994,
+    0.6688373449383012,
+    0.7162298011504965,
+    0.7125802374479073,
+    0.6332715804795186,
+    0.6456867246595899,
+    0.6248076426607956,
+    0.5928021603589686,
+    0.6757677468674094,
+    0.6693671481669687,
+    0.7467329729662728,
+    0.7431204472375378,
+    0.6854339384577027,
+    0.5889760060868164,
+    0.6413110132695415,
+    0.646098007892657,
+    0.6938103707615682,
+    0.6407394235696576,
+    0.6595801288238612,
+    0.5586124257437232,
+    0.72702169334407,
+    0.5773512414850521,
+    0.5750152853029581,
+    0.7143589518289135,
+    0.6578888752673321,
+    0.6346030541865579,
+    0.6256943915702199,
+    0.7064040122584256,
+    0.621945266485449,
+    0.37917126278904356,
+    0.5915237536219164,
+    0.46961208567050605,
+    0.47226202119596944,
+    0.5671847707690321,
+    0.595419926988668,
+    0.6217396001067266,
+    0.5593121170179021,
+    0.3698055297954015,
+    0.5988196319319598,
+    0.5653255141371029,
+    0.6484243008033947,
+    0.713183639719571,
+    0.6955958457918842,
+    0.5814897938759956,
+    0.593968214686417,
+    0.6866787860805419,
+    0.5663637468250968,
+    0.6767641361557595,
+    0.6826232004452395,
+    0.5954310009733206,
+    0.6313745354083825,
+    0.7086340758710213,
+    0.6963929129577877,
+    0.6790048263842495,
+    0.6859348259574545,
+    0.6967762432569758,
+    0.6797696309688518,
+    0.6870642499231909,
+    0.5648358711587631,
+    0.6467707483184033,
+    0.3681179842674405,
+    0.5925832661179312,
+    0.639704792295688,
+    0.6391683743014295,
+    0.6808398332427933,
+    0.6586510942627499,
+    0.6045797376365134,
+    0.5696471714467507,
+    0.6966110910699426,
+    0.5501050939422619,
+    0.6632743534747692,
+    0.5677069249157942,
+    0.4640050099805049,
+    0.6320305510954722,
+    0.6226623865990631,
+    0.7292800349689124,
+    0.5923603667518187,
+    0.6904390681328425,
+    0.5646299974269859,
+    0.5852040494012161,
+    0.5852950922578543,
+    0.5842668831185251,
+    0.6476237476481177,
+    0.5816110630313789,
+    0.6155317905859586,
+    0.5237571262742095,
+    0.6460715308635393,
+    0.49891721668943256,
+    0.5570031848413811,
+    0.6889586755186325,
+    0.5602599353736073,
+    0.4855521657368785,
+    0.6711818463909948,
+    0.6399285616920203,
+    0.5136984343720835,
+    0.5120273917368103,
+    0.6665329319622445,
+    0.705098418858185,
+    0.7226904145037304,
+    0.5954448930682844,
+    0.45918970076037297,
+    0.5610579015509009,
+    0.3823154505663267,
+    0.5043568312405367,
+    0.5671325647202156,
+    0.5615511696690436,
+    0.6378344467186525,
+    0.634912244972641,
+    0.7071831909876526,
+    0.6777354931564444,
+    0.6839512098851912,
+    0.5899828944255283,
+    0.5924981433094173,
+    0.673041116235417,
+    0.6035794462774191,
+    0.7057398781223185,
+    0.6919818152850238,
+    0.5811312848389529,
+    0.5700687280519664,
+    0.610111435306517,
+    0.42127281578148496,
+    0.6873948945904238,
+    0.5630687297005509,
+    0.6398145200789885,
+    0.6310652324970962,
+    0.6302821064682312,
+    0.6392655535009776,
+    0.645617129576755,
+    0.5187331533349597,
+    0.4339857524317273,
+    0.484544194758609,
+    0.6514617251877522,
+    0.6029065493810336,
+    0.6990777735406483,
+    0.6639957590860767,
+    0.6135293624059742,
+    0.7662911814968295,
+    0.6388614385512108,
+    0.6314876343813794,
+    0.5907180956206707,
+    0.5519806453089088,
+    0.49233351528328095,
+    0.5025168916662766,
+    0.5416008892223317,
+    0.6277001407449865,
+    0.49775287361300435,
+    0.46088370256994277,
+    0.6776888479664201,
+    0.4790715369944068,
+    0.5166622155906679,
+    0.6368684754113382,
+    0.6674573896386619,
+    0.6201410967297777,
+    0.7361409902944926,
+    0.5707125557148954,
+    0.6306969392896524,
+    0.5894743572850318,
+    0.5330098141528506,
+    0.6078356289193546,
+    0.5730391143910785
+  ],
+  "M06": [
+    0.21154410805464777,
+    0.3871488051408393,
+    0.2870680298189898,
+    0.20891195151739214,
+    0.4441720643312028,
+    0.2170326768904517,
+    0.41348391584394517,
+    0.38482278171957723,
+    0.3863058119990857,
+    0.3377128344388274,
+    0.29766508273726816,
+    0.3073024796074453,
+    0.3738265314014364,
+    0.37546615533314237,
+    0.30988432307715896,
+    0.40285624792784036,
+    0.5447038434369721,
+    0.35087226573843455,
+    0.5130673050057527,
+    0.4173819648761111,
+    0.2779079950580144,
+    0.3439213465905077,
+    0.2778782861481663,
+    0.2745729399559976,
+    0.3332339170219366,
+    0.3797965574193311,
+    0.20065392194081344,
+    0.26325360776187817,
+    0.4477669141858903,
+    0.37066978229569336,
+    0.3863168092349529,
+    0.3701708194998715,
+    0.30293095784522417,
+    0.25335888452674243,
+    0.3923130039903059,
+    0.43769338965617693,
+    0.20517730353794847,
+    0.4286471215840796,
+    0.40750065204477515,
+    0.4068110789948963,
+    0.3881545051172085,
+    0.4578821202501249,
+    0.6837585817719395,
+    0.3909462832196139,
+    0.3540806176604743,
+    0.40478211340116116,
+    0.2895732255759621,
+    0.2527785961743129,
+    0.2861356149536676,
+    0.4511825439505355,
+    0.2859236364026415,
+    0.35182910186651306,
+    0.27940476005454423,
+    0.297701627891853,
+    0.3649670412831275,
+    0.31641884153054806,
+    0.26312343085696693,
+    0.33714302400569934,
+    0.4316625475033395,
+    0.2973900668979287,
+    0.31699602221039497,
+    0.31678322539060394,
+    0.41940741525898917,
+    0.37009879302909293,
+    0.23398772716451172,
+    0.2463596219851985,
+    0.3376310669897255,
+    0.26629038420842127,
+    0.28995339405684,
+    0.5427341744697555,
+    0.39365081672310803,
+    0.32703532723389644,
+    0.399776802104173,
+    0.3719195017586819,
+    0.4454331733279235,
+    0.4367832949698158,
+    0.4601688185531274,
+    0.28622449586604864,
+    0.3883098674443091,
+    0.3014721142637465,
+    0.2845803652954833,
+    0.3195463181215058,
+    0.2641987179691857,
+    0.2630841271625722,
+    0.24276486676958584,
+    0.34375528925731624,
+    0.3739893442176544,
+    0.307169028826781,
+    0.4174989607816566,
+    0.31811752015428685,
+    0.3136584602542619,
+    0.5201265815031804,
+    0.3797855051798778,
+    0.3995296444451531,
+    0.4254172634850456,
+    0.2823771937274111,
+    0.5122276118228004,
+    0.3601249831404163,
+    0.3257590825876797,
+    0.3226884453933702,
+    0.3565956848680913,
+    0.2605958090941156,
+    0.1550743634915599,
+    0.31500202011607203,
+    0.5395129335189794,
+    0.289281819221877,
+    0.3949412815291584,
+    0.286787589829569,
+    0.18809792364531328,
+    0.4231992879079218,
+    0.32554404984640817,
+    0.38704821348720747,
+    0.289544633093406,
+    0.36295025984173335,
+    0.2793338024489124,
+    0.3045612736680238,
+    0.43299024092040195,
+    0.32429568446906704,
+    0.18508547162358846,
+    0.36408785544451244,
+    0.4746998395297795,
+    0.3872130512841527,
+    0.47281799044889494,
+    0.35658698085340684,
+    0.29928375555444925,
+    0.3029424151778667,
+    0.41275976902226647,
+    0.2601936088190723,
+    0.4493225092067403,
+    0.38003763740315466,
+    0.44203464275752635,
+    0.09936525778346068,
+    0.43795804871745614,
+    0.28455012973351124,
+    0.3754286508799701,
+    0.3783576874655496,
+    0.38216775433610395,
+    0.4713781406912754,
+    0.45607337960066324,
+    0.30727262213229956,
+    0.31444344436563165,
+    0.31832945691737397,
+    0.35967124354276137,
+    0.3973507644036665,
+    0.3493921493935788,
+    0.22382564690515944,
+    0.4212756799310407,
+    0.3130966171828075,
+    0.20817104611289597,
+    0.27699263049907,
+    0.4635489979666055,
+    0.32893933015694465,
+    0.35379905519498994,
+    0.24424437382068634,
+    0.33707690428226983,
+    0.49392037177144354,
+    0.41096569827418494,
+    0.39776227574333206,
+    0.4373459140760273,
+    0.326612957664806,
+    0.45930685533982674,
+    0.2832880860267311,
+    0.34143310750324635,
+    0.260870265031748,
+    0.19534818082100996,
+    0.3809477388101869,
+    0.2528284631405488,
+    0.2131043424515344,
+    0.21172412881303182,
+    0.2695793678916191,
+    0.2883270739294583,
+    0.267162447490981,
+    0.3678072683881453,
+    0.3350832290656565,
+    0.4738254584674461,
+    0.5976157861194198,
+    0.33173771024152426,
+    0.4772280723365545,
+    0.2905948196434259,
+    0.366322803685807
+  ],
+  "M10": [
+    0.24856056340712138,
+    0.38593593007302707,
+    0.31257257487438533,
+    0.13612848838477334,
+    0.3898021326846306,
+    0.2600971058204065,
+    0.3970537275064799,
+    0.3920219235015452,
+    0.3313323909066825,
+    0.3459412549671728,
+    0.26088052479023816,
+    0.340446258395375,
+    0.36306120387783175,
+    0.32020905190668436,
+    0.2628406241895553,
+    0.41998106550129527,
+    0.5793501904485645,
+    0.3908188650656767,
+    0.4935516800509545,
+    0.3879159593445862,
+    0.2996877525070279,
+    0.3223281149628985,
+    0.28872085417886517,
+    0.31611517359123603,
+    0.24783771040437186,
+    0.32933009694683946,
+    0.24524955874675447,
+    0.2888905189600873,
+    0.4589484475859481,
+    0.43507220723086343,
+    0.36029187205577273,
+    0.37584163574491064,
+    0.33917637049364213,
+    0.23745560022096843,
+    0.3576051591375212,
+    0.4382700538832432,
+    0.2632977670240554,
+    0.45526536857140254,
+    0.37597171057070206,
+    0.3594558824668561,
+    0.42810534829623414,
+    0.3544665622146379,
+    0.5407253070875886,
+    0.38353684905181307,
+    0.24219877918569732,
+    0.40047837551897153,
+    0.3252880067909847,
+    0.24405546659420568,
+    0.2721447620777869,
+    0.2691108220741148,
+    0.27281154835367444,
+    0.3219553355172009,
+    0.2907032189988272,
+    0.2079874340561327,
+    0.3559500266081253,
+    0.42182062576576057,
+    0.30048836773095644,
+    0.35380373312266267,
+    0.4155281820511867,
+    0.4061648813268678,
+    0.29987897084490306,
+    0.1849216999983475,
+    0.41839784070892133,
+    0.2711216629462497,
+    0.3019625373581178,
+    0.33146168170404633,
+    0.3593268611390316,
+    0.31218624797575417,
+    0.26290060177397473,
+    0.5847436156797475,
+    0.4492507287435623,
+    0.328800106635956,
+    0.4028719042170041,
+    0.3725725384838031,
+    0.42496662818637587,
+    0.5160003648815927,
+    0.4311430754105052,
+    0.2720031243017686,
+    0.33953665700771135,
+    0.275979469250352,
+    0.30922770755593626,
+    0.19890820351542554,
+    0.26160172225766337,
+    0.24535366497795585,
+    0.282541156915919,
+    0.37870690462986406,
+    0.30098603552390674,
+    0.3121232427033076,
+    0.40396861298457265,
+    0.27074646204542907,
+    0.3455186693278939,
+    0.513770534889693,
+    0.368840142524328,
+    0.3629169163730263,
+    0.5483009227503706,
+    0.28697977494654053,
+    0.35459666873398304,
+    0.3643316725990666,
+    0.23529323924922926,
+    0.3029459941329086,
+    0.2841390462772743,
+    0.25189469608809123,
+    0.26534458501934327,
+    0.35101013482965465,
+    0.5130186829264369,
+    0.29051184733989427,
+    0.3833942832829036,
+    0.23565978493169185,
+    0.2066432167005972,
+    0.5020773328132976,
+    0.22314251952001363,
+    0.41029298464885466,
+    0.21217138601447727,
+    0.30516352060251184,
+    0.33891642458402,
+    0.35483029166680347,
+    0.4481531048866937,
+    0.35934915809472917,
+    0.1776905946647411,
+    0.28469086806143606,
+    0.42632532163681985,
+    0.4377829149966384,
+    0.555528328462518,
+    0.32145017268290377,
+    0.3322139880647244,
+    0.21525261890063946,
+    0.39968794054630713,
+    0.30020613813857955,
+    0.29448934017153844,
+    0.36522505820083984,
+    0.4321969834947136,
+    0.10123089480355967,
+    0.3714515721227652,
+    0.36517528908928426,
+    0.25604742368547817,
+    0.45981251457539013,
+    0.36972652734383465,
+    0.42667624903056117,
+    0.472596438859065,
+    0.24748386602878156,
+    0.2743368164539331,
+    0.3692350774300784,
+    0.381172518452687,
+    0.349985044374641,
+    0.3335207201613608,
+    0.2906352271427782,
+    0.46432846909718145,
+    0.38584131316555575,
+    0.14508791507604865,
+    0.27140641286118217,
+    0.4745047254052711,
+    0.3217912865202847,
+    0.3460010942202927,
+    0.19007031594865567,
+    0.45110026892582794,
+    0.4682753380979885,
+    0.31695105650016303,
+    0.33192641761808206,
+    0.280800737970518,
+    0.39828980328610636,
+    0.4498480818513006,
+    0.27731543085345756,
+    0.34744137402947484,
+    0.20874528433465478,
+    0.17766416628147097,
+    0.3644804333079641,
+    0.27273690062901856,
+    0.17697740725358124,
+    0.22989046219395382,
+    0.26778216253219733,
+    0.3081874297680655,
+    0.3635876356016012,
+    0.46577341338873796,
+    0.334637842944364,
+    0.4804182790651328,
+    0.5780882168061241,
+    0.3107627757412381,
+    0.4350360643151633,
+    0.28900963537756946,
+    0.38361832880111846
+  ],
+  "M04": [
+    0.177105158146608,
+    0.37860306025951884,
+    0.3821929338713624,
+    0.10181606970432891,
+    0.367358963161647,
+    0.292028693926145,
+    0.29481175358687156,
+    0.3685004820225463,
+    0.3499364382506618,
+    0.31678705136258717,
+    0.2785599550800788,
+    0.3331814596810362,
+    0.3419527730639281,
+    0.27119169951188726,
+    0.31239907241363296,
+    0.3513396745111547,
+    0.5545232128950663,
+    0.3221913255294795,
+    0.45649407592029684,
+    0.3790144092668351,
+    0.31688868299299217,
+    0.21490874410727911,
+    0.21421674503577728,
+    0.35885348228576325,
+    0.3293489013178105,
+    0.30386507921067407,
+    0.26354370003059285,
+    0.19496522679071648,
+    0.37482317830260053,
+    0.22523800652545467,
+    0.36868353897056877,
+    0.5132371646362242,
+    0.3250243481336556,
+    0.20996239345980677,
+    0.39116624854256704,
+    0.4368075177776379,
+    0.29522070709445225,
+    0.37013704966550204,
+    0.36342339885049935,
+    0.4173226621904477,
+    0.3526232681586477,
+    0.4441653876249909,
+    0.6813089405526961,
+    0.39775778032870196,
+    0.2989245293178056,
+    0.3770759418121449,
+    0.257875174158875,
+    0.2657887399028713,
+    0.28604946295217687,
+    0.3350896740302183,
+    0.2801844544169058,
+    0.3104666012578903,
+    0.2742451730572879,
+    0.2481409882293654,
+    0.3644729542077482,
+    0.4483756407241762,
+    0.26752705493036844,
+    0.33537003666329884,
+    0.5067478221020983,
+    0.25944729098894675,
+    0.3052545328138779,
+    0.2436972935296724,
+    0.3782028981241331,
+    0.3364695617725939,
+    0.2938589116108957,
+    0.33648068430293226,
+    0.37450659082120047,
+    0.26121338930094173,
+    0.18330740357320283,
+    0.5380883666583828,
+    0.44337375665681317,
+    0.3298587064540368,
+    0.38089561485753975,
+    0.36557667596004384,
+    0.3932364774421919,
+    0.5562970219616878,
+    0.4544807773154418,
+    0.28473480473173984,
+    0.3104875215740471,
+    0.3224519700287412,
+    0.26247264504714296,
+    0.24409547554073033,
+    0.28656537666691834,
+    0.2704185225907736,
+    0.26475544203541945,
+    0.42871779232323765,
+    0.37712509340920647,
+    0.3214818814213785,
+    0.3879906414832321,
+    0.2580837110378713,
+    0.3427845892007087,
+    0.5243192408912994,
+    0.3980993669397593,
+    0.4160982041441324,
+    0.40760769357959037,
+    0.3013069588113057,
+    0.5490616758446605,
+    0.36008207578385365,
+    0.24588642162048013,
+    0.406996213051839,
+    0.35394772403923536,
+    0.31020321241049426,
+    0.2578160032755362,
+    0.35672167545075234,
+    0.5314304153073071,
+    0.3493329314928689,
+    0.18950070090618124,
+    0.2862020896615474,
+    0.2624840379769226,
+    0.5063820057793936,
+    0.2871522947933386,
+    0.41145807916136096,
+    0.2514838666468565,
+    0.35736504167895217,
+    0.28788528585420997,
+    0.44105937108903687,
+    0.43326200045114516,
+    0.2638858733775115,
+    0.2273085488935159,
+    0.38927352859368863,
+    0.4974198096513934,
+    0.2706982848069851,
+    0.5635725130180876,
+    0.36443096829429705,
+    0.23680829245116497,
+    0.30457614342122213,
+    0.3940699922451069,
+    0.1620829129631956,
+    0.37848110086835046,
+    0.42050212106517426,
+    0.421339976657918,
+    0.24159104047803906,
+    0.39938971026411935,
+    0.29219630195086066,
+    0.36808131182632164,
+    0.4654936696836831,
+    0.3002293414451174,
+    0.5077403908311275,
+    0.4904369602248754,
+    0.35277322701541947,
+    0.3092313708084841,
+    0.41878335266418176,
+    0.34524410485241236,
+    0.21857904537419592,
+    0.346577908449651,
+    0.1610229040966561,
+    0.5037263567203507,
+    0.34939190292921585,
+    0.2370272559195984,
+    0.261135746631501,
+    0.41184405719695727,
+    0.2807470277818158,
+    0.355152934847826,
+    0.29313548792241656,
+    0.24665117854911636,
+    0.3987627570816059,
+    0.41374743364278926,
+    0.3958348936296642,
+    0.40542737432900827,
+    0.45404854764005065,
+    0.4360758718934947,
+    0.29057704436438003,
+    0.2943282441727425,
+    0.29070010528112955,
+    0.15362501230465916,
+    0.256481546049441,
+    0.21651183123742235,
+    0.21979250056132676,
+    0.25696447830090224,
+    0.2607169679542265,
+    0.32226295075128797,
+    0.308166909764297,
+    0.43404103098438246,
+    0.3027824961957274,
+    0.46381493662944473,
+    0.5870301624093989,
+    0.3003041439225252,
+    0.3347520768940701,
+    0.2686215124103944,
+    0.26641057480149277,
+    0.666789835045993,
+    0.5450465778272,
+    0.6477663878258385,
+    0.5204069337962677,
+    0.5050351391584786,
+    0.5367816146514187,
+    0.5729331134490204,
+    0.6315709323086397,
+    0.5510068405515092,
+    0.42465194985755705,
+    0.43182062691495693,
+    0.5988484224924474,
+    0.6479166855417975,
+    0.6341437746838714,
+    0.5202100606956256,
+    0.5790508720837183,
+    0.6894084958988046,
+    0.6541557690403563,
+    0.6251841347209636,
+    0.5271534453494358,
+    0.6562029008663688,
+    0.4050602823185937,
+    0.56089072164881,
+    0.6028697177701788,
+    0.6122044129091113,
+    0.5772722330881292,
+    0.5686630464709254,
+    0.6506476108022266,
+    0.7063337993766378,
+    0.4641786441777613,
+    0.5891961695404948,
+    0.6309987779598966,
+    0.5618016205660817,
+    0.5046892336347057,
+    0.5937460251601535,
+    0.4506716497980958,
+    0.6855960459685991,
+    0.6594867308468914,
+    0.6169827092876434,
+    0.6397367667223741,
+    0.532176808942572,
+    0.5664585251963125,
+    0.5142875066849615,
+    0.6227556684969356,
+    0.6213498746918185,
+    0.5849823583662961,
+    0.6209340543416062,
+    0.57777117442266,
+    0.6492523714167533,
+    0.5478876805775734,
+    0.553728481561265,
+    0.6745090073600267,
+    0.6364762303551931,
+    0.6496096187715528,
+    0.6317961490946915,
+    0.5450475463905347,
+    0.5107170534648282,
+    0.4486650700624311,
+    0.546588446265295,
+    0.7193763976364376,
+    0.6880986048817529,
+    0.7104525835017359,
+    0.6937712716390624,
+    0.6043659221042023,
+    0.6696751250574691,
+    0.6140973078869859,
+    0.559713949316321,
+    0.5214771275208941,
+    0.6782643225583479,
+    0.6487064426998453,
+    0.6212338243486629,
+    0.58293728418367,
+    0.5997367534227132,
+    0.5757165977048151,
+    0.5636570203738853,
+    0.6261546597910405,
+    0.5481191423481956,
+    0.6412971601559064,
+    0.5560846793110701,
+    0.6957392982028653,
+    0.4995358108831462,
+    0.5602063625743271,
+    0.754584344450249,
+    0.6384484958242531,
+    0.6397559147887559,
+    0.47043351831854496,
+    0.5537507630210277,
+    0.5865807652972507,
+    0.6463096906597755,
+    0.594979721865826,
+    0.5959502753218866,
+    0.6365888928817803,
+    0.6841108893806479,
+    0.6150456793614477,
+    0.6222777370247694,
+    0.44337258194130896,
+    0.5948430992251089,
+    0.6474504222310008,
+    0.6198535768076964,
+    0.6513977786127649,
+    0.5308198330672634,
+    0.6542759043816146,
+    0.6328025233308254,
+    0.6396477266915279,
+    0.589579559787317,
+    0.6520503604054876,
+    0.6855898939065147,
+    0.44736920827784443,
+    0.6184369575245312,
+    0.5427049018105069,
+    0.5849860535461259,
+    0.7152370875283117,
+    0.6071263038832032,
+    0.5370239260309269,
+    0.5762789415628508,
+    0.5933336389471588,
+    0.6790011308489825,
+    0.5642575794784171,
+    0.5522315404451056,
+    0.5801529686302646,
+    0.6051434519162601,
+    0.6257924037770121,
+    0.5383259747257388,
+    0.5617883694165534,
+    0.6793849545224837,
+    0.719153959047833,
+    0.5708363258307987,
+    0.6148661558178014,
+    0.520111114829089,
+    0.5744065888411264,
+    0.5729881045596844,
+    0.5933725417124485,
+    0.5554113435821185,
+    0.5567115127004519,
+    0.6484991579535908,
+    0.6002153157854203,
+    0.6312221943699358,
+    0.6288255690939185,
+    0.6795746140046964,
+    0.5789137363156387,
+    0.5509885990401318,
+    0.6797385438032296,
+    0.6666303929557724,
+    0.6377313946775459,
+    0.7056660499081964,
+    0.5283718826726373,
+    0.629303880738502,
+    0.6605548246892552,
+    0.6545039192880234,
+    0.6326304088936218,
+    0.6884807804443617,
+    0.6754154020714112,
+    0.6633048747781917,
+    0.5863992943960324,
+    0.5933194044777871,
+    0.6196647799747546,
+    0.37887565505446597,
+    0.5574917927121655,
+    0.6328076694845931,
+    0.7036460718363199,
+    0.5486239077012353,
+    0.5631142670110721,
+    0.6789134466927851,
+    0.6184482320967433,
+    0.6619983409224812,
+    0.3518047701983135,
+    0.4548281149411733,
+    0.4599526245549356,
+    0.6899762982630488,
+    0.5931648302629847,
+    0.5755487537233416,
+    0.7234248193698057,
+    0.6980927287064522,
+    0.7003960109112879,
+    0.5778258634871356,
+    0.6103546168381484,
+    0.4521780628236203,
+    0.46430355879306856,
+    0.4291233885469247,
+    0.4258727037761505,
+    0.686965067726479,
+    0.6318294678605502,
+    0.4797681019737849,
+    0.6677881800109206,
+    0.6223530890655011,
+    0.6500346708082481,
+    0.6470220615860736,
+    0.5628846879371547,
+    0.5486047721305044,
+    0.6523768053517404,
+    0.6198866974612594,
+    0.5828392316869526,
+    0.6011834385122764,
+    0.5653553536718064,
+    0.4462964880982585,
+    0.5076290463904679,
+    0.6143807934203004,
+    0.6368136089791777,
+    0.6541282554729455,
+    0.6360905804771121,
+    0.6576141711054128,
+    0.6380712843381463,
+    0.6150824553502202,
+    0.5194581136709979,
+    0.6059552227526083,
+    0.644249007543997,
+    0.49160011204409765,
+    0.5066932800989277,
+    0.5438477666097058,
+    0.7117662527670907,
+    0.6347408476536356,
+    0.6928412185634422,
+    0.7095256175085075,
+    0.6673800666347568,
+    0.6446271857019523,
+    0.5629679686547984,
+    0.5988498397971042,
+    0.6711969020967737,
+    0.6732483073578976,
+    0.6441697708106691,
+    0.6617391758008807,
+    0.6701844716185291,
+    0.6011954355737816,
+    0.6854079128142234,
+    0.6610906773968953,
+    0.5462364466081979,
+    0.5632356017022155,
+    0.6347748229825577,
+    0.6543674281776735,
+    0.5169709336870192,
+    0.5430969570162574,
+    0.4952188181556061,
+    0.4310411170944588,
+    0.4834792136869304,
+    0.5584961363615003,
+    0.6190728552235799,
+    0.41313616026872346,
+    0.7477563026591755,
+    0.5793914487713239,
+    0.50654202306873,
+    0.5963964812983499,
+    0.5972817396622832,
+    0.6022725225874599,
+    0.5590114572003945,
+    0.614805798991637,
+    0.6541568743173586,
+    0.5464070829143373,
+    0.6239385518539569,
+    0.5605955775507356,
+    0.6581912130038915,
+    0.5107988445926015,
+    0.5627972848954718,
+    0.5489471184903963,
+    0.7190505958337088,
+    0.7239696962055622,
+    0.6976605494450023,
+    0.6594533090669444,
+    0.6315089524488071,
+    0.5029769035857143,
+    0.5055635073805131,
+    0.6232413768426484,
+    0.62312468497818,
+    0.6035978864889826,
+    0.6592153771755478,
+    0.5416151330754535,
+    0.48271775070873335,
+    0.6589688198892765,
+    0.7126326949269869,
+    0.5099135326978612,
+    0.5865728727426137,
+    0.5234226082624385,
+    0.5890559802072497,
+    0.6677133693943377,
+    0.5807875066202628,
+    0.6431829318695867,
+    0.6447796598113197,
+    0.6549401911158954,
+    0.6082596288045767,
+    0.6259399726176114,
+    0.6958499859738811,
+    0.5991839181135119,
+    0.5341062035920422,
+    0.46609240058743323,
+    0.6574741582483086,
+    0.6380166218975671,
+    0.579542609610822,
+    0.6354706598178267,
+    0.5872540445520997,
+    0.662301776273754,
+    0.5522088416701261,
+    0.6352883986126509,
+    0.6122207074033574,
+    0.6793008315143051,
+    0.5413403247033478,
+    0.49191926195884267,
+    0.6139183663001205,
+    0.6487406077538155,
+    0.6403764937922576,
+    0.5180059082998125,
+    0.6094745300653358,
+    0.47504366223390915,
+    0.5724312311064319,
+    0.6396405930980206,
+    0.6211435451094808,
+    0.5515418359358011,
+    0.6594516197354348,
+    0.6320336826580886,
+    0.6491347784604605,
+    0.5942721988953604,
+    0.4542797405837854,
+    0.5937694861502044,
+    0.5893330589900725,
+    0.5361716574700118,
+    0.5320730913393212,
+    0.6001454589152689,
+    0.6543269639955683,
+    0.5157588518911704,
+    0.5533768552413314,
+    0.5017106058863515,
+    0.6180693659568943,
+    0.5387485302092142,
+    0.5401814026707791,
+    0.5732897178076294,
+    0.5840839261409302,
+    0.6538800105423112,
+    0.5363232076872837,
+    0.6378882850155211,
+    0.620747012126079,
+    0.5823256986300713,
+    0.5469999178565464,
+    0.42636871467127885,
+    0.5293877811911494,
+    0.6451406803972127,
+    0.7039236770332457,
+    0.5756044531097534,
+    0.613641132502296,
+    0.5978636815735789,
+    0.6088463578269216,
+    0.5428066854754939,
+    0.40001125655853315,
+    0.43468591345649027,
+    0.6695598252861855,
+    0.46510537289137327,
+    0.5424999609428965,
+    0.6229935746715534,
+    0.5651219633397782,
+    0.6325693659959395,
+    0.713726515255991,
+    0.5577864635536448,
+    0.6460836894373873,
+    0.5247688747196102,
+    0.5744180467029202,
+    0.47664048112561536,
+    0.5853648705684236,
+    0.46817940394855995,
+    0.5528262271999804,
+    0.5327382286923092,
+    0.5839855187924953,
+    0.6256052581039467,
+    0.4241743593815046,
+    0.5805124811117237,
+    0.580002832376787,
+    0.6829043220183902,
+    0.5536093303296671,
+    0.6403556988937581,
+    0.6753083074925003,
+    0.5047675370320491,
+    0.6319576295892947,
+    0.6457598196054467,
+    0.6709664497773721,
+    0.5724744957765602,
+    0.6474031493158507,
+    0.6393251494929059,
+    0.6697128314888842,
+    0.573537259176347,
+    0.5179967212665411,
+    0.45406059454510517,
+    0.6047180106951718,
+    0.44847560753392957,
+    0.48711347423738854,
+    0.5546144145769643,
+    0.6422623441593424,
+    0.6112904201101388,
+    0.49398123341549705,
+    0.7045351317305899,
+    0.6354705480211535,
+    0.7155665895209993,
+    0.6254061028333375,
+    0.667027771909049,
+    0.6266868478822297,
+    0.5928726711421305,
+    0.6136989413170988,
+    0.5336072774983085,
+    0.46408380540345096,
+    0.6962162429946877,
+    0.6815773607551348,
+    0.6282132404022721,
+    0.6166796370538014,
+    0.6662539745333586,
+    0.5020642933825618,
+    0.6502632674389406,
+    0.6867523930981213,
+    0.453215626829436,
+    0.7139986613086133,
+    0.6977696713733079,
+    0.5807341983922173,
+    0.5884065462694386,
+    0.6047564159215981,
+    0.642624673692888,
+    0.6872196968982173,
+    0.6298844140252536,
+    0.6105690563294863,
+    0.6701548015013117,
+    0.628632359529514,
+    0.5787186242825788,
+    0.7027421454703492,
+    0.5095698348272385,
+    0.534747929194504,
+    0.5323867704841363,
+    0.6199830282138141,
+    0.5685932176952818,
+    0.626931852942354,
+    0.4273564578090763,
+    0.5732605839744769,
+    0.5840908288358206,
+    0.6835561898157674,
+    0.6455488033387464,
+    0.6009835584998914,
+    0.7311996509553459,
+    0.5657307065928335,
+    0.6777189366557795,
+    0.6600176745529448,
+    0.5671855896993208,
+    0.5995924566672489,
+    0.6057847379728091,
+    0.709751833884113,
+    0.6732526352054107,
+    0.6659269529108134,
+    0.5575077685937115,
+    0.651551255706499,
+    0.5751596639204081,
+    0.6006244024728502,
+    0.7044337699995202,
+    0.5220478002188207,
+    0.6967840390775258,
+    0.6369275659219192,
+    0.5228207754831431,
+    0.4803244675372702,
+    0.6745735097142221,
+    0.6031128700299866,
+    0.5784062019552794,
+    0.5767300600149353,
+    0.6418396710501239,
+    0.6365763739317488,
+    0.5593511409857567,
+    0.5546455297971311,
+    0.6034517436822131,
+    0.5621932571204776,
+    0.6040208441897951,
+    0.5305310792629608,
+    0.6120402661063258,
+    0.6458273458557197,
+    0.6508416289147674,
+    0.6116524811445315,
+    0.6158402697041737,
+    0.6057846443730771,
+    0.7044575551833842,
+    0.4309857173495444,
+    0.5548086383007893,
+    0.6762232611045018,
+    0.6523694505579071,
+    0.6934612351953952,
+    0.636064426354535,
+    0.5640712048176564,
+    0.602891677909797,
+    0.5887153792787577,
+    0.5749797827374912,
+    0.7106572111510878,
+    0.5254876273805469,
+    0.6553434477040612,
+    0.5854016816399917,
+    0.6267031771311112,
+    0.6858329255813654,
+    0.6806109226728377,
+    0.703054643332264,
+    0.6687680800608206,
+    0.6514409664243134,
+    0.6961083218863348,
+    0.5910733282906726,
+    0.5690276949137443,
+    0.6925130504129696,
+    0.599523585300881,
+    0.6112062935683215,
+    0.715439087164151,
+    0.7254233023356494,
+    0.4984052217907047,
+    0.47426687733787165,
+    0.5531556027779351,
+    0.6208333832766707,
+    0.30220485569166067,
+    0.34468343205155055,
+    0.6213030753439066,
+    0.5386014297065645,
+    0.642328790839417,
+    0.5884926511317015,
+    0.572262058284152,
+    0.5340215021615221,
+    0.4559778781318304,
+    0.5315777980346177,
+    0.6088542878262535,
+    0.49604506189888486,
+    0.5917175892068648,
+    0.6229126076286361,
+    0.6185198936621071,
+    0.6951645675298046,
+    0.7262256345854886,
+    0.4349194783356436,
+    0.3513270664814656,
+    0.441583331773647,
+    0.680024109493337,
+    0.5861772735383395,
+    0.6239994973504979,
+    0.583348057929727,
+    0.661523088895554,
+    0.584064586626844,
+    0.6224331228333354,
+    0.6813304592485746,
+    0.6057031559473774,
+    0.6850357966621228,
+    0.7307878148408538,
+    0.6042310600828724,
+    0.6105836243258896,
+    0.6605887462557877,
+    0.5078191987874905,
+    0.5652541074036407,
+    0.6433494238833968,
+    0.6577508322780624,
+    0.6390721586254293,
+    0.7070658248657627,
+    0.5626484440688285,
+    0.6154752399547531,
+    0.5527521681866785,
+    0.6559883165325847,
+    0.6247418935452851,
+    0.6595978766198269,
+    0.49072211695870216,
+    0.6591762595181169,
+    0.5660943310008766,
+    0.5168357124154499,
+    0.6732051135839822,
+    0.565215150676689,
+    0.5718565441504184,
+    0.5475932113523699,
+    0.6043649859801141,
+    0.41145424756728394,
+    0.620868577318795,
+    0.6862040315890258,
+    0.5735676579347985,
+    0.6052116445199613,
+    0.6504273082080055,
+    0.6780575233336897,
+    0.569657882087003,
+    0.6048503751450801,
+    0.6101432941402217,
+    0.6098089068819942,
+    0.6870738698641012,
+    0.5868920149812963,
+    0.575150526890674,
+    0.6931856417854816,
+    0.608688245375303,
+    0.5868443043978928,
+    0.6473418224150224,
+    0.5514822205977536,
+    0.4566488978481875,
+    0.5848025438094093,
+    0.5681772158350172,
+    0.5264188190047954,
+    0.564366524723108,
+    0.5792028206848447,
+    0.6516980269535585,
+    0.6643855613702535,
+    0.6878766617522036,
+    0.6521344758269537,
+    0.6711568060611194,
+    0.5964391541757562,
+    0.5365020232574056,
+    0.6465287830795017,
+    0.4112878755529838,
+    0.6497229835851425,
+    0.5404253780873529,
+    0.6414524886655264,
+    0.6329169065473633,
+    0.5623499770210136,
+    0.6125722848026914,
+    0.6195285683259567,
+    0.5640164521237186,
+    0.5444844463787732,
+    0.6199651717606114,
+    0.6010336374812186,
+    0.6637406586500842,
+    0.6390459382876684,
+    0.5505566913983366,
+    0.6388698653347579,
+    0.5129952084251599,
+    0.608806556525805,
+    0.6161083497520076,
+    0.6421146951598896,
+    0.5364881402148243,
+    0.5065916552762133,
+    0.5628168034750247,
+    0.570787748054214,
+    0.533950940367367,
+    0.31256258504950224,
+    0.4463564018308639,
+    0.6134855697001318,
+    0.4431450509318065,
+    0.557296925646459,
+    0.6287855174796039,
+    0.6551946365712309,
+    0.5292801809721648,
+    0.5441472289389601,
+    0.6227193461451311,
+    0.6026636488761894,
+    0.504797754190057,
+    0.35539204563280996,
+    0.6171353578951208,
+    0.44288891150097515
+  ],
+  "M09": [
+    0.24620555903606484,
+    0.3948158486474247,
+    0.39481545382333016,
+    0.22589188373235244,
+    0.4164325799200406,
+    0.2696971379051062,
+    0.4341657495140628,
+    0.41819605673328464,
+    0.35327106383480583,
+    0.3372666306708152,
+    0.2977732204334537,
+    0.34687758866526064,
+    0.35363218995062423,
+    0.3933248834580169,
+    0.30304441344393646,
+    0.4175981710506036,
+    0.6031179891317191,
+    0.40642699730870574,
+    0.4699630755122161,
+    0.4304061770774626,
+    0.25593731956086846,
+    0.3893366881721898,
+    0.3183866804178089,
+    0.3440232929590851,
+    0.33378698170451826,
+    0.4656435842855631,
+    0.250737303731089,
+    0.2662954632867349,
+    0.47263510682857535,
+    0.3852864062767294,
+    0.35377380042510803,
+    0.5092403496521741,
+    0.2959857814376935,
+    0.20764951017309577,
+    0.3396672507796114,
+    0.4905114461474987,
+    0.2867108983717546,
+    0.496328663697664,
+    0.38357211625818866,
+    0.4044420101601225,
+    0.40503455890391044,
+    0.4059091093663914,
+    0.7204344220814699,
+    0.3850960726925079,
+    0.3484533084971692,
+    0.36591232531632306,
+    0.25561342540173115,
+    0.2952452178892852,
+    0.26606090530103366,
+    0.4421019757388839,
+    0.2755984209185306,
+    0.3941165392814342,
+    0.3102916544481169,
+    0.316555560420699,
+    0.38030397875526445,
+    0.3794383728782678,
+    0.2841061517688109,
+    0.372299825334455,
+    0.5207966671644374,
+    0.4242498502228559,
+    0.27660129089199487,
+    0.296260726505322,
+    0.4195207722605183,
+    0.3397706290385904,
+    0.29617011959363765,
+    0.3242797657389006,
+    0.3205705497763428,
+    0.3036336907541656,
+    0.25327073184557103,
+    0.5930601212500446,
+    0.44535929041797256,
+    0.30439668795546676,
+    0.40703431681559293,
+    0.3718968623462827,
+    0.4490581976821987,
+    0.5649769215826788,
+    0.40943788032414885,
+    0.30524832529191953,
+    0.36546228016868887,
+    0.25628953470202054,
+    0.29853743326483584,
+    0.30670991618607113,
+    0.23570638037167485,
+    0.30415804040527145,
+    0.2881092739589294,
+    0.43125097454292444,
+    0.3313994064413522,
+    0.29645998289684555,
+    0.4776296209981818,
+    0.35908515001309255,
+    0.345374391953075,
+    0.5451107259031465,
+    0.37322401305899067,
+    0.4005259837788507,
+    0.44141009110991664,
+    0.34960028196771725,
+    0.5415106573842747,
+    0.3735165606776926,
+    0.3058938077153504,
+    0.3812251623057208,
+    0.3644996673826102,
+    0.2926577287484254,
+    0.2581052609274248,
+    0.3369417240958422,
+    0.5379167111065762,
+    0.2559735300647637,
+    0.40093175535017933,
+    0.28069283104742215,
+    0.2534944005947054,
+    0.5178337713274452,
+    0.26827077770070223,
+    0.4584473623203238,
+    0.2609993680670876,
+    0.3795707753965285,
+    0.3294009642783761,
+    0.3836629020875285,
+    0.3513596826488039,
+    0.3846422546675543,
+    0.22097584438309953,
+    0.33675766668589097,
+    0.45408343520857314,
+    0.41135029184505073,
+    0.5707863583054645,
+    0.3661614214366847,
+    0.31819548959033495,
+    0.2891229228394635,
+    0.4207870887983795,
+    0.2323625731105838,
+    0.4053892938630206,
+    0.4325682129242587,
+    0.44002391773658167,
+    0.19164850428018346,
+    0.46252382375257584,
+    0.3828012594137682,
+    0.37604749841551377,
+    0.49805475003641403,
+    0.358095087432385,
+    0.4921672800226002,
+    0.4943295294586075,
+    0.3104770922998274,
+    0.37815590381211434,
+    0.4351456407703839,
+    0.373657737334982,
+    0.39268962300583854,
+    0.3661966291329069,
+    0.3043989970592146,
+    0.5104280378848925,
+    0.41280820587861544,
+    0.2300769849221541,
+    0.24486873427225286,
+    0.48813556180436357,
+    0.30711172214781507,
+    0.3344846689574606,
+    0.28548927865035373,
+    0.4517827421584506,
+    0.5066910675726242,
+    0.43735831263675773,
+    0.4099227871904444,
+    0.46194655837188114,
+    0.49033453713294156,
+    0.5487673555142134,
+    0.2804120154200782,
+    0.3128503215977568,
+    0.2987260814319371,
+    0.24863089010632214,
+    0.3092972121808167,
+    0.2727863855298464,
+    0.23909235690151248,
+    0.24156832245490287,
+    0.26237164441933325,
+    0.3239975522389573,
+    0.3554415443127115,
+    0.43902650504734586,
+    0.36586821470556624,
+    0.49384373117039576,
+    0.6191971044701686,
+    0.28433448451191934,
+    0.4861518927704656,
+    0.25970641152397456,
+    0.40169891233083355,
+    0.6614059242030057,
+    0.24642568130834733,
+    0.6569457976081841,
+    0.6468855669560868,
+    0.7016393229326255,
+    0.6937250140513309,
+    0.557451148250703,
+    0.6287251672735722,
+    0.637888148757263,
+    0.5844232841047053,
+    0.6202372577236562,
+    0.5925622619292857,
+    0.6492475092813366,
+    0.5776719314319484,
+    0.36501571313890674,
+    0.6013137649790189,
+    0.6312447439599946,
+    0.6229240061673669,
+    0.6144902167198713,
+    0.6625886008802231,
+    0.611133650984098,
+    0.29268931056692393,
+    0.5023254427690367,
+    0.5290568970957915,
+    0.46511312782958103,
+    0.5411919509304614,
+    0.6207679559056417,
+    0.45470215351248633,
+    0.6662275249110302,
+    0.5419194139035699,
+    0.5963999364002721,
+    0.6079680810909657,
+    0.6559723444469933,
+    0.6218777913985735,
+    0.6149972366280297,
+    0.5592700750728586,
+    0.3641688026231279,
+    0.46766327030902566,
+    0.4409341263259563,
+    0.4960828946310811,
+    0.33507050540447664,
+    0.6831005719476413,
+    0.30718724817615967,
+    0.6105721980652127,
+    0.5581500968499735,
+    0.5672693761751539,
+    0.6298013285714759,
+    0.6122018442560344,
+    0.6287613806158695,
+    0.5484483233416041,
+    0.5239210449266556,
+    0.6377801913557107,
+    0.5972185716129723,
+    0.6621648162151371,
+    0.5331376258244296,
+    0.6231829198620383,
+    0.4952395752798406,
+    0.5299894279478136,
+    0.6029851515467043,
+    0.6038061803056305,
+    0.594812249720579,
+    0.7262632660022008,
+    0.7304326004430766,
+    0.6653056876785292,
+    0.6956612289364988,
+    0.5159185768163155,
+    0.6104600860660314,
+    0.6196817810750889,
+    0.6170174993933124,
+    0.49757468947976696,
+    0.2949718260707447,
+    0.41305206086215307,
+    0.4778749497896014,
+    0.553381754751153,
+    0.5771811195738472,
+    0.6396652118972019,
+    0.3865662547049783,
+    0.4390946366867644,
+    0.5294346522013397,
+    0.713803566127512,
+    0.6085212797668668,
+    0.6579745026282012,
+    0.7710719814577272,
+    0.6138622726784647,
+    0.5032405321163722,
+    0.3580577703287693,
+    0.5344628106299877,
+    0.5635109903915976,
+    0.6445729344497835,
+    0.5779386029446347,
+    0.5834924561620202,
+    0.6597386446214011,
+    0.6641211167093518,
+    0.6626207214732551,
+    0.64387123306601,
+    0.5328854674685841,
+    0.6223889479691964,
+    0.5913865067470797,
+    0.5915903935818974,
+    0.6423807692714522,
+    0.6210653794230018,
+    0.6805167735244054,
+    0.5293741394246171,
+    0.5345526592082314,
+    0.7162336789495833,
+    0.6778733274187707,
+    0.5435675699620591,
+    0.5521239465600862,
+    0.5743868597824264,
+    0.627220440342816,
+    0.5183475598970905,
+    0.7201650222011171,
+    0.7213597363937694,
+    0.5011132988953765,
+    0.546072922119871,
+    0.36626058215076585,
+    0.6740338523036646,
+    0.4669647746114605,
+    0.6490238714722931,
+    0.5761162288042495,
+    0.5777415311786159,
+    0.5154762778839347,
+    0.6244572224770704,
+    0.45824480757958175,
+    0.6706514950727138,
+    0.6807644011905477,
+    0.6174098622371365,
+    0.5723033868132535,
+    0.6211095224012044,
+    0.6181948557198184,
+    0.610045310409014,
+    0.6004342568384432,
+    0.6844907883095297,
+    0.5015738176969605,
+    0.62309893267239,
+    0.48984101561429705,
+    0.6042642867210388,
+    0.6308436581142337,
+    0.6977562182666655,
+    0.5926785788876343,
+    0.5751605654887956,
+    0.6768711091147079,
+    0.5994430929230469,
+    0.5645272496537354,
+    0.6265003456309189,
+    0.4032259685306878,
+    0.6334456860809103,
+    0.6446849037837137,
+    0.7133810173949305,
+    0.6609448517704011,
+    0.6653540903404312,
+    0.5700834826975995,
+    0.659644407583136,
+    0.6047603633504965,
+    0.5578512898968947,
+    0.3969347991573869,
+    0.619661210620012,
+    0.5708872818749152,
+    0.6587662125107462,
+    0.45692670606321667,
+    0.5904830655785469,
+    0.5657882529608973,
+    0.6312683504893132,
+    0.6203610314289142,
+    0.6640009903076469,
+    0.6235033279818649,
+    0.6115169345569111,
+    0.4880770781592955,
+    0.6832348704376239,
+    0.5983848795150569,
+    0.5818683867800568,
+    0.6878620278644948,
+    0.5371287722645672,
+    0.5533017346789304,
+    0.6062884216002742,
+    0.5837834933311381,
+    0.6516175634837846,
+    0.5457909782961512,
+    0.5552308481169009,
+    0.594961462291569,
+    0.5724572815044,
+    0.6879825054423302,
+    0.5835902765754205,
+    0.6581924584710915,
+    0.43683163563727434,
+    0.7688077337526159,
+    0.7115877494464202,
+    0.5774991197469683,
+    0.595310496922133,
+    0.6345490991265992,
+    0.5793832081701702,
+    0.43471901543140656,
+    0.5878646932349882,
+    0.31050347461365646,
+    0.5989054248213674,
+    0.5719824533686745,
+    0.6677865498811406,
+    0.6309093445758371,
+    0.6398720416727202,
+    0.6127490365662461,
+    0.6438016391559443,
+    0.6513918861972253,
+    0.664661570055445,
+    0.543661091356072,
+    0.6349479791750147,
+    0.6175710418999542,
+    0.5139594788210129,
+    0.45513654077571364,
+    0.5073229730425995,
+    0.6672407395409761,
+    0.5102790342596937,
+    0.5800496522026057,
+    0.6969177987927415,
+    0.6528670167055175,
+    0.636361533860927,
+    0.4997688037534724,
+    0.4112997764589862,
+    0.5428545203510029,
+    0.6111840739891723,
+    0.6357141440872424,
+    0.7291964072430858,
+    0.6822485303256337,
+    0.6038371640078875,
+    0.7045129852375507,
+    0.47900429517686155,
+    0.536642017978097,
+    0.45262422076138736,
+    0.438138948770357,
+    0.6452606862430502,
+    0.6032211445288291,
+    0.5257133787918417,
+    0.4528522529348289,
+    0.5920148882756908,
+    0.6031496436451262,
+    0.6010080946679298,
+    0.6411467038148027,
+    0.40105321201495714,
+    0.7629501000965416,
+    0.5126634917357257,
+    0.635040840230265,
+    0.6587539161274364,
+    0.6848751881394363,
+    0.6223292282333244,
+    0.5826885125266963,
+    0.3337073174193933,
+    0.6117443293680639,
+    0.38194933678927806,
+    0.6357321398963023,
+    0.599723023845856,
+    0.6786980087967057,
+    0.526930779143327,
+    0.5284573723249907,
+    0.5384331262252635,
+    0.6100061562030749,
+    0.6983667052319057,
+    0.70607528713194,
+    0.6490697636320373,
+    0.6327694788770591,
+    0.6193884207711099,
+    0.64699165959982,
+    0.5697184926102132,
+    0.5971921555281454,
+    0.6517389240977853,
+    0.6215958048200194,
+    0.5405031574924334,
+    0.471055830071932,
+    0.4382442541319232,
+    0.46418151167646615,
+    0.6115517760213663,
+    0.6196960978944709,
+    0.5650507910096341,
+    0.5931268761180677,
+    0.6566289408653856,
+    0.6861630909746889,
+    0.6096755196190481,
+    0.6233430008406463,
+    0.6157417641829532,
+    0.5814551385050937,
+    0.6430223533140089,
+    0.6516934152004151,
+    0.7145642986989925,
+    0.7370996729992619,
+    0.5802842301260617,
+    0.5728846675710916,
+    0.3850513752138698,
+    0.4890915270706432,
+    0.6348880541273836,
+    0.556963064364106,
+    0.7133121521136205,
+    0.6140747272432797,
+    0.6273118223953397,
+    0.49138653241282326,
+    0.6705819851267492,
+    0.4969164336427393,
+    0.3666142625045911,
+    0.6489330156329551,
+    0.5704569438419816,
+    0.5830033374575088,
+    0.5931726600840209,
+    0.6614687521364443,
+    0.5867528691807016,
+    0.4825210250272749,
+    0.6204171844664034,
+    0.5302356158534177,
+    0.5066265872167917,
+    0.6542408510128277,
+    0.5496956091283228,
+    0.5099876262237726,
+    0.591048618875664,
+    0.452146072090296,
+    0.5621570190336993,
+    0.6044854323306578,
+    0.5726760722554869,
+    0.6089356236854789,
+    0.5862945605266067,
+    0.646529677691741,
+    0.6117382242312579,
+    0.5347943123933634,
+    0.5844237033744757,
+    0.6532086105062039,
+    0.5763956338075661,
+    0.521309586372615,
+    0.637685057153101,
+    0.5787887764882658,
+    0.6838077514975066,
+    0.5312583334643328,
+    0.6189100446392204,
+    0.6540016644640501,
+    0.7193575832951142,
+    0.6551781287447336,
+    0.5144874695629594,
+    0.6151516595352777,
+    0.6301059877162968,
+    0.6546603084433745,
+    0.6066324986714665,
+    0.4715908119655192,
+    0.5935782069408937,
+    0.6059499822792896,
+    0.5511614114613252,
+    0.5174427429395921,
+    0.574317096743785,
+    0.6943720503869286,
+    0.6103167304334859,
+    0.6144745456785876,
+    0.6520426773048561,
+    0.5495805883633558,
+    0.6759154179495137,
+    0.6885235378183573,
+    0.5317174049855771,
+    0.5678434316524074,
+    0.5992994833627265,
+    0.5162800343661367,
+    0.46464159663427507,
+    0.6121165473155967,
+    0.5583574721545982,
+    0.4724249981204705,
+    0.5642654388061383,
+    0.5008260446965734,
+    0.6521828321926278,
+    0.4662737643852922,
+    0.5789828298817459,
+    0.5747530101485746,
+    0.6648670517668858,
+    0.6264060432851983,
+    0.6696727926823027,
+    0.6642862265219472,
+    0.6463352243594871,
+    0.6471049355516196,
+    0.6364736740343291,
+    0.5833716728645869,
+    0.6029125645570698,
+    0.6087075498838044,
+    0.6752729144191009,
+    0.643685003159432,
+    0.6147516821772091,
+    0.5205257720510417,
+    0.6416593683688642,
+    0.6307598202377127,
+    0.5687523388686628,
+    0.4797429689372655,
+    0.5626762170098617,
+    0.6379764424645952,
+    0.5928470368748283,
+    0.6458819608685408
+  ],
+  "M01": [
+    0.18552717512553676,
+    0.34423874429892987,
+    0.40085683233759756,
+    0.2445656842643939,
+    0.4125208973345468,
+    0.10958581057511031,
+    0.3894463272790612,
+    0.40305432903674243,
+    0.33664148692762147,
+    0.342638448307639,
+    0.28605282663851916,
+    0.2587117306093814,
+    0.36115185632573493,
+    0.38438685755339513,
+    0.20251180353621673,
+    0.40698332976830376,
+    0.5509549191221178,
+    0.4167851589284333,
+    0.4192379756971553,
+    0.39447950411390303,
+    0.2665917212441062,
+    0.3757329427663056,
+    0.281838746883395,
+    0.3472370519254497,
+    0.3234888734597156,
+    0.27610731280368794,
+    0.1182680307585708,
+    0.25330276338704705,
+    0.5149447160485661,
+    0.3914735223731941,
+    0.39310650719149515,
+    0.4764458190753373,
+    0.3406055141381135,
+    0.21839408373363128,
+    0.2539756184655083,
+    0.4409343142462494,
+    0.2841063373449171,
+    0.4785116680868929,
+    0.29968133842714184,
+    0.3606325097658951,
+    0.39877981113787825,
+    0.4333194911530902,
+    0.7041120317616271,
+    0.37504887765481837,
+    0.3073696829425746,
+    0.37372827621783067,
+    0.34803474561745507,
+    0.2229876273416782,
+    0.33606722313492515,
+    0.42015591724055623,
+    0.17414886987390782,
+    0.40005223395458966,
+    0.28933730708048655,
+    0.32084764955649314,
+    0.35088014770477327,
+    0.454943239081389,
+    0.21262651028762994,
+    0.2935951553349123,
+    0.5080136876700048,
+    0.3536656411568511,
+    0.3120312817955264,
+    0.20381860945129512,
+    0.33402719365085615,
+    0.32760011053339094,
+    0.23970870525025362,
+    0.32955866093974373,
+    0.2584849946967293,
+    0.23335848982953325,
+    0.28656819600258926,
+    0.5811674850283558,
+    0.42476941883175445,
+    0.28991120882835847,
+    0.35402380491865565,
+    0.2911769175286332,
+    0.4466014237840706,
+    0.5541141286235689,
+    0.4499563665877308,
+    0.27338730278417933,
+    0.3756365363770192,
+    0.2942567002010192,
+    0.28013496256293224,
+    0.28737350237225295,
+    0.3163817709383835,
+    0.2586481529441115,
+    0.2663875489048407,
+    0.4100701136297126,
+    0.37227242966290064,
+    0.28353953153775124,
+    0.43652371711160404,
+    0.30177910356126636,
+    0.17891971811006757,
+    0.4206986519164201,
+    0.40778774792130146,
+    0.31725043297855615,
+    0.525170220913029,
+    0.29071228275065963,
+    0.5391007014314777,
+    0.35864140233024294,
+    0.2547989736011117,
+    0.41287227562776213,
+    0.3456963545856325,
+    0.316291827923396,
+    0.18408862379036056,
+    0.361220733795789,
+    0.5612689477244273,
+    0.2817933083574384,
+    0.3128220779846835,
+    0.25892866871695674,
+    0.24781484444432972,
+    0.5020777509456053,
+    0.2700922729037634,
+    0.4083149559921326,
+    0.2058761111583174,
+    0.3348096927310133,
+    0.3298252471362621,
+    0.41269948741169615,
+    0.3337244087722776,
+    0.37494711831142513,
+    0.17092311088774387,
+    0.35177389947657395,
+    0.47689741812131986,
+    0.46127728598366347,
+    0.4676168650714051,
+    0.3527605091056717,
+    0.3581209356198067,
+    0.2559358478333558,
+    0.37138235538357023,
+    0.2781242793909927,
+    0.401293805482939,
+    0.4160565822663907,
+    0.34263356003720963,
+    0.16979431321973437,
+    0.4490294595757419,
+    0.4140483401435553,
+    0.34501901046053324,
+    0.46909259446078705,
+    0.3677683217828932,
+    0.5296470920131054,
+    0.47338058534786404,
+    0.3749411129692097,
+    0.36846486468951595,
+    0.4485568619554325,
+    0.29187820709148843,
+    0.3408366585519685,
+    0.34815666424070074,
+    0.2687369206684254,
+    0.4368368351118656,
+    0.38366285845391773,
+    0.22949372989952158,
+    0.2805181217164194,
+    0.4702704142871783,
+    0.3102436984947936,
+    0.3402961896621192,
+    0.28209640694304366,
+    0.4082384864106881,
+    0.4745463483062862,
+    0.2791240571137858,
+    0.38480303350870476,
+    0.3946138155313427,
+    0.48114933346108296,
+    0.4792146119825492,
+    0.2831976517153227,
+    0.3211361307530807,
+    0.2846184634655023,
+    0.19437397472686369,
+    0.39022666876263623,
+    0.24506314997653414,
+    0.2276166178693257,
+    0.2618566719452272,
+    0.2963469683210766,
+    0.19056258686936733,
+    0.3619026058530526,
+    0.4379212327951469,
+    0.2866852890912208,
+    0.46213523654229033,
+    0.4699027906172139,
+    0.29740598183569666,
+    0.47066490849451253,
+    0.2589988774820793,
+    0.38800339321916144
+  ],
+  "M02": [
+    0.25562207217995037,
+    0.377079548085495,
+    0.38201839392565495,
+    0.26016220082508534,
+    0.4286467025718982,
+    0.30208095129460855,
+    0.39703150546247584,
+    0.35536029578477196,
+    0.34594377505088647,
+    0.3367171703430332,
+    0.3004418132826703,
+    0.3620363885811449,
+    0.3520548396951445,
+    0.3464715278792007,
+    0.29273992976823304,
+    0.4088459440766598,
+    0.4193019437077293,
+    0.39523528020205734,
+    0.5337180458764407,
+    0.4123115536841725,
+    0.2933445139989934,
+    0.41352486055622323,
+    0.3190193758517901,
+    0.3624837211522492,
+    0.3298063266111217,
+    0.44843051883198265,
+    0.23131161619333704,
+    0.2998910935267604,
+    0.48914000473518027,
+    0.448001298226952,
+    0.3952109005968992,
+    0.4393335877238141,
+    0.34184939666128694,
+    0.2483884390020688,
+    0.38283225005336036,
+    0.47343582859217054,
+    0.2990319141539463,
+    0.512307842557608,
+    0.3602583122401828,
+    0.41578122461931594,
+    0.42310129078553427,
+    0.4569678000615419,
+    0.6541988323755351,
+    0.39438346068886104,
+    0.34769622583703436,
+    0.2808862738095513,
+    0.3168944937004606,
+    0.28257525431770625,
+    0.32624430968041046,
+    0.45149775507872425,
+    0.27364756025610815,
+    0.3799811873337779,
+    0.32064776332308054,
+    0.3244422969090745,
+    0.37030205158294577,
+    0.47604242968210236,
+    0.3038256505101421,
+    0.32973017463753784,
+    0.5053057713241661,
+    0.4096955392608256,
+    0.304454790730571,
+    0.2665879599533132,
+    0.40974616789346086,
+    0.30983567659601846,
+    0.2705031789360504,
+    0.3264784101387327,
+    0.37710526506563524,
+    0.32777027832682404,
+    0.2685851192900389,
+    0.5786736585688005,
+    0.45118056451260424,
+    0.2911883544532312,
+    0.4223512053603014,
+    0.3797380771887868,
+    0.4428811450585722,
+    0.5470412588449796,
+    0.4423223590332026,
+    0.2914160824156477,
+    0.3837033679663056,
+    0.31255594561046113,
+    0.3568868427932119,
+    0.30282277358343074,
+    0.2843743622405857,
+    0.26709651035773396,
+    0.2555056574202832,
+    0.4450693566838286,
+    0.3055891918628504,
+    0.3213449682660836,
+    0.4339855065205863,
+    0.27548461542610414,
+    0.2547270518792048,
+    0.5486442074742705,
+    0.38781233837036494,
+    0.40240028959856805,
+    0.5299687820897802,
+    0.34239465102914834,
+    0.5411746022876502,
+    0.3392044292399982,
+    0.3458236352032568,
+    0.4101232254186599,
+    0.360583418749225,
+    0.2651388394881618,
+    0.26826617930891594,
+    0.36914575065154753,
+    0.5391178998933656,
+    0.3151471615978223,
+    0.3560968841546306,
+    0.302727829681203,
+    0.24425824262384713,
+    0.48744193708871647,
+    0.2955506242099992,
+    0.3848500772803996,
+    0.2809894922326896,
+    0.3655946645917917,
+    0.34465980232408727,
+    0.3639255206061961,
+    0.4293566810796299,
+    0.36870985419965796,
+    0.17528577454624975,
+    0.3869203748722883,
+    0.4047092066928778,
+    0.31332459118305084,
+    0.531652909584508,
+    0.38023208697837585,
+    0.32234555494719613,
+    0.35721777040275077,
+    0.4137982968530577,
+    0.28408163737136577,
+    0.4261056951557693,
+    0.43406259663520086,
+    0.4114579979752785,
+    0.20092940512376029,
+    0.4656818302318497,
+    0.4034022879041429,
+    0.3785604601303087,
+    0.4650999696893829,
+    0.3896805013507149,
+    0.5473179304476882,
+    0.2947793961326203,
+    0.3600914733484818,
+    0.30655945583332833,
+    0.37819065463679374,
+    0.3604531042650462,
+    0.3744466488447227,
+    0.38871123648574524,
+    0.27625896336704603,
+    0.49032882095835184,
+    0.4104019386034641,
+    0.2580483255065758,
+    0.30121069877924606,
+    0.46379957916792236,
+    0.31539464992196603,
+    0.38297577173584835,
+    0.24285830827685106,
+    0.38307710795102556,
+    0.4806513408228262,
+    0.42508572211223494,
+    0.3558082595746324,
+    0.39256454868550655,
+    0.45151814809190804,
+    0.5410943810648294,
+    0.3138869261033844,
+    0.3471699548213026,
+    0.2810695045627499,
+    0.27604218533124,
+    0.37889330345111893,
+    0.30605170635233503,
+    0.20233401383326013,
+    0.26616989365453947,
+    0.2644128781648513,
+    0.3275827103244735,
+    0.3634679669396793,
+    0.42625971361819753,
+    0.29045889863241203,
+    0.47659110917124536,
+    0.5870622709360591,
+    0.3198500238309773,
+    0.39286196875599494,
+    0.30599125927814985,
+    0.3214737709711416,
+    0.6171903716728963,
+    0.5200584072929498,
+    0.6560692647305689,
+    0.6439867969948827,
+    0.7131932766915384,
+    0.6703512729444837,
+    0.5609402695062472,
+    0.4751380202173237,
+    0.4691153951817819,
+    0.553278920247045,
+    0.5542031980433055,
+    0.5255865415546779,
+    0.5109001732330112,
+    0.5646631745339096,
+    0.5142116752939793,
+    0.5773524069705761,
+    0.4838707068909351,
+    0.6052218188139934,
+    0.5473208960636149,
+    0.6617240019796885,
+    0.5884407656446361,
+    0.44090527828187615,
+    0.5605287518396534,
+    0.574791340540517,
+    0.5524466889596583,
+    0.5470137640480665,
+    0.6404552254937581,
+    0.630761866710482,
+    0.5883859951613895,
+    0.5663835720930669,
+    0.6213164569054953,
+    0.4777922902262829,
+    0.649741272552248,
+    0.5982002669568751,
+    0.6075889670765464,
+    0.6002285458294295,
+    0.5235419204091866,
+    0.6571977746126199,
+    0.5945890192220973,
+    0.5985971007521215,
+    0.6465741834882912,
+    0.5500311099648304,
+    0.42650327857792075,
+    0.51092035246109,
+    0.5493617770829419,
+    0.603275903557361,
+    0.6167156988308798,
+    0.5971767271908056,
+    0.6086972762325491,
+    0.4934462550330879,
+    0.5396741725926266,
+    0.6243232836157108,
+    0.6005194215957868,
+    0.5739638706461844,
+    0.6009788141438005,
+    0.5994945836003925,
+    0.5847284877336726,
+    0.5783632762985611,
+    0.6388058869460631,
+    0.7174680516056465,
+    0.6505631295642661,
+    0.6709919437611099,
+    0.6547521317193966,
+    0.47037221777069976,
+    0.6024682851681514,
+    0.38904952238122176,
+    0.5295047753069706,
+    0.5829616821545602,
+    0.46049022533281997,
+    0.5247499536650209,
+    0.5199438603522905,
+    0.5293415890787531,
+    0.46334263915728197,
+    0.5790654696743125,
+    0.5644725275162611,
+    0.6234257053662167,
+    0.513439945584368,
+    0.349524078156637,
+    0.5568806852060026,
+    0.6923238850672886,
+    0.5876533904012611,
+    0.43047828943028155,
+    0.6495331154119363,
+    0.6617432143795526,
+    0.701460303192035,
+    0.579151793708354,
+    0.6054260846810268,
+    0.5493062479757748,
+    0.6555803868463137,
+    0.6230607142728797,
+    0.40091158960979767,
+    0.3758175405300384,
+    0.6269829824893455,
+    0.5984925966257644,
+    0.5986039264040732,
+    0.5242980751029032,
+    0.4999962730539795,
+    0.5204781001235087,
+    0.3841401913457045,
+    0.5852248581145696,
+    0.5722027798094487,
+    0.580366498273256,
+    0.6272079166638987,
+    0.5311063549663305,
+    0.5072376589193214,
+    0.6270735974362996,
+    0.4781317647444879,
+    0.5944077302250063,
+    0.6416951157754294,
+    0.6203297352688145,
+    0.6056282905554188,
+    0.6663339761167377,
+    0.6674276521689015,
+    0.5386301900591444,
+    0.558761291110642,
+    0.3982357381051367,
+    0.47039685786553925,
+    0.6670960510886523,
+    0.6256603056192539,
+    0.626164782969351,
+    0.5852529723636467,
+    0.5867017814251879,
+    0.5851780084047938,
+    0.6416821054345974,
+    0.5907147229180236,
+    0.5839698239794084,
+    0.6032863028623108,
+    0.468619082204215,
+    0.6378955125101392,
+    0.5550165103767908,
+    0.585349761557175,
+    0.5896850942633779,
+    0.6718110813523301,
+    0.49335899162213087,
+    0.6269899000912497,
+    0.5320082797822095,
+    0.6007309710779782,
+    0.6557035699294149,
+    0.6056754253092713,
+    0.42626793531370993,
+    0.40290684673055244,
+    0.6660275686223702,
+    0.6411676380321828,
+    0.5339566558209125,
+    0.6778439050830961,
+    0.5192590893693878,
+    0.6695136617932443,
+    0.6421289490965918,
+    0.6038025246287333,
+    0.6119446287203502,
+    0.49028485297027086,
+    0.3357913852187861,
+    0.6239812902036636,
+    0.6030672488816725,
+    0.49615667049927975,
+    0.6294206418273736,
+    0.6667384415152033,
+    0.622909878829663,
+    0.6203322304688353,
+    0.6661964332068064,
+    0.4852233355297407,
+    0.26769051519491993,
+    0.4904953716031315,
+    0.5722632855651154,
+    0.6709102189407505,
+    0.5818990308504635,
+    0.5219007078364829,
+    0.5073026793155178,
+    0.44936285285827643,
+    0.5608816709757801,
+    0.5354264992676769,
+    0.6430612414511636,
+    0.5900288799596533,
+    0.6833845008613,
+    0.5717279962923444,
+    0.6386362885290191,
+    0.4896167172767403,
+    0.6101640522814143,
+    0.4792965589996034,
+    0.5971854779099584,
+    0.6727510850211845,
+    0.6574242212191599,
+    0.5498878547578901,
+    0.6811566933599618,
+    0.6427291100301054,
+    0.6705723184816909,
+    0.6929475897066596,
+    0.3474440725110904,
+    0.7112095211032345,
+    0.65822392764721,
+    0.6224346023180157,
+    0.5786772130608968,
+    0.5031865678596984,
+    0.551074744515566,
+    0.6355973608321918,
+    0.6140888542327948,
+    0.5482647818814798,
+    0.6396689090250459,
+    0.5337619028433431,
+    0.5458407167858211,
+    0.6419242377426354,
+    0.49819469137083505,
+    0.5118599097771807,
+    0.42789294623668095,
+    0.6197700466557263,
+    0.6361225743191099,
+    0.41568492565897563,
+    0.5774657107167886,
+    0.4304389781383794,
+    0.6602429503917832,
+    0.6203665717231531,
+    0.5835005721513018,
+    0.6993806361083322,
+    0.6153923643287502,
+    0.64642703722265,
+    0.5844327719159205,
+    0.6451443964644169,
+    0.6194219942821947,
+    0.5067460060328771,
+    0.6830474736409845,
+    0.7231973114948159,
+    0.593186012381712,
+    0.45859511755728755,
+    0.6261846069375676,
+    0.6071146175747492,
+    0.34784126602493565,
+    0.5438047591138734,
+    0.41071444798195156,
+    0.650731163297351,
+    0.5548884197556568,
+    0.5860467160739407,
+    0.6053683132685475,
+    0.5834887941832376,
+    0.5861008342053039,
+    0.4887164169824558,
+    0.600764839925047,
+    0.44434800847825895,
+    0.7183796780206432,
+    0.5943448159512815,
+    0.6023256086832924,
+    0.5165045538044967,
+    0.5232833526121142,
+    0.5791622389247537,
+    0.5338646900860515,
+    0.6505110207619121,
+    0.7008471403836652,
+    0.6147993786458373,
+    0.5272702391612828,
+    0.4614207849933811,
+    0.6421003822742171,
+    0.29159676903420617,
+    0.3974839347267498,
+    0.5871220148940647,
+    0.7290585277336064,
+    0.6797974681497133,
+    0.6955069583483259,
+    0.6180970644723102,
+    0.6140879695649699,
+    0.5943146848570189,
+    0.6101569238001384,
+    0.6154226600903469,
+    0.5682957216803907,
+    0.5874600105032901,
+    0.6289747030275444,
+    0.6406477483251773,
+    0.5583499252332582,
+    0.6524243766781086,
+    0.64586333572453,
+    0.5534285980270576,
+    0.5942685617050182,
+    0.3968606013150563,
+    0.5106867627582442,
+    0.6282367058464741,
+    0.6842266836713017,
+    0.5695963099395744,
+    0.6723969231149458,
+    0.6588939229668966,
+    0.6089114557756026,
+    0.603375085578578,
+    0.6969606783072545,
+    0.6992548978886118,
+    0.6715991734888932,
+    0.4630455516946872,
+    0.5110815101247844,
+    0.529683599588696,
+    0.5245070276184554,
+    0.5948722641201712,
+    0.558481960693563,
+    0.6741508772053869,
+    0.6016369888202409,
+    0.6126002932387994,
+    0.6159516784988656,
+    0.6823997119655916,
+    0.6196431232814876,
+    0.5106738830194509,
+    0.6428866618138611,
+    0.6388517523190841,
+    0.6392162680600203,
+    0.5761900904797019,
+    0.6342673393300736,
+    0.5167237046040076,
+    0.5536768980115092,
+    0.3988891967289328,
+    0.582104911586552,
+    0.5954543144554236,
+    0.6393960520503329,
+    0.6177568934654627,
+    0.5352450426416087,
+    0.5721021848386979,
+    0.5199682143122449,
+    0.4690813529295931,
+    0.44750163073376237,
+    0.6014806730775888,
+    0.6036425435677857,
+    0.46550802214614195,
+    0.4672117472247011,
+    0.590001867320164,
+    0.3377400395693352,
+    0.3324477423869508,
+    0.35903907455365386,
+    0.4491314218265687,
+    0.5337672171995763,
+    0.49830465309755423,
+    0.511892115435467,
+    0.6032801525420196,
+    0.41261722112832155,
+    0.4607294745921804,
+    0.3722491998106422,
+    0.5969780866247721,
+    0.5801192107148815,
+    0.3391106981967857,
+    0.5508266408174239,
+    0.5134965834097549,
+    0.6858312389648528,
+    0.5928992273447958,
+    0.5933575226250091,
+    0.5521446109551914,
+    0.5739693582465674,
+    0.5514123466795431,
+    0.5057269162402485,
+    0.48753726683255055,
+    0.6712794296447402,
+    0.6188308189126869,
+    0.5647268566292885,
+    0.6272015961572049,
+    0.5503633058677125,
+    0.6578001414345722,
+    0.5986301854141051,
+    0.582034544243236,
+    0.5532532729039177,
+    0.3551628048348692,
+    0.5346266228948222,
+    0.472079030871168,
+    0.5762653051343786,
+    0.4683008491595214,
+    0.3432021254942949,
+    0.5601394807513888,
+    0.46201472076337724,
+    0.5168217948124398,
+    0.3974027389644345,
+    0.5712098087783717,
+    0.5188071930750007,
+    0.650477452606969,
+    0.4968756380265787,
+    0.4808832345408183,
+    0.45608401692880346,
+    0.39197041779039304,
+    0.46924508412396154,
+    0.6483184094196346,
+    0.6467165369629464,
+    0.6164068097147097,
+    0.562060167353338,
+    0.5061103719273123,
+    0.5695713420878251,
+    0.5229659942210666,
+    0.5793345504799496,
+    0.6319321539441369,
+    0.6207802493528839,
+    0.5996838463573351,
+    0.5358225485440969,
+    0.4507827100155659,
+    0.5527062185944752,
+    0.5370278092424964,
+    0.595402850129427,
+    0.6742419625353359,
+    0.3777190872019376,
+    0.631310111308121,
+    0.6999242025913361,
+    0.7575716586690798,
+    0.5837017691128993,
+    0.6012087255311114,
+    0.5932943776768398,
+    0.621440005143701,
+    0.533389327153614,
+    0.7185224804362769,
+    0.7366552016813377,
+    0.5593988331151704,
+    0.4185696095552991,
+    0.5718365958834839,
+    0.5090609977374186,
+    0.44975507742350823,
+    0.6366026124953846,
+    0.6818612710604,
+    0.6618663454089547,
+    0.665193905273213,
+    0.6819633809541389,
+    0.6464349577280292,
+    0.6851118637432347,
+    0.6578634854383782,
+    0.694307649282829,
+    0.3549427845576915,
+    0.43794227404594305,
+    0.6486441007536937,
+    0.59715352448872,
+    0.6108882002780122,
+    0.3631980184210748,
+    0.6085432499517879,
+    0.7035536495020183,
+    0.6892844546769528,
+    0.7095139353901333,
+    0.5793601389031972,
+    0.6568976873089504,
+    0.5767915788564439,
+    0.5707343375454214,
+    0.6385817343930725,
+    0.4956901499110722,
+    0.622596305288674,
+    0.5828459844231436,
+    0.6404817343873115,
+    0.5932817000451557,
+    0.5809095212371165,
+    0.6492082940659891,
+    0.5554357584698957,
+    0.5777061176049357,
+    0.5339378837613075,
+    0.6938638316663085,
+    0.5651441190876632,
+    0.5279264773785041,
+    0.735395055399342,
+    0.7037970539630433,
+    0.5198987322513274,
+    0.6038892565512479,
+    0.6913669602554489,
+    0.5705027635109009,
+    0.6636315115338459,
+    0.6712299931135218,
+    0.6164755847944551,
+    0.6338829670016265,
+    0.6365218102098846,
+    0.5141755844952932,
+    0.5839624018374667,
+    0.612438017874131,
+    0.5637241321066324,
+    0.4442762871148759,
+    0.6300867864607671,
+    0.6674128552047862,
+    0.6942611655804466,
+    0.5399412573037945,
+    0.5869312646716233,
+    0.5243106913757465,
+    0.6022055395901325,
+    0.5771718630938969,
+    0.6818152598537838,
+    0.6205863104563722,
+    0.5995369074653828,
+    0.6506595749557516,
+    0.68437488652929,
+    0.36621379327928316,
+    0.6620102947100126,
+    0.5500234988920798,
+    0.6495469775032324,
+    0.5803867511031088,
+    0.6542501450883397,
+    0.6255028758949216,
+    0.4765470994195799,
+    0.5956131134143979,
+    0.43716288414143606,
+    0.49951276308735176,
+    0.5730534564997206,
+    0.5241050790671903,
+    0.6351976424828363,
+    0.5468854238383681,
+    0.688582071101637,
+    0.7311238895418445,
+    0.6985257967080569,
+    0.6926570150854231,
+    0.655397573104597,
+    0.6027824945766816,
+    0.5718769754136329,
+    0.6252343557162119,
+    0.6660962436976976,
+    0.6273032576707626,
+    0.6592194702889188,
+    0.6648092944346622,
+    0.6709138916072553,
+    0.4293257042729284,
+    0.4298313448628097,
+    0.6017762782468106,
+    0.5630535549670942,
+    0.5542065822489128,
+    0.4765445157554427,
+    0.6187259733737702,
+    0.5106775386306616,
+    0.6161047857598494,
+    0.6010872948696806,
+    0.6049708867204276,
+    0.4796521899750806,
+    0.5159611902651324,
+    0.6417536434971347,
+    0.6522499449552136,
+    0.4150476555899408,
+    0.47999012567180754,
+    0.673742601837602,
+    0.5448512889985381,
+    0.6903734340959446,
+    0.7217459109465658,
+    0.5928722534000678,
+    0.6031360087357055,
+    0.5983460862377299,
+    0.6587432033264576,
+    0.6622319267102634,
+    0.6579211696044621,
+    0.6617530553196578,
+    0.6177156545505289,
+    0.4183957301898417,
+    0.6225673797740314,
+    0.6270798622440051,
+    0.5701682524932722,
+    0.7098037861863621,
+    0.6157142401880011,
+    0.6546924769252164,
+    0.619593289008557,
+    0.6586785700148015,
+    0.5679465651709865,
+    0.5737474634855462,
+    0.5096314407586399,
+    0.45406336460646485,
+    0.5631688594387456,
+    0.7253477674366904,
+    0.5297099156477241,
+    0.6145866126493043,
+    0.6414977540791934,
+    0.7299103397640822,
+    0.622816085257335,
+    0.6762511773659611,
+    0.5631627461919473,
+    0.6377695526118442,
+    0.5139987140254796,
+    0.5381020239884595,
+    0.6395042141839333,
+    0.598490814227281,
+    0.5891787535591667,
+    0.5163321082205883,
+    0.7063836678578034,
+    0.5909276336442787,
+    0.6011188746010157,
+    0.506367141994173,
+    0.553636715209522,
+    0.5050639017460838,
+    0.5443319909881995,
+    0.666619687871524,
+    0.4098935428512717,
+    0.5770895958373191,
+    0.70807223928869,
+    0.6637477644545143,
+    0.6214057919181821,
+    0.5423681114886074,
+    0.5914256088584279,
+    0.6213257608702922,
+    0.5830571748773493,
+    0.6658492164787684,
+    0.6042643826498362,
+    0.516493357539297,
+    0.600373780969284,
+    0.6266165425887218,
+    0.7019373919668889,
+    0.6932882446338894,
+    0.5189684402091669,
+    0.4789790064218355,
+    0.6410845162170525,
+    0.5929012763356998,
+    0.6968126245275367,
+    0.6313546024473878,
+    0.6928397852971021,
+    0.36695142141914644,
+    0.5378441601327146,
+    0.6753988425969905,
+    0.4132883846601311,
+    0.6294871184707237,
+    0.544495645726732,
+    0.5976417404442296,
+    0.6889248502881591,
+    0.5729985542809893,
+    0.6330769360705591,
+    0.6153831809918078,
+    0.5618445447779166,
+    0.6029497594397927,
+    0.584689410995331,
+    0.5442157849619444,
+    0.692650627944797,
+    0.7576403037116018,
+    0.6028332742220586,
+    0.6572390071192107,
+    0.7345504705196916,
+    0.595904233887253,
+    0.6141162421380729,
+    0.6391318764571745,
+    0.5551155992357476,
+    0.4949271818286765,
+    0.5916480488150992,
+    0.6482370349455943,
+    0.6994888873253668,
+    0.4650029768638498,
+    0.5161282421000555,
+    0.5478608170323123,
+    0.43106818519764656,
+    0.48481286918018623,
+    0.5250047987549684,
+    0.6560559279795048,
+    0.5846698470650132,
+    0.6113027633283298,
+    0.6112309207914663,
+    0.6141989162020687,
+    0.5623040342624169,
+    0.6247320721681004,
+    0.487305414220859,
+    0.5657162160982973
+  ],
+  "M15": [
+    0.2276575295684517,
+    0.392019586169226,
+    0.3303514218492971,
+    0.19007101237399465,
+    0.400815015885644,
+    0.31525571965984694,
+    0.3817587097217731,
+    0.4229248230248237,
+    0.35398524661893427,
+    0.3342776360164593,
+    0.2431875085330122,
+    0.28483563706209636,
+    0.3963621189120035,
+    0.3493894771463121,
+    0.31380763678078005,
+    0.30842152835014014,
+    0.5542319388038883,
+    0.3844060866536428,
+    0.4491574497747357,
+    0.41597947158480725,
+    0.296650722025831,
+    0.2851734818987208,
+    0.3069485257559159,
+    0.30839982292439977,
+    0.3038945398688603,
+    0.42485094714387167,
+    0.23957842974075394,
+    0.28502397259201323,
+    0.48640057597779496,
+    0.3117116765145949,
+    0.38789720220576646,
+    0.512479774849097,
+    0.33215537875271084,
+    0.23867021041946915,
+    0.395182922267304,
+    0.38829922767997016,
+    0.2967262569072056,
+    0.28426625774720654,
+    0.34983790063022674,
+    0.33349556554979404,
+    0.37257505346384767,
+    0.4414382834857689,
+    0.6653800164948522,
+    0.3718895227537539,
+    0.33284079624343954,
+    0.41095673893330764,
+    0.3336681197813496,
+    0.2668239353164889,
+    0.26307966043803066,
+    0.4518008668962265,
+    0.28918894642087256,
+    0.35451981868110266,
+    0.3028768115118106,
+    0.3004580163318647,
+    0.38302906785895197,
+    0.4452195386030507,
+    0.2730053147114605,
+    0.32884753390991694,
+    0.5278299995431519,
+    0.39599975875242127,
+    0.2897902488872355,
+    0.30878423637729896,
+    0.35852833114339694,
+    0.2998275803861236,
+    0.2785987370920534,
+    0.2586856323612536,
+    0.37687782280831,
+    0.2791003185087688,
+    0.2841899016238848,
+    0.5568843612857391,
+    0.3708629706198895,
+    0.3050956724156723,
+    0.37305349851062447,
+    0.3589276038766677,
+    0.449395321989353,
+    0.44231254040975954,
+    0.42549838225918124,
+    0.2932245603749644,
+    0.3678340281692995,
+    0.29708374360180256,
+    0.3513774287527422,
+    0.3115743004515554,
+    0.27211573604108424,
+    0.3068622084867922,
+    0.20699797796087022,
+    0.28872899847225714,
+    0.35544757674851535,
+    0.30727605089608745,
+    0.4170552030555714,
+    0.3579590482693372,
+    0.36231960246420297,
+    0.5388648278347565,
+    0.38327486659515325,
+    0.43620288588032197,
+    0.4666103000681014,
+    0.34381720906542224,
+    0.5250296387447341,
+    0.3805688743079657,
+    0.33911103105732743,
+    0.41876027678035,
+    0.3504413539793293,
+    0.28518127139766186,
+    0.21931474763097308,
+    0.35193343131305566,
+    0.5363844329038482,
+    0.3229990499060258,
+    0.34685023779997154,
+    0.2778960481269517,
+    0.22954313693404324,
+    0.4646325281930661,
+    0.31881463877281796,
+    0.4283509839475216,
+    0.26347129811432196,
+    0.236497344581351,
+    0.30437802507123035,
+    0.42342367417934423,
+    0.4563495452961793,
+    0.2861575582300379,
+    0.23622641792674862,
+    0.3844341702067147,
+    0.4092252848672748,
+    0.426574706140332,
+    0.5715626027260942,
+    0.30283365162404935,
+    0.29362582292915346,
+    0.34594712933892907,
+    0.33349283965111726,
+    0.30881262971479717,
+    0.43544069022903126,
+    0.4426722364818718,
+    0.3680822437320322,
+    0.23248250101940118,
+    0.34587680397200155,
+    0.38086197632303265,
+    0.327898435408057,
+    0.47283884304883156,
+    0.3548434092560997,
+    0.4729371650188311,
+    0.45209418094280607,
+    0.29533304078901207,
+    0.36299612910500695,
+    0.37162287307947556,
+    0.3400135361008547,
+    0.3693406325633539,
+    0.3664477590159067,
+    0.3019821607304912,
+    0.44686936624651696,
+    0.3857138987912656,
+    0.24539723429851734,
+    0.2978065308607198,
+    0.4164357780562636,
+    0.30136535999841857,
+    0.3579823079085826,
+    0.2603923861940583,
+    0.44275475488392785,
+    0.40843845578680354,
+    0.3781365369721563,
+    0.30474112587437097,
+    0.40224280475839735,
+    0.46632994958258833,
+    0.4094563234143341,
+    0.2003980971784746,
+    0.24823286718563498,
+    0.28682771458869155,
+    0.27996325005753575,
+    0.37625461315237035,
+    0.2805334627663192,
+    0.20721084394377567,
+    0.29205686631553635,
+    0.2756246877474283,
+    0.3188936920246444,
+    0.37885767624198485,
+    0.47303199215619435,
+    0.2671081285253049,
+    0.44928786122617204,
+    0.5356415500381452,
+    0.3024055260421067,
+    0.4686418000351763,
+    0.2987520074383955,
+    0.4199360257048522,
+    0.6685581010097222,
+    0.49059673506601825,
+    0.5669258894411486,
+    0.6545956387528371,
+    0.5203479285518724,
+    0.6420217546476854,
+    0.5079034373188852,
+    0.6167862930145115,
+    0.5464103485496069,
+    0.5140298495084094,
+    0.48006411517840636,
+    0.3704700705124485,
+    0.6097757533533675,
+    0.6071092402773166,
+    0.554205904766156,
+    0.592432979588912,
+    0.681088789973746,
+    0.6434922758358145,
+    0.5627460974464066,
+    0.3913106898507966,
+    0.6215136985024365,
+    0.4490676627799822,
+    0.5430976530484312,
+    0.5607002355283494,
+    0.5602421994140101,
+    0.5952367343324886,
+    0.5597532001021521,
+    0.6653559187794807,
+    0.5270154825789919,
+    0.39218709157070347,
+    0.43198311084046676,
+    0.5009531653656928,
+    0.6116630590474366,
+    0.4951233485403349,
+    0.6044943892314137,
+    0.6276290383358248,
+    0.34484978457282,
+    0.22168221063097035,
+    0.5418812815822076,
+    0.6237054861308735,
+    0.6416428025060619,
+    0.6914980919279446,
+    0.41951179225320806,
+    0.6209959832491344,
+    0.5908992629629756,
+    0.6540910840685822,
+    0.5438223777821528,
+    0.5968981214896185,
+    0.3815490736445977,
+    0.5570436855248958,
+    0.5665636984057297,
+    0.6549848035437643,
+    0.6550017564570121,
+    0.6372906434479666,
+    0.609313890482645,
+    0.5710340457377563,
+    0.5942066269478914,
+    0.49869831425169214,
+    0.4858431255704615,
+    0.628977803063597,
+    0.5995466940391683,
+    0.5912484683526232,
+    0.543088666512958,
+    0.6471137412122033,
+    0.6525134498359565,
+    0.60411579996228,
+    0.5903005569670013,
+    0.5700712844974146,
+    0.6788798095560534,
+    0.5718629975575865,
+    0.564133408354867,
+    0.33567520725684413,
+    0.5759646299116706,
+    0.5852513144736522,
+    0.511569474025155,
+    0.6179164469997753,
+    0.538799960614827,
+    0.5961835629404182,
+    0.37409603446202616,
+    0.6245791519720831,
+    0.5785024805325922,
+    0.605590136435185,
+    0.7458614829300442,
+    0.6665154437648534,
+    0.6902027328940177,
+    0.5537859122229218,
+    0.6418885544977002,
+    0.5035236641928018,
+    0.6020240370483734,
+    0.6788403065464436,
+    0.62853358470166,
+    0.6555921491607573,
+    0.5946307949297134,
+    0.6014822003695073,
+    0.6165588687211495,
+    0.5304579053035461,
+    0.6084077114265909,
+    0.6236546792902811,
+    0.609386063913986,
+    0.5704999226066539,
+    0.5300077427785664,
+    0.6394368072026483,
+    0.47459793601069233,
+    0.5846147046706197,
+    0.6704162009771204,
+    0.6057603686961869,
+    0.41360728829364246,
+    0.6286280662364863,
+    0.6485015591209362,
+    0.45523939126071133,
+    0.6075947568483047,
+    0.7050650642200835,
+    0.5984839601299059,
+    0.5172672908941873,
+    0.41361684903245377,
+    0.36415142177270027,
+    0.6827172553920616,
+    0.6724380769588826,
+    0.6616090017624571,
+    0.4854513959901914,
+    0.6069998927719499,
+    0.5925671117725493,
+    0.5925035439708287,
+    0.5962012127965983,
+    0.6711155822144479,
+    0.5413666907890422,
+    0.5734595294593775,
+    0.5919651160894993,
+    0.6439522916033853,
+    0.6155252274726191,
+    0.6271389100174145,
+    0.2732380001630056,
+    0.5841491433769443,
+    0.528835928177154,
+    0.6035698760380923,
+    0.6024231503473929,
+    0.5349769479460396,
+    0.5065164116429766,
+    0.6511414618746978,
+    0.48344845785834817,
+    0.2489758760116575,
+    0.6658597189785657,
+    0.6205837017903765,
+    0.4728722987510249,
+    0.6199665131175923,
+    0.509652350363696,
+    0.6242433664602928,
+    0.6039432326036684,
+    0.6997880680729621,
+    0.6506358869368953,
+    0.5271318669444733,
+    0.605117797724471,
+    0.6492146166617694,
+    0.5616966621623564,
+    0.5408742128531571,
+    0.626649104072909,
+    0.6476548778585458,
+    0.6318013954849179,
+    0.5367959956552091,
+    0.6884014155487469,
+    0.5425810602487054,
+    0.5456624635857082,
+    0.6247890221858712,
+    0.5993090264290264,
+    0.5658806092510849,
+    0.5389189261454674,
+    0.5711391386689942,
+    0.505925963914388,
+    0.622768790972127,
+    0.5922039498369408,
+    0.5424093542508543,
+    0.5845409317821422,
+    0.6595944967052731,
+    0.5995141933689838,
+    0.5479015441050411,
+    0.6182168546369154,
+    0.502687045564473,
+    0.4597387242435645,
+    0.3827495742072015,
+    0.34017885480957166,
+    0.646991064726098,
+    0.5267869709806817,
+    0.5472533767751365,
+    0.6414189760245995,
+    0.5761240344914879,
+    0.7394244288575841,
+    0.686678171323461,
+    0.5738289408648762,
+    0.7069177703993791,
+    0.5350544438010607,
+    0.4944554264310739,
+    0.2917241384482516,
+    0.5341614315851676,
+    0.42668944923503804,
+    0.6160991325380314,
+    0.6069225038018036,
+    0.5459097386431563,
+    0.6310007241847208,
+    0.6351451720007812,
+    0.6360647494284917,
+    0.6624811612396821,
+    0.36309623905778265,
+    0.3579326919653152,
+    0.4161831022999634,
+    0.46335016171527305,
+    0.6827199830466291,
+    0.4988403553462712,
+    0.4580972992333023,
+    0.279608962102182,
+    0.6741773945172457,
+    0.5748147501432781,
+    0.6518243743509959,
+    0.6995819416512983,
+    0.655871564431862,
+    0.614901028425554,
+    0.453666836203662,
+    0.6238565683985116,
+    0.617361318726258,
+    0.690275292283554,
+    0.5632867174281585,
+    0.6806298097787343,
+    0.6649329189701558,
+    0.510113227972024,
+    0.5378516842289399,
+    0.5416261656129482,
+    0.5830859180790858,
+    0.4455492616564917,
+    0.6259417378971495,
+    0.6067810176173128,
+    0.48263690310297674,
+    0.5965531323708952,
+    0.569503694324302,
+    0.5469891017165215,
+    0.5884879201716865,
+    0.5569266869690819,
+    0.5407091784860183,
+    0.44795396367393725,
+    0.6982732496881516,
+    0.43403879836073705,
+    0.6264732377154568,
+    0.49602874585169926,
+    0.6137193425121983,
+    0.46936205289390837,
+    0.5539654143139553,
+    0.6003099275253014,
+    0.6658250402444549,
+    0.5046144137629939,
+    0.5340235441502093,
+    0.5874671875895954,
+    0.5932637004596026,
+    0.4663961035106655,
+    0.549100580057287,
+    0.6415115042324575,
+    0.7100895263433116,
+    0.6756653885781632,
+    0.6534902513989941,
+    0.6608308019824672,
+    0.5295802840064155,
+    0.5904392766736852,
+    0.5511231103732124,
+    0.44627804273893357,
+    0.6020411885809364,
+    0.6055982482378579,
+    0.6460667071116379,
+    0.42457909605642663,
+    0.3883326829572301,
+    0.4137399155434499,
+    0.7202505164940504,
+    0.5239886497206059,
+    0.50634599688524,
+    0.4648798258882079,
+    0.5353331070774056,
+    0.6139019287694439,
+    0.6646578948591015,
+    0.46242362429450856,
+    0.6595765859903019,
+    0.6559779321826696,
+    0.3983786832563268,
+    0.3189887884019099,
+    0.5852433538358056,
+    0.5409272062537784,
+    0.6732900713165177,
+    0.46250544827239953,
+    0.48264927057822293,
+    0.5983953486933051,
+    0.5540161428734137,
+    0.545215032745698,
+    0.5954952415965203,
+    0.6065166634643137,
+    0.4844934895758648,
+    0.6099773126880789,
+    0.6032207988579239,
+    0.6967057518555013,
+    0.525231961406406,
+    0.47796843055660454,
+    0.4230321113444016,
+    0.6150753967997242,
+    0.613287511925547,
+    0.5238786046407307,
+    0.6580209037276226,
+    0.5129951652800682,
+    0.5005497138702135,
+    0.6194635942590913,
+    0.6184530170711771,
+    0.506547783885503,
+    0.663478343377769,
+    0.6268708244448971,
+    0.6028285326687208,
+    0.5502219846853463,
+    0.5125776255050234,
+    0.5563610682864931,
+    0.5593724176940988,
+    0.5523794231438819,
+    0.621472087803445,
+    0.6160368259283401,
+    0.6475143203399908,
+    0.5829538049835045,
+    0.5726289829290201,
+    0.5351589009764489,
+    0.4950815928910877,
+    0.41680668873677007,
+    0.5609447415383374,
+    0.5207442687264291,
+    0.38205373224167605,
+    0.607945346398254,
+    0.5208750486411665,
+    0.4567945258194477,
+    0.32415117376107944,
+    0.6416720935940795,
+    0.6065876877166174,
+    0.3346438486633436,
+    0.5791146699721329,
+    0.4728650183727117,
+    0.559580473663955,
+    0.5756740584371663,
+    0.5507795834544422,
+    0.4892823636410579,
+    0.5621353453945132,
+    0.37415495068425125,
+    0.48938669564423176,
+    0.5949254028615689,
+    0.6563458559539265,
+    0.609438171745044,
+    0.554293658852219,
+    0.6569065382793916,
+    0.48054633343247477,
+    0.45596760366215,
+    0.63422671359042,
+    0.5987481891003537,
+    0.6005776626623985,
+    0.6142867112508412,
+    0.5456111214990077,
+    0.49183025649130535,
+    0.6318497512768251,
+    0.5581997548931081,
+    0.5639084259405936,
+    0.5446674054867311,
+    0.41910241554137323,
+    0.4791591494994969,
+    0.40288327031387344,
+    0.4868508811638069,
+    0.5346421200133468,
+    0.4882663389563418,
+    0.5579241291637806,
+    0.6196081238134474,
+    0.6320145931396525,
+    0.5865300349009009,
+    0.6191988264188327,
+    0.40405485669922003,
+    0.5577294960776342,
+    0.608209032316704,
+    0.44269387993835524,
+    0.621310672702206,
+    0.5882089401310094,
+    0.4123767730335401,
+    0.49388301461366424,
+    0.649712162755486,
+    0.6148128409225364,
+    0.5534602120199784,
+    0.5482580659826136,
+    0.4194072792969757,
+    0.6356013982369872,
+    0.5518247389943629,
+    0.45959960921884696,
+    0.6999901234570411,
+    0.6203081691777752,
+    0.5468351841805176,
+    0.48596583100767426,
+    0.7216213182721618,
+    0.6463775024265394,
+    0.5557338595775193,
+    0.516974083006624,
+    0.6825318617770997,
+    0.54144310007955,
+    0.6515863135003104,
+    0.6331307408207097,
+    0.6718014480363615,
+    0.5328739492243099,
+    0.4929814365797404,
+    0.40875312995429636,
+    0.5269859730210538,
+    0.42913760642175963,
+    0.4609774660852886,
+    0.6528558906251312,
+    0.6332455414619097,
+    0.6083646827571542,
+    0.639711006498063,
+    0.6202488523405536,
+    0.6768473185477282,
+    0.46612023347158993,
+    0.6068262447539904,
+    0.6099420062310479,
+    0.6883369709621374,
+    0.6817456376198776,
+    0.5673198735900508,
+    0.7120524307251604,
+    0.6527722699173514,
+    0.6933171810806227,
+    0.6005850419421952,
+    0.6787748848011658,
+    0.52034141182597,
+    0.49160728192703884,
+    0.5837535527832418,
+    0.5694629736407523,
+    0.5977725016542584,
+    0.629349014200771,
+    0.6161307815009858,
+    0.6512777267197704,
+    0.6757019028444642,
+    0.5073127730280965,
+    0.701420155609996,
+    0.59032001945968,
+    0.4515865101708609,
+    0.5773426594921637,
+    0.5636089845552104,
+    0.6728627657325726,
+    0.48378321802695073,
+    0.5952043990800492,
+    0.6120920113934105,
+    0.6065136432993757,
+    0.46968773115454343,
+    0.5011802469013702,
+    0.7090052094389492,
+    0.5386784213735233,
+    0.6351150739769508,
+    0.5278189131871804,
+    0.5486701962310538,
+    0.2616492308184752,
+    0.6660238823833338,
+    0.6146599583580176,
+    0.5915895830453084,
+    0.6189928512724466,
+    0.5579075328673592,
+    0.6544829438914662,
+    0.5940710081787676,
+    0.6363699706569073,
+    0.7051477392376565,
+    0.5795545038027418,
+    0.49204446265857416,
+    0.5015854103784112,
+    0.47172335690811623,
+    0.4413032663541667,
+    0.5793319807301409,
+    0.6588296249355411,
+    0.5382940662944947,
+    0.5439412625865185,
+    0.5684695339307637,
+    0.5308218448926687,
+    0.5900893899648365,
+    0.5616197648560598,
+    0.584027956315291,
+    0.5172246914562418,
+    0.6376512954420126,
+    0.6117681808008505,
+    0.5787028876204487,
+    0.6527648794056277,
+    0.6443523521163131,
+    0.50145625297954,
+    0.59654285976351,
+    0.7004814919782812,
+    0.6216927982185027,
+    0.638786275123919,
+    0.5562163558853656,
+    0.7061247791239731,
+    0.5539562162325219,
+    0.6280606271525463,
+    0.43041173599942195,
+    0.47148910422114393,
+    0.6071126916100861,
+    0.6539295062099657,
+    0.6416060730436576,
+    0.6725099961550771,
+    0.6677485205101742,
+    0.5749558067320197,
+    0.6749283162769464,
+    0.6208306770032408,
+    0.2637961654714103,
+    0.5253241117313231,
+    0.44148415129063723,
+    0.5754435108288752,
+    0.5624178225524279,
+    0.5856977067102119,
+    0.5173837169352071,
+    0.6119388850920333,
+    0.5109764674918406,
+    0.5141603133583066,
+    0.5808241633686064,
+    0.5276763126744993,
+    0.4972258357322155,
+    0.676118686717477,
+    0.4772982930892211,
+    0.37484289723507036,
+    0.4928694389799105,
+    0.4489078138906407,
+    0.48901520426643197,
+    0.6697979822514981,
+    0.553255139468469,
+    0.3671028425594883,
+    0.6670228377999886,
+    0.6427622284769898,
+    0.6439533549522957,
+    0.529401033189278,
+    0.537507578057667,
+    0.38816498927001186,
+    0.5190710096914704,
+    0.486686253178059,
+    0.5435763265218628,
+    0.49975764625301994,
+    0.7225045299660459,
+    0.6273994921937596,
+    0.6344878171147251,
+    0.5695908776046457,
+    0.6224861410581533,
+    0.5215323883548539,
+    0.5501384195427494,
+    0.6501445033163186,
+    0.7153418446811175,
+    0.6117020115606546,
+    0.6466393966030647,
+    0.5841426467348708,
+    0.5712458223660157,
+    0.5432081896415871,
+    0.6728138724573464,
+    0.630181287242738,
+    0.504164354763837,
+    0.48508216375914187,
+    0.6070718948871788,
+    0.6141247656837832,
+    0.5231543423872629,
+    0.6552229174849585,
+    0.4087497293708998,
+    0.44798624039825513,
+    0.6115593434398483,
+    0.5373857310067874,
+    0.5857701699955894,
+    0.5821215730938438,
+    0.6569106504590517,
+    0.5870658611138444,
+    0.5541721031486009,
+    0.6597146336805682,
+    0.6721809036228862,
+    0.546062399842123,
+    0.6361509773913117,
+    0.6450008611260942,
+    0.4661719675630544,
+    0.5121210579563059,
+    0.5582555135840419,
+    0.6037349656608905,
+    0.7034224750466197,
+    0.6422763413361847,
+    0.605920010996879,
+    0.5369830590792387,
+    0.48412837429263095,
+    0.6093736868643395,
+    0.6354391354855028,
+    0.6629859545911199,
+    0.6557568782051858,
+    0.590830345767698,
+    0.5592188591218027,
+    0.4944552065209698,
+    0.6371086644577931,
+    0.5765886072982149,
+    0.5126968207040126,
+    0.6728319518321707,
+    0.5654276329509539,
+    0.6179784053552518,
+    0.6565614959464945,
+    0.4265052406379261,
+    0.6099725042753549,
+    0.4531987395916378,
+    0.4500972732097148,
+    0.6593174177070376,
+    0.6168917091514472,
+    0.6173354614969553,
+    0.565893328943389,
+    0.6376569161386926,
+    0.6071161327683156,
+    0.5335639805304815,
+    0.6146672730521034,
+    0.6820948719696,
+    0.6929446492416504,
+    0.5486541299371601,
+    0.5899146671025675,
+    0.6125258218160546,
+    0.5318333228760254,
+    0.41243567026567146,
+    0.6135315562297795,
+    0.5301168453668734,
+    0.5677262805054649,
+    0.5612066307581127,
+    0.6158278724056022,
+    0.6659657547323801,
+    0.44368881308358665,
+    0.4951341170430751,
+    0.6404149284096576,
+    0.3788551383863476,
+    0.5457853367862321,
+    0.31759972056164365,
+    0.6588934086740501,
+    0.5554859930170545,
+    0.7287804650712898,
+    0.5247716933830943,
+    0.5830910547853417,
+    0.5580272567356428,
+    0.6400207620026811,
+    0.5625533200655897,
+    0.5678232056943635
+  ]
+}
\ No newline at end of file
Index: alice_ae_corr_user.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/alice_ae_corr_user.json b/alice_ae_corr_user.json
new file mode 100644
--- /dev/null	(date 1617582482000)
+++ b/alice_ae_corr_user.json	(date 1617582482000)
@@ -0,0 +1,1 @@
+{"45": [0.7331478622678026, 0.45017161615585755, 0.746686673313902, 0.8444829642624424, 0.7709045177936613, 0.8560649628025205, 0.6946803126361643, 0.8568086225102223, 0.7912787098744896, 0.826044098669586, 0.8352424448741785, 0.8372936187072394, 0.823705573585501, 0.8030290422855861, 0.8296040836534476, 0.8036400434973867, 0.8287688793947993, 0.5458480239683947, 0.7780192062316366, 0.8084441073627701, 0.8045786525814911, 0.7578555548615105, 0.7550206539894868], "39": [0.841282243297127, 0.7777380083886993, 0.8382494032461892, 0.7976366045388307, 0.8184081689699992, 0.7505937477776093, 0.8382855447256246, 0.6940243782535148, 0.5643956273253028, 0.7734025048414559, 0.8336427922177245, 0.8319040896627733, 0.7144071026879003, 0.8020025052139421, 0.8346286522634279, 0.8379330863530595, 0.8433293872074222, 0.8422306994424226, 0.8417247641674295, 0.8053020638004821, 0.7692649148447471, 0.40414081273473235, 0.7154100018943322], "49": [0.852464158097774, 0.850097354130813, 0.8567174365242453, 0.7520349328423461, 0.7281823195895062, 0.6961327676433009, 0.8043320322304581, 0.7719089090306073, 0.8410689784115867, 0.8352713212047398, 0.8279768127842156, 0.8012379946233552, 0.4490056198217322, 0.802859750558571, 0.8353969934773688, 0.7752697768250488, 0.7830551108906847, 0.8458175322142104, 0.830767541477213, 0.5050046059050339, 0.756786563925194, 0.8089703409091444, 0.7901898613613064], "30": [0.8147902466764554, 0.7928085940900209, 0.7744528311648365, 0.5649996413627192, 0.6948140613066482, 0.8411197373526994, 0.8191350363752319, 0.849876180923586, 0.8559719440187449, 0.7320325475882694, 0.8256856619157238, 0.8389437192103576, 0.8397904931263388, 0.8355679433099867, 0.8434126928309701, 0.7694384082265759, 0.4484107492408666, 0.8265334531528781, 0.8042699038854286, 0.7917958255178038, 0.8144562412561798, 0.7546188375410966, 0.6904086271596716], "48": [0.8341973708208539, 0.8581193924500684, 0.44944945080252685, 0.5641427542433948, 0.8098402737318103, 0.8150256901803683, 0.7518513155877448, 0.8137852371484623, 0.8530467676428245, 0.8424721099423667, 0.8416604012560759, 0.7525208912361828, 0.8386874302050458, 0.8265748225332349, 0.7861586701811113, 0.8353150573906366, 0.8356074853303651, 0.7814528118586137, 0.8263547762067164, 0.8061796394092765, 0.7401617521722806, 0.6904379350737151, 0.6416349545670291], "43": [0.4503760825249232, 0.790962290726705, 0.8145971471906702, 0.6955986485009868, 0.7740180537162115, 0.7309757098541065, 0.818018719387802, 0.8400017087561404, 0.8379262623386212, 0.8260523385037275, 0.8426962512779052, 0.8375664436264288, 0.8420848640079869, 0.785034373073168, 0.8250376212054386, 0.8401638159170125, 0.826392386930658, 0.8347807095501018, 0.8015377229800446, 0.7384200235496415, 0.8091553494515784, 0.503488630812882, 0.7106078051409381], "36": [0.7326465717707892, 0.8337726972762328, 0.7747344573568213, 0.8111658991316485, 0.85591901910513, 0.841449494562274, 0.4499054475079307, 0.8504639697809435, 0.857361192246532, 0.8422639315690107, 0.547466953162309, 0.8393658001438363, 0.8346754992922663, 0.8359125719668296, 0.7298888969207147, 0.840217269970226, 0.7976176213471123, 0.8267109641389971, 0.8007672840798843, 0.7363303443200194, 0.7359353553279103, 0.6451746006378154, 0.755011193634058], "35": [0.7848644549789913, 0.8125165043455259, 0.8529384879785256, 0.8548558085471746, 0.8522642567394431, 0.8166424650742694, 0.7856229648430774, 0.6971079156896028, 0.8524940523985605, 0.7120656467678225, 0.8003103551421293, 0.8341285864972842, 0.7833329152810038, 0.7574657788653365, 0.7301450359406164, 0.8267562981732863, 0.8259083989600973, 0.8415528197127147, 0.8443571406830704, 0.7926397096412503, 0.40346330869322267, 0.5052441616801546, 0.8064330532981218], "41": [0.8573796730234778, 0.8497295000337144, 0.7301205978258418, 0.5651811171541731, 0.8525123154006045, 0.8515558011514276, 0.81286516167828, 0.8339105628838485, 0.6925339533897481, 0.4476525641447685, 0.8000166543463411, 0.8413568485723322, 0.7319342099164899, 0.8327997003381672, 0.836798607555799, 0.834566493172383, 0.8004944141917892, 0.7796350020772468, 0.7595294390344519, 0.7923762557293246, 0.7393658711581003, 0.7561267690988307, 0.7931139340651181], "50": [0.8401311727110963, 0.7816589544773462, 0.8133770532377798, 0.6952045754381831, 0.8498395796300655, 0.44958573146600345, 0.8524798586088677, 0.8527016078197953, 0.7520662250284134, 0.8458239130159426, 0.8341816215714418, 0.8270060455436138, 0.7860983647998812, 0.7529371376309802, 0.7920444298528491, 0.5455927561273732, 0.8013196928924688, 0.8388871535346589, 0.8342123378786777, 0.8078548716383195, 0.6910574983511163, 0.7417569275800865, 0.7929848707324925], "44": [0.8528526273501572, 0.693111746431725, 0.8417590564598039, 0.8552945061498263, 0.8558241396926033, 0.8414827406251467, 0.8563201228905812, 0.7838881554064484, 0.8527972254081035, 0.7559206480620304, 0.7875051303081819, 0.8377445832897686, 0.8014175357017432, 0.7299053113164269, 0.8243241191942448, 0.7154247878409316, 0.5472343775200806, 0.8014563258554602, 0.7769297825120139, 0.8005625021176053, 0.4045878451387034, 0.7593057623595696, 0.7918268676688749], "42": [0.8524035214441479, 0.8519649212529203, 0.7886392722046552, 0.45022550381774284, 0.8565128927838117, 0.75005261729122, 0.811568519920732, 0.8130331075462746, 0.8577590765903271, 0.6787946111273082, 0.7802362920093657, 0.8297442073951102, 0.5475348432194046, 0.8355587955255177, 0.7140972669898483, 0.8242650570771458, 0.7860106507860799, 0.8402001308580155, 0.8250364899381801, 0.7134071392823758, 0.8039493945925338, 0.7920359807600107, 0.7701851512570757], "51": [0.7498176302685384, 0.8519856095545967, 0.8414594982830047, 0.8149228093114926, 0.448815385897135, 0.8165016187767331, 0.8522536461504349, 0.8507009564763796, 0.8467291512789494, 0.8376933708107361, 0.7829092375079452, 0.82623444122922, 0.7914088754513043, 0.7138781293346474, 0.7575402031429791, 0.837875621533359, 0.681017092711283, 0.7729683875134757, 0.7804820852029946, 0.8082368961577066, 0.8099958186501307, 0.7926740076130182, 0.5040138703118971], "53": [0.749222642521675, 0.44953575981317495, 0.8547231347637475, 0.8576476601100891, 0.8140992171670475, 0.8402005257915315, 0.8527172346747565, 0.6955403498099655, 0.8431025844736924, 0.8368317810440332, 0.8338707574767601, 0.7877855687434616, 0.5480672685350991, 0.8364202523889768, 0.8424353298229177, 0.7146700956980568, 0.8241334258045572, 0.8244494133319233, 0.7807548017225108, 0.7533019039285949, 0.76840612115069, 0.7153888580423958, 0.735037497619738], "22": [0.8524605823124253, 0.7277372660740778, 0.7919638347682503, 0.8511743205726706, 0.856272058487402, 0.8522916844167847, 0.8382008101009077, 0.782386833045067, 0.7984789583715639, 0.8241072131906865, 0.8018437173469348, 0.8383047764121467, 0.8411959051347975, 0.8404514867203843, 0.7338389022463313, 0.8330328447278422, 0.825590296698333, 0.7994980141105844, 0.4478468362390794, 0.7135280397490971, 0.7710097003636894, 0.505739633581992, 0.6428492366974349], "26": [0.817846997830488, 0.8489869803897708, 0.44957207893279166, 0.7756619866472778, 0.8516395109022467, 0.7528025861813195, 0.562995202198943, 0.6954948292072248, 0.7979712305157943, 0.7781851603396166, 0.8447102873439994, 0.7126908865191757, 0.8407464171999286, 0.7798731525903411, 0.8253211291626178, 0.8250589793290517, 0.8342124843733189, 0.8262192232433139, 0.8387483038088682, 0.8044224138294006, 0.7705158687088847, 0.7940589850167006, 0.7569785221168135], "31": [0.8379110263916092, 0.8498414207569793, 0.8195917869775233, 0.8389386189860291, 0.8144407214859135, 0.8175937848368927, 0.8553099959065132, 0.8578065959998227, 0.7980157346664035, 0.8254943464989033, 0.7121740559209815, 0.7314185994642521, 0.8348115682498409, 0.6792470294304335, 0.8405886558291803, 0.8273458247721136, 0.7764807741028901, 0.8374777176032207, 0.842700321924188, 0.7135273710068178, 0.40368802062396336, 0.5048835371640882, 0.7358103781286534], "18": [0.852320191834652, 0.8336570737367275, 0.5641360989878991, 0.8568494195133091, 0.8539379235486166, 0.8014906725178296, 0.8520517530259107, 0.8169492159506377, 0.7985081961887411, 0.8259411292294566, 0.7289983420487478, 0.8019516847814898, 0.6778045673921612, 0.8250050586393263, 0.8455679109496462, 0.8003046539599069, 0.7556754511742597, 0.8370266949442309, 0.8375032018633426, 0.8014271845256866, 0.40413156798988736, 0.6919049987004339, 0.7355706382831741], "47": [0.8555629742044737, 0.7671308646512756, 0.6948810448686589, 0.7299694741437315, 0.851937561909812, 0.8152507144594398, 0.8408310439030009, 0.7485663902326241, 0.851031686723502, 0.5471393945862909, 0.7832017387767022, 0.7775263681514928, 0.8016170789601366, 0.7968997884567321, 0.8459809405809526, 0.836022647746372, 0.8238588619608732, 0.8353657535357244, 0.44810294862304806, 0.79261309348809, 0.7966128173854532, 0.8110243576337794, 0.7562443016989885], "24": [0.8396799413579615, 0.8404138026974277, 0.8354662269951121, 0.8520156751253847, 0.8157458636240444, 0.783012309679405, 0.8127125706978608, 0.5642658843462738, 0.45054773589933084, 0.8407502641183884, 0.8347791772691088, 0.8404137247412152, 0.7817419902487497, 0.7128253488705207, 0.8266712638162405, 0.7840573115164013, 0.8452015187418143, 0.8017406591320705, 0.6793389604097461, 0.803860332499064, 0.7124448051833929, 0.7118150187076246, 0.8064506400523292], "28": [0.7296539653049603, 0.7988363228005051, 0.7522149766662938, 0.8547096912068454, 0.841361894191892, 0.8504669926733178, 0.6935942833707519, 0.7774622054003515, 0.8540036724389936, 0.7826444332250688, 0.7718834772543541, 0.8348075674249669, 0.8014226719653237, 0.8009409497350357, 0.44826005915110534, 0.5466590042759272, 0.8328292727929345, 0.801780046690048, 0.8397251174104301, 0.7944127470721034, 0.7918726424803926, 0.8031558369663865, 0.8089004119891424], "37": [0.8412549973517992, 0.7958256913686078, 0.8527413783441, 0.7748278665345854, 0.5654283245444512, 0.7790138120434706, 0.8368407003506455, 0.6988705286542993, 0.8578297667521104, 0.4482729314690078, 0.8274917994577279, 0.8400711482521399, 0.8004806594168221, 0.8375856982728832, 0.7752082342994926, 0.8430185603551504, 0.7992291013260399, 0.8346264140440435, 0.7299202614564356, 0.809124363573885, 0.7955445132479427, 0.7565582701310349, 0.6942442238121809], "23": [0.8519252259662031, 0.8538937183684417, 0.8545459118766201, 0.7922329786093871, 0.8578192156293968, 0.8412142391624703, 0.7545706174042249, 0.8522383576515762, 0.8135174345886106, 0.8239965062045115, 0.8368401715526348, 0.7876259377681321, 0.8408792048938941, 0.8262401703850539, 0.5464757415394133, 0.8027554259667254, 0.7740103120059856, 0.8016260863014792, 0.709569463684011, 0.7143770316783185, 0.4038282519683054, 0.7940377518492922, 0.6426527202888779]}
\ No newline at end of file
Index: run_2vs2test1.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/run_2vs2test1.sh b/run_2vs2test1.sh
new file mode 100644
--- /dev/null	(date 1672867290000)
+++ b/run_2vs2test1.sh	(date 1672867290000)
@@ -0,0 +1,5 @@
+#horovodrun -np 8 \
+# shellcheck disable=SC2006
+cur_date="`date "+%Y-%m-%d-%H:%M:%S"`"
+nohup python3.7 -u src/com/model/2VS2Test.py \
+>> "output/2VS2Test_$cur_date".out 2>&1 &
\ No newline at end of file
Index: run_AE.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/run_AE.sh b/run_AE.sh
new file mode 100644
--- /dev/null	(date 1674105055000)
+++ b/run_AE.sh	(date 1674105055000)
@@ -0,0 +1,6 @@
+#horovodrun -np 8 \
+# shellcheck disable=SC2006
+cur_date="`date "+%Y-%m-%d-%H:%M:%S"`"
+nohup python3.7 -u src/com/model/run_auto_encoder_shell.py \
+--MODEL 'albert-xlarge-v2' \
+>> "output/albert-xlarge-v2_$cur_date".out 2>&1 &
\ No newline at end of file
Index: extract_brain_feature_ae.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/extract_brain_feature_ae.sh b/extract_brain_feature_ae.sh
new file mode 100644
--- /dev/null	(date 1620912013000)
+++ b/extract_brain_feature_ae.sh	(date 1620912013000)
@@ -0,0 +1,8 @@
+#!/bin/bash
+# shellcheck disable=SC2006
+cur_date="`date "+%Y-%m-%d-%H:%M:%S"`"
+str=$"\n"
+nohup /usr/bin/python3 -u alice_feature_extraction.py \
+>> "train_ae_alice_$cur_date.out" 2>&1 &
+sstr=$(echo -e $str)
+echo $sstr
Index: extract_brain_feature_prince.sh
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/extract_brain_feature_prince.sh b/extract_brain_feature_prince.sh
new file mode 100644
--- /dev/null	(date 1695532992000)
+++ b/extract_brain_feature_prince.sh	(date 1695532992000)
@@ -0,0 +1,8 @@
+#!/bin/bash
+# shellcheck disable=SC2006
+cur_date="`date "+%Y-%m-%d-%H:%M:%S"`"
+str=$"\n"
+nohup /usr/bin/python3 -u alice_feature_extraction.py \
+>> "prince_feature_extraction_$cur_date.out" 2>&1 &
+sstr=$(echo -e $str)
+echo $sstr
\ No newline at end of file
Index: alice_ae_corr_nol1_1024.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/alice_ae_corr_nol1_1024.json b/alice_ae_corr_nol1_1024.json
new file mode 100644
--- /dev/null	(date 1624432176000)
+++ b/alice_ae_corr_nol1_1024.json	(date 1624432176000)
@@ -0,0 +1,1 @@
+{"47": [-0.0058042575513561675, -0.012879735317623415, 0.029355225195612566, 0.03941817769262416, -0.00925513496233259, -0.011022313966398325, 0.024301690197289158, -0.017920388391873564, -0.008375478799813381, -0.043510977729725515, -0.04017150736446283, -0.0013190503471597437, -0.022572396576036984, -0.04297651648473525, 0.03412575970343421, -0.024582042797561793, -0.034208961569271175, -0.018178385490089596, -0.0031435578470246374, -0.021631702514412727, -0.02179210607000859, -0.0268896275851565, -0.013547721947285516, -0.01919396855159051, 0.02196750442081719, -0.05832265437781413, -0.005720360669043796, 0.002571626850727645, 0.036845250505369756, -0.007350281419596349, -0.012118640424415725, -0.0034497804197382563, -0.0096698549543656, -0.006657014764218057, -0.005272621987865106, 0.03006354714423234, -0.033770795615327046, -0.0192978445174194, 0.004032033149630819, -0.012645668373931662, -0.00151631909030173, -0.003145964814806466, 0.005803098045448132, -0.007405492962627687, -0.0068447840987469226, -0.00842364575540736, 0.017406975806524505, -0.013203059933826405, 0.00026868605050515184, -0.0027752609105607205, -0.030761488672381498, -0.004105889746132833, -0.0015335560525054713, -0.021488794435343177, 0.04921085822121234, -0.030952227354729904, 0.0404247620510844, 0.026810847570137235, -0.07366824336465522, -0.014668668695583613, -0.03146530543465806, 0.0587420724898511, -0.058378418011663415, 0.007246904329997909, -0.01671684605699859, -0.018184341050617146, -0.038608705325072955, 0.028065748842388258, -0.007590644122269516, 0.0011648997812863235, 0.01008387200027835, -0.00013016629732624492, -1.9717543058292147e-05, 0.00014458221535493525, -0.05338063092219607, -0.0007651468961297572, -0.0021673969548104146, -0.03667985748572599, -0.029885960381490335, 0.02789030553674466, -0.02891036529762722, -0.04063255566734156, -0.023115875714499665, 0.031080309207364987, -0.04160388061494124, 0.005022679400879305, -0.027112456973793313, 0.00619902334978983, -0.03791710635703365, -0.05394601587948517, -0.018179910066090762, -0.02948487014510329, -0.020561504434819546, -0.06162940466448026, -0.01694175272889782, 0.0010379435520930934, -0.023260121439108772, -0.009382429947642079, -0.00988500738322816, -0.01186213058279545, -0.031066727491010245, -0.01722611607327397, 0.005055621045249465, -0.061530482309208025, 0.007345455915542236, -0.005211462036950295, 0.01700311446334583, -0.002076017741952749, 0.01194966844864549, -0.03479520183130412, 0.0054231486590249995, -0.0020904681362640823, -0.0363024678766777, 0.0297202645731378, 0.0025835982536872373, -0.014801979374490341, 0.01655081279621956, 0.02762592638511108, -0.029402363608260006, 0.031038511672061977, -0.00673684329011382, -0.054483522190912285, -0.02078912890976823, -0.027877456854219346, -0.060113601987403995, 0.06594740939257682, -0.03506154133974014, -0.03561708271045796, -0.03163229713256422, -0.07642448452053485, -0.0386822081787698, 0.018395593719610265, 0.006709991442354634, 0.025728685916624472, 0.05181762913826919, 0.03826285304417461, -0.04114983055326755, -0.049316778162737225, -0.021570543384654122, -0.027568337731902814, -0.021182757258406616, -0.04951381762837846, -0.05707012341965559, -0.051641027812041336, -0.06857739223224445, 0.0009361053818894166, -0.024011151738898954, 0.03337070498661517, 0.027981323435242525, 0.013727029027064727, -0.054177379457824124, 0.03494500790506752, -0.020715271435872505, -0.01911436861727998, -0.029998838986600395, 0.02135885416159826, -0.033733461336186474, 0.018575316805371958, 0.03499157802233316, -0.00507485949512864, 0.021780019217542947, -0.024440404550608415, -0.025208036173474266, -0.03275524503364034, 0.004132754679801636, 0.0439125349804614, -0.014672099900108785, -0.005134288915072916, -0.038951821443817695, 0.005356200286072107, 0.021179806916361843, 0.050090102755388846, -0.018133305620066088, -0.02276485953237026, -0.07221245005500442, -0.017352625775983378, 0.04015201904384519, 0.04139171339735406, -0.046271349788305736, -0.03238300231698804, 0.00989160749667476, -0.03792983241330206, -0.03393537928152821, -0.01941635264457542, -0.049405450132946394, -0.0003733711967602896, 0.005758104417912269, -0.04979843654801597, -0.0021611716749022837, 0.02575265765865168, 0.001532795300548518, -0.07185730428702816, 0.026940309484849743, -0.03789719895244023, 0.001240586112559761, -0.04398955628967242, -0.01490691537593412, -0.009023557289161148, -0.03423955197364918, -0.04363389801167088, -0.010013019636188308, -0.037333238789392646, 0.008364967233642124, -0.005332302285393294, -0.04030549416809622, 0.030104167432223373, 0.0381776706677763, -0.018853502231194343, -0.021960963200734786, -0.020250042669448708, -0.08835471503144149, -0.05402997760554569, 0.0019570816229523952, -0.05222143467144431, -0.012018429334327691, -0.013332139293381102, -0.0703389670882814, 0.038469001550798854, 0.028173420042403672, -0.01741655070178721, -0.002051031127467052, 0.016069680315317064, -0.05479295744368964, -0.014923092178797843, -0.031586918138824784, -0.05892621644171039, 0.00769806507297432, 0.07436109604010685, -0.041353441448367875, 0.017361738750596954, -0.06969116141653565, 0.003218295363743888, -0.05670701339902906, -0.029714805549113613, 0.015254533487864513, -0.007299505980175681, -0.0030916043870017782, 0.03128249281364372, 0.020971157120320476, 0.00899162397487715, 7.91883789037129e-05, 0.0010560978854674886, -0.04159938786306938, -0.01757728712597415, -0.009847515088409446, -0.012070622656363786, 0.001537500891783346, -0.006882953700120154, 0.034048625702773415, -0.01610645813216494, -0.001522341458152449, 0.017835397904390704, -0.03287820046847193, -0.020466589724773172, -0.022055457455167935, -0.03247009220837437, -0.02167812138757229, -0.04613623822234556, -0.05702402687737828, -0.025398383360713532, -0.01883082441951232, -0.020329611848086335, 0.037420070665663115, -0.032700488346493126, -0.04750492509570023, -0.0019688547224998975, 0.023977088087076256, -0.021736070673175966, -0.02069431847623684, -0.06703188096727354, 0.02197140401346847, -0.035603307091866855, -0.039436461612835885, -0.05840604808398318, -0.00385665109494653, -0.05121859828979418, 0.01534527416620163, -0.052756974753097596, 0.009162407060787092, 0.012260224751546799, -0.009091442879064228, 0.03854481670732906, -0.041901194590202286, -0.006912700136264566, -0.02581036238929961, 0.035713929993736536, -0.05021740259254674, 0.04469345011343904, -0.050641834140462416, -0.06019609283768534, -0.04415795184280495, -0.011863999316280344, -0.02562185566747842, -0.019428639078687814, -0.018702448302770396, -0.00857919169379746, -0.036721113257328894, 0.032626381412410824, -0.006580824805390278, -0.08149090840788158, -0.0349644225761613, -0.01700302328038161, 0.02037891858572495, -0.013449460556767986, -0.024112194897358972, -0.010577381921324548, 0.0017947015324670634, -0.06239133912462778, -0.014591771213840447, -0.0043063879528253525, -0.01023061925642074, 0.0015420978440831147, 0.01034768216121944, -0.0390846744532489, -0.020552557145893262, -0.05777577458470865, -0.016647559634653, -0.047680887710704, -0.023899067691009645, 0.019331199951155856, 0.027704564425146457, 0.03270337334296097, -0.027907089796510128, -0.03030216469737589, -0.031096637097507332, -0.04527352190424961, -0.026899193989816286, -0.05803783915128188, 0.015130648002200554, -0.029536184176788785, 0.011338073111020468, 0.009449183533896899, -0.03572040944157305, 0.0069026606496299815, -0.02059414315580821, -0.018436220115815125, 0.03558260790695247, -0.026164294275325434, -0.02847249145402866, -0.015295135976268191, 0.00514087149583059, -0.01678396902328147, 0.02944328889804313, -0.03417539530698559, 0.0074000631438052855, 0.01545520034085276, -0.08960681617444573, -0.045687372126719535, -0.04169822509232781, -0.03755299478984122, -0.008308886600783117, -0.04871167304409863, 0.005451061296608364, -0.02376746200376878, 0.04509519414073958, -0.05386428938230839, 0.04902692539931462, 0.038869873361931116, -0.08476006866839249, -0.030709636979840235, 0.05891864305035964, 0.05172092843342815], "24": [-0.015764853016115653, -0.028103597443536035, 0.013001731504396371, 0.017957033202331527, -0.03543887404690554, -0.011578660427454392, -0.014603582976878695, -0.006147629802617353, -0.0055271943314498875, -0.05449799933007175, -0.03369486252525049, -0.039090680418079636, -0.017954398399045536, -0.02673554118883054, -0.05239924628521254, -0.024412584542727073, -0.03143325139430385, 0.04754097326020658, -0.02118660834321831, -0.03489331848733146, -0.021319914646796844, -0.02027356320417805, -0.014265622250428904, -0.018774207142955364, 0.009535154734221379, -0.01598239656107564, 0.012085866637332764, -0.011733160008718158, -0.015875851413650055, -0.03701307320970075, -0.011145649852945813, 0.0013933539618729758, -0.033008295071168176, -0.006790263144330319, -0.05851216997953071, -0.017815843008732547, 0.04789085972251686, -0.04694074654048564, -0.07611271534645919, -0.06785050087418451, 0.030565821325689035, -0.028431144363137453, -0.026312911483971857, -0.0158125411052124, -0.05074645982962298, -0.03517248231318948, -0.0328681790555693, -0.03680676125484117, -0.0062347768945535675, -0.0006555348824105646, -0.06570287844727717, 0.03229003634838419, -0.005939202799255854, -0.011224854830515643, 0.00813900468188926, -0.02228621130846604, 0.021769312901089303, -0.00992658209888048, -0.0321952804323893, -0.019349584328405264, -0.024049900932100545, -0.034995431351978135, -0.02503158104189447, -0.053986238581228065, -0.013329246372063354, -0.013613017813396838, -0.015260966686298661, -0.024731781913131905, 0.016207423858657807, -0.006003212866592783, 0.03265482610450206, -0.052184596006019476, -0.019191632419042138, 0.021584887297932866, -0.021384210457690463, -0.055886836739207586, 0.0007294340923067027, -0.028459955529521585, 0.032268638378138335, -0.013020639599708141, -0.017577827339594725, -0.03394263572503557, -0.015192963259677282, 0.026300322940395394, 0.024431461755051738, -0.03607175455171334, -0.00019053142930261475, -0.005890184895508758, -0.04555488446246135, -0.04172256316042376, -0.041012695496472684, -0.019169967938338087, 0.03475707827296121, -0.03700329754218437, -0.05770491091230017, -0.008011794105418111, 0.04240036377912995, -0.007114676395319022, -0.04206370488712451, -0.04530656672845184, 0.030927987866536902, 0.02821010654035354, -0.024272383708015557, -0.004266825274299074, -8.766111723399791e-05, -0.016733231195554928, -0.06955831487928865, 0.01536110535806974, -0.015742370495342942, -0.004026228527082909, -0.02551476326050501, -0.03630317402122368, -0.020869225396146933, -0.03645353815730681, -0.05249959643135077, 0.037617021150396335, -0.009359632354188366, -0.024811838503983327, 0.013163563382729128, 0.054265653531065126, -0.07798693590339066, -0.05255777727866052, -0.04332779795948281, -0.021163686782610408, -0.06208550915538064, 0.0381592871411554, 0.03070274836356318, -0.05095901015100231, 0.042923367870921686, 0.04980242774382665, 0.002413614489900338, 0.02127254700432796, 0.003647438846085075, 0.004974198741050096, -0.07148991751322774, -0.05075609993996745, -0.01914654195708087, 0.03627138971298505, 0.02415246816802123, 0.0014523391016403034, -0.013686865075979146, -0.05399978333670197, -0.028102473017807134, -0.031395040937436045, 0.03330474541865421, -0.028245455105562447, -0.033303953376529756, -0.03759456452481856, -0.03757261223237703, -0.07882435923458041, -0.04386186465537686, -0.07566132877372181, -0.0803745582564009, -0.05295214295726245, -0.03926146999107834, -0.02717253877123522, -0.02875465775734536, 0.056242406203574576, -0.027378470949264388, -0.05715268501343203, -0.016852333164731427, -0.00711812510238965, -0.013294123712280198, 0.012859407520961446, -0.030704647224209396, -0.06839152958317861, 0.04205144821260519, -0.025279350418930778, -0.0408231159940434, -0.05627064885543155, 0.012863736458329673, -0.02416223998044792, 0.05824488833357071, -0.010487178298050705, -0.04374054434295846, -0.013453836526808951, -0.052501691929230765, -0.027205413784642047, -0.026995671437151984, -0.04922545420305911, -0.0019095888183855987, -0.005246301597661843, -0.04950571641602043, -0.04989074396443264, -0.001200743490063973, 0.023260756485251943, 0.003003045886150913, -0.0043620146344473835, -0.076743912424744, 0.0015838208815077209, 0.004864174705157205, 0.011270014774853083, 0.005115236013712736, 0.0005745047088661122, -0.008215010543239762, 0.027981338520235505, 0.0024848929846687986, -0.0029486284094123513, 0.032503160686456055, -0.027285302893630726, 0.018810320585303332, -0.07628251531716021, -0.02329506348064283, 0.019956104278428168, -0.01832294110882207, 0.011382982516751707, -0.03660382809647272, 0.0301725008873248, -0.021142894260302202, 0.020416618153458795, -0.00653221628941641, -0.08200036684519765, -0.04526875886822101, -0.0466494804022578, -0.03345868466324628, -0.02157523108474931, 0.03616295792366355, -0.004147580591537219, 0.009023284529410676, 0.0348879207704901, -0.017355155032147535, -0.033597257317245145, 0.009879969654085354, -0.0259664659091172, -0.013588054034857648, -0.015157872834990819, 0.012299645421797234, -0.00550546614811476, -0.018799094141510264, 0.0037800283798073973, -0.0006830747221024969, -0.06209261400231984, -0.06092334456569882, 0.01001633700209963, -0.0019712132685148296, -0.0014247871345755652, -0.09453087938903579, -0.005124216664836982, 0.03171336203324794, -0.002388661585166917, -0.02311919751379524, -0.02075428292036381, -0.012839892602234745, -0.005071926103296994, -0.025457126743472065, -0.07082378433349683, -0.06407214535911455, 0.04425360710987966, -0.06671790968061206, -0.0021453908005740698, -0.007482010800952966, -0.02098947131842407, -0.032662129545104994, -0.03369239416700879, -0.04658239268635202, 0.0072715688936288315, -0.012755069850870425, -0.020399072283858986, -0.023754579325559976, -0.02276169173484688, -0.024013172334667193, -0.05012398631375735, -0.03613751160197006, -0.0035558276334076992, -0.038997850320855315, -0.01937488120361412, -0.04631274081881348, 0.002137307106724476, -0.014799765623523725, 0.03213524317906446, -0.05417999637635402, -0.0566594297712109, -0.08851811960407177, 0.010569446190089113, 0.017269979286652474, -0.08235458661134003, 0.025132906592308282, 0.027076409881271732, 0.042505800386985274, 0.0010735760291306648, -0.022624237233384026, -0.0463289136132959, -0.04099090833819535, 0.0475529525444105, -0.012788471842266108, -0.01144497223859527, 0.03545371821340908, -0.010324163762320574, -0.053245358297381404, -0.039930021267574826, -0.05311107209496721, -0.015075054811684675, 0.024896799326442596, -0.02171565292924554, -0.0356695975337898, -0.06664660694017911, -0.058512344747339295, 0.026631607627454354, -0.05544869179766384, 0.032266853880685745, -0.04577123905313341, 0.013534079698474534, 0.021407680066210705, -0.04039260606646686, -0.06054911429403845, -0.025616945848448962, -0.05938462523294291, 0.007579641307105446, -0.008833392458275151, -0.0017603645018622693, -0.05230799439699511, -0.05721949297840235, 0.01935242809504291, -0.007482417880828236, 0.0007768921407777433, -0.0019206761196336537, -0.014858908423684418, -0.012354021635402425, -0.04395477851795231, -0.044889399429443755, -0.028676215195540207, -0.031947050049699194, 0.028350571420814864, -0.03607480730069789, 0.046212228647850455, 0.0205639137727006, 0.004442874031660238, 0.001800438233875905, -0.006345287881730345, -0.03688746369938176, 0.03731303568476274, -0.04051161966245525, -0.0570519406046032, -0.025860471871083115, -0.06362930871610377, -0.01323407131094364, -0.034862521040049235, -0.02493764099115853, -0.04668528994786303, -0.04557595950617156, 0.0044274472964207535, -0.012150128628373441, -0.01384587233534325, -0.02920390969575939, 0.013647968076796229, -0.0002484029499275597, 0.051866146401575684, 0.03193997857361925, -0.04113088508644211, -0.03659763421062262, -0.07029429314327357, -0.042806672810425585, -0.06638662027682804, -0.05547605885523512, -0.04268183788122347, -0.04425772736334234, -0.009207392348801292, -0.022562395509698605, -0.06661193266295377, -0.019971604868937873, -0.01739594687861633, -0.028664308658108532], "37": [0.028808937628217297, -0.014365028082135096, -0.010165763471107293, -0.053744305247412735, -0.008571890497035864, -0.005629591846988108, -0.060658781692741345, 0.024386243940179804, -0.044414779611164405, -0.041740665888442, -0.07180939529517029, -0.03416413101155665, 0.015126343035249946, -0.03195067358715429, -0.02548991028731004, 0.011251664355247881, -0.022536645225489586, -0.04491807995611867, 0.035044354740482266, -0.02812955091880885, -0.01678793369314055, -0.018954736470706047, -0.014805246648296128, -0.01703423041869097, 0.005810659752160875, -0.06379433673165265, -0.03192659846785011, -0.0203540074487344, 0.007961157309139226, -0.001560170597235839, -0.038436241976376254, -0.020082098253717165, 0.021900476870219617, -0.051516656210799504, 0.05151682041701777, -0.0007521565958323224, -0.006704928647137888, 0.023838722465092516, -0.05317217630720531, 0.006110810369480592, -0.016151042217412367, -0.005983725699115316, 0.030035236935556382, -0.037407722700002186, 0.009189608430300861, -0.01307729279150968, -0.009561864336214485, 0.0014542694348799873, -0.021804400392505478, 0.002065667779898412, -0.01121719711712008, 0.030101352110581174, -0.003986680457826465, -0.020345890272523412, -0.01767416879412245, 0.033231627201091775, -0.08307865211514771, 0.05492585791047068, 0.02129257355260879, -0.04971719111315754, -0.05730494733173475, 0.04146791237352385, -0.05875045458795097, -0.023439414216036823, -0.027975099947555454, 0.03689131346469541, -0.014836414645810139, 0.05722456436453147, 0.003499742007564996, -0.0347851684007468, -0.07468071013025086, -0.020930483818104903, -0.014350085570054094, 0.00060930450934894, -0.05415571364385732, 0.020221722959734963, 0.014952365627372802, -0.030658941775787055, -0.03926426153914556, 0.03257005551567314, -0.035831825422261314, -0.022026095342458356, 0.024211063646101514, -0.005385697452120798, -0.045450251662820906, 0.04473668257891493, -0.017253858543079526, -0.0007633368371291618, 0.05176067627349395, -0.006625261003771797, -0.031998282860413105, -0.06409653127688668, -0.015143925644743553, -0.010647902775829467, -0.008194658251648753, -0.009092864287956274, -0.009001738742714656, -0.03094684159966406, -0.025352870773996214, 0.03271674016453838, -0.002306498110586706, 0.013775764738128693, -0.022894055383851596, -0.0697166330530718, -0.06748032916697225, -0.009695812648885431, 0.007393464311250104, -0.03110741618153008, 0.0041178847990684, 0.02485917210964496, 0.019079250573111012, -0.03953151036336469, -0.03622622864818604, -0.006059003975086275, -0.01988926078388776, 0.041221545698206415, 0.0288539384541676, -0.022590998320434694, 0.023310999976869695, 0.030018947250468372, -0.029129824340603037, 0.0006274699155006363, -0.006705221643156845, -0.009839388181032483, -0.06648795483298368, -0.06371905572855935, 0.030041228986580615, -0.02538124576322527, -0.003308422714501145, -0.042536005583926, -0.046949642350861825, -0.046453593294150136, 0.01614452351957049, -0.0229606860288771, -0.04036464453920173, -0.04526664514418379, -0.05871145884935849, -0.048785143647352446, -0.014528994218342604, -0.023461265795990806, -0.030277109346696897, -0.04512444373250927, 0.03733562725312841, -0.046392625100257795, 0.013017622148984918, -0.03588971017153938, -0.0019406427355160784, -0.01839763294224831, -0.03482248453357537, 0.025191613138919162, -0.05109571303689081, -0.06009777487473408, -0.017060116928230337, -0.0759180948770437, -0.02458915269359582, 0.014484740359182603, 0.038440831726644274, -0.04697845290902035, -0.026419261747368743, -0.02716063006954665, -0.026292910130895727, 0.027587416626946946, -0.006975758495781694, -0.014267758224172339, -0.02811937182326359, 0.003933736912979807, -0.032139223599303164, -0.030285886789256707, 0.031164845835927553, -0.027806544244879307, -0.040187812744939065, -0.023575007839903055, -0.0541713560146113, 0.03489456487574385, -0.020964742794966917, 0.011839496268507482, -0.01933329848220837, 0.034928040227735394, -0.02176866995726844, -0.042293707618164124, -0.010412450898690159, 0.005857252978951744, -0.05373280239307502, 0.007765837750564286, 0.004953438744436438, -0.052906246927494315, -0.008770097556179326, -0.05335815956934038, -0.021167306601741116, -0.0006240270868707998, 0.009372015146078352, 0.000924618624551798, -0.0028927929772304167, -0.015923272908858418, 0.030345743963917576, -0.003075032157056421, -0.003472931303354524, 0.012432532473142242, 0.0027843695622588103, -0.061519385817222036, -0.045088377925493896, 0.004713845975881465, 0.015462825645956892, -0.004821369178101082, -0.004473019503501109, 0.03323334560634431, -0.029696031618509817, -0.030769011825387806, 0.021951609853926093, -0.021452553675696002, -0.02846729215158721, 0.004656796076358987, -0.026865787386581158, -0.027426001997316606, -0.0403355196001137, -0.017740582417530754, -0.03225562270361114, 0.03036940812547642, -0.03955167958865446, -0.05537253266820575, -0.022886447185839355, -0.02830410220967824, -0.005670894592431453, -0.011887028962324204, -0.006219410815934399, -0.025641182158725642, -0.02285317304066926, 0.06441553157728395, -0.036148276093719275, -0.04962288054520973, 0.003205573052886472, -0.04957495948092778, 0.0037325873138909066, 0.004300625090718351, -0.05497628547789144, -0.05032047528071366, -0.014434453200446506, -0.02501296362255685, -0.0017768187670949161, -0.06922223925892068, -0.05905072704253495, 0.008483124786627355, -0.007074063531106799, -0.0018049602601783769, -0.017225033096168834, 0.01930919861041578, -0.013654625573005074, 0.04615154603082267, -0.02888451459465631, -0.0376270310604079, 0.0242630367146917, 0.024470732274232618, -0.017709262229757567, -0.03711637915202817, -0.06607096926452895, -0.02716449198487306, -0.05871351905481468, -0.04944241957431758, -0.016861911001280185, -0.039876547150710255, -0.037370303586074016, -0.027104923613231437, 0.017159836895496505, 0.009236106713916633, -0.0582887974328383, 0.0030188536388191314, -0.019572814979685164, -0.015835016203560905, 0.006763762443778354, 0.001979222241130348, -0.021090088684767187, -0.07744538604060941, 0.02274468666593027, 0.023820343779426652, 0.021430924216126194, 0.010017798112103394, 0.01367016897415546, -0.012147658654482219, 0.011604811432875325, 0.008127250896827929, -0.05554704988438608, -0.03228318250239368, 0.014287493774267718, -0.008262825976725185, 0.03924620614633843, -0.04718159257558484, 0.03508186988215339, 0.031651952834049604, -0.02763204912866007, -0.01797023406427441, -0.016962800088762078, 0.04649013052122607, -0.008155982549494567, -0.004353951480560499, 0.012033412520046858, -0.014948037871568953, -0.017321273912388056, -0.034601518847859, -0.03431833770260333, 0.016936868569545422, -0.03522277452529417, -0.03921209413798878, -0.0194549977286371, -0.014154136334834843, 0.002580416840860107, -0.009054892941406031, 0.007483975049294496, -0.009983376587783269, -0.04027292869012411, -0.01475465217200194, -0.02304127045125303, -0.020119564123872027, -0.009224395441026293, -0.03528717940219274, -0.007301231959396415, -0.005289898548894421, 0.02442484352062921, -0.015699202235122306, -0.019633866411410315, 0.026231778494906384, 0.03501674349728447, -0.03406395101154009, -0.022658691742172207, -0.019099769381132073, 0.017179288682390076, 0.0051495520051880765, -0.044689143151445905, -0.031133723705674254, -0.030229754591314, -0.021887287297828684, 0.026854043743827796, 0.003840293245185749, -0.04501164321164529, -0.010868623977461628, -0.008885145576831057, 0.0022333957921575882, 0.021391692089698683, -0.02933170117289201, -0.018773195851318286, -0.03138102974510451, -0.07021628856273208, -0.0011894695319870632, -0.03584598455322296, -0.0310660270565607, 0.024021314660166212, -0.037896221035526874, -0.03230689823370975, 0.03694750506270666, -0.04738354473288195, -0.04660449204566052, -0.04989391728643066, 0.013057441488537632, 0.005608310538812022, 0.006931117320978455, -0.024734848615876243, -0.0628718559450292, 0.028434407033737612, 0.005523733977961132, -0.07006701757957276, -0.06280350009685443, 0.011531462288146131, -0.0024729195948359644], "49": [-0.029017346875942526, -0.021245791905843792, -0.005387156158188335, 0.03713116486821205, -0.014508376136002771, -0.01676511345722507, -0.03504519377746297, 0.008561148154659784, 0.0316267529070542, -0.01861951143850486, -0.030260484224049287, 0.01664998861804857, -0.027172292403552904, 0.0038117460805015655, -0.012698655420340836, 0.04719192231891511, -0.014810340139971031, 0.035023760450756336, 0.02917370702577758, -0.033483096834539185, -0.007599362611872378, 0.019990110152103193, -0.01102419728305153, -0.014157428428897003, 0.009853722424046436, -0.04121746821675362, -0.000815635654700283, 0.0013367231950654804, -0.0051988909426255595, -0.013355539013591133, -0.0662683891297426, -0.016533838381067683, 0.0034398251411232456, -0.006160896491259588, -0.054165878440590676, 0.023395643320553095, 0.04108799313687787, 0.05146582260177878, -0.0011648171405842574, -0.07718610422341328, -0.08777242450389627, -0.010539430998044871, 0.01131242191338115, -0.04446900196690139, -0.021241589453385036, -0.02290208202671517, -0.008223304888113866, -0.05344793281343779, -0.039105242745168876, -0.0033798923713013974, -0.012993930806206876, -0.06298880718499401, 0.015671201256751137, 0.06248066841325223, 0.054584059157480484, 0.020466438010319245, -0.04746882877161307, -0.06233422535239554, -0.02938398428458792, 0.03641249922154442, -0.0755576226019076, -0.019885711074057254, 0.0325462314529326, 0.06666236355309582, -0.05291896751043679, 0.002844916775846189, -0.010255177603836258, 0.01611516262835425, -0.00039332228469711575, 0.0021920807500055085, -0.02168011031657652, 0.009732467779704827, 0.05886058373694746, 0.0007055722422227914, 0.002895665556319848, -0.011312791846780603, -0.034940417620474756, 0.015341347251249545, -0.01851296201772856, -0.019954524544306473, -0.03642011798676249, -0.026502471443480773, -0.023934344797711636, -0.018640760816152714, -0.02652427685261144, -0.02515867763933518, 0.0023551454797999544, -0.015131659340497235, -0.03226896090497136, -0.03301041143365709, 0.007270459555855068, -0.008640154683977348, -0.017813977211960694, 0.03395651859629216, -0.02036255742466448, -0.04739968970281492, 0.023535804661690803, -0.010935946293093992, -0.07816873239193843, -0.05211483454230647, 0.03363999533933385, 0.041703146226690656, -0.013416345473783873, -0.015070215791411518, -0.0037005396381966644, 0.00799520984596365, -0.023549484011419677, -0.08233748333281908, -0.033142281054186894, 0.002786389058400524, -0.05526883620039664, 0.014696039007685045, -0.04644618544927944, -0.01333222058165851, -0.0026342651516187135, 0.04493561462489039, -0.040619712354674674, -0.01782282984277959, -0.01847500328363439, -0.013882660177428183, 0.030609630068610366, -0.03777236115183421, -0.0383492461021518, 0.027244971969046027, -0.06359402766552183, 0.009061127942891984, -0.002909505566554235, -0.046401988077346204, -0.06443954226018239, -0.01896074874467127, -0.04296615205778088, 0.008681067549195171, -0.02100998355544002, -0.01681011798130519, -0.043532554073282236, -0.0628133512739755, -0.03141723978921718, 0.030548200700136103, 0.012776666697050706, -0.01547549849450798, -0.02095903008783615, -0.04415896594827271, -0.06505575011647556, -0.06899639588145147, -0.059345622557599495, -0.08340391753612215, -0.043215442846377156, 0.013199127756001995, -0.05219771702617195, -0.05890793260263221, -0.05247745349628877, -0.029146005437658613, -0.007473226174834064, 0.017803802213921076, 0.027836000322757275, 0.045973122750867505, 0.027481313461991577, 0.017274158076222335, -0.024475342251035082, 0.05059037658018019, -0.03425927141400703, 0.027581185514255067, 0.015584357782560834, 0.04587604523245465, 0.054546575153817514, 0.06010733380815049, -0.020002809288967492, -0.027790943643871482, -0.04368273439365472, 0.05234817918891518, 0.04701091706895501, -0.039032986556425966, -0.023019073613282873, -0.055061059154300866, -0.02946402780841327, 0.053486020423062, 0.01912720494211458, -0.06040560524370806, 0.039429602204713865, -0.028501106269279937, 0.04125575757767659, 0.000888031805111123, -0.03179250085641465, -0.004788400925795528, -0.05743845792750799, -0.0065544307351686005, 0.04228522802827977, -0.047197382655346544, 0.040359931739327774, -0.02026514140674801, -0.013159293407910595, -0.01133329171420433, 0.04049820088906244, 0.004399423818893871, 0.005310190380181436, -0.004521345899603465, 0.00018607081839480528, -0.018736513582565135, 0.0034254070531085524, -0.009376956688382447, -0.011000995229594086, -0.03331121704026995, -0.03261380747844375, 0.04133702866695789, -0.01815458299705457, -0.03989225410278875, -0.04045141596807229, -0.01634062483878534, -0.030395900485885294, -0.034122109453430756, -0.011084537860571505, -0.03596123721230226, 0.0020101548038332995, 0.0018806568075340664, -0.049680497904964885, -0.014527866684820872, -0.015361861290256757, 0.01757123353669337, -0.024176075437126708, -0.03528650981881641, -0.05386332709088209, -0.023979846825348074, -0.0161378065573549, 0.02107341055052841, 0.01854684430887039, 0.03516294759152885, -0.010971241752675873, -0.015468006108851243, -0.07597564355339614, -0.0640746834055975, 0.0028023107916962373, -0.04758306957432138, -0.00877454136813291, -0.0401568533526227, 0.0030088395629022397, 0.013152069098069446, 0.07275347907397421, -0.039909022871086657, -0.0003733516274127927, -0.0038541116414219415, -0.022724055458819937, -0.0200235233712045, -0.01412382543208447, 0.0008465141950783215, 0.001206996726934823, 0.01056659056738868, -0.002371345432965349, -0.03707509409333363, 0.05447203636191534, -0.01626669946045063, 0.016954714618096924, -0.01323817146254316, -0.014108376893762082, -0.005366279911992784, -0.03003577010312, -0.016525402114727677, -0.004094557366783172, 0.03224804721467007, -0.035156831031000646, -0.008208912938952586, -0.00980242232503642, -0.01690195221649652, -0.018523878791531372, -0.01645436739285695, -0.037892458253967316, -0.013865065419636433, -0.01743580753488268, -0.042950518627367734, -0.02530651790536845, 0.022371701816427465, 0.018017136067667888, 0.03263784789680258, -0.058042492357561856, 0.021745211776031562, 0.028756719378244037, 0.011506830808539445, -0.0014493678494596723, -0.020709830878272002, 0.0074942366383537766, 0.021297671811555962, -0.04490493494782367, -0.010202458565752123, -0.04398888826704858, -0.04023549865120714, 0.033753775871380225, -0.007030943874268038, -0.0043132091077185035, 0.003921315508363929, -0.027647232406125342, -0.016014087267145084, -0.04665499629235935, 0.022461615589467066, -0.029060117914307973, -0.01007849203509646, 0.05842579561941746, 0.012562732541875758, 0.0472396342944899, -0.021772562386728228, -0.031999783322305214, 0.011066369388258716, -0.0264400109016554, 0.0008326684795733266, -0.023990273950436524, -0.02507630049850131, -0.054154634402569186, -0.04423736525169682, -0.002898588819119227, -0.019764515565629276, -0.03281483467833834, -0.042340938528548144, -0.005458718522783868, -0.00439377390381479, -0.021310275379683986, 0.022226959799739925, 0.0013690933119570332, -0.011281993648985739, -0.05295797317537218, -0.014967842046186603, -0.03122514698989014, -0.055010673207449436, -0.06591763253302738, 0.06034329402926959, -0.025763688330009613, -0.030478134596885788, -0.03977231121580737, -0.02651624138738851, 0.0231972802690788, -0.045666001063221794, -0.027507346673377116, -0.013107135400700146, -0.02664683598682506, 0.013927403088337611, -0.04312241047131885, -0.04849264126512383, -0.0055809210673654994, 0.016726327822197923, -0.04131553994243442, -0.017337139662795008, -0.03363283353997974, -0.02481261967415585, -0.05716518201094752, -0.06309213316683078, -0.008102416497063518, -0.024941881097479805, -0.01441197385439647, 0.016927096680111848, -0.03862869449629927, -0.05527596095793687, -0.034790645533809075, -0.04377572586779347, -0.036142334926536325, 0.028624002095114634, -0.052009343978259244, -0.018384267530599917, -0.03598188653176711, -0.04919891963935575, -0.007068823270429421, 0.0656371106737823, 0.026807410441383343, 0.07994621495491078, -0.06230188320247535, 0.0672665069586106], "31": [-0.0018686867336006935, 0.022653727386065033, -0.040617012596, -0.0071617425414854975, 0.034206699914648746, -0.013734127104244861, -0.01625932400404089, -0.011789392421422766, -0.010510765127152613, 0.012455299882591989, 0.0207567637170311, -0.02579291274000335, 0.03805770230075219, -0.036183135756092256, 0.008894419813394385, -0.03395055821948043, -0.02613250420218652, -0.06074217842749634, 0.013922459772090907, 0.01840222168760875, -0.01621816411088746, -0.020365354111839637, -0.0427601714079842, -0.04432556700827525, 0.020323868777734372, -0.0027439540639628917, -0.04415406728407472, 0.0035196176074668555, 0.013958736834987058, 0.035521576915076805, -0.020120909154914973, 0.0009324028333414037, -0.0008556589158317871, 0.03351075575650232, -0.06308733011635036, -0.05349484899267061, 0.027266635295194023, 0.040439147643261446, -0.0084905811580067, 0.02683976494057701, -0.019771871698001934, 0.027664811601392874, 0.03824234894342714, 0.02243305838141953, -0.016520669234276454, -0.009708071872292796, 0.02478517352616571, 0.007134351444376239, 0.000653468889791892, 0.013461394790463174, -0.03599678043252206, 0.0031285617864595765, -0.014626799251267234, 0.016290053085717647, 0.03389362121924245, 0.039123290997746245, -0.06356298946239794, 0.014202070549326632, -0.005384300040953826, -0.04079531706387052, -0.07282501702632137, -0.06294369366988975, 0.050338901738745355, 0.03811423515777803, 0.01176307138614031, -0.018123585679454986, -0.0342871004084463, -0.033245120048578436, -0.001692872209669042, -0.01510179283404179, 0.03804594455999129, 0.021411229929937853, -0.006283867809162205, 0.005891813348072184, 0.007282202769574211, 0.02049033602804186, -0.07495980757511832, -0.04350241232089226, 0.03249563524204304, 0.04487865744433303, -0.06366497885182974, 0.018331616246059893, 0.001284841043485749, -0.01587363183841806, -0.05294863710051311, -0.05269472681042463, 0.008897183031070075, -0.038368156424910364, 0.03537325263142673, 0.002559809761209403, 0.04228659886660153, 0.06824590821497925, 0.021404615596380686, 0.016395582992763922, -0.04350606221123005, -0.03166385721904615, 0.017366489980213423, 0.017920014314491133, -0.029361887769649833, -0.014541490252412177, 0.023047590499851518, -0.017321301861332933, -0.008301471984544864, -0.013082649614600313, 0.03540575062600295, 0.0033755349203199556, -0.01106045580839404, -0.00899124844542946, -0.040047846526812994, -0.07052733141959816, -0.007950363697470625, -0.008616044562878535, -0.05505875381303451, -0.05397577027402971, 0.00033522759246677904, 0.008409478909610205, -0.04331270699056099, -0.015047928989609825, -0.012232965142160586, -0.01239259018872917, 0.001418069389047496, -0.03294203692390284, -0.041088060069488896, 0.0021133665784601645, -0.07466558389643703, -0.0654310374416322, -0.03882699605398909, 0.043468134021481614, -0.018247164065500705, -0.027183679322248376, -0.03153492465422329, -0.06339105704051896, 0.015820793329279728, -0.00019470500789846922, -0.0534526025590505, -0.021395266768959014, -0.02384377936746417, -0.022535136380356265, 0.0035613476848491573, -0.03300020305352787, -0.001947740369055592, -0.047488970780355036, 0.015199164776689833, 0.028854536968378773, -0.07533605044566184, -0.048592510811473304, -0.05490423855121651, -0.03350859189501993, -0.02769600250383622, 0.07182142321663165, 0.058908702084759956, -0.009727081919997263, 0.024474946245850775, -0.009452752848157277, 0.02600441651378359, 0.019055155890395175, 0.011433365363151161, -0.030804979080105207, -0.010187146398218681, -0.039831146548702394, -0.06983262382005498, -0.013307320435033767, 0.03935228981898931, -0.010269339352023206, 0.046450772032863394, 0.029194853390176533, -0.008083208697253052, -0.06875672873905096, 0.02982936135116994, 0.012207894677296568, -0.029230717886632125, 0.04962430508297897, 0.04078921388571546, -0.011415188409414478, 0.032653117084901435, -0.03239444561617649, -0.01725286416961707, -0.0030745196547833087, -0.040161359949592496, 0.03226935724658835, -0.037614851551940734, -0.05215108429516712, -0.031810062975877275, -0.06885602438278954, -0.0011147003559389887, -0.07062728535262375, 0.017598524771002936, 0.033589414740120734, 0.017353708950479683, 0.009964139435315253, 0.009305002752939195, 0.01365370199919702, -0.028160520445800617, -0.010995783751074155, -0.018587709820296013, 0.003029739617611028, -0.0016054067872583828, -0.007986907313330094, -0.013692614836835565, 0.02353769042616489, 0.035976400904148415, 0.03283787369513194, 0.02614851146527615, -0.02040502892015359, 0.00042162384307420516, -0.007093898865163326, -0.014429752816294526, 0.002362284282507066, 0.0307044567748558, -0.020562194329328754, -0.02224672125905792, -0.01193438947628251, -0.011177337843354179, 0.021217858135692234, -0.013910394857070123, -0.061142183932113174, 0.003978378684045469, -0.006324125975534361, -0.0518896923066125, -0.01576609590452358, 0.03896745357755463, 0.04264163034147994, 0.009204605388604953, -0.03338050088228318, -0.019713980161640356, -0.024942590705056066, -0.02253367859484958, -0.06402223036368974, -0.07405700546051527, 0.006958139787486247, -0.04137132000176572, -0.04104446181368208, -0.05569852331792702, 0.008322448346766084, -0.0006634760939409404, -0.008723448425139523, -0.006434213760503574, 0.0032108657867183426, 0.0319787845939891, -0.053574530259809815, -0.03960508887750858, -0.006354893482346118, 0.0259716813934094, -0.03492781311714597, 0.0003235463788741257, -0.007684533176526028, -0.015258740225151555, -0.052074699936634675, -0.03926865095230584, -0.013934636875429837, -0.02266498924603085, -0.02526459488619438, -0.022351675374182277, 0.02089428452216818, 0.03167947063068517, -0.01758722795192825, -0.018498377991798973, -0.027364002437911233, -0.02186589338385982, 0.015440980495716228, -0.017201986303649705, -0.016215529663913684, -0.008933389357330623, -0.04067110515500868, 0.013036400653374023, -0.02260644112728724, 0.022668931209845717, -0.02198633729928475, 0.005949019355889953, 0.006159147057507156, -6.925634474553315e-05, -0.07367123891454994, 0.01324875932595432, 0.022289219772342064, 0.02871957890943045, 0.0004790317142804718, -0.06128208638280585, -0.00026104598140691966, -0.0006826741057781676, 0.02994513792656907, 0.006849406485631344, -0.051524589691192946, 0.04070746232136063, 0.0203857837127207, -0.004425642597978656, 0.004944785850270294, -0.01585738931736978, -0.03359962109713959, -0.051173365799727054, 0.042657523732369564, 0.049045055161992764, -0.000404789731376484, -0.06042410136474186, -0.09283001221814317, -0.027158671201501318, -0.07910688614333651, 0.03209443725808378, 0.02292489780269405, 0.017265320725823034, -0.04027838956128585, -0.06407627590818533, -0.07352643588124076, -0.007928316851457548, -0.08653033942546871, 0.0013030845392699726, -0.01730178791157199, -0.049788885113792446, -0.030786206420035215, 0.02092137807998422, 0.007693686464948029, 0.010014216192075664, 0.0187708210073085, -0.03427672721470134, -0.015469148205108849, 0.007780561163840944, -0.03774169392216153, -0.006342171751863485, -0.0028066894833429427, 0.009942297144367384, 0.031258112875204455, -0.047138002374462626, -0.028440856287696055, -0.02284210155083365, 0.033695866201769155, -0.04315456756595561, -0.027903067729339807, -0.022466546356917336, -0.010394252130137059, 0.014646135307197992, -0.06144720720185479, -0.006738624686061674, -0.06763399016431276, -0.04121416288935344, -0.044023987585127634, -0.01597241535526654, -0.028919529796124336, 0.03141636281126979, 0.0299075541176365, -0.014359972758424277, -0.03853247624132855, -0.01983130515473309, -0.0008665260122218606, -0.021373226272792648, 0.04367566241208816, -0.021057086119761797, -0.03914883624959085, 0.008927684825589838, 0.020130937604375822, -0.030875071795291795, -0.05598233783151999, -0.0706771474969355, 0.04353289950143355, -0.009727412042411033, 0.030287507996481992, -0.02173660874060845, -0.04957620188265794, 0.0010834196159195536, 0.05268932878373322, 0.04842122886373532, 0.021767193791736132, -0.01538457258524301, -0.012285027717889445], "36": [0.009787777861549723, -0.027891585652991217, -0.01105836526896048, -0.025944025213188573, -0.018462779617435254, -0.0696842402886598, -0.015004408127617932, -0.07276605508902234, -0.023416228899306026, -0.0450184916727072, -0.04546079586276315, -0.030148702865656345, -0.027719843667628304, -0.062418732053751445, -0.03721779263625648, -0.009221150978926654, -0.02651518056751007, -0.02802369780763968, 0.045739103698856844, -0.031008312231850577, -0.003783101803698749, -0.015616856578246355, -0.015481204861262239, 0.01869954441401391, -0.00032281657910158203, -0.003526844153788696, -0.08398222003953591, 0.0007186437696682526, -0.018032437252239346, -0.035727182624690344, -0.03592488557174329, 0.026599896711974855, 0.029858442623883343, 0.02367867559007489, 0.00964512897604666, 0.01796462915454231, 0.023296599888358603, 0.008080751259024431, -0.030273039340947352, -0.037798408098071, 0.0316992078361262, 0.05506151216337551, -0.032604499865614596, -0.03914608936786588, -0.05420497471500469, 0.019918112242978722, -0.01010820689343872, -0.008815186281414105, -3.093892024023928e-05, -0.053114350366273794, 0.008857619607869254, 0.03535692147871197, -0.006474329693351075, -0.017847038611301935, -0.011549069059716567, -0.06567732813872959, -0.008230950921832519, -0.0381828195287015, -0.06587165322066836, 0.05934675312623155, -0.04707008156391857, -0.05286460650413173, -0.0031168120600354923, 0.06581337051608901, -0.056441244343009456, 0.06178721896097778, 0.06231579418814761, 0.037961522949771946, -0.031405611735387674, 0.004588366275276277, -0.020565565021935368, 0.0032753885172213384, 0.007685309987949172, 0.0051092393633101274, 0.007686053990681962, -0.05871768540285203, 0.004551574279829256, -0.018886855987384505, -0.06607165514329957, -0.026740298968751054, -0.049403055200487773, 0.01954090498765735, 0.01792085124187528, -0.025508842937817442, -0.04691791390647146, 0.025776866773539537, -0.06062463265785063, 0.022313692366740478, 0.03189474679051612, -0.05394846585084639, 0.05738175418064753, 0.05908395647272081, -0.006523113177107883, -0.018055138166164626, -0.01066657815976059, -0.03175319982540584, -0.003918030930902693, -0.012146075975497524, 0.023711232940974176, -0.005738684502577852, -0.017251707477219956, -0.016912058258101253, 0.024498958421115706, -0.0032764275043604633, -0.005471173089090511, -0.017224398938065995, 0.01849056861151585, -0.0023093071404724137, -0.03678356504654901, -0.03514351282636255, -0.022315690261165054, -0.032897580949816235, -0.042288219467773, -0.02554413034368178, 0.007293749098493, 0.004548025529495053, -0.017547160093475234, 0.009002416786776142, -0.026596391413024757, -0.019423892869808498, -0.08702664658649237, -0.0011149628651905958, -0.002127006163833117, -0.04553349872715573, -0.01927224855242714, 0.042031052450628305, -0.03879226004290619, -0.030541861422390456, -0.03861214326576663, -0.05694947203789417, 0.03782613924973996, -0.03288100592549254, 0.004206271908812687, 0.001959375461376462, -0.009649166609163574, -0.023457964560878633, -0.010483428037997128, -0.059608212175560796, -0.041829875522356286, 0.0019615754564797573, 0.012671200149918562, -0.05562328069562228, 0.03687491828995951, -0.04121418607493796, -0.04840426122176967, -0.07804539318506802, -0.04955993535996021, 0.025667099939292882, 0.031834383288520895, -0.0699559405796278, 0.03668259336441531, -0.009394445407736055, -0.0063441592052409625, 0.005785480442608433, -0.03022377492328315, -0.028943206542914362, -0.031041404319915002, 0.061892412061788415, 0.025542081456930363, 0.009665606020521621, -0.01612517858437614, 0.023458507959060338, -0.03425060938397936, 0.003394988498335662, 0.05999586392494951, -0.028151308097250093, 0.05190732300080813, 0.018298699577327576, -0.030443664367551807, -0.027622937683788124, -0.0022741137927168296, -0.028716452663347745, -0.021807492392791863, 0.04816055002779397, 0.029124767390630784, -0.022240760798890116, -0.008388330254443662, 0.034573751688849214, -0.03870460412429173, -0.0017939961132308084, -0.05273763644978758, -0.04098059259992725, 0.04249248406533323, 0.04296391424523745, -0.008799006954274921, -0.02694877736354954, -0.04160882647284085, -0.002112180445097544, 0.005376879967671482, 0.009934415372979696, 0.00874565163346613, -0.008051591813516251, -0.0608859971916907, 0.038975418378688856, 0.0263375339294679, 0.03167387752565196, -0.0267132537239975, -0.06081448130279273, 0.014862124957176374, -0.04229044405378935, 0.03765023564570816, 0.004192059692926824, 0.009452936551874987, 0.020170087727312932, 0.01167783615903827, 0.04034909453861847, -0.032648542116364684, -0.03150951669620532, -0.021111148642249146, -0.026774552563684165, -0.015516458860599519, 0.0003999900943924322, 0.04142086277356292, -0.0026263830307661656, -0.0125077727687, 0.006236526247129453, 0.0321861812643704, 0.0426034126507066, -0.02650509742661358, -0.04908337309335061, -0.024571834684953348, -0.03320313620776114, 0.02930485911039615, -0.0415999775232957, -0.018295691961025713, -0.008611901147231664, 0.007580694732140212, -0.06993802946284483, 0.0356921013495504, -0.022744531285715203, -0.030114086645522373, -0.0034210492848306667, 0.0015665341562519897, -0.018193721929956466, 0.00047712384821347036, -0.049785037476102856, 0.053695628684815574, 0.009012234392889257, -0.0397677023536155, -0.005896424214843957, -0.04797022899514065, 0.016050830886296236, 0.035095204332019014, 0.002619693292972946, -0.02896746322902455, 0.047785387397086265, 0.0013131541003886394, -0.01622736652899411, -0.040119078612800556, -0.017222546929257537, 0.015397277174622765, -0.030918160786355686, -0.02019632559106344, 0.019689706686506252, -0.06880882067493138, -0.023111912884146917, -0.05228917152271295, -0.05723280332017919, 0.01856473530438224, -0.013178110435890067, 0.02538968974545993, -0.025894197535413152, -0.08065626827255579, -0.029896261635393856, -0.02242125116651128, -0.021430496029258464, -0.04528585341774642, -0.02136292127463061, -0.04061197171256713, 0.021311818859302695, -0.018247396175894253, -0.07261079043936816, 0.010138188857290979, -0.007567998146662391, 0.021035824005752428, -0.0315652694949356, 0.021307715303507634, 0.00537656594331415, 0.012704588988462866, 0.013314675416480121, 0.026994646976200777, -0.04472988548849716, -0.006503806066737557, -0.05080232176852403, 0.04503552748660139, -0.018958267872016727, 0.028887925935768766, -0.011502327594388198, 0.030926097282705806, 0.05661636330170758, 0.03653610415530008, -0.06670427769579475, -0.013754795020523526, -0.024086196277172362, 0.016171463354459896, -0.04028459130228931, 0.02830742462616114, -0.04443276418946698, -0.041940629950681055, -0.03145465622364328, -0.044326970038194254, -0.021479288685480952, -0.07430317396772758, -0.040267819429021, -0.008957805477912561, 0.02810006877017514, -0.015974473128596955, 0.02447297820994089, -0.007989673974778623, 0.02449028624781978, 0.026097667536161284, -0.04295988587961364, -0.010420514398140892, -0.006093758388834616, -0.005382057392461716, -0.033745631705202415, -0.003808648831874943, -0.022410105443425945, 0.00284019933524129, -0.03172946817682458, -0.03937882415151209, -0.06699261016982191, -0.023002383104209132, 0.018825930058581353, -0.04837266460300361, -0.03888614846196899, -0.017859139764812754, -0.028105058371863643, -0.06249047755420081, -0.033526907247259936, -0.06447282632784933, -0.04005352924977722, 0.032215327004744575, -0.047966429671444204, -0.0037047685131384634, -0.021303497884212992, -0.04192984586006446, -0.022766436386810026, -0.020278901696033143, -0.017083540308915474, -0.014818792732099685, -0.02191888249585254, -0.00438174327634845, 0.035254560483393815, -0.026766552990983166, -0.05119243477949121, -0.07094581351038692, -0.04650352741128032, -0.03897643155522175, -0.040634555621866505, -0.07483238223485436, 0.055141938984603574, -0.046792357384459464, -0.024493660272296488, -0.024378355608567184, -0.051338180731383416, -0.03325951248194192, 0.011030646193886044, -0.04959458521645281, -0.006263878407451005, -0.009746036513594526, 0.007420191542352977], "35": [0.02527234756483875, -0.01208038908374697, -0.04832247388060047, 0.007894498102239326, 0.0309494717076261, -0.0965757250845528, 0.03338539014647465, 0.06333378838191749, -0.0001530550727639395, -0.003918346875689457, -0.030149931434699878, -0.016189961001104418, -0.018131066913425083, -0.025230622223331903, 0.008547580073582863, -0.04957024039722272, -0.06530289895338388, -0.02407843930014582, -0.062066781144963085, -0.010811615872857637, -0.04518098085310515, -0.023056351027690433, -0.016682486800191552, 0.011396958296365675, -0.004129169199806501, -0.09001935273342149, -0.0058942838095655545, -0.010335714821189366, 0.033203842517786214, -0.0005826995022466134, 0.004039714946174064, -0.0015622657021324422, 0.006549313555265272, -0.07101626921199045, -0.05225571794195881, -0.015783873067122374, -0.032526437603504765, 0.02131936352924864, 0.016720665520671783, -0.0009976210291085268, 0.0029688105536170863, -0.03020170724437451, -0.05074835713847391, -0.006696141701540258, -0.05286709412281302, -0.01021016214519563, 0.04973352943731497, -0.013268816483634191, 0.021784749483219245, -0.03613488843483391, -0.0718387064011682, -0.07875669212902148, -0.08726862832409461, -0.07561379942629765, 0.009530417917974153, 0.03548754687360101, -0.016422160967637118, -0.07669635689476961, -0.07027375545203328, -0.07297822879657602, -0.010711313517914578, 0.061497464242762985, -0.07497210091279881, -0.026078677815356957, -0.03366736840363271, -0.01437087163948388, -0.007359830818814736, -0.0078585552282142, -0.06587742427795594, 0.039443768880427645, -0.045941260244699224, -0.021882492076394817, -0.007859118076064492, -0.028157493582794214, 0.03423600491547527, -0.07833988583506842, -0.029637889432321405, -0.049264737704885105, -0.0439788682427738, -0.04031723791055687, -0.038734351165106276, -0.04483793418769229, 0.02506041489819645, -0.04610213912065442, -0.03230219520837611, -0.030615116968985133, 0.009355119515888587, 0.01504727471187373, 0.07352556312180335, -0.06670663591454386, -0.07613152409420111, -0.0457575934966005, -0.01901327594312407, -0.027110327925148853, 0.024045085298255966, -0.07186278158979138, -0.023746268407884644, -0.0057436811263429375, -0.04525294429744314, -0.005462777523581562, -0.007422903018204135, -0.03811853120417122, -0.03549886259650465, -0.009544378285777694, -0.015285116786559232, 0.012766630535858628, 0.00407913129829182, -0.002843163259377961, 0.0518639423956441, 0.02163444431025622, -0.03526095013341993, -0.030035049798588516, -0.023092818398428427, -0.01196824317496432, -0.025303306474428564, -0.01981636166607873, 0.023108527007347526, -0.06322974962503015, -0.007135609575797367, -0.012737657729619909, -0.029964141872431058, -0.025307582702709813, 0.02030577270205451, -0.05252752373937109, -0.06233458441754918, 0.022661682499385064, -0.02572004767224715, -0.02676397162346839, -0.05173857744853586, -0.02834636453429846, -0.03576337475690845, -0.047590588757381855, 0.007858170311593032, 0.005656336302478021, -0.0573849622029826, -0.013567592838827601, -0.06340671512301109, -0.03233355157149734, -0.04478283182734791, -0.03213018011399941, -0.04717379344930238, -0.056278483890615516, 0.04326592380792301, 0.04292887589220282, -0.054548997033305645, -0.03367316141008517, 0.017380446405080994, 0.006818074461093041, 0.05023104061425844, 0.10498531847230703, -0.03943250065396577, -0.04626354114364058, -0.0054416522831835235, -0.04639137065760477, -0.024605535731948878, 0.021738321855514605, -0.020620494274183217, 0.0322286274071343, 0.016034789896774124, -0.0694904671660393, -0.07055399569541287, 0.014758709598132346, -0.06346891236264146, -0.0028467989963212874, -0.024198327413629497, -0.009518759912536638, -0.029872616186241083, 0.04390150238361546, -0.03892620575720688, -0.019572482333959914, -0.024174245437300318, -0.0430774781311635, -0.05537497242503254, -0.049982688365285896, 0.05521279994663743, -0.004300197194085504, 0.007606059369957102, 0.01687033162353631, -0.0323026404040273, -0.06493391795406327, -0.026050151997092912, 0.01344677039273788, -0.02596135677542012, 0.03433967274473699, 0.026514207688633447, -0.03195752240904593, -0.04687970938423496, -0.013807901853627938, -0.02930372662222637, 0.007763415069106959, -0.055176301237401484, -0.040144373704488485, 0.0405943496285947, -0.018821691223902245, 0.0015749358639029322, -0.022223550453453707, 0.037846875702938064, -0.04450266896069249, -0.06989987749520984, -0.003634973585386722, 0.017946640952885756, 0.057278887515238866, -0.015068620379123975, 0.014116670963781604, -0.018319059658575058, -0.04391896148068746, -0.028556614878039097, -0.01352378187101937, -0.03697359885987378, -0.01733509166133873, -0.05313641149797841, -0.009912735463864683, -0.06359780253415775, 0.014447927226276962, -0.017334445484044225, -0.0149588880498401, -0.0278564734423085, -0.020672759386007305, -0.010111735080316089, -0.015729380981305677, -0.0172407110399112, 0.050478023804703426, 0.001280399175336511, -0.011424102729298934, -0.03320427006953939, 0.0341310732243883, 0.00533887129927761, -0.05209478230996702, -0.031664737094303945, -0.020883768889750638, 0.0004245820615664874, 0.014961373105296848, 0.014212195709978791, -0.07148179871894597, -0.006273363820132848, -0.003944422094075912, 0.0006259295753076435, -0.04021499268196908, -0.040266982973251146, 0.036244505487554236, -0.022793226178055157, 0.02601206548746004, 0.006187890014365448, 0.003411237610156839, 0.01479508609704105, -0.05191113669501243, 0.027897966793564863, -0.008647782506641655, -0.016499813105400527, -0.029748751195290312, 0.05901130303261679, -0.06547806508471184, -0.01128092681157964, 0.03544426853273799, -0.040315200385143725, 0.04352454100866984, 0.011200372746257823, -0.036399525709548235, -0.017239041060468602, 0.05703120186333029, -0.06572022875050873, -0.02267905036494578, 0.04220730512104414, 0.03855635205449084, -0.0872624410748602, -0.010126623592827825, -0.024630225846088996, -0.0011111473778245588, -0.014640644075930279, 0.04204320225351189, -0.03914128845646763, 0.02581022340132873, 0.020997800434767195, 0.011527702278669321, 0.013985271178326363, 0.005516005357601868, 0.018736446528807408, -0.10909866098878986, -0.06722975957285712, -0.07449551125120338, 0.02042624042227627, 0.004020765009491844, -0.030092198776656778, 0.037412439439380225, 0.025577283853340144, -0.005245359530154897, -0.006856285132783358, -0.018359085005298426, -0.012294398499674147, 0.05075810531827822, 0.002469684313334691, -0.06974623612303066, -0.03268606518334365, 0.0290240250434189, -0.008709749652418785, -0.030193679398783032, -0.03465018766597662, 0.04806614393691172, -0.04479039571543209, 0.012608067648990097, 0.002059418994269954, 0.0017473407464413395, 0.048274672081192994, 0.0425948501090172, -0.06422671782113974, -0.02818971067970012, 0.00140693717747835, -0.01769104905120822, 0.031543450068276864, 0.010487949063198559, -0.016265352047442113, 0.00806168824282536, -0.02986993553485976, -0.03819676919244049, -0.05029831294577219, 0.01891275073802245, -0.004350256060839817, 0.02203802324554832, -0.04721910547340022, -0.03128259981586117, -0.0026519170884245, 0.028965618098318612, -0.02749708664249638, -0.0055933173363346, -0.008680955439042957, -0.02479435158160627, 0.05155159861595959, -0.013822477950489503, -0.035524192694145515, 0.02366798683651523, -0.028460675003283385, 0.04612695419954819, -0.015416585354864688, 0.043004170276188865, -0.010606186865969256, -0.0016850755707196795, -0.0842383103440735, 0.04542523783577192, -0.007233803529870028, -0.03203684613048935, -0.01812131864302628, 0.036179068497882265, -0.04268355032733346, -0.03589333347062585, 0.02591301425155105, -0.03560981226895896, -0.05024020390864715, -0.06588031814861493, -0.040392944558756756, 0.039300648393477466, 0.03736360502094711, -0.0041476362982756235, -0.050231284955953075, -0.03925126663117358, 0.040975643233692766, -0.06364163478553116, -0.05651587269171265, 0.05533451148640353, 0.009740163978918415, -0.011785071982749995, 0.06935343731150508, -0.08783708464032966], "39": [-0.001012441432690957, 0.03324405720204087, -0.01633463929430045, -0.02435789837526294, -0.020362786018250666, 0.03008891158823874, 0.03131653701965988, -0.03679012060742859, -0.004656149092036829, 0.033133200284164464, -0.03331170323717904, -0.040681564737231383, -0.01168215443720118, 0.042945013560117665, -0.041444754672640347, -0.031308085191593116, -0.018824096397842945, -0.031208237557322945, -0.05910888001590661, 0.021241767797605577, -0.00953175669461714, 0.020505115060569724, -0.0133352053550365, -0.0005718370355602684, -0.026913602338670996, -0.018115351674609877, 0.009224648129472381, 0.027186762575726248, 0.0009908402697883473, -0.03438254964176382, -0.037824068179121345, -0.01164095219324148, 0.05020705181993528, -0.03317739699762544, 0.007193235298097426, -0.008734633625225623, -0.022081080286246786, -0.020896698381799323, -0.08509546663711212, 0.03844685186695819, -0.03314949087245587, -0.04816463201383727, -0.04592297752689967, 0.0008541434705554354, 0.03484192422124533, 0.045526306178013586, -0.011132052016100133, 0.0003184041162159774, -0.0015250093109034483, 0.0157002967686712, 0.01729092617079038, -0.07305191796830503, -0.0004493061058195249, 0.03093593038330922, -0.04564614812678048, 0.028462385125618543, -0.015922264316848934, 0.05439828855905179, -0.046278921318634036, -0.05055774399660137, 0.042928571314280725, 0.05277574348936561, -0.0014888316390242239, -0.05206153739260733, -0.037953549209181224, -0.02892134748014084, 0.04943043490444226, 0.05117776010160339, -0.03341795490401547, -0.01622860792870833, 0.010984211638867198, -0.010815048094742026, 0.037439770628418585, 0.03892347587045469, -0.0017175744193017725, -0.06364717227162967, 0.0036635817286733083, -0.07393563542925621, -0.07264686227350002, -0.028521951573614066, 0.018821527298643958, 0.002587010961511999, -0.014941180135417047, -0.04263099027661999, 0.03760448452308353, 0.038560678734643535, -0.003511785712496862, 0.0021643883065902763, -0.041780383143900576, -0.08384567306918674, -0.024830168927194387, -0.028442242896256183, 0.01765310385083127, -0.00963861782570878, -0.01784673691104904, 0.011813404204762654, -0.03246380131322257, -0.08442653887133345, -0.026227401050468536, -0.0026152700187014703, -0.002226949459586787, 0.03769196445573944, -0.05051707439734506, -0.045196031711973395, -0.021383445997989796, -0.08631649724526923, 0.006184256308378915, -0.0017679798226572156, 0.03275639579234226, 0.05159327402559633, -0.03002468404897153, -0.02953551560685217, 0.025221649516647057, -0.05476710444131744, -0.04359970283446672, -0.017932752426626827, -0.005305771714094157, 0.035170587199173584, 0.038514168146803265, -0.02391859921687324, 0.00952937430530777, -0.04966114321775112, -0.041554538331928945, 0.005731256702616824, -0.05568252238405128, 0.0662899769554069, 0.016672707627980014, -0.0275972934794907, 0.05029298599285981, -0.027580912314414677, -0.0595562322192488, 0.01679652745062204, -0.03587586588000991, 0.032816866848539704, -0.05209433018954303, -0.08142991053413874, 0.005486621017063118, 0.002947471194129565, -0.015619992695957867, -0.021347625144311405, -0.04377138088222224, 0.004884501905873014, -0.037009271253282905, 0.0056263412741435976, -0.09361137421009753, -0.015645289108286765, -0.012271182343271134, -0.05836092027116638, -0.006705802724249964, 0.03567172385382939, 0.06238529145589343, -0.04293964755747967, -0.049758984946889614, -0.010541739365865992, -0.013692746493589723, 0.03209676178827917, 0.04837921658126855, -0.023257340551923064, 0.04647292468782445, -0.04314836148683033, -0.022173871333709995, 0.00548955248598244, -0.025199535433175595, -0.01008100988203661, -0.0317713924016703, 0.03138410402761453, -0.027683320435925262, 0.0454155975184462, 0.02577414827444043, 0.04836504597136811, -0.0159867373832192, 0.03203553481502661, -0.02325576621729112, 0.03514739582779868, -0.022325904037039646, -0.0305644157656256, -0.0458824607752207, -0.053720587962260556, 0.013061600243688666, -0.035246867960925216, -0.05238402642872194, -0.03618370910537269, -0.019132907936517805, 0.01345755863907504, -0.015038028962058518, 0.008209577443635756, 0.010868348832414896, 0.0013467249055145896, -0.06631184142273967, 0.037945095287614715, 0.006927967978831917, -0.038090461987722875, -0.008670569381624532, 0.004157040514952771, 0.010984947393468763, -0.000525014507574072, -0.02638392866573483, 0.0032569947634108324, 0.005129952551522431, 0.015286405562765804, -0.04505374735349628, -0.04126086719444531, 0.0015261473283144393, 0.03284769118030082, -0.011792524287887601, -0.026513316982522874, 0.009496331382836764, -0.03552292151637078, -0.02974939201440995, -0.02941702648624798, -0.02557263118439112, -0.014852271130082643, -0.00855465381488663, -0.01098564514481332, -0.04603224303248498, -0.03807546911363298, -0.060537365623384735, -0.052155451838654346, 0.02713184345151921, -0.012496225304269292, -0.018743059518706057, 0.013897363318552637, -0.04890219598736937, -0.02864969104729132, -0.01514089284741525, -0.019022271231379374, -0.017502943707643562, 0.07143114018356406, 0.037649606630884416, -0.02524446526113156, 0.006896823270401269, -0.00235268353133827, -0.05093687588723729, -0.004304269283221152, 0.019919943666258575, 0.0021885813757918054, 0.012947437635345177, 0.04370515822794658, -0.012115511992414799, 0.00026819883780373013, -0.010358928788209142, -0.007649032713666093, 0.03617133311196789, -0.008830016154889013, 0.03498657454066098, -0.006892622993690849, -0.025092980338715525, -0.01103558347532672, -0.019362088539742917, -0.024667965199536953, -0.002206677994689625, -0.050045243567350114, -0.02366062002904663, -0.020344667401502734, 0.02411971138062503, -0.0442434776671876, -0.03205432176652318, -0.002712303396099196, -0.04574260555316631, -0.007035555737194039, -0.041517742729078794, -0.022630699792095525, -0.045075769526209404, -0.011099846372739338, -0.007630220495964464, -0.026041938231523676, -0.020495452570765474, -0.04029348366334874, -0.06140012605867053, 0.02654660828706854, 0.012191643504337261, 0.014128625476943723, -0.012636347984959129, 0.004287159378776258, -0.0389393692638938, 0.011341551815292918, -0.004541110439780969, -0.02190742911122999, 0.022235378736348007, -0.027713144950386934, -0.027324628166843182, 0.04352022311601809, -0.031761296456232296, -0.037502489357446364, -0.059741499893558536, -0.032533881392997004, -0.022779917154066912, -0.02425695835244539, 0.004379001932251272, 0.006452654543716549, -0.020236957663489697, -0.019263671510056063, -0.011405024536094512, -0.027580767214184884, 0.0579298581011509, 0.019677863207314905, -0.047860101549910314, -0.03361721565387708, 0.037771455518846093, 0.01712456181081701, -0.036967086964470784, -0.024097774698977784, -0.03797317365389892, -0.07473399027094353, -0.002408803030211839, -0.029243636974630918, -0.007097885789925947, -0.03280888860107412, -0.004763633839717712, -0.041847737453033614, 4.2018540627160596e-05, 0.010421384950620328, 0.03342534382079477, -0.006221389175269002, -0.01109958409249226, -0.023295121230530846, -0.013729512577006862, -0.008660614370503368, 0.03879997260506279, 0.03963927935339113, -0.033352436824876465, -0.034875636987759265, -0.031134048248708045, -0.02344561315863412, -0.031003032168346906, -0.04688850416831836, -0.021145055687300452, -0.04696710054808215, -0.036176288116983694, -0.031470214943455525, 0.003896704937457297, -0.009059117897284827, 0.03908758778234242, -0.019290875811775476, -0.011006093388585608, 0.014935509149399635, -0.047497523736210294, 0.02202454338212887, 0.013128916164201032, 0.03428111644232707, 0.030093689214525033, 0.017834569948706944, -0.010023728456707699, 0.01364409819163302, -0.019949292702089342, -0.06717617649887672, 0.01248226490640615, -0.0746135215631463, -0.0327635589815681, 0.04454987227367427, 0.05167048039769483, -0.03968248431582802, 0.0008389715848863779, -0.05340760111094585, -0.04219550722794989, -0.008816444769269486, -0.033542062914310125, 0.0010959818732285767, -0.03150943002167197, -0.002949936332617234, -0.023331969469079436, 0.06811319120231131], "42": [-0.011088922917482646, 0.010763798692964722, 0.01570679620617506, -0.013831008519957647, -0.010231151880811118, -0.05150753405563619, 0.018889304696808, -0.019265647141907597, -0.016720704534642746, -0.04601573548211238, -0.02993095959538252, -0.026910601339771037, -0.0359858415840628, 0.02113064993884473, -0.06247681599190354, -0.06535535951111432, 0.04414809346432117, -0.02377172443539217, 0.030545934008212348, -0.02217202270154182, 0.016258151937677285, -0.04963426672273821, -0.04967487005744766, -0.020539769231030975, 0.013474528144403624, -0.0007939628862048303, -0.0009212813841237957, -0.026753859561028145, -0.004418695360328959, -0.022471450993603335, -0.014362333870545991, -0.026521984631612264, -0.009441588645664016, -0.06524374700997046, -0.05875549418410715, -0.05078240043690384, 0.02013795587420048, -0.0045320285521580645, -0.003319363686277354, -0.003104169108867388, 0.006404293675398906, 0.003361873305659391, -0.004867192361014408, -0.038992755863138065, -0.023897912661490384, -0.043818471851932154, -0.0026742396667790245, -0.04971874812821814, -0.07651852988625607, 0.033306011033168575, 0.0017146751327542919, 0.00739148002011184, -0.05867317461671196, -0.04062088381116709, -0.06483638107944904, -0.02135060545058338, -0.026912383540060363, -0.06042411739025595, -0.018761891852676547, -0.04015133145503517, 0.015056455897186913, -0.009282631746207259, -0.08337071622632285, -0.01509849041009444, 0.035371656543189585, 0.004261972802749459, -0.017113397907311513, -0.021438401785928717, -0.018554452197142683, -0.017507082431679432, -0.021046993182973386, 0.002786871907952237, -0.0005198823120631842, -0.06810826144889667, 0.00267523497211901, -0.00022794608017328276, -0.03787737362629015, -0.026877489363765477, -0.06553542374748662, 0.04791219048371616, -0.017687248609775514, 0.04291785513609297, -0.016685088970340423, -0.01767982471705504, -0.05443803378347911, -0.04380865362382491, -0.07134325543320395, 0.0063000283046056645, -0.05155657231225438, -0.03841577559212406, -0.025645026711530503, -0.011990296662745382, -0.02810819796261892, -0.032574081617165726, -0.02101806132034095, -0.013306916356188006, -0.026585043351084667, -0.04448525433028744, 0.013127861958457304, -0.0570297339138781, 0.024456654010138478, -0.06414785742678902, -0.026286973421527294, -0.02812173719998443, 0.0233100365560035, 0.002176476552548197, 0.015451500126272059, 0.003125889063891301, -0.037990555663914946, -0.06464948833997326, -0.05188011187394262, -0.04163706573973821, -0.04910490376655582, -0.07530499971965186, -0.07276199062758337, 0.054663049582321856, 0.026090109389127814, 0.05377447979205539, 0.026664556476405078, -0.03336268729447483, -0.07198058945169744, -0.012756211293767966, -0.01737588483888756, -0.04139346850206947, 0.012410046123253077, -0.05739349692938561, 0.03756184057516557, 0.04113749684593548, -0.04221817451293881, -0.0359189260515717, -0.053749210283131656, 0.01210703868468944, -0.005130864326041507, 0.00600031322983645, 0.02232304105271657, -0.04664685256983749, -0.009684498090915499, -0.019684324395203998, -0.019680308514472056, -0.008245200678827213, -0.013000126833847322, 0.0010463602223615334, -0.05848869204509711, -0.04941581612612666, 0.03575483270637924, -0.030360633281066154, -0.020704212345776834, -0.04202031009621416, 0.033386877579112316, -0.101440562081967, 0.029867729728471147, -0.06476574117356221, 0.015673481003317606, -0.06980402974097956, -0.023904873931156624, -0.014011626327151272, 0.035879419524920894, 0.04168592468487977, -0.021475478220896457, -0.02693260788112929, -0.04011152430284629, 0.030807598299503282, -0.016915525943181922, 0.04576095913734574, -0.011509826778260998, -0.044932124641990874, -0.035844383644902805, -0.032322664634975906, -0.022461904092122557, -0.012754175629631243, -0.038332203601642814, -0.048414396442996936, -0.06025085338126069, -0.032518600566936395, -0.025849114013798753, -0.018286712164070316, -0.031042635394848143, -0.04696027386095208, -0.034077241538855746, -0.032391399696328364, 0.03385171601674635, -0.044221070793356555, 0.04323679315771555, 0.0037898712712925494, -0.0037097672260415736, 0.024241142279776997, 0.005702366060798132, 0.008022610573646533, 0.007790757668894852, -0.027240307965650183, -0.0031057403036216418, -0.009158132044680281, -0.07515992045485374, -0.015542476473277044, -0.019715914555267028, 0.025731705622496957, -0.01958957690511232, -0.0013653831725633661, -0.01440976542599088, -0.037734316388480925, -0.05422214082674802, 0.03855230951268511, -0.022292133227340107, -0.04124825953343895, 0.023781742205459727, -0.023280076117856777, 0.015490387334805103, 0.0131826238161844, -0.04457131946399538, -0.017902105773916495, -0.03248874713416583, -0.014215901580078353, 0.015339200597667971, 0.036784494830562356, -0.01707276055176682, -0.050908057123465376, -0.020995519859410738, 0.03376302131060995, -0.019157696667955183, -0.021696089841799444, -0.025704300870407055, 0.00022540785300320548, 0.030894584946176865, 0.026545439864594168, -0.05264035792433729, -0.022818662610696587, -0.03248465577000569, -0.03280525766741682, 0.07068541319389675, 0.0019058229086326894, -0.0220778731611905, -0.00954922495016394, -0.06774402608445844, -0.02205308230568447, 0.011482960102154695, -0.057843666854682126, -0.04221869411086256, -0.004048284494098202, -0.013440530437264864, -0.0751696958192007, -0.03802528940347141, 0.004806792246070686, 0.008738254387051636, 0.032020326511781924, 0.010572132316264976, -0.016784588255504693, 0.00035012728444478613, -0.017687381682647073, -0.017382949910921455, -0.04937917177253083, 0.02911007621835598, -0.013522136147089752, -0.05561089689293322, 0.003418075791115002, 0.01785882987199718, 0.011967230087989047, -0.0206102340863424, -0.007883083647860221, -0.02827111038531512, -0.020873305068466644, -0.06250872225668364, -0.029584374336777342, -0.048972992713515164, -0.0034966692618516415, -0.025288288627249078, -0.06375334497992807, -0.0023050874666339545, -0.014714752863570836, -0.02910292188244359, -0.0012405717369268388, 0.0204204421198056, -0.057175457756233714, -0.0331167404215024, -0.004856608047695791, 0.011924588137604487, 0.026094549872089652, 0.018239730362085437, 0.025413863088532884, 0.023105937889155586, -0.01211415008392507, -0.04009250766500406, -0.03656417461604557, -0.009052460008008965, -0.07126206329431031, -0.07242551960928911, -0.009982151133014436, -0.021736834675434608, -0.02333813775220589, 0.038558506432239265, -0.025628888022723152, -0.05850832433673104, 0.04885344666992985, -0.04186279141329041, -0.038107404517344935, -0.010760640000987793, -0.047627842432758104, -0.035440218720460645, -0.03822691025201886, -0.03150115907974259, -0.06008163963274201, -0.03163307050998503, -0.02067059076482874, 0.013152579227581038, -0.010264359900913974, -0.012825768764518602, -0.014802249522323082, -0.031929113057047424, 0.02479982379045652, 0.024581860071432808, -0.02998665165058446, -0.0041239242560115194, -0.017312211144738923, -0.03411220100684094, -0.00877270663142644, -0.020828676067126965, -0.0505542602877522, -0.016243350496694158, -0.050351101150116054, -0.02283891600820552, 0.04234543946243812, -0.06637859604237839, -0.025199507389157393, -0.028578847987369326, -0.030368716721629968, -0.056059663685794466, -0.037901057359471614, -0.0011388041183625801, 0.033428817533361965, -0.02424779732978184, -0.010995843841932624, -0.06470917018724795, 0.031464640024105685, -0.02818365810296031, -0.03312236946555249, -0.040559895163702904, -0.012675667454505244, -0.0275159849326413, -0.03501787336006681, -0.023535063698212955, 0.01784190174666568, -0.028451056049454217, 0.03714112865149563, -0.026395731975772704, 0.003831241487805794, 0.02777645668086642, 0.004615238000154843, 0.02789262317749542, -0.06727463843378549, -0.034631200280893636, 0.047724806301980394, 0.03866137763845172, -0.03843970497011545, -0.05535828629593165, -0.06347815832762686, -0.047222908835894965, -0.07101569194452415, -0.02345001409591163, -0.01168285918490965, -0.02244300894570042, -0.0005613694076141355, -0.05686660425319505, 0.058460498486978915], "41": [-0.06397804933531884, -0.05951934711110844, -0.035836750897446285, 0.025527207094872655, -0.0045248545823860925, 0.04168426257613858, 0.03902564560913641, -0.0012994706499777774, -0.056132891905869016, -0.022729105659786804, -0.018330640690533924, -0.007585064507756215, -0.04675374342192107, 0.03911378127497364, -0.016070039439172363, -0.018551540777195764, 0.025781475060772743, 0.0580937274881655, -0.03690099449656011, -0.03154982660998634, -0.007369815109700703, 0.007145972622335584, 0.027887997732483034, -0.019355483015585144, -0.10612425827748789, -0.00190518236113929, -0.0010885229839269217, 0.015128925934621618, 0.03799085470565085, 0.01576130645919074, 0.009070642182072973, -0.010098839230117737, -0.07655717627912731, -0.07081244431402414, -0.017171943394567124, -0.026507233882223744, -0.006456571387489335, -0.06859616256199376, 0.04884518852972674, 0.016095123469310472, -0.07578704753929946, -0.012416543094558603, 0.03320351755255006, -0.0032096685933677193, -0.011906608690313156, -0.01889173819966221, -0.008184875856959251, 0.013135550101280858, 0.002164050267629238, -0.05840772570016178, -0.018174456387303986, -0.009714883827198482, -0.04244379253674177, 0.044929842119943116, -0.01939676147572614, -0.05989263352773074, -0.02059836878031956, -0.03414403991848675, -0.022415748788292823, -0.07502607783804427, 0.03613996144840086, -0.0033442478125501373, 0.03589780218339975, -0.06547427468218478, 0.05041065106819101, -0.025899078854316592, 0.0014449484291366675, 0.03335834145536581, 0.0014388736975791943, -0.08583791650291621, -0.04978349365348165, -0.050961233572235115, 0.024366387374154117, 0.03270165979285594, -1.675411378158574e-05, -0.09193052087437449, 0.03506043122200568, -0.05608288166203655, -0.019867249811403115, -0.03769297274698616, -0.06530323330247882, -0.007369501680630878, 0.01326796776735537, -0.01526710426352068, 0.03665457271081066, 0.012846267570864356, 0.011488281343670814, -0.01962954959559248, -0.04641991734068374, -0.05832696720948802, 0.0014024426913521928, -0.016505299086387277, -0.016023450385586998, -0.0010971468053808965, -0.03331614838900038, -0.018323349809065418, -0.06089837515146997, -0.04310913608165314, -0.05241287019201541, 0.023090809148524787, 0.036527380314184114, -0.02587116157256505, -0.008784172475105252, -0.004034757138100655, -0.021482788819990026, 0.023935492153042737, 0.005876992419256722, 0.024582867937404877, -0.031761524507809294, 0.04447425412023079, 0.027845825126327762, -0.04113193114138501, -0.04192522869716118, -0.061162421982751625, -0.03253986781455761, -0.003745851599470632, 0.014709921451989287, 0.037585761239339786, 0.0493192104907329, -0.03471341805062874, 0.03219456640662153, -0.10591705985655211, -0.020775174043819507, 0.004761874336038166, -0.04795196277241815, -0.10820813171881287, -0.029438115971922862, 0.05620819216764679, 0.056472365271143646, -0.026426400489230242, -0.02412713456909708, 0.004029198846183265, -0.0054797119818691545, -0.04162017506503839, -0.08367253362863587, 0.032568276207701426, -0.08817343582260101, 0.03312891885360745, 0.034805686689076895, 0.005839599855770137, 0.032638151178339674, -0.05029903443675915, -0.04965693527907927, 0.060749880597378306, -0.048852334882355714, -0.0456620015930913, 0.003459913657598212, -0.0033680836080451112, -0.029002594231949265, -0.10019716940934963, 0.05811818713433797, -0.10152021294729034, 0.020392111955688248, 0.03388104123777279, -0.02014288017428345, -0.04544649612821238, -0.02402121724540401, -0.024573932706733394, 0.03073789700062375, 0.04310384127735183, -0.01547442953827763, -0.014634257239409316, -0.02134912544867815, -0.021191577876046405, -0.03172678791591035, -0.012531358360409462, -0.03874911468682167, -0.03303674867994837, 0.023524778540982585, -0.034757222380460535, -0.05721297118421202, -0.03194999057469211, -0.020344493987091372, -0.06754191620494496, -0.02416687014601445, 0.03206351835820869, -0.027593096539112585, -0.040561112656155286, -0.039692227507804614, -0.010732355517583558, -0.02973777588855601, -0.027168912663947425, -0.021066559389512848, 0.002533254251718509, 0.003788574032612296, -0.046980502811859934, -0.0039674320135878165, 0.008032121636101223, -0.07772954588010439, 0.05087042206622283, 0.02640816054626731, -0.046962920932678245, -0.04328461458700343, 0.00401324045919545, 0.0029331861722467654, -0.05106168518820466, -0.0357293021591398, 0.006231144322384975, 0.011664756479981468, 0.00045552904902088613, 0.002632841103264723, 0.006208562902009021, -0.025703304930269153, 0.0013366890417069168, -0.028638824922280676, -0.014399652638067919, -0.014789038383798886, -0.004646670903114988, -0.009755119901318447, -0.024708495985219073, -0.011687436957350958, -0.058103104459919556, -0.007363173898743556, -0.026739150692308294, 0.010563604327781754, 0.0008956359732317364, 0.04015300628865174, 0.03861560371473554, -0.022845402121979427, -0.026494644767561505, -0.034000814225474095, -0.005083674200575607, -0.03039658298929008, -0.05012430659900206, -0.009861684890129525, -0.07239526088700515, -0.020736884394923664, -0.04583748880937328, -0.03336582553259702, 0.002842375429127815, 0.010113438203322476, 0.01944245251836402, 0.012315555183231021, 0.008374239700087525, -0.012927301572979277, -0.07210176584546227, -0.045678501492514643, 0.03672157024692601, 0.022770140634915736, -0.07990132057111632, 0.001315568419636265, -0.016117848717146582, -0.016821738142074553, -0.01902020739092215, 0.033141784640593905, 0.036416766875340824, -0.022282972259303233, 0.068846689345012, -0.004297008369557952, -0.002028896753982257, -0.025673424138957308, -0.016396410977643695, -0.02791938875095159, -0.05673757867997497, 0.01668639345225767, 0.04040529175920167, -0.024137815346157925, -0.01601378276850897, 0.019042373919513998, -0.027395427457088364, -0.01618005430529226, -0.013664547860525803, -0.07787264696836983, 0.03234017013258859, -0.03600816857829151, -0.015932099055160683, -0.053936476629365564, -0.054395239154421564, -0.017345979571159662, 0.009416702054655102, 0.011776477723182998, -0.05486412736325613, -0.01081168434932595, -0.01848531342293424, 0.00979308988912458, 0.0029658291261211, -0.017464643837312017, 0.015895430379435093, 0.016253391745290197, -0.010679981780060932, -0.057839389160780026, 0.033406799822381, 0.001684716885333451, -0.012448350374378222, 0.01883965683163302, 0.03547006730096777, 0.019832146782243782, 6.790421503592185e-05, -0.008942551271482763, 0.0494171085954664, 0.00018931799612638975, 0.019832167651793974, -0.006152400021600347, -0.08142968281815541, -0.03126984383886367, -0.07585316529449808, -0.022489207526862447, 0.027381114881856735, -0.05938707229310905, -0.07070281904190646, 0.01913500172303189, 0.022888558372632522, 0.02175253594712864, -0.06608108718120052, 0.019241648713057783, -0.0010902892773380485, 0.0019574945080505337, -0.010149053979547167, 0.028861894926076014, -0.0024828935553545942, -0.025352901844525065, -0.07618701064859879, -0.05703947822164968, -0.011616370398969787, -0.032159227939715235, 0.0029406500791515355, 0.00712797112365809, 0.006429192900231786, -0.036542645980579457, -0.03746446204009444, 0.049363213703626674, -0.02067695786511239, 0.010280043466372298, -0.051248234680063696, -0.0703142475374102, -0.00014862958721005508, 0.017902614255155123, -0.009095219470349422, 0.03637164619731345, -0.02197164250463871, 0.022951156819008146, 0.045903750644894686, 0.04357931727892079, -0.022402304251227485, -0.059185398193945464, -0.019495724692018154, 0.036042205944261226, -0.02179110729193004, -0.07255879926822568, -0.024369350071467046, -0.013483059547780256, 0.01920450638054577, 0.019623017703285943, -0.028536724409488328, -0.011195002032873722, 0.015896474413802854, -0.014791755553030963, -0.0881789684088785, -0.04432847982616112, -0.06363782328047819, -0.08349634980256392, -0.04122093437778853, -0.007574599238346621, -0.03750665602617987, -0.03455705121607135, -0.053979778754668105, 0.04634554105132835, -0.002818120325326198, -0.048608274457469985, -0.0472287339600858, -0.003833507336446375, 0.0036324671063648274], "28": [0.012668217196153474, -0.0378175953422811, -0.0035400413073343757, -0.006575028469439883, -0.03419304106196585, 0.03187047065773428, -0.05148192021227699, -0.023450505548681024, -0.02636829953160379, -0.040245727442423614, 0.036961955116377024, 0.036811455058324234, -0.02872736815028396, -0.00852131160166031, -0.019094898737921712, -0.039358757369573255, -0.030948033403227257, 0.00991747609265069, -0.015455315092662233, -0.025994852829188772, 0.003655276318573502, -0.034180919070643835, 0.03266414152497659, -0.022514769227948785, -0.00438345827538172, 0.025982713454985405, -0.00982522005679567, 0.03538671665237881, -0.000532640566031661, -0.02977791531164266, -0.04609306177592289, 0.011801653468509497, -0.0004941933110027398, 0.005408371612960121, 0.0006004225924640617, -0.04012554863559179, -0.019237398010691756, 0.045615483297051236, -0.006267564583331063, -0.021576247630235513, -0.008653505217737629, -0.002818278528169466, 0.0009581515913080114, 0.023441313693916502, -0.025760515319785626, -0.003319432053717557, -0.008328359190305376, -0.02632257617283892, -0.009676133460835777, -0.0015829963160348419, -0.02899029256616023, -0.0429009052873927, -0.014195524447549906, -0.02004945639489991, -0.053684510314495545, -0.020915275550105868, 0.04637222740461781, -0.08403204880585903, -0.015590827136656417, -0.024226436296094802, -0.010269366870706832, -0.004934767601339996, -0.05873276486521346, 0.04403852249853142, -0.007702847679557515, -0.012793477745383206, -0.02868331115141499, -0.014997246373096799, -0.03400812391513931, -0.03100239056186067, -0.026723631823253755, -0.03183943242963365, -0.016201618848079066, 0.009426375809958509, -0.04943000328018345, -0.045744469787361276, -0.02379723800054325, 0.0645282447790801, -0.017505841787612164, -0.03947033926466033, 0.014779118264173505, 0.019336145193039687, -0.01763863852182198, -0.03527714269675722, -0.04259756813187697, -0.03656557198677095, -0.05810117489198501, -0.04946728308936868, -0.031231521833037505, -0.054452210169820096, -0.018218491232925054, -0.001231276090736286, 0.02817668148843931, -0.006009743762266739, -0.017971710693993403, -0.0764175065044488, -0.0029410465394523757, -0.048984403815882004, -0.031297805992646394, 0.021964811001090243, -0.04699278449415198, -0.009112277475043791, -0.06453180478809466, 0.049701991772195336, 0.03964843164421024, -0.0029499650837784626, -0.002932622449777489, -0.001838018991020284, -0.01870676331234498, 0.05355167811945214, 0.00548271291712467, -0.02718628698729415, -0.03633312993376344, -0.03285840115993043, -0.005127997952605407, -0.027603277622842884, -0.05084587755861308, -0.024144620511998522, -0.029796876357360377, -0.037665275035724796, -0.06488057064976066, -0.0263144104205379, -0.04068589856762747, -0.019282728994040824, -0.0601274816872707, 0.011201784562891896, 0.04253981498757873, -0.03258240470140398, -0.06560524932022303, -0.03748081862230126, 0.049421829921041424, -0.06561892661137296, -0.061904982076595214, 0.004392843512036148, 0.028478340776645072, -0.0618475701830862, -0.02002242479016262, -0.02297204948529661, -0.03511307361169632, -0.032093544579778754, -0.05464508006130915, -0.004011341573193766, 0.05404422590215262, -0.04680494518311226, -0.08143984884887606, -0.025956636221942, -0.05213932619011924, -0.0189531171198173, -0.04412532677552851, 0.08729490111065216, -0.040796821027774155, -0.02138383791736911, -0.007537600485362002, -0.06821891800263025, 0.04663801191020558, -0.08104187722862513, -0.020004521234226837, -0.053317751722381616, -0.027257905234743616, 0.03514205152126192, -0.046588373117090603, 0.021980677259055406, -0.028367411732279236, -0.005383994177779671, -0.007608555977854626, 0.031026788122155594, 0.04676260835532968, 0.052930515015413994, 0.02277073331828905, 0.003120153075824644, -0.037412804075142525, -0.03504583458029543, 0.0074646588608370526, 0.0013663417593912895, -0.014144549268069836, -0.015659998225535134, -0.023432449736752597, -0.035054575775307004, -0.03271942804668198, -0.026377066462553264, 0.00904647688047776, -0.039486070549320657, -0.018615030849600218, -0.04067080995679304, 0.02696668980224528, 0.04020484868675286, 0.0011874349886952381, -0.01646499692179286, -0.05884756754206962, 0.020835604950247742, -0.005346561582688289, -0.0010092686137811592, -0.007394318007197404, -0.03891569267140833, 0.002824781425740567, -0.012043046882901729, 0.002428607349487019, 0.0027258898275967186, 0.003619069417824992, 0.00359864060945916, 0.03894780674153336, 0.005886216794004222, -0.018986574658081783, 0.03337115817628952, 0.026533670763579927, -0.024919887521326494, 0.022484607237952745, -0.043503010371678426, 0.027668315289671386, -0.0407913692220837, -0.009557249215903233, 0.02816862555458746, -0.06537787234820562, -0.0536767826121024, -0.012279907223884381, -0.054810708415917855, 0.020809557792346476, -0.030696263839280775, 0.03206212614428234, -0.02864605083859136, -0.01064824783307661, -0.0290442992517295, -0.014383204241688716, 0.04665213286130397, 0.04029112801964603, -0.012537169262062168, -0.003795988309786153, 0.05705869874881615, 0.06596368922964112, -0.02236103385454525, -0.02428850899444334, -0.02604381066028796, -0.02027829436573235, -0.01921074031200119, -0.009028992119486875, 0.008505702639121322, -0.05280577600020407, 0.027942842340785517, 0.004534462481777242, -0.029447478578754235, -0.023890245646723787, -0.013009297598734773, -0.003480652783344862, 0.004321050177277576, 1.7854970919128782e-05, -0.021981384842567044, 0.004404015771989708, -0.013822794713885232, -0.014922608297116148, -0.021992161460935702, -0.034141037508442086, -0.022631220031651685, -0.02771820768050161, -0.013483020585044898, 0.017517941072634952, -0.017784270089328747, -0.02699222799548779, -0.02483440189336079, -0.017861320042904635, 0.011549411681463109, -0.03535797858673884, -0.03349500703852502, -0.021700947724932425, -0.029734055335509837, -0.020644027006397926, -0.029369585891915767, -0.06320400363142482, -0.010879001298122758, -0.038571373878588375, -0.0704219059732503, -0.029062102476902392, 0.003761274840879772, 0.012198368139650069, 0.029505396151044742, 0.021371132159837013, -0.008608024128928735, 0.02640875814405366, -0.07242319895466756, 0.016794084585989348, -0.023878465968445676, -0.04626935933895082, -0.027186779726462502, 0.02141827430019515, -0.001357314113141937, -0.02157580474891576, -0.03278452277003613, -0.0029178571959034907, -0.03278675267862279, -0.016616588854335937, 0.03775347763448565, 0.022267149396593914, 0.029781945088622284, -0.04039007603063068, -0.013088423393728652, -0.0351079332290525, -0.06067978397648426, -0.029438078447881627, -0.030771373507825304, 0.03656485869177145, -0.055255429949672134, -0.04331761485061335, -0.05314010658972517, 0.012675259360761032, 0.011445685274669274, -0.02151109218719416, -0.05052418062388633, 0.023106037221364395, -0.026030990480172263, -0.003219547794369677, -0.012124799021261751, -0.03837405812034878, -0.02729254345810983, -0.013880326197482327, -0.017734115145908655, -0.016229282603863335, -0.012769784493673567, 0.027995930061369446, -0.019132815512604723, -0.06023665979313969, 0.04082425439739826, -0.04371770041208997, 0.04517856545988158, 0.016544422510688554, -0.05234973512594573, -0.028700586333382648, -0.033018170896455624, -0.046276576064140415, -0.04124153706195965, -0.0460025089892063, -0.03299246855274206, -0.02296476300519269, 0.025873147398664028, -0.0265547071346378, -0.05848804523075478, -0.03804835549679669, -0.024571989168098034, -0.023376046685279817, -0.05294055712776543, -0.013201159976332729, -0.017397223744474118, -0.04830290021591416, -0.012664772280313777, 0.013578693603286748, -0.05163480920964394, -0.04369661825232777, -0.07366403846578107, -0.028286385722774365, -0.04607258510257536, 0.0448739153445014, -0.042575559155910166, -0.04753685161991824, -0.054430704125717815, -0.03331845204424267, -0.016851044693034643, 0.02492940032502819, 0.029281624227466593, -0.046945771697743874, -0.030016309624720152, -0.012785299198701427, 0.00045766140696383817, 0.05378554230268123, -0.04640685280077451], "50": [-0.030136567795583685, 0.014950759738850891, -0.015334931640437172, -0.017386877184671908, -0.06674616189457878, -0.009511172576133391, 0.002758203949435351, -0.0037138902080786278, -0.009367393827421196, -0.0363676640608648, 0.02938420765972648, 0.017320275715218537, -0.028095305389524722, -0.038233477788655004, 0.03376532972941829, -0.021234486535946645, -0.030967449678091872, -0.05577526843786403, 0.03152731794833991, -0.03018657684168337, -0.015145628284054798, -0.012659802348873535, -0.043765656937208575, -0.02780113407143879, 0.0014497520541861444, -0.02203899587997154, -0.0632356937767288, -0.033766988991844646, -0.009682849387387239, -0.03159022065880658, -0.038286159098899986, 0.02991324866671204, 0.006125450889553386, 0.034451627501773156, -0.0325601244479697, -0.014341679790820646, -0.006422682107767422, -0.054537360848457055, -0.02122002704174578, 0.02752594415235851, 0.0012466170299448355, -0.012314001512918171, -0.007651882364834842, -0.007569652638015176, -0.009383431807757638, 0.004129634807279985, -0.016622891366000304, -0.006823815456173161, -0.0007768971133542791, -0.07825249772108529, -0.03680560393576345, -0.026252598637621794, -0.07717464847403105, -0.03964031014929148, -0.022444144578647997, -0.03834765146114312, 0.037375903627195096, -0.0026985260023494363, -0.04581800070664381, -0.06110501253019512, -0.027720453929875558, 0.026186197032621376, 0.059373660961028245, -0.030689013680143182, -0.018330861671429374, -0.019595369880424936, -0.007968575635204363, 0.01763800335587269, -0.08114165914423561, 0.004327410959583957, 0.022481808827847758, 0.04947745610541765, 0.0036293109343317957, -0.01910155806923345, -0.03860465525765782, 0.014936344071928447, 0.008968014165328855, 0.04209910124279762, 0.007308575984608, 0.018619542955647973, -0.019181601652711933, -0.05109317306502045, 0.011764393014618818, 0.016281387295364113, -0.027291049774506262, -0.034456438389007644, 0.020538906749009964, -0.05536314540811196, -0.04527736576977556, -0.04273598470986646, 0.010802588940427993, 0.057902208076972175, 0.033664855884972505, -0.07565416627102467, -0.009882044330365351, -0.06552485382801541, -0.06692784131269153, 0.02018955643515092, 0.01477228751784575, -0.009069051173263202, 0.040800019458860665, 0.014213506457931496, -0.05223863181743468, -0.01367248088387806, -0.019829401708031186, -0.010668153314192009, -0.062087917331443775, -0.0031438692137731095, 0.017524643900214062, -0.012612155445740366, -0.05370434957527287, 0.006178582926874827, -0.03663516344260695, -0.06097154280972715, -0.005087584420572812, -0.01286042603101529, -0.05889288764797299, -0.024343761934191258, -0.03698671123440121, 0.00927410031623706, 0.030725953250393817, 0.010321355346142381, -0.021694268652605427, -0.04584575513715182, -0.07519662721281963, 0.043329319505351654, -0.020529985884853275, -0.02720361034716677, -0.03605281040837979, 0.027092423405551347, -0.027904672959665023, -0.0011512562084564355, -0.01769548741945182, 0.01196939347123081, -0.06893047556054964, -0.022458634956782915, -0.029182709096854016, -0.0339987447838756, -0.029300352114189625, -0.001956270649440844, -0.03146835085028786, 0.02518281301493733, -0.046510446387955005, -0.05893734691338574, -0.06838019796164964, -0.05188627288549526, -0.031701366795713934, 0.009727083706760264, -0.03288380351287003, -0.07747606424362302, -0.04217906058710779, -0.033394178325682054, -0.018928949971743388, -0.04009573930819514, -0.05489084516622505, 0.0076321957518423285, -0.0005921334860327273, -0.04085722224511525, -0.04297638459115068, 0.021695999017341015, -0.06445874902574007, -0.005741642527185645, 0.05107497950953007, 0.03090272725393524, -0.02423151403321812, -0.02335199661852537, 0.035091977892007686, -0.02675582764625579, -0.02035339418228036, -0.033594731248636205, -0.02889843249264857, -0.021171750633166807, -0.028006481062611506, -0.05210919620493604, 0.001518358020576716, -0.013500825343884184, -0.05349300622075106, -0.03561697688543783, 0.04397840514507504, -0.028047275238634598, 0.039934839349409966, -0.026479747934487943, -0.04957498850538205, 0.0035440951412480893, -0.0027898986804501804, 0.0029103610864886754, -0.016829376826944468, 0.004106996422878465, 0.001656251152830606, -0.05973589130354389, -0.03896174408085975, -0.019875233236136578, -0.004505695553500789, 0.003767336530419057, -0.04504340414488038, -0.013843030581040859, -0.04366048923247981, -0.034054248391152696, -0.07175647610932329, -0.035759419224528806, 0.0010277449302054978, -1.6656737836132826e-05, -0.012808633565808053, 0.0208322118869089, -0.027589212617011492, -0.01738566960564717, 0.009587039021104941, -0.030419305061088756, -0.01792035237759999, -0.026070660973512023, -0.009194652641612311, -0.009918945517156809, 0.038259043120630595, 0.0007836717123705215, -0.014023173088981485, -0.03450178013305437, -0.006332807688076957, -0.04907560345397967, -0.01821183060101482, -0.021945690522086506, -0.051921753585495195, -0.020540361772612366, -0.01612863673356473, -0.05863334890547343, -0.027896928800502954, 0.034381108717214635, -0.025883307194554155, 0.04999452972534588, 0.01933269010506585, -0.04578363590780255, -0.0014850510685757831, -0.05291693932759252, 0.010318441997557838, -0.014437996374925799, 0.011788745636179378, 0.006634450535788758, 0.027434346745849516, -0.038715119663982216, 0.0028630577210957556, -0.06846297879669065, -0.0010385366007719511, -0.06184818970164299, 0.011685090282322536, -0.07980359310336636, -0.03821955569066396, 0.003549937696092732, -0.004244599904408822, -0.023661021415788935, -0.03439258770124003, -0.03814707202123071, -0.009657740109276086, -0.025670858276898037, -0.02836616481582956, -0.053587655085704906, 0.009754065789703647, 0.025493422494406278, -0.056148663255451724, -0.0659872630611842, -0.05733534602278547, -0.06080336645454433, 0.008640620827844813, -0.030288707101137465, 0.009039079011680481, -0.061772571410163, 0.019914865894196346, -0.04711333436003458, -0.053305276758085385, -0.06427538962618094, -0.029815447447655675, -0.02577340188313927, 0.02342228437426855, -0.05168250332889907, -0.017887245734334315, 0.02042693082996043, 0.020209297016730174, 0.026994749064980398, -0.05999223855225439, -0.0674254385304058, -0.03639720400688851, 0.025404289834339962, -0.051631145486990764, -0.03828865366022467, -0.005161387140961273, -0.04741477143631469, -0.031118127456881826, -0.06404964286201714, -0.034209296332586535, -0.008773890254037643, -0.022184363582632753, -0.018155287190531368, -0.07418264264355927, -0.010343886936681507, -0.019495969284801896, -0.008970539776132415, -0.017281519499472025, -0.03565476100556271, -0.016950642845862673, -0.022416562018552095, -0.023656583708937612, -0.016660385379943344, 0.027890182991484876, -0.03451555193386267, -0.01731476258580846, -0.06622464814155145, 0.03816191640956621, -0.007358653985525511, -0.022096215677914036, -0.017048066427040424, -0.053054642995592684, -0.004208714758039604, -0.005734644983128487, -0.01429405214272628, -0.05981846636548143, -0.03458121303690001, -0.001873898911388528, -0.003189044000629422, -0.06849209499248454, -0.08522436514481287, -0.02770700479244466, 0.027251732057948203, -0.054344538464930446, -0.048631736783155716, -0.03864901665267992, -0.02522572703644665, -0.009350348787259584, -0.02855440024083556, -0.026378654458610727, -0.02925015610699061, -0.048458578897710235, -0.04163629148560371, -0.050739518421119255, -0.03035250427805071, -0.036350463687189825, -0.02702930794330377, -0.025554114378683712, -0.02391153183858269, -0.030541104352167846, -0.026921212694694757, -0.01835608886032901, 0.008247554427033118, -0.033304914301824216, 0.013441977079305216, -0.005451102253942151, -0.010858314040363228, -0.006117753061189479, -0.07115010329922107, -0.06553156693015953, -0.04958570543250386, -0.03658717424842228, 0.010079385730233393, -0.07380184485900769, -0.08116688395623736, -0.025378218813594523, -0.03303693108692215, 0.0033977165971077234, -0.06158414694601039, 0.05425843912325786, -0.06101917930582991, 0.06074029124269177, -0.009113326510604446, -0.014067578415349299, 0.046715816930452084], "53": [-0.06851430611387864, -0.07268047532012525, -0.06867823993730914, -0.0660927207939922, -0.0547779794249596, -0.06542229006845424, -0.0639072563124703, -0.0657131046125585, -0.06019145279378863, -0.056727436207226395, -0.07405780603827485, -0.06340803314022286, -0.05935761727822921, -0.05890131656574862, -0.05868744328074556, -0.05141578603277174, -0.060101233051283745, -0.06437597002364394, -0.05678669057844279, -0.04395858259355933, -0.044514455326639446, -0.049053390723927205, -0.05059750573515043, -0.01237792805875724, -0.05988259753897501, -0.06071707023624725, -0.08170171005370744, -0.07443441419892695, -0.07271676656855797, -0.08006417946277848, -0.07776426679246372, -0.08154782651566102, -0.025598839548249562, -0.02773425872480591, -0.07493220163899453, -0.07790588618686627, -0.07778291720937844, -0.08241021518658488, -0.07449751853819538, -0.07470845571559621, -0.07055628715634589, -0.0776069737821731, -0.0721973016976479, -0.03913387905240837, -0.05579545602452566, -0.05350102994310524, -0.04478701152323833, -0.07684241578996549, -0.07648861172798142, -0.06833412710586508, -0.07694625752810266, -0.029608098065449086, -0.07906322443649727, -0.09357566818508053, -0.014457444598017202, -0.07894228288513941, -0.07649014861175087, -0.07916629641532615, -0.09219035816363952, -0.06962668500372418, -0.07249163471835937, -0.06762689525074823, -0.07955952437929462, -0.06194309400222977, -0.061363755524169755, -0.06870607166456055, -0.06791342263749604, -0.07772336755822587, -0.0507110012626443, -0.08362585385796784, 0.02688837403181242, -0.07375944044277888, -0.07535487987696869, -0.08275833254987838, -0.030251108129800183, -0.08025155509331286, -0.07792520611942584, -0.08690862261178697, -0.05461437815337352, -0.04193968200162127, -0.021888103687649266, -0.0504006218309103, -0.05062049726810156, -0.054764806661256535, -0.05567357078391341, -0.028003570688189025, -0.06909573492939806, -0.043333413444298655, -0.07483260335730764, -0.07445835708101113, -0.0679170424666347, -0.07426317115771094, -0.062311766576537295, -0.05931979442952664, -0.03388066516630777, -0.03595554388985832, -0.07404204353661961, -0.062286700159210805, -0.06275058838878782, -0.06273276386064727, -0.06653392896594318, -0.06176403855579894, -0.06997146526511362, -0.06486152599572871, -0.06954913322495213, -0.06773511907548774, -0.025034933701320646, -0.06942733505296947, -0.021059400651043756, -0.06363586248530194, -0.07050791120171773, -0.06341398144595603, -0.05016187626747926, -0.05217944804688515, -0.059189915777346794, -0.06545791443552536, -0.03908856163218296, -0.05110866739946657, -0.0508056507479366, -0.06412786591589323, -0.07112000183915447, -0.0789707111426266, -0.04267609323799224, -0.05051955964467112, -0.06447019636283109, -0.06149246759750088, -0.035533735223937296, -0.05974278583057303, -0.0666684998863622, -0.06482243830509526, -0.021756782471721556, -0.05770977155239966, -0.06728495456947257, -0.06513672085750583, -0.08497367411788116, -0.09618790084375226, -0.04662647511759736, -0.0695877073023246, -0.05747074472710105, -0.040368925725379194, -0.05304927535349232, -0.07319118096804944, -0.043342357886948304, -0.04396846931087247, -0.0747634328948846, -0.05727535936452172, -0.06635901983767895, -0.05155612267026267, -0.05196494559184223, -0.06123663868857149, -0.08056847793992501, -0.07103879337279878, -0.08686810917512232, -0.06977959744873723, -0.08280432539453345, -0.07046080916173368, -0.06209702623036914, -0.07000183626300424, -0.06773783429142971, -0.08042803121899213, -0.0535320370295179, -0.058391271988056534, -0.045272110856227704, -0.03391124276346802, -0.05194250330923516, -0.04719455222000627, -0.06200120776660056, -0.050871205453129696, -0.054845809425309346, -0.053367655743028264, -0.04571870250074092, -0.060406667314533334, -0.06087725310660835, -0.07301359847915269, -0.06682370368110149, -0.06340056656739662, -0.06333311738413669, -0.06502809172117359, -0.06536911725432629, -0.05295324524372768, -0.0537791982456985, -0.0687033675183503, -0.05259757253037435, -0.06448228843709108, -0.040950327802851495, -0.06660079352528911, -0.04867899727247737, -0.06250824854983608, -0.06533420645463137, -0.030900446034831636, -0.027298913430274453, -0.04769175876562261, -0.05182369609147328, -0.04096354193907317, -0.04830815602612501, -0.044202187375529424, -0.03634743341458988, -0.048644067912342, -0.07293505756211191, -0.022917027812564005, -0.0648709300917016, -0.04343371965613487, -0.028855083211141837, -0.028917950105768322, -0.039789600539170515, -0.04426297688205225, -0.0359342886015294, -0.02758358657359706, -0.04316871216095824, -0.03553257740555452, -0.037162101240124486, -0.024351273738487084, -0.05737338927985696, -0.059656120406175565, -0.05307115293029526, -0.05298247365427004, -0.05726581678897271, -0.05820089994785041, -0.05612873294549521, -0.06608036501319543, -0.06680773589149998, -0.05902841458256613, -0.056665571572875995, -0.06184037954555033, -0.06008582473197386, -0.05183567696963006, -0.035071298275802146, -0.0661769670578996, -0.0649576768060887, -0.06623423650792679, -0.06650010713490068, -0.06529968205971087, -0.005816607889898002, -0.04891917179268225, -0.06611947691174563, 0.013588889812697985, -0.06623931419473061, -0.06343966603819154, -0.0611699877027521, -0.0673949816728326, -0.06835071647915764, -0.06654433669375098, -0.06803178267922862, -0.06458352876917692, -0.0388726178549847, -0.07495002565272864, -0.036885304871366924, -0.0627777630420909, -0.04852623828104237, -0.04079002485500541, -0.046178857375088554, -0.06823025949169197, -0.04285318198433487, -0.07356227392673081, -0.043518753207822634, -0.06529037649081802, -0.06522505248702182, -0.06883113126529379, -0.05190671175973588, -0.05473330445607965, -0.0640153877767531, -0.0671176653042417, -0.06835626882728126, -0.06402897478877548, -0.06442431859842114, -0.0670115536276834, -0.06297170762393187, -0.06569089880432849, -0.06955663901984094, -0.03291171547065327, -0.07937003443354437, -0.019719108196852218, -0.07907327250904259, -0.08208917165470826, -0.08374016702518003, -0.07718853190827679, 0.005606753763588662, -0.011819700173479471, -0.08312570869909021, -0.08764936604881116, -0.04772314214217499, -0.04461785944330648, -0.07034878196526921, -0.06557399235396752, -0.06105007715886323, -0.06743594374322377, -0.06062093846238738, -0.0722356033462581, -0.060735912015345034, -0.05311830502049138, -0.04989577019830058, -0.04812349000922339, -0.06083424515410758, -0.03217199797938622, -0.058513887118286805, -0.07348036594277652, -0.07009223838994533, -0.0634804471868205, -0.0602628544357249, -0.055961739898083236, -0.06779350882666242, -0.06521931875885414, -0.042010601352236505, -0.05980313406329552, -0.061437895797336446, -0.05652306833354204, -0.05191140812650755, -0.054900424424532496, -0.055537114411826266, -0.049846567436746606, -0.049937973084158906, -0.0502657449933286, -0.036102931677301615, -0.04983282995654584, -0.04909336725792571, -0.051062083331693583, -0.0543993389636371, -0.052325054539001645, -0.04204349556801755, -0.07067288752414978, -0.050808400751643196, -0.051370535746659125, -0.06199473991885215, -0.0727779186625641, -0.055853689310021194, -0.047693603955495815, -0.06622290176864798, -0.05485834418694409, -0.056428805545925796, -0.07553115215733985, -0.06626979864283278, -0.053906236172294696, -0.07613459300002662, -0.056234919260204255, -0.03695228092924263, -0.03192385094495878, -0.08285492960787838, -0.09126315301408146, -0.05537865575913015, -0.053750354162722766, -0.04943184232596871, -0.0467494963513109, -0.05047223524958902, -0.05068262277990926, -0.055609153363493466, -0.07223541186520507, -0.08254946079756983, -0.08171132661387079, -0.062416929689613466, -0.04786001702520417, -0.0674562432294771, -0.09052984103979718, -0.06173993243528414, -0.055708856697330354, -0.04308265432350944, -0.06661522363192265, -0.05027462593858617, -0.046104647415652344, -0.05630212697670133, -0.08090915750427745, -0.07468877505487317, -0.08081956556868876], "48": [-0.0674273658502449, -0.011968790915157202, -0.019704063608359173, -0.004901687810019634, -0.004146221673173975, -0.059766152391607714, 0.009392849692313835, -0.01452371564417925, -0.012959243610678572, -0.019252091427217694, -0.028163866462031548, -0.037419066251105255, -0.02328046916212647, -0.015152955031523557, -0.009445582341704077, 0.004822150287985746, -0.011454528760329985, -0.03565749817953467, -0.025345464787384257, 0.00705202746834215, -0.0428849690581943, -0.04408113706550613, -0.03944106279265405, 0.0017413271484574286, 0.007787159012646207, -0.024998163201979524, -0.009619443431172853, -0.005117452295065502, -0.03799260476697596, -0.025706694763657136, -0.07051148647023583, -0.01902727067933857, -0.007677779780660419, -0.0013993750890665259, 0.046837594877379776, 0.059417666321740815, -0.06797370200576165, -0.013493239002847473, 0.04509399603811587, 0.04808041917553177, 0.05527292162789783, 0.0036845959903486756, -0.0016547965170388014, 0.004337367285991667, -0.049741273982116925, -0.008681301738571429, 0.010647488987680703, 0.037998496341080996, 0.008387796402090324, -0.05883376450649145, -0.01881113563855238, 0.019038860363004815, 0.040913429231424284, -0.08454663861180967, -0.0711051637046877, -0.08240512311784713, -0.05046130016574005, 0.068138696282133, -0.06064202696460671, 0.0031892812765130928, -0.02128225024251127, -0.06854711759469971, -0.017879104449930905, 0.027698342045806193, 0.032134026424316287, -0.004097832161799274, 0.0008011142351973456, -0.0246655842088362, 0.002784458458245589, -0.048664088068652314, -0.004957630636512305, -0.012109679976161854, -0.024132657142420723, -0.07090791876993013, -0.02213028012351596, -0.036969911957811824, -0.06181501534102156, 0.053182975887447546, -0.021269099025232597, -0.04630018624356518, -0.02741207106006293, 0.024443368244587507, -0.014510985908311364, -0.018599662375874564, 0.037808239272157165, -0.034520763474269925, -0.048567290965778005, -0.036084810825501794, -0.026409575727778932, -0.04271785158864561, -0.044338289201896364, -0.059823796751311636, -0.07142673905741904, -0.03157743862389653, -0.03186653655337669, 0.01701774960926537, -0.051626392336757754, -0.04508941858032708, -0.06330790833300588, -0.0242537685009485, -0.013956759575764425, -0.028154266188340694, -0.019699529188727357, -0.007366558017580729, -0.011708687372987029, -0.06979924812476887, -0.0614018999021095, -0.06130760299531201, -0.04539667076313206, -0.03394873242842785, -0.06364428282614472, -0.02214331552946868, -0.039679612281446126, -0.053462617032936484, -0.018301550961806863, -0.0407396370450563, -0.01941826414544308, 0.04972274841234324, -0.008722139667196979, 0.056309516582893765, 0.014428800655639661, -0.07342520848142776, 0.000978065736485695, -0.04404622751307992, -0.0727338057907404, -0.05139898023231991, -0.0066799337522068635, -0.02602312909018532, -0.03485622433359067, 0.04341563446743853, -0.037255117603093794, 0.007535309008412555, -0.03891550032010408, -0.014826948202815826, -0.0695291955564964, -0.05584191783716867, -0.05971971559442018, -0.029381538592206734, -0.030913240197632395, -0.0205690644621411, 0.0031228279273360533, -0.0473632240212733, 0.052034439069362344, -0.054301500293906665, -0.05096680817304334, -0.07767622936836079, -0.06013221571193534, -0.04595310166346612, -0.012608552413381241, 0.08778629711382885, -0.011594532975836843, -0.04845789465161527, -0.026665662265265462, -0.03784759074764277, -0.016586414914197177, -0.04012456501638695, -0.08641503751816924, -0.0585759662826561, 0.021978952953891896, 0.0031070968186969394, -0.021209336501464126, -0.04442670478186211, -0.01839059883092212, -0.02936751666705763, 0.06142287098010097, -0.06635376618933071, -0.03193268531322531, 0.040314773666567896, -0.023726288228314296, -0.059963489704299607, -0.035179634571253934, -0.04673544320554986, -0.04181208336208085, -0.06755781062779374, 0.0510616917036067, -0.039891178749780466, 0.01476319581837468, -0.030956640135400726, -0.059549002146642376, 0.041701912718174826, -0.07271766388771755, -0.037569925323560634, -0.039381328738090624, -0.012305691717796564, -0.0014412705659670975, -0.022060409982005206, -0.06361507534183755, -0.06360010305296643, -0.04179731261156162, -0.014245486429188953, 0.007089268416030519, -0.053813107470900894, -0.05556896645045261, -0.024482680598189914, 0.02134504597078924, -0.004860724909769894, -0.006354145861794279, -0.05860394892393835, -0.0650576884855347, 0.0035933366590126, -0.03363586977642546, 0.006671800065755467, -0.0403885280486933, -0.05363646079291281, -0.018116794035201975, -0.045561193642701135, -0.02830209140029823, -0.027223960382763677, -0.017919638422206233, 0.01857872853364451, -0.037428169250393654, -0.026848420795181783, -0.06055839007941004, 0.04185744004790207, -0.010615500249773773, -0.051943449457390926, -0.0305021401968591, -0.02631356985267517, 0.0060067021542427965, -0.025110337355041767, -0.050160095294157714, -0.04121515227741325, -0.015548150845933277, -0.014095249840617904, -0.023209296383618606, 0.010142323895348667, -0.015876273520539382, 0.03929731303080518, -0.04947047264093252, -0.017256378984320236, -0.06467394079783517, 0.015703298383966818, -0.0028899940050775676, -0.03133528206549469, -0.03500975231792889, 0.002335021594030663, -0.001033147537707873, 0.0003054243760221338, -0.006417362765690972, -0.045386171251136725, -0.004197070736973776, 0.0007056710164296095, -0.01643031551132746, 0.009746617210120021, -0.0036432007230008763, -0.07231198419742633, -0.06965292577983015, 0.02068806306808867, -0.017561356484605294, -0.02014666640664252, 0.03396118399786285, -0.019815572419570996, -0.047747497186498254, -0.06065143236950082, -0.016756818799985976, -0.01957385739423399, -0.0789525921331567, -0.02004474463987356, -0.04201971952327576, -0.025097364675141353, -0.05409319981413686, -0.04943266031914064, -0.06771465129760108, -0.008396623580709021, -0.0031254367135618885, -0.023044711795120472, -0.037893979519344825, -0.03204158488880589, -0.03987036339397355, -0.027994139989259228, -0.06554911567970398, 0.023977184526773075, 0.023611253901305758, -0.03882053244008981, -0.07482468149542422, -0.07072195968614699, 0.0065574424392263655, -0.007106636933386229, -0.08509077410774933, -0.0487994331052626, -0.015324061975862184, -0.026769241970353245, -0.0016369260256106956, -0.01800256870910552, -0.020025357068943712, -0.005756287661618905, -0.01037148975509312, -0.04336261060114865, 0.04055815970788147, 0.05260709821519228, 0.049599987907328745, -0.05743719982421592, 0.002056841781872233, -0.04232701400704362, -0.010141657354684972, 0.052897235630142835, 0.04036028521740559, -0.012363885709169976, -0.05501294691198433, -0.07107569605096821, -0.03850507831018319, 0.0026047334913451244, -0.03788571518216998, -0.012278010733890473, -0.011200186325724344, -0.03621365614705882, -0.02936488919060664, -0.005485489959284776, 0.04803767521094668, -0.01860784521674222, -0.005735341787913328, -0.006864529583166946, -0.030860636157532536, -0.025137502237117984, -0.02138823862497028, -0.007118008626778874, -0.023918968336194196, -0.052148528093835446, -0.028287603918009423, -0.021275717265762308, -0.029011458842899348, -0.027768498636794276, -0.04043947684757421, -0.04287434853555539, -0.06215973539706101, -0.02631281647664384, 0.0037670071251805727, -0.04300201994983078, -0.04535461934227758, 0.00787696551839659, -0.027894644684611565, -0.04974298192639957, -0.05123634612881274, 0.019340541812075854, -0.05675284136961823, -0.016160409131548804, -0.025470097937859513, 0.011559837223280363, -0.025010919767867672, -0.015146545158961954, -9.433444728896281e-05, 0.001263160612358208, -0.019456295604638813, 0.029060983679056747, -0.027405672746177237, -0.035881844005716944, -0.04860697904557791, -0.06304179271615593, -0.06472073328890482, 0.05793289576511756, -0.05150659435556675, -0.08389859527484153, -0.04765505346095652, -0.02616115105295969, -0.020819414452649697, -0.04580896844754253, -0.09178849646970512, -0.001195227171456434, -0.022772407882225124, -0.057711988901985235, -0.028675887769680712, -0.001888128606405454], "18": [-0.07081422373384953, 0.026194349111664413, 0.039238006550649705, -0.038148180038728115, -0.01931889574260884, -0.06712117338418004, -0.04670420702733726, -0.05293177170095964, -0.07372709731795475, 0.024318817786266864, -0.027006817344374833, -0.022914327116269662, 0.021537549972988106, -0.06061285433110809, -0.010842096076497072, -0.018793327985988182, -0.03850981543200525, 0.009789225417987182, 0.016035883054454626, -0.053775578959810326, -0.013591920918978411, -0.021942607898834975, -0.008274251549109837, -0.025977678563080177, -0.0678123401293818, -0.0171926107465961, -0.014900213178523327, -0.02489191185690651, 0.027519893086255163, -0.0012247747489215794, 0.0017214277766711475, -0.004206024121050767, -0.1048076742146104, -0.04252688897053494, 0.022049993272453765, -0.05171698775141189, -0.07758351869196597, 0.008908639396766782, 0.03830453315783333, -0.06895904293811421, 0.03211483411059431, -0.03494310007627441, -0.05652732586202088, -0.012822924124927219, -0.003947568926277184, -0.049519750224412414, -0.03221489782296972, 0.0221673027012841, 0.02921140878282755, 0.0006397354004202863, 0.005986066039666985, -0.07418970072911094, 0.0013054405490064056, -0.049372390848245164, -0.06244309618830166, -0.07878499502605922, -0.02475779249438369, -0.01616902578035454, -0.05272287951527107, -0.014073515197302523, 0.02068474686779493, -0.05402691187380437, 0.05911525992727824, -0.02404337418645986, 0.06027227135764829, -0.043814684836791726, 0.03994259126546391, -0.027425589927699653, 0.029390733435375613, -0.01874366510876433, 0.03570376127708767, -0.06573588452784662, 0.00657325133789917, -0.07456830531548148, 0.0013120629628487702, -0.005434809860747546, -0.01600898543444634, -0.02073793405873334, 0.022452595485941636, -0.0723454045202008, 0.002398801545619259, -0.03998648268518149, -0.05432119113977972, -0.06274287210556019, 0.004453197406215837, -0.031530789727468006, -0.03644287669672478, 0.007482087598805431, -0.04287874125846195, 0.04109171554198493, -0.029118957834806634, -0.06516332404177015, -0.07384940695356526, -0.020192260941178476, 0.027306120079758835, -0.060348432598869885, -0.06951045558696162, 0.024478563362630316, 0.0005018531166038125, 0.018065044455675923, 0.02257784150897081, -0.0002655733059130751, -0.04545280468575987, 0.018234430301742283, -0.039286725437379474, -0.045965340674109983, 0.02565936714700523, 0.006057615648395718, -0.019240390089411558, -0.00220507753277053, -0.027737914867868394, 0.03291449184207099, -0.03491321592882253, -0.03716202224852551, -0.010148192299964217, -0.014829018052238426, -0.07304067946633425, 0.025490334744931713, 0.0012296721356241363, 0.04206275668289793, -0.038954101041418505, -0.03821232447456592, -0.01644077152198475, -0.020149229354607938, -0.11020576539412588, 0.042016936930202683, -0.04139349934360508, 0.025465395230806175, -0.018009057492356543, 0.04486960167336961, 0.049212406123847675, 0.016435851974764056, -0.032315408388029376, 0.0032096004518515522, 0.03659191654086829, -0.0504159685779775, -0.08141942010429587, -0.002444361313347789, 0.026963154919261816, -0.02679087023742229, -0.05807101357127494, -0.061741159929157324, -0.06889395336390737, 0.030495974841985993, -0.02800696448739787, -0.03252998259012026, -0.03257828987040677, -0.059350350184039405, 0.03674207088769297, -0.0772002461407865, 0.021898048938902133, -0.02927224218471632, 0.0015019813915332168, -0.006299471491051694, -0.055181194559604255, -0.019927155567618086, -0.06770520752181056, 0.03800517126732018, -0.08741238461584318, -0.016286380733407543, 0.020262392274089578, 0.029222772092536455, -0.03378714581948656, -0.004550875014829445, -0.01994790241436737, -0.009718356707662237, -0.014631363220932581, -0.021614930472220146, -0.05927306598923689, 0.023875058401576534, -0.03215219952893605, -0.030156524171791356, -0.047496748894576016, -0.02901776485559641, -0.037744558550452306, 0.018122894611766655, -0.06990100317857056, -0.045874259490108975, -0.011076415986048424, -0.01413479930864877, -0.030727804176847916, -0.011072021127319939, -0.04806751832358848, 0.009198515545432388, 0.002738091702546235, -0.008901054606396917, 0.014807897687772327, -0.053450086101043175, 0.012082963354641943, 0.01694471973861104, -0.027441148199955575, 0.04662608775646259, 0.030599673205272033, -0.025703510051455467, 0.009113479941235679, 0.004829802000008756, -0.0006735848135053214, -0.06453259393455378, 0.025414078384525956, 0.007298781589071833, 0.030898749308509013, -0.01897441327793558, 0.013630936292887924, -0.0557050904795626, -0.05330365867408294, 0.027611254428588562, -0.026490876224889843, -0.033097550215235645, 0.02677742431560101, -0.019609419229362057, 0.007473467523881682, -0.07300188527949293, -0.03137211094401863, -0.056405190563863616, 0.005115199465182016, -0.054798911512818856, -0.06913302416202292, -0.03885191293786156, -0.04769138997185412, -0.05651437653624792, 0.035746823429371584, -0.036435317924825045, 0.015076981447182423, -0.00011754364494493918, -0.01224295649965213, -0.02571983839536738, 0.01766756965680605, 0.060198719613462015, -0.04201266866635922, 0.00606678425623827, -0.06310435731230986, -0.018391198202360647, -0.011941066252765012, -0.043968864996804476, -0.022586274757568536, -0.04506701593381408, -0.014718871828160467, 0.031520930988868275, 0.0061435916419663094, 0.00996847003891889, 0.014146482497944802, 0.0023364986300784094, -0.024717055773896775, -0.022872944502153728, 0.006631286125666861, 0.024095518049077013, -0.0837448692585942, 0.037216041491655756, -0.019415972796647384, -0.00021624631529918887, 0.04078538358594738, -0.013104343069814565, -0.02304645990847971, -0.08473150116813918, -0.07894710044424653, -0.013261760351070186, -0.00022556489775931528, -0.043112436642002636, -0.038410194625722004, 0.008225222507236925, -0.08891304713969664, -0.052566976762343474, -0.019284902470765954, -0.030122126982481987, -0.024997387197315417, 0.02295479797609756, -0.06075043978820338, -0.0029466308074662627, -0.011740754463950061, -0.05371868236259775, 0.005893824381484573, 0.02189520537011936, 0.03122780286048888, -0.027996620352439855, -0.04185397988375332, -0.08627703621913761, 0.011113544732646821, 0.020799880840490368, -0.0008083608893885571, -0.02177175340079454, -0.05302099814964802, -0.029983552867200294, 0.022222622582921268, 0.003087240494836925, 0.0016379006513249953, -0.00949964264079003, -0.022849185195739162, -0.010622659548643842, -0.07227890289527951, -0.007690399057909413, -0.015047343734435413, -0.014838816056927695, 0.017841720370480967, 0.033897983279907985, 0.04087128265896521, 0.022228585477662287, -0.027271326925338058, -0.07317313458437444, -0.05031908640808901, -0.03592092637919061, -0.02173318642775316, -0.041862649914198594, -0.0093040495649873, -0.021712454136598378, -0.03819465998975177, 0.004138345038151521, 0.008862419374293705, 0.03212512865210477, -0.015269849396059527, 0.03600684261444207, 0.0038911940180489913, 0.020104976820805868, -0.022513064838712023, -0.032154356645324254, 0.024629926830105824, -0.002406612327036217, 0.026030634728955646, -0.05337211506072066, -0.06012804669100826, 0.03227397978743921, 0.032190275338044715, -0.016550641176694865, -0.03425043592899815, -0.04756740406182372, -0.03296700124854864, -0.08043163105278654, -0.03321051002554165, -0.02927001008324132, -0.015173345020253715, -0.07749114091343484, 0.012077760005966482, -0.04197358669017549, 0.008112468256622566, 0.03217500271706724, -0.022413164442574296, -0.013108700323952107, -0.002136489244865942, -0.08877448674670012, 0.022297809278120136, -0.022430527297208645, -0.011947398906090112, 0.004785648035669785, -0.04452464387434298, -0.06707503028551302, -0.05976464846601031, -0.044088289604142995, -0.03648443427051217, -0.03272174497281449, -0.03029794325705632, 0.04318868696670612, -0.04935154838565151, 0.041726648267790205, -0.029555182467799077, 0.03366146626177353, 0.003125852333080442, -0.05057799585203274, -0.01460977817439181, 0.020658274440966205, -0.05945263806687223, -0.0026411878153339715, -0.07272000790100086, 0.02262752785612312], "43": [-0.03355602479275486, -0.05811061756125892, 0.002272549133908853, -0.07273960193663863, -0.004520222404893265, -0.048836715680609856, -0.015836893864107936, 0.013818489085278886, -0.004993224742492153, -0.03338873000107386, 0.017622485536656442, 0.04410525306483484, -0.030068583909267553, -0.0474580146664674, -0.026342425947439053, -0.05742734742982838, -0.053283961263309504, -0.017684110307532076, -0.0222252836525186, 0.03493381158670616, -0.03141582260870883, -0.04037184643728732, -0.0007649652908322461, 0.015425984698296763, 0.012981081684816816, -0.017316245897863118, -0.0700116153053069, 0.0279339645672067, 0.005793480336836614, -0.025919432492360277, -0.016508975416655778, -0.06640546582117698, -0.004843313586712421, -0.02818338295945098, -0.061828077571573284, 0.031520656698022724, -0.03077607138589793, 0.009071075647659733, -0.013541216583697604, -0.018414776846076193, 0.027828143182175264, -0.049439364807371114, -0.03112140899226256, -0.0053829650647246405, -0.009185484954236984, -0.024278605290117734, -0.06977452684073872, -0.008110557328641148, -0.010087254218978364, -0.0050069451177054995, -0.018746501876585945, -0.04423663358843787, 0.02682510264160945, 0.01660230336185508, 0.04271458735345954, -0.05536326344683789, -0.041966168998645116, -0.022430020164070107, -0.022008856721675536, -0.011267278514122804, -0.018871378607808256, -0.012390194004407239, -0.00171417256048597, -0.009338534465510464, -0.021781667665747375, -0.054894905368009624, -0.047999184543893916, -0.05632542057963828, -0.01393117018062974, 0.01150564997942775, 0.004465600625928933, -0.01193011834284026, -0.0845733888733523, -0.03537831511825009, -0.059222384172484564, -0.001908646860454323, -0.009250154866652054, -0.02026873204534532, -0.06709222334070408, -0.016702484730753774, -0.04799459578211381, 0.025911911941219386, -0.018286442674742755, -0.024640558406317115, -0.03837736860229033, 0.046383773074682236, -0.0076940225142537975, -0.002368802393792107, -0.030136097009060208, 0.03612000382785538, -0.0239102516888812, 0.025946078682037244, -0.0035228208645442637, -0.04476562602410463, -0.0009140698595980412, -0.013114948207083633, -0.030378952701196504, -0.01506279899310951, 0.001634080212738977, 0.000578146041619931, 0.019199472458236118, -0.049325097068717565, -0.06190348010075941, -0.04166081468814477, -0.005376019091571027, -0.004663309865073368, 0.0020429905020374864, 0.0032062940161434314, 0.00012593206206326453, -0.03347488685752313, -0.024921410408621808, -0.03981517148855425, -0.04301318434287662, -0.060155491283353534, -0.028470265238621662, -0.015866845871097702, -0.018744308505942706, -0.05257292800550086, 0.04120924335250313, 0.039958789137960846, 0.01499091090148095, -0.03563243827910904, -0.04984117654589924, -0.03725665043734429, 0.05960281089483893, -0.05225435386963616, -0.026788886218414295, 0.012102871617997824, -0.06298045597636438, 0.025978911734466693, -0.03396579424885022, -0.0006324255655491928, -0.011581628321464865, 0.009776777855498242, -0.07725694604130559, -0.017124588707995676, -0.007481526932418202, -0.040953922561547555, 0.021674069291745757, -0.004162143774296078, -0.052506165996662225, -0.030490575929476887, -0.009759355049029753, -0.016489896005937654, -0.03271269624767687, -0.037594554142727825, 0.012649194777536482, -0.07946473375464147, -0.052460166336162566, 0.05132661625586337, -0.04262925727313497, -0.04991341225240647, -0.013259993806187443, -0.07595760499170161, -0.042047745656773, -0.05578829996942336, -0.009859049424811844, -0.012711014239904695, -0.00961353791228565, 0.04303792788337511, -0.021937024570896604, 0.033829697047997, -0.010269981474695435, 0.06841627921528341, 0.03277052828854197, -0.056703027435911144, -0.06751253061528797, -0.04496128105978894, -0.06099660961652258, 0.02094654587630087, -0.01653200666029496, 0.0028533558222772746, 0.03431062240217767, -0.01850543783957177, 0.009542825452756074, -0.022123339348282242, -0.03667803643030504, -0.027868661819249026, -0.03038450956700499, 0.04271743718985599, -0.019312280363197005, -0.026461387814731938, -0.05137899728910687, -0.007481544227276383, -0.07888389329323771, -0.03086259267391273, -0.023419263004497703, 0.029505276837586462, 0.007064172923763648, -0.06397373518875256, 0.004030185715813002, 0.0013471927582816585, -0.0404303412836039, 0.003629238753003184, -0.03497378557490224, 0.0548670447225768, -0.009982929316043606, -0.038949325994788814, -0.07076052328635214, -0.027940495460344605, -0.007948872164311083, -0.04052176831625843, -0.019141152608242736, -0.02881821199607596, 0.0224995676046897, -0.015569645380484089, -0.03281710931545601, -0.025191466019159652, -0.03912488050465559, 0.02335420949874544, -0.002449618476092284, 0.018656623473671984, -0.05214116059437295, -0.013428023904327133, -0.018814192093657915, -0.02545304490563072, 0.028070530483465993, 0.04140194781031264, 0.020923085703527248, -0.06203636106835499, -0.012505284502360646, -0.02032293700921284, -0.03418848512054356, -0.0503005397340132, -0.03834687193818058, -0.027799785380728064, -0.02140064262320944, -0.08448849526366671, 0.06783492711535705, 0.009236318067000886, -0.017405891786453007, -0.0464663695567302, -0.06605788143561771, -0.006734374405217536, 0.027099902965197483, 0.0037179074876476, -0.012436060531543235, -0.0006194122315416631, 0.03446689757742567, 1.7426234451763344e-05, -0.046339829563669555, -0.04713906494707935, -0.02715599850883681, -0.053814296562360725, -0.011585592507279908, 0.028154302981048446, 0.002394667846564343, -0.007435129836773279, -0.007787093548664683, -0.028186695314955962, -0.000425774900624466, -0.02641954519427025, -0.029946434965380325, -0.009933856398814462, -0.012445992359747785, -0.048009292332030454, -0.030850376810614165, -0.015640372052948312, -0.05061906444106913, -0.011320866878747674, -0.018632753197358673, 0.026733329878548255, -0.04030454325795897, -0.013170854149705166, -0.04639003144803298, -0.0020924561149536407, -0.009949827285215299, -0.047177106163234735, -0.0132181520885671, -0.05513404325470977, -0.07755257463310392, -0.006098238280198213, -0.037087299815357, 0.008271018088429534, -0.02494395093372384, -0.05861271436780816, -0.044152642140316584, 0.01567306063583661, -0.03320595750854459, 0.018870171960805607, -0.03255994513839865, -0.042370615206251565, 0.014422095687501489, -0.01613768269176148, -0.0004316224440840925, -0.0019723455633215334, 0.021729999651408198, -0.00344994480507458, -0.011907716183995358, -0.013988160679382777, -0.011864673350533879, -0.016250061766766764, -0.0734118144913, -0.02813843837782429, -0.0163299796771941, -0.0034689203027978553, -0.05524124884034657, -0.03835387720940678, 0.03505241941434987, -0.02470182639239363, 0.055007220908915425, 0.03658142484941776, -0.06975909233922531, 0.002147005357555888, -0.011203277686425758, -0.028473346556302622, -0.02086534410561879, 0.0006417427578542345, -0.0012798387957981244, -0.05160451462130591, -0.051062173613738666, -0.00357473250976114, -0.008734854991024782, -0.004061771367222338, -0.0533774331875493, -0.04002525005701244, -0.0202987212626972, -0.008162872805988186, -0.042321702353251334, 0.005347480773424569, -0.055757916886803816, -0.0313467214983134, -0.023024110856397405, -0.01905365846234497, -0.05908170691135844, -0.005627553016489789, -0.017148472567674055, -0.038523013468405885, -0.02957904331289282, 0.018935396822610445, -0.06191623869555548, -0.022108893138462878, -0.03776806673153955, -0.04094696644124873, -0.014424150979704044, -0.0323722072242262, -0.0743080293360819, -0.05273400631719463, -0.03196917076653677, -0.017379558551883098, -0.013176544287606845, -0.06919442271975952, 0.014936877479563996, 0.011307819006275482, -0.06344498407738373, -0.034309727214829874, -0.05609245346118611, -0.06978724127203936, -0.060331198242900744, 0.026903028165101827, -0.06329730768607998, -0.06312891697244126, -0.002469381704346333, -0.019653915275601452, -0.04456799121180561, -0.0297343839471342, -0.05596442263308431, -0.046108594907154556, -0.00499419599579, -0.0171206560069374, 0.07366636318551449, -0.035383437122242505], "51": [-0.06556981504585366, -0.002521978317061676, -0.015359180321373102, 0.0237854772663737, -0.044200215179156295, -0.07807395770923109, -0.008358869071171367, -0.028329986677847026, -0.06925316690293906, 0.03793781016183168, -0.08202605307659162, -0.06055352585904281, -0.022689202516043897, -0.04312110103556807, 0.04451429030285062, -0.02840051622936197, -0.020929129507185555, -0.023202646749324048, -0.028055403044500132, -0.010056819587853321, -1.7455682689847414e-05, -0.04482775868955585, -0.009815775914704346, -0.027950775437673787, -0.05073104988605609, -0.0037042480611382067, 0.007091800656365348, -0.0027870648430772713, -0.03398275022922284, -0.029288743238083222, -0.031866242082297, -4.949534315293858e-05, -0.052859309787354355, -0.0003344588167554612, -0.059508015513595997, 0.037361403326746805, 0.03868102369389829, 0.036890393194369084, -0.06537258847949624, -0.005753022455032165, 0.0010395332882618998, -0.019762410154357878, -0.0520676508369764, 0.024135308165725535, -0.04304857463438506, -0.03460944920766477, 0.01568063508143403, -0.07383641230111936, 0.01450354877562694, 0.03049510416631882, -0.03923506730517489, -0.020299906219561868, 0.0367631104475578, -0.029006307782842668, -0.06331710401256418, -0.07020290842677818, -0.0250760245656556, -0.01934304376231833, -0.042793480349819446, -0.03476075270772777, -0.036577351885658166, -0.012283688642654233, -0.06240807828156797, 0.03261572923067351, -0.0149612622728097, 0.04087916647733301, -0.043623735678684356, -0.039382644112106686, 0.04385029105032174, -0.0883909675024535, -0.08994561460418768, 0.019851592156403364, -0.06288342155715952, -0.00012166571118893302, -0.00042907156460747693, 0.0035090347078580997, -0.011471986752701713, -0.017592801685002178, -0.04751317452729352, -0.04182032121686825, -0.045380255569067725, 0.021815162837457762, -0.05842044900984568, -0.011935950300368536, 0.02734086322602254, 0.027159097814997302, 0.001759137245638258, -0.05340143537688707, 0.0668822895474574, -0.06538067461924033, 0.06145445987463631, 0.07333760158155946, -0.02039843977742547, 0.033080659719414776, -0.058972454725715384, 0.039397686361409244, -0.02406551311489238, -0.0669793849773961, -0.007460431591796645, -0.006678701056578422, -0.07678939344090396, -0.011325343056115407, 0.03331869452692775, -0.010952132414713194, -0.0056593607873730405, -0.03901319493577216, -0.06667532389460569, -0.0008317133405117087, -0.029546318140881028, -0.0007529721852039726, -0.005890242223660971, -0.0315578858507351, -0.03882417920467185, -0.05173181060219992, -0.03938845441855066, -0.021055374706988438, 0.04102152594324319, -0.03426022491615822, 0.01138302267830006, -0.04176568409374829, -0.02170203583611576, -0.03213863250875357, -0.010472485801522833, -0.021465507206191864, -0.05055543433766764, -0.058802104126144145, -0.05868044194780759, -0.005395597632975366, -0.09485440779814787, -0.03574098120642346, -0.03293808817164406, -0.001184026228720745, -0.029306306533736337, 0.030286160668231393, 0.033246756445219273, -0.030609471519992902, -0.02258366228373157, -0.03433568831659744, -0.025581168390617134, 0.002869490318255199, 0.04427073445043656, -0.06493588850495408, -0.004838630053924093, -0.05684842106447881, 0.030877278740195437, 0.013836243469807349, -0.07114501966793406, -0.031066677361815224, -0.04027822623456426, -0.050051771363569995, -0.04007702270673194, -0.01598054312488793, 0.02000142677984995, -0.0042799208601856376, 0.03376382264085247, 0.03614341487971128, 0.015756278991825544, -0.04533905117037247, -0.08238568504293708, -0.03256539465095597, -0.024477473965026062, 0.0029081259415192438, -0.018528245832835924, 0.005335552563340475, -0.00743313569786606, -0.045438317431249826, -0.03618593843618194, -0.00486249135064381, 0.046383750377557854, -0.043276843567635066, -0.016251104243754224, -0.03726776399789555, -0.02015407118772056, 0.03351336315917425, -0.028598891927279425, -0.0021514787384714863, 0.03517351258016408, -0.011729175029076368, -0.05761222123343467, -0.030221254376679083, -0.04962449341251025, -0.052607691220524055, -0.05198330839870545, 0.01632271411124439, -0.015013480154897648, -0.018516904338051525, 0.01515229422384418, 0.042994232055154104, -0.005286191173295517, 0.002807554417399803, -0.052554438067960875, -0.0332033871943588, -0.03201877098483656, 0.03034202099064249, -0.02861237108542143, -0.04307992753942672, -0.0015487057518344318, 0.03588475489189809, -0.039272432200280344, -0.0010992848600770504, -0.00545172776297691, -0.016282917831001366, -0.0343708007068815, 0.0009486992320758515, -0.03701266912438053, -0.007688678245677064, 0.02873320335453147, -0.026465871323207123, 0.008783668680002025, -0.024707781123613624, -0.030348429955073843, -0.006803108920924391, -0.006163770550408268, 0.030457164797524434, -0.004156246333195307, 0.00645320906560769, 0.024515380438737227, 0.0281372169726472, 0.009095663277384779, 0.04101731721451409, -0.022248734795176483, -0.040853056710263756, -0.06967032896360217, 0.0025701891970403446, -0.027393381500427187, 0.027515372690639642, 0.020781822292267094, -0.07443432130177365, -0.08332363635491935, -0.05777503088331035, -0.056332987517908634, -0.057961132796142505, 0.0004936282081681764, -0.01603354451827955, -0.006421165266120849, 0.002329065398277498, -0.032712011718715225, 0.001120253096822738, 0.02216292973284915, -0.006228618769090299, 0.0026397064356114084, 0.02046700654701318, -0.08272762975764739, -0.06295942433557848, -0.050146113143592304, -0.011803289129029707, -0.03601318597445514, -0.013742844275478474, 0.009296465089662321, -0.013792338716509518, -0.05436330316442287, -0.03787528366176182, -0.02864833817485304, -0.05716074327724067, -0.032013669745911334, 0.014339763582480847, 0.0007424632165248849, -0.03126131945119049, -0.020677100908374053, -0.028586236818032375, -0.08324512767070696, 0.008456234697639575, -0.07742114250774797, -0.03070531274769859, 0.004932367613423935, -0.006708825134436109, -0.051949702124894956, -0.058573411172423026, -0.05553644482746347, -0.008435949846931835, -0.007500765019704725, 0.020613786941134866, -0.026486187360387665, 0.023333399980225846, -0.05597403392005769, -0.04891951030286459, 0.003981030227783267, 0.019135737839979957, 0.024924250676202988, -0.04030855839387761, -0.008691844131235521, -0.019155685925678227, -0.008133193862314455, 0.03793591378229616, 0.018580784150761104, 0.030384926978978145, 0.014057542847262875, -0.0008080855935954455, 0.001963418160729152, 0.016645936899856623, -0.02118627003494235, -0.016137679446914605, 0.047071790526739765, 0.0522064031420234, -0.009243955850489418, -0.025774247227162195, 0.02229430704530592, -0.02371472961728752, -0.024674108120897747, -0.02720513791796746, -0.04647042534172673, -0.051844224958662546, -0.007050702249357593, -0.03668354351925137, -0.007302235220566936, -0.06081438726339103, -0.007875186907510092, -0.0752022496188123, 0.03148192154434568, -0.008552384118499743, -0.05037526871345586, 0.008473040559369701, -0.025524732001064296, 0.013192156190976329, 0.03730140117460049, -0.01881990256094444, 0.05304305503179229, -0.06579294048204308, -0.026973792625887227, -0.04651289374675708, -0.054572242721472985, 0.041573113479573924, -0.023486849803044874, -0.04308494519790177, -0.02705721766404107, -0.04570612262984814, -0.054990980190262405, -0.02247375080572435, -0.03715251198661119, 0.04061529660660827, 0.026566901731482934, -0.06630541135910295, -0.057828080825496266, -0.026514732856827036, -0.025595305460132618, -0.024833721343400377, -0.021685584192382798, -0.06802493201528775, -0.013629970439599619, -0.05533715054062171, -0.049323117010400104, -0.011410592615270932, 0.008498654815686933, -0.027648093575858533, -0.04082565959372272, -0.0014203442016020524, -0.058813588111044195, -0.0600209031722805, 0.004744808964516368, -0.040929737613077166, -0.04190604870095005, -0.01740757334064437, 0.04639954437740847, -0.02389005230225969, -0.03714103162122346, -0.044710149492986656, -0.053599413502357196, 0.0069702780425144805, 0.02177182477307904, -0.06116656890510359, 0.002859968097482222, 0.07041009790200324], "22": [-0.02370375471575781, -0.021993321939227914, -0.005349090988261057, -0.0157306429060567, 0.013394210062953339, -0.05055004623225262, -0.024191279267182633, 0.03927570773741647, 0.02835306759700855, -0.03914354113984148, -0.00634896372540668, -0.06605090959000823, 0.049307193173738696, -0.03943732688560457, -0.023335010234651454, -0.05981809372684213, -0.014386250266645534, -0.008786078262215983, 0.03397980351757666, -0.012182379586822292, -0.008513556074205895, 0.0025568377448561214, 0.015380532891361636, 0.0025489430345615317, 0.014396274989581884, -0.015888173710438158, 0.002783878526152372, -0.020826774880094403, -0.0426322061025089, 0.008104782484267214, -0.0005811764539901857, -0.06575890462298808, -0.024519022586040332, -0.09246442467319911, -0.019694219909939307, -0.02939844126456628, -0.0067366601268669234, -0.009157240356875254, -0.02000797683548906, -0.02431280370830061, 0.036623596417924606, -0.025399149389927204, -0.06330691534152043, -0.05661376665062008, -0.018474772985308235, -0.0061563306604067594, -0.017695567835891764, -0.004627456467265577, -0.06515221639350123, 0.0109702941420269, 0.015880184475309696, 0.0023268888521167062, 0.016758139517405925, -0.0738028344677386, 0.05004849858122747, -0.07009409245005979, -0.05044819366690415, -0.023517527425977514, -0.020714613362328792, 0.03434741605320418, -0.0554401561802253, 0.04059035257910549, -0.01289694814667403, -0.017662459124632032, 0.04331247195655522, 0.03760886076552955, 0.023939111357220443, -0.02379773281704194, -0.0007472003484824404, 0.021963389357142257, 0.03337754511953518, -0.06351519008146644, 0.01078090020164308, -0.01613748553111758, 0.0018208517859390266, 0.035055196388177154, -0.0025049169447698832, -0.015381002365576482, 0.02916730120344262, -0.01738602096326012, -0.04595500314565453, 0.03612927279663653, 0.008435170466475314, -0.02323294394284448, -0.031768326152930106, -0.03258175910910871, -0.033836900195370466, 0.0001580468072192694, -0.02941521597136335, -0.03240109203542111, -0.04325288370215083, 0.048486258753617555, -0.06071752657921972, -0.0017560119002429189, 0.012319829475823064, -0.06254682556095907, -0.005093709762638302, -0.006054161630645358, -0.007979990237975966, 0.021437267494209343, 0.025306971889137515, -0.014877100310800438, -0.004484161258204509, 0.00571957918920889, -0.0416790566465761, -0.03186924566222335, -0.03196620869456914, -0.04251932047476025, 0.029197793953596278, -0.03685806758465653, -0.03659252457096507, 0.025014918496734616, -0.03975626014712455, -0.05881980489219217, 0.03848700563994699, -0.05535623694032335, -0.014826817332365252, 0.04157770833478207, -0.027374957010985086, -0.017216238446192134, -1.2446335944527209e-05, -0.05051592597693043, -0.02014334589552391, -0.01666654707256309, 0.06313918768633603, -0.06654419458579416, -0.049573671713967586, -0.053184518226129185, 0.05082059803012725, 0.034970152554400176, -0.032600130023810715, -0.004447048317715061, -0.01081742831915972, -0.06907942368059088, -0.05114279516828531, -0.050023306723246605, 0.008618079675176648, -0.03881867806681639, -0.024387373115961668, -0.010955008768190966, 0.0329754660801805, -0.056406251356614, 0.005357689849145661, -0.0528746486472938, 0.019020162073417165, -0.05292863590789155, -0.038704804760266914, -0.03715800990487457, 0.017821939554880067, -0.06396118986843838, 0.06182582347317635, -0.02582389710239417, -0.02581940994980283, -0.08129604737957852, -0.02328787152946567, -0.07515263834306918, -0.022753769941089387, -0.023515587729099705, -0.02643064565573473, -0.04457418670648005, -0.06545198227471849, -0.021028996270606514, -0.018197117552021712, -0.009490321312837635, -0.04023071975484798, -0.02002652501284979, -0.038645070333407534, -0.019052038559245168, -0.01915403834279242, -0.037847159531712644, -0.004597147883488599, 0.041235124337795526, 0.023262525859262775, -0.021910796504284485, -0.01671801096716519, 0.04995671304646588, -0.037888688520421536, -0.028568898089374326, -0.008314184149668159, -0.044988018005690855, 0.021237903292486433, -0.06442590860111247, -0.04647610553285242, 0.0030088623976041303, 0.010955832009308854, 0.008348884335798102, -0.04177853253043131, -0.028327320717358804, 0.005906148728952976, -0.027189264396776644, 0.041564020817597074, -0.02503642151088315, 0.010300310716954275, -0.009960835363320673, 0.0036568242469520117, -0.03353297381008629, -0.04674434525369674, 0.004193708275643847, -0.06672248488558713, -0.08401992972662797, -0.002438529985601027, -0.006387226920064189, 0.023658864996499735, -0.054963771303976595, -0.026005696430606667, -0.03854069386267909, -0.028003901523857865, -0.035154417280786304, -0.04627395675810317, -0.010271551498421062, -0.024290791823320588, -0.00930361314180359, -0.006909156051428494, 0.010494101346276949, -0.015756702214374207, -0.04582448848523478, 0.008010903344595035, -0.034732291669866196, -0.05087770199034332, -0.03437388718195064, 0.03442222901574513, 0.027437881534995077, -0.019857355502170375, -0.022579207143337422, 0.02074618729148809, -0.017621914410546394, -0.025963673949699364, 0.058373501117138564, -0.05095728541804035, -0.018533961349426375, -0.05523514973787113, 0.004278967239760016, 0.004218766450800672, -0.07342087775379462, -0.03193686596178294, -0.024515696900496584, 0.0003405530723567003, -0.058603669837313986, 0.00868980058555171, -0.0055354058875954435, 0.0017668182545458279, -0.057697997597697365, -0.009275342254196175, -0.059678093894212886, 0.007726246248257228, -0.03156497831258678, -0.04199907246345288, -0.028110609164286343, -0.05011447926956685, -0.007779812785681168, -0.011728351542107591, -0.025265972783280858, -0.04977178497021347, -0.015378736153926013, -0.026565721102906562, -0.03082278093088807, -0.01914716133983555, -0.06448120470872244, 0.012947440159541369, -0.016905408308410006, 0.022957001462407804, -0.016373892493277507, 0.024958454591866474, -0.009313609969324088, -0.06610529873417606, -0.019112027710078684, -0.00527890843536469, -0.0022433245617760433, -0.06484856941943254, -0.006495647565818853, -0.06527059830405152, -0.013900351006360447, -0.07427899419891201, -0.044715299600569025, -0.07439162533271304, 0.02428858909663857, 0.0012779757334069107, 0.008622681339865245, -0.004026770950696085, 0.0205768063769285, -0.06604730435995146, -0.034171013911041034, -0.015711772216812848, 0.03731491697123774, 0.02514747694763712, 0.01139251035403276, -0.06467844207980915, 8.715290384161661e-06, -0.0490066751067535, -0.04165819264201468, 0.03129450712085453, -0.01383234384361988, -0.06819645549598372, -0.01860800867819072, -0.05750283349092645, -0.03511740973522743, 0.02742443067756214, -0.05291536862571416, 0.008087309025023037, 0.004839999135821541, -0.007243877837620434, 0.010276186166692045, -0.025924857723188435, 0.01817746117445825, -0.052617229857705165, 0.0025015408743435746, -0.033394896612687575, -0.01814614207000313, -0.04372339402973557, 0.02333471660488316, 0.009950002595388039, -0.029853262039116278, -0.00428584926392134, 0.0022637036714900005, -0.0012149825038781236, -0.03903434406780006, 0.03181606271442548, -0.012962082586350602, -0.012696692529994011, -0.04085111466919109, -0.049012210775052155, -0.018376064173145815, -0.059224962846708994, -0.031087640175174906, -0.01622460394559558, -0.049244591786406826, -0.02394614369379666, -0.04292374656165287, -0.043290203085713394, -0.06820405832050515, 0.006418645295961696, -0.020325609873234462, -0.05362075858391321, -0.028200003167197896, -0.04076144842141993, -0.027149349561397352, 0.023481704479906593, -0.02090767493261995, -0.014998402950495227, -0.030841571423042276, -0.01903629797303246, -0.0038572369797321175, -0.022606441631002026, -0.009322437895980917, -0.0101300598991782, 0.004595487917184333, 0.03125817482973341, 0.0038607288962126977, -0.020056410836155, -0.042682453255386596, 0.048020899783819154, -0.05387865940854633, -0.012290147657236997, -0.046749232988559784, -0.03572837179265351, -0.05055648139533882, -0.014118722847257003, -0.025287607913315337, -0.012064159201074917, -0.024633967615872245, -0.010620401092575971, 0.04913569374396514], "30": [-0.009647915630571628, -0.009686445867544337, -0.023722955745240103, -0.0030246165935528075, 0.05510691041146741, -0.0023157046478110106, -0.04112443406794716, -0.07234009071642089, -0.007969122524677673, -0.03267855667924072, 0.017668609205388108, -0.012502825603514038, -0.0698915019532778, -0.07591511622153582, -0.01950233930373778, 0.014082622090037343, -0.03816643612517954, -0.01852486641854595, -0.016323174112003614, -0.007120023953702815, 0.03118358510992211, -0.03799645327258625, -0.05803659695018975, -0.020563310658279904, -0.06842534567151184, 0.006942657585317678, -0.026510266418419342, 0.0019939585882309103, 0.053993316662487495, -0.054655490147536664, -0.08522935808679313, 0.004862513378836843, -0.027392105467139577, 0.029385609958054875, -0.06865915921651253, 0.03862898439525201, 0.006949160866077762, 0.04539061294702793, -0.027770042440754983, -0.029894805506868675, -0.040627963999995576, 0.03211968341148348, 0.038960332639293986, -0.0014568576178560942, -0.0013383804299407838, 0.01838644715587785, -0.04504974580109163, 0.04294305789262005, 0.029222865539651578, -0.05796387510976713, -0.05140105777166482, -0.0040792829898217975, 0.003729436911027173, 0.04291274881536403, -0.013843637474538525, -0.011214480381402707, 0.045325804884095475, -0.06214276073281405, -0.018745314188907465, -0.013757000233572729, 0.011564559946598565, -0.026428296916050243, -0.0773192128626696, 0.04166139246095274, 0.02980347957591969, 0.07362914185959239, -0.004054195177328684, 0.0396284096583114, 0.003492697341882303, -0.043712472891637856, -0.021682254341971588, -0.09167396648139703, -0.010088217386244302, 0.00852249773379167, 0.005843365891597407, 0.005478083223652562, 0.0020540766659684043, -0.014335042833016344, -0.01417743266703275, -0.05083267109961236, -0.048238941884302125, 0.03454471369831563, 0.009909740512900103, 0.0064846641155572714, -0.036890001462469506, 0.0395818673851403, -0.03324709326454776, -0.06606055825101562, -0.02053874686663891, -0.02619467593347394, 0.048608055819304635, -0.006631854327906887, -0.041454474336673965, -0.06719210392295945, -0.010663029840604042, 0.017035747724855884, 0.013990477577296167, -0.007388841797699588, -0.019173726808817747, 0.005820504501510316, -0.0034476469495984393, -0.029314864942998262, -0.00946106361465999, -0.06737508367645365, -0.072657123957618, -0.003266974051057772, 0.004201258278617576, -0.013013853369613776, -0.04675205314434618, 0.03629941376508784, 0.04718979073054568, -0.028453968048556485, -0.00943044247931947, -0.032919590669225014, -0.014533074615306877, 0.009529791845911205, -0.025996877090422348, -0.03082686742424469, 0.037247868268409506, -0.0830592560332486, 0.022767186704662996, -0.03136705329733293, -0.019773562489997235, -0.01328718887953002, 0.007853837546419296, -0.039838282420467844, 0.023616589174285652, 0.0034401783707222926, -0.008189910423380504, 0.019918961389728904, 0.046887594659484624, -0.004784483081252457, -0.024965745360949056, -0.004123331697095114, -0.09002747166747695, -0.08824379570645219, 0.0029046669546741208, -0.034458731086857305, 0.010096254080493982, 0.007901059190502248, 0.038076731479691754, 0.01371937499344924, 0.028939695140637663, -0.06729956388633293, 0.03380672310001617, -0.08048724367871793, 0.025699811371305725, 0.024908817047726035, -0.052768668076252336, -0.039787258185472185, -0.018791906713843613, -0.008271581561131211, -0.012904850270299688, -0.048597186391580505, -0.024363864812870537, -0.028902511524716838, -0.0331267768096309, -0.015175885502042592, 0.011487578995786781, -0.05877780730151719, -0.023718366169478262, -0.04492697821011168, -0.01569015086498891, 0.026550710606768446, 0.00042285331347964426, -0.058671765457952225, 0.012229360441373776, -0.032022694438745745, -0.02448495467797329, -0.016438450366893693, -0.01702750327964412, -0.020825556596083223, -0.00958442004209476, 0.03250214753406793, -0.016113152359989946, 0.051653499176208886, -0.011559417618816304, 0.030984897020746607, -0.058689476751190156, 0.010183760315154097, -0.023155279364316262, 0.038952713614723244, -0.0648787742399372, -0.022785730179584927, 0.0053214702834028195, 0.010138289410792775, 0.00391924385603629, -0.0765371372451115, 0.021453424171681407, -0.03883423774527352, -0.033731974246320934, 0.01065746390593202, -0.009968047932478661, 0.0033518911758415857, -0.013716914282426865, 0.020406408988251693, 0.038600331946133576, 0.005636664273631971, 0.014982753798706783, 0.0012402932982990215, -0.08834609130723865, -0.02954399513830617, 0.029926653509462057, -0.016889632952788974, 0.00644119387189991, -0.018109242920204167, -0.029767983619023955, 0.008604173045399632, 0.0005278898927249596, -0.02866611339603799, -0.006594130951984456, -0.005942880845521991, 0.0338991337625732, -0.008689836880089083, 0.002730182367853414, -0.05578501080661022, -0.05599886845529376, 0.011607323972107038, -0.056514384359020196, 0.008141596265834458, -0.020842324712713457, -0.008360432327857293, -0.020802533774472606, -0.0027965278025828444, 0.016941628177781644, -0.05053336932018754, -0.02880648589984171, -0.06264092393636163, -0.057444703670410886, 0.009248064439274685, 0.005824581183073962, -0.03868799651105631, -0.008731642727469461, -0.05967896006216277, 0.006464703625573489, 0.0064832274652932825, -0.0037348342113739416, 0.008578337677392387, 0.0025147808975182462, -0.0007734972850895946, -0.005671695037657521, -0.07998273966348639, -0.08098417356063826, 0.02327316132680513, -0.017578329251062945, 0.0033076691274094732, 0.0036141271595833383, -0.02481531940155389, 0.031422687544427, -0.01721285248918439, 0.01581780425412522, -0.034098825762427086, -0.005636908986015854, -0.012248857752281135, 0.005379469253493847, -0.008442969602131539, -0.03563762712545831, -0.004521132942842011, -0.00497070475027249, -0.03860213634754516, -0.014711930975737954, -0.01282379985162874, -0.06725994731305499, -0.0157118971718019, -0.019368581122524445, -0.08780400936099941, 0.011070270291605325, -0.028619427226442885, -0.04998117495106516, -0.010394184097092083, -0.02953095659293605, 0.013577651533811498, 0.030584850808461166, 0.020121343477515395, -0.09009009086043446, 0.06840134080042297, -0.08222789225591298, -0.0351737791678119, 0.05687980151896518, -0.07575689874554707, -0.050020711313978686, -0.030371670796026328, 0.003198362193580739, -0.0007039542924187027, 0.005039575268971832, -0.06264853201626726, -0.01964706787787812, -0.018287001381496682, 0.027647686733174776, -0.01511113610564343, -0.030721747443310507, -0.06115042642394449, -0.04774997644516984, 0.008843115461333699, 0.011374208060575385, -0.05361791840145691, -0.04030179433550121, -0.046613569529823026, -0.01134853488651751, 0.014535546339537719, -0.06278002238642062, -0.03954881874101149, -0.012619489837961066, -0.007323009357025334, -0.06344203754386232, 0.018055386651889802, 0.027172102227994887, 0.029673401518580077, -0.03682665491305637, -0.0011831660512620534, -0.06561745203903936, 0.0011797403586730518, 0.0013333747909998078, -0.01595347821142574, -0.07361789013418735, -0.02705141802613083, 0.007990856732241236, -0.0027633563507307533, -0.033782014740385204, 0.023757095396348012, 0.048447107948616085, 0.025759019884327997, 0.0004830253326775806, -0.026355046295343302, 0.024529007177899242, 0.019056007067276094, -0.029160257951662046, 0.009361105951657095, -0.06236332911182398, -0.02990879495105545, -0.025329854928444973, -0.03405611080972037, 0.031163991437641262, -0.05582918680100341, -0.033936951881419826, -0.015782156973383143, -0.05450895438673114, -0.05936148365587792, -0.04290933733569806, -0.012904721894778943, -0.0033656899298338244, -0.017352771167539763, 0.0019636193352325715, 0.015878266400052618, -0.045052934317683736, -0.04871790880154651, -0.03407722583789635, -0.06605689605832692, -0.08547209464787907, -0.06394199467289086, -0.09052199236117313, -0.02096791775847944, 0.031184140305633656, -0.014756412187602281, 0.05749206761600432, -0.08320815470898588, -0.08154753015529073, 0.03071748085318827, -0.02953137960928662, -0.016068863946673076, 0.03982357971392102, -0.00624454677356048], "23": [-0.06141936098171334, -0.005070895720776312, 0.05015074728303325, -0.034068701157836716, -0.0126699678699287, 0.03259958191217382, -0.009923101779306, -0.007942607693660503, 0.02915946249810645, -0.0687244466042056, -0.03075840100938548, -0.030595201982157254, -0.021479549538907593, -0.014454998882657555, -0.017725187429664162, -0.04083680869954519, -0.040773508530666414, -0.01311204703850852, -0.02104708853710851, -0.007780183966302231, -0.03191552568801242, -0.023387537850617136, -0.02017067516398829, -0.06823371056018543, -0.08069143005064265, -0.07866716631054246, -0.0689769170447451, 0.055568428952037084, -0.0420277454215797, -0.05887566614350626, -0.04757463147249521, 0.008200649328488708, 0.015166950789283836, -0.07918937875297138, 0.0029906369012753643, -0.07631374365095897, 0.002722609270116115, 0.053363521277050414, 0.00044538580764862996, 0.003425887313075567, -0.010250554890881754, -0.0411591333411327, -0.014946640799049542, -0.0007105249092751431, -0.02111202210241005, 0.032336110295658915, -0.01276394734833811, 0.006589721956830124, 0.028155239903822155, 0.018158709920412734, -0.09315299016679726, -0.06364231820827017, 0.026865091115663434, -0.031230862058468926, 0.0023720752739334883, -0.05893874717614284, -0.04251542380720972, -0.02870436221227595, 0.05287358267286804, 0.04558543994442796, 0.06310860730193772, -0.006811199161760566, 0.057630478526514144, -0.055014886925813, 0.05562256895587683, 0.026839635039521272, 0.029138571633415954, 0.06660957910745695, 0.05530227383078061, -0.033247719151156686, -0.04532465832559116, 0.004964289723189659, -0.0696574788634338, -0.001572352683989198, -0.010626815456804653, -0.026657321599583055, 0.004468770083820851, -0.07517055893118361, -0.02307402533669661, -0.03452365669287785, -0.048417151162429645, -0.045794243584476965, -0.04963900261048779, -0.001190821202055553, 0.03213767708002609, -0.02869634610490955, -0.015082443029179573, -0.03584840444842451, -0.03819622886970898, 0.013511021060737994, -0.025096752749849047, -0.08422389070805542, -0.06735918445829109, -0.05240553908522235, -0.03365974519193654, -0.017822746188458003, -0.05903116937669986, -0.023258639423451404, -0.04810061505255672, -0.05805540529602919, -0.06185955082208808, -0.013422215941267152, -0.026921247143216392, -0.004351020092163144, -0.02304599773203395, -0.017261912644897445, -0.05314331940100034, -0.03141873727118109, -0.03151050383033602, 0.05328475824727051, -0.04207469976925149, -0.06031688556551824, -0.028856074948351195, -0.02635079620399306, -0.016845909647568203, 0.013995954853397451, -0.051819779018591736, 0.0564947097157941, -0.030476700163899872, 0.044734346190757314, -0.08112832266557098, 0.03847163817758601, -0.026714021898643327, -0.001613864118912512, 0.07683490165407829, -0.05659442966984997, 0.0015156893845192625, -0.04385893263007818, -0.06785605293190952, -0.02711667386542795, 0.03495900852424548, 0.019221139089770512, -0.03586746405249435, 0.0035524888694335064, 0.025804721509946612, -0.05706052530356931, 0.026255653241931073, -0.021597425493945187, 0.019984615748264763, 0.008537135271761455, 5.965694341054279e-05, -0.04077408337501171, 0.03250022271441337, -0.05592939396452036, -0.05676197224569057, -0.006938430955100558, 0.003912998066246717, -0.05006351875333907, -0.04974775963790021, -0.09016040211086912, -0.050525773294422704, -0.08268150055673786, -0.029095282319005628, -0.05519754095683006, -0.05747986258213391, -0.004872790420183498, -0.029900026651996328, 0.04730493223504964, 0.06473777884787883, 0.050355420025025494, -0.03125549184426554, -0.025789301140049712, -0.020178456417548108, -0.023605410489569694, 0.05655442455453478, -0.025602947378979325, 0.03077853675612671, -0.046018783194029064, -0.04395748269727197, 0.05077040618336469, 0.006556245413555448, 0.013908217955278322, -0.017895546589612413, -0.01865998689034292, 0.024484571001822213, -0.05490084354709361, 0.029257669988046655, -0.05275672493682143, -0.030517611127981657, -0.009048654908868466, -0.038037908929607796, -0.027972513491322255, 0.046784966719657185, -0.061254962290199486, 0.007645108880383055, 0.010051485632749622, 0.0036532910892602085, 0.039520597520186426, -0.07575028469914026, -0.053888122248497664, 0.007632423639160068, 0.009514739919116241, -0.04330803656203485, 0.006995220804365062, -0.048284705502106874, -0.04465190841634063, -0.0036490351481220816, -0.017209747534120363, -0.018082364355118792, 0.005081599224252242, 0.007023072411186667, 0.030041898428932793, -0.036498489639682934, -0.03497724935504017, -0.021708349983201095, 0.0526124656507102, -0.017281946679802415, -0.025543038435135355, -0.008458752979067992, -0.01632917847234471, -0.016608330348055488, -0.0035935021884840003, -0.009176633177462134, -0.04755494038546389, 0.00841997213436414, -0.006804839955287067, -0.03658717508559586, -0.02173991231388917, 0.037922362575511084, 0.06320217179370909, -0.020813556627841505, -0.031164284154394938, -0.01792854852580729, -0.043205497884759955, -0.025953916946984228, -0.019013281202785674, -0.032918536515057106, -0.038811586134171835, -0.05740546111143293, -0.006018217824139769, -0.05307069692605249, -0.02569156959914675, -0.05217422391116794, -0.00136276417952828, -0.06746925077734975, 0.007173956519818849, -0.06041586528840545, -0.05685592630988899, -0.036755911499961984, -0.030044926399524077, -0.050877895798962076, -6.156312525589399e-05, -0.04885115000505585, -0.0027400236593902714, -0.004317792634653646, 0.04160160125364827, 0.032954098268865986, -0.01515737781594078, -0.034945824057298916, -0.025924708680808352, -0.05509886297002123, 0.024458723451016847, -0.01951092457494167, -0.017370702205957, -0.03300256937709409, 0.03005061185744641, 0.024567030273336295, 0.013032805598953458, -0.0445361511582683, -0.011193443299821278, -0.01788869123216992, -0.03837568979617976, -0.03957875181129924, -0.062349483578286985, -0.05620453382771828, 0.04324640136476344, -0.04427217627052305, 0.032010987109198266, 0.02888885890222555, 0.02099245484993777, -0.10299414680574535, 0.0056689271712957985, 0.022917301819523086, 0.028959420283495393, -0.08818853164966707, 0.0171073314407472, 0.02373423118886929, -0.07593472635297051, -0.07363705571607007, 0.02008455018476939, -0.04973847393741445, -0.018161030178490443, 0.0357973665628652, -0.05928490970099611, -0.031495229809298524, -0.02791112857724232, -0.010606391306678205, 0.024202314697901014, -0.0008096037849508105, 0.003325857747598001, -0.020053151362176426, 0.009832812306484414, 0.0035856643085846155, -0.01946721931902798, -0.035219876724081424, -0.062235485053458606, -0.037951485936204, -0.0200211552537105, -0.01792131772510955, 0.03790162609391955, -0.03642005951457723, -0.07003566757782738, -0.041225201670357925, -0.07689961213466058, -0.05531511155127659, 0.008152168153270672, -0.016251602231152025, -0.0029761623332066854, -0.017255776791748792, -0.04154543534097586, -0.005835199754204259, 0.013533266075144218, -0.03060982254741148, 0.06093796641539674, -0.04642731350541412, -0.014251048139012764, -0.014166819883782029, 0.016618745504087595, 0.054738697921322285, -0.06124939047003348, -0.036441274418484944, -0.03765159918508214, -0.029237416634827228, -0.028825695236704415, -0.06114221030397487, -0.0247505089299116, 0.0429021931385136, 0.031771233341916, -0.024395600017270543, 0.023745266458799277, -0.019296701528792967, -0.023080203769694375, 0.047175839746920585, -0.022172363978618742, -0.003923099161826149, 0.007916571986832587, 0.0490267120679927, -0.0004939289893332204, -0.0027692810939827605, -0.01364894972028241, -0.026174356639510267, -0.05901424574149141, 0.009962063817387175, -0.0107324551013895, -0.0019315321748189743, 0.05590323028034606, -0.003438768183456394, -0.06524092291086794, -0.0014178132575294923, -0.0374131939105386, -0.037832200925379623, 0.03024663157767879, 0.061618712174008584, -0.02709358461251308, -0.031260469427568244, -0.04300688986736943, -0.07991274025695576, -0.026921538268776406, -0.05136341308405799, 0.06096217352192056, -0.01637244000995831, -0.01823083439873144], "44": [-0.04441971289475804, -0.01939269321637479, -0.008965108682926734, 0.044382257260406156, -0.06812414795188407, -0.0022047427981655597, -0.009106599350415426, 0.03861935721984075, -0.02924706133551477, -0.031075547631741994, -0.05977703045119102, 0.04705635164848536, -0.03995293967215208, 0.02929034688161207, 0.033921587377300985, 0.031431521687987275, -0.060697841644096986, 0.03913121618446202, 0.030248383326707956, -0.017435033551810676, -0.007884196588015908, 0.014089172956300144, -0.009246359533465285, -0.0015878788617734844, 0.03312847189569587, -0.05310070984382112, -0.019704726234807634, -0.002044709345446239, -0.08247641822312576, -0.010986839887691854, -0.012779034598889386, -0.023258195404357734, -0.05024183883202116, -0.046104767513127524, 0.02931582651434549, -0.0657414264714739, -0.07977620661051915, -0.0003626598900079855, 0.0370551780274909, -0.03196752814732685, 0.0443766391076279, -0.01928436594364445, -0.07232158050855021, -0.04928618608458731, -0.013548449358283554, -0.021989549074112325, 0.03873991242082576, -0.01554815386272343, 0.0033504230732168618, -0.06959080441742545, -0.033083426643716385, -0.01054132844906288, 0.00029940901893529685, -0.02376234843930747, 0.04457042326755784, 0.04359562109578829, -0.08088470602501847, -0.021676284326508595, -0.018699394199881664, -0.07998530483947185, 0.0006832292543655311, 0.04997412400605266, -0.01566540510818297, -0.030750430517445113, -0.0863046846791785, -0.032959398092129555, -0.04851116363283015, -0.07659096553884957, -0.017715909105407535, -0.009450216018067246, -0.08357997204177729, -0.006251923015483741, 0.04083983917779007, -0.06304460780218592, -0.007971845887628632, -0.05286589471156389, -0.013857036259354982, -0.04989477847022992, -0.0687588031478039, -0.010423681296810317, -0.06610167937914975, -0.0014637491555122562, -0.023285918481277628, 0.04266009974585747, -0.04747768696292633, -0.015065287398707598, -0.06868152556848413, -0.058877134279019354, -0.041797232184425055, -0.08432959879747742, -0.02849970426341979, 0.01202897196898133, -0.05199728745545517, -0.054632267490176564, -0.011113027193691902, -0.07227671520563175, 0.02963588801804488, -0.014935718022909113, -0.05059450837212756, 0.00026588848540921465, -0.041898173863217286, -0.0157131196960607, -0.005349244651558813, -0.011242967534529243, -0.007132844084677949, -0.0591885841531465, 0.03601871903596496, -0.006368785603919276, -0.027963722922415665, -0.03307270157997711, -0.034480002707452787, 0.023279975607919928, -0.027191589792212097, 0.015987387199355906, 0.031001636657055232, -0.025300479414075226, -0.01938874108132899, -0.014806054587300587, -0.02048218207915693, 0.032848754369049944, -0.05222376236477282, 0.034904708359424726, -0.024409854786526786, -0.03075681160741125, 0.07157292603403467, -0.07973589946166101, -0.032850518686270966, -0.032729565414967944, -0.02771814376877222, -0.02736452879810124, -0.00014414093190484687, -0.04143852208009582, -0.06418248273647342, -0.06516709211659484, -0.0697167002457494, -0.0694208888718384, -0.03598200396394091, -0.0541323313623112, -0.017791070939658083, -0.0023286363457447725, -0.020372398588264732, -0.016461852094208373, -0.06296367773919097, -0.060212730921276894, -0.03523117758042271, -0.03394509883815444, -0.03313825314254146, -0.03353784882023951, -0.003673660854752505, -0.00906828454947654, -0.012950080303257776, -0.013255304616614647, -0.0500040739246187, -0.011250995776747414, -0.024221920663424577, -0.04132027790792918, 0.03763532722050682, -0.030517169222508016, -0.0017082279621412975, -0.02074656022572711, -0.02654451785931959, 0.0318831172893079, -0.023439751289857164, -0.005171552214038878, -0.013556506850651838, -0.032029305823967257, -0.062355495562214855, -0.02573978506049352, -0.025330268081430428, -0.054484448124809674, -0.04663208140014502, -0.035997882185072806, -0.012753354381411801, -0.06489748262388192, -0.012744845609145034, -0.04130594703125558, 0.01125365139914931, -0.04710435660252456, -0.023389390597207734, -0.03603770813369103, -0.029676438695706485, -0.03180602282362026, -0.02391076262290969, 0.007204299840734692, -0.04932961999825999, -0.010758521797195579, 0.02394745087191959, 0.02529267197439894, 0.006276173992701624, 0.035741138809926444, -0.011527065841932046, -0.058985535737540416, -0.011446077466901556, -0.028825218398020668, -0.05195724788586537, 0.004261268465535137, 0.03881258609742874, 0.020531610288334223, 0.01037560140287, 0.0072806695209135085, 0.001340940861860822, 0.005031759127862729, 0.03284545211494603, -0.019095105236572363, -0.019292573599041917, -0.03197801144921826, -0.01694954095279996, -0.007924659769394188, -0.01362767124522556, -0.03651811273995915, 0.01997352830683089, -0.009141127368094182, -0.014344041595637519, -0.05594524810805604, 0.03874142930901996, -0.025547800058417194, -0.07648716111089601, -0.04411352243462076, -0.06139240850263277, -0.025410800580706425, -0.032891949790496984, -0.020464495597809843, -0.0386036328184782, -0.013478540147659326, -0.051113551726469475, -0.013533054195068792, -0.05905844258223308, 0.04957035295424641, -0.03783169079789958, 0.008520872155478105, -0.009239312566440507, -0.047681048811901806, -0.022936089760484123, -0.02608224877288601, -0.007877564069462923, 0.0517730249351794, -0.0376205175997162, 0.0034972083806411617, 0.043533373020514354, -0.04857726750728306, -0.07002399637537507, -0.04113349914484578, -0.0263896081905026, -0.02397684911983901, -0.000399413945272609, -0.01682942475962435, -0.026907321655862536, -0.008026707294078181, -0.025120071023013675, -0.002052774461675487, -0.055322137019579304, -0.020998338145354723, 0.03420829529106436, -0.01744973058918277, -0.018607856633315736, -0.01932138708371839, -0.08205414118750518, -0.014679072290142592, 0.016978145047402166, 0.012545995304765365, -0.040867227903589584, 0.02315091122295525, 0.007169766656264676, -0.038091129247101264, -0.017196065859127464, -0.02078153249717684, -0.022282169345272614, -0.009075486587941807, -0.02275222782112829, 0.009570984678383878, 0.00633035042083864, 0.019639061501676533, -0.04608666017727395, -0.011934547427402057, 0.0025947203559846, -0.048048493057508315, 0.01847775253476003, -0.015150340755566007, 0.01477831244300627, -0.048580760947759795, -0.04307085012670747, 0.02636536634498467, 0.004647321735531195, -0.04869133337281693, -0.015121834862339907, 0.040737326290333414, -0.0006005788491255775, -0.015426318935474024, -0.03788296873417277, -0.021365158432277008, -0.036084803361413016, -0.05983762818689596, -0.060898556668460654, 0.03016448225738058, -0.02059799170447293, -0.044247804601831114, 0.028568319581764458, -0.02353512232513004, -0.0487084212772582, -0.031028755023599346, -0.029357686268848073, -0.04808620057001755, -0.01920173877397614, -0.012663645228512621, -0.016395510324206563, -0.01195226778677865, -0.049992065024692965, -0.05152098731735805, 0.025029596374829134, -0.05278971691444864, -0.04057186609476813, -0.00861125557062205, -0.04788035111095302, -0.009640461651961292, -0.04375742684561407, -0.0024454635084973104, -0.021448423522436484, -0.03523147719220141, -0.0006643840471140822, -0.022207648951196545, -0.05463884475141551, -0.02579216079100869, -0.0519083045788412, -0.02314822554402392, -0.04571256586391431, 0.012382273009183733, 0.019343316112549733, 0.01643513978406816, -0.04132148506272932, -0.02043581810132495, -0.02856803595545181, -0.042390619407566485, 0.004438576677890592, 0.03763467694842965, -0.017367296666165197, -0.01733160971497172, -0.037971790460315964, -0.06792045699222024, 0.021753012329133025, -0.03817025412218583, 0.02843582148043722, 0.027002056409112435, -0.021237928094946134, -0.03634596923953239, -0.05227631312722616, -0.04002479993613695, 0.025046263226831882, -0.0580096251420815, -0.04450367203305432, 0.027958271992992546, -0.023098150362964646, -0.06654479528115025, -0.040155740243721864, -0.059403176482193294, -0.06190347874673082, -0.054007239211405746, -0.08785413346809498, -0.04404950360234976, 0.04912799738230103, -0.06928158450634352, -0.03659276226846885, 0.060765977174327385], "26": [0.032984823398787194, -0.018568055763304548, -0.014344401311615577, 0.03707200224763532, 0.010694189442604371, -0.03207144305912995, -0.032190434451870004, -0.03708695060364356, -0.024252031795384776, 0.039821541448656274, 0.01540572866609, -0.010402454588270212, -0.0856165136248122, -0.05594226005296205, -0.06520229160990622, -0.05221816449984545, -0.06918782639924581, -0.03919619321059744, 0.03310079965276093, 0.010739377268156342, 0.022238522719637055, -0.02638206146343969, 0.014353517362037778, 0.00531251717278121, -0.02135010437755411, -0.02048278129716488, -0.02560061019854961, 0.03718327002773814, 0.0006094746902402904, -0.003164844283671855, 0.031322977818918143, -0.012755953698812102, -0.0009815021412617213, 0.00044091989183437275, 0.0434541110510705, -0.03419225942565735, -0.016397617742969092, -0.003358501628634939, -0.024374621058759125, -0.004541937868143268, -0.017824416954235763, 0.04273595257365489, -0.011257141944021515, -0.007258387384971268, -0.01459343540487666, -0.036434643524204585, -0.02628061269842212, 0.042886032427845014, 0.01761885897750108, -0.013555694190761254, 0.0031077378520337536, -0.010496554107255762, -0.004699548742159091, -0.012979589321944485, -0.06752224631455081, -0.0026536193362174123, 0.03815426426721488, -0.023311795277907818, -0.055543723131478685, -0.031165801088905765, -0.056176858682288534, -0.016580558876448402, -0.05639826911480549, -0.03176317463842018, -0.03894206547293282, -0.016914082916462955, 0.05525821566159177, -0.013318956301298071, 0.02319535582365575, 0.032733144362887184, 0.03288380203900624, -0.005760581287808788, -0.013911139775784861, -0.021218730607700055, 0.0011796056140820606, 0.0036772420578745834, 0.0020679640020240717, -0.025210117872225192, -0.03275497537229118, -0.02969152811657991, -0.033013121255581604, -0.029241046908066875, -0.005680276862101213, -0.015289796638554285, 0.01308862074402922, -0.03697501430271812, 0.0023184425367453977, -0.00566323216064102, -0.037018217719888294, -0.06573163962229403, -0.03362827801835296, -0.017672433480691953, 0.001613897744679446, -0.015620022342234061, -0.023011301054706113, -0.04467840795221612, -0.016585443021112558, 0.021403698598289153, -0.015957152818393164, 0.01850927779626643, -0.06962766565590353, -0.03286283548264547, -0.01702527906642544, -0.03084678204847517, -0.032503020960229084, -0.06023881443621768, 0.008293180426937243, 0.0004156388587423876, -0.04207047182591597, -0.034743877712928126, -0.06480219003550791, 0.0058820815001824405, 0.0005791439503111805, 0.04206770147010556, 0.051356328235113345, -0.010369744811575788, -0.04862189416784316, -0.013632404064358524, -0.028406761647589082, 0.03345334834355223, -0.05454600713916514, -0.056880509364575824, -0.03501925618043603, -0.043493893609204685, -0.052789991748566946, 0.01728280678205636, 0.020153572075462506, -0.030579095538869186, -0.040183025225785006, -0.03834330247946559, -0.05922302411395954, -0.0034987470767445647, -0.03316752509500712, -0.010957137064622098, -0.046155953958120916, -0.049420325571607374, 0.0065868498813572976, -0.024617080490635167, -0.017735338112816516, 0.0028419699182919817, -0.0626655266097656, -0.051049648735489825, -0.0293355683983684, -0.050428763235550705, -0.04599442690560759, 0.025917953523234886, 0.02961151142213207, -0.03163215692850088, -0.05108455823449768, -0.05829653161842686, -0.03412457624113277, -0.015454870369113282, 0.041539143575339055, -4.10448535923152e-06, -0.023494587113345643, 0.029225513471122337, -0.07401314220239341, -0.03197071954385506, 0.04734271302651123, -0.013725668823333136, 0.05713907197565101, 0.014194174148820427, -0.010047920898564155, -0.01753628385382622, 0.03413223507611922, 0.031822219699536754, -0.04154986826030598, -0.057087959140258826, -0.03456890209118174, 0.000413821877404092, -0.02207498192870353, -0.029076950839403332, 0.0045966792587992505, -0.022847695688830445, -0.0405280965471358, -0.0494156380709352, -0.035836121126723894, -0.028840310243994836, -0.056072338611163335, -0.04858934932844208, -0.0027607838632866476, 0.0038974335390660796, 0.01119488052710221, -0.073636935918944, 0.03586852868613329, 0.0024018919113284187, 0.0022314168815571874, 0.0068037076435194695, -0.06070677592147771, -0.005346741645769814, -0.00867982242341742, -0.047578498584613285, 0.04364700136575613, -0.00808482605391391, 0.0019746555447950286, -0.03448791105919294, 0.04163389151421317, 0.0021320585297368326, 0.010673519048507482, 0.0014910741652329038, 0.005288797722710376, -0.06458294654666433, -0.02934207873002961, -0.02914661637738376, 0.02717479483745955, -0.04006869525963908, 0.010081271051216475, -0.00771270683402984, -0.024539553281927924, -0.023007844355517927, -0.019704691504991077, -0.022579726845184216, -0.04827355798999346, -0.02236404008268556, -0.03826522275610365, -0.05515285337631269, -0.013361887054263583, -0.032552277305228396, -0.023333721691052772, -0.03962902911975782, 0.03321630059402683, -0.03446610312552526, -0.009904659879790478, -0.002380253758593917, -0.0014092330815659128, -0.018457003730925202, -0.031148786026335685, -0.04955568240251935, -0.04030165549684012, -0.00028346269237257746, 0.009980777527989251, 0.011002535978041293, -0.016019187435435688, 0.007822682312253882, 0.025847529787608552, -0.0013395677231751713, -0.04780957368200085, -0.012858417793438352, -0.0018697366396620498, 0.01736689173069689, -0.0066930411031437395, -0.006296296474918351, -0.0007477202966356564, 0.03674119604566567, -0.06850258943580603, -0.03647970784754605, -0.03291578421864502, -0.04709078852586225, -0.05770123156686269, -0.013075140851845907, -0.036539133865364434, -0.05779061749528763, 0.02658572498778008, -0.025632280411797426, -0.01897239609876546, -0.027965941649009264, -0.015413315045620105, -0.0417424705983024, -0.03426782404764861, -0.04217086570785932, -0.0389646727467126, -0.027762967496507873, 0.024883412725887455, -0.04500598292646637, 0.028326411863895513, -0.013760223537985086, 0.023990752172837766, -0.07569035592923914, -0.05459321510515913, 0.010323901323464708, -0.0015397304464529811, -0.004065144922122307, -0.060072327705323315, -0.010753057607226923, -0.038315261444424244, 0.01912925998413504, -0.021537920748042103, 0.0205444849970849, -0.013603224178113705, 0.013894128390404737, -0.060563376044105284, -0.02901620792909689, -0.01444486379547704, 0.03062451824756745, -0.0653998372648825, -0.030883863211428986, -0.0004066616484502426, -0.06801919046840144, -0.06128784706128822, -0.021110521595270444, 0.025831461230365727, -0.021625733814205336, 0.052730392496065745, 0.0015720385252846485, -0.014313306460104888, -0.03880382109270588, -0.05647001533498548, -0.08066388173244504, -0.03166474829801941, -0.04472513116043291, 0.0435825214398889, -0.02113385336398265, 0.021970686440086182, -0.014666585933054383, -0.01339750445736606, -0.0069019150044532, -0.015164597203810318, -0.04407179242028296, 0.015832865509382184, -0.0055988810684550186, 0.019258627723831048, -0.05871455229484817, -0.0060055621461406975, 0.014541350344158672, -0.006668393785961012, -0.017525739860390674, -0.015233153729758003, -0.014281949749618241, -0.035513077583509293, 0.04141643068364657, -0.05104306616539837, -0.028116553651239294, -0.0693131704927047, 0.021802535111846207, 0.00607133326917914, -0.02629279963433235, -0.02801303371735862, -0.020510284398414135, -0.03919109481873034, -0.034747550045318376, -0.05675584930498797, -0.02827221332761689, -0.05951625809979885, -0.04229432621392246, -0.016782198283703906, -0.019109594640586796, -0.03359783246362972, -0.03855065418708277, 0.005325004878378815, -0.03907034498047864, 0.030414874639868972, -0.0188175104464207, -0.023499527587035704, -0.012008608844495089, -0.04626130274914226, -0.05940721152449038, -0.06774163194643316, -0.02270279891102782, 0.04725759023295237, -0.040148236144618175, -0.04041608513679728, -0.051160138826785245, 0.04854303611739961, 0.018862911246788523, -0.05852494547415851, -0.061711137517757926, -0.013144525242901967, -0.06070697923274313, -0.018786697736911013, -0.06273381230308431, -0.03159282596554476, -0.008620267688461872], "45": [0.03808928792750053, 0.0248657956950341, -0.0208887762816286, -0.01233804335808924, -0.06415175895273374, -0.0072658704777806, -0.009040619145482907, -0.023685820086116076, -0.010517425212618208, -0.0160112432806485, -0.03915063446164757, -0.05092193520443263, -0.033552660428816355, -0.03523611497904371, -0.06413784972887734, -0.08775563165475231, -0.07728055943870879, -0.02393170592338682, 0.00998938526587201, -0.0246714100839564, -0.014430272177911294, -0.013668867359039542, -0.0023451571644083373, 0.0039161426240721855, -0.026681710713793938, -0.023731309966565656, -0.01758089591302535, -0.005952479202566386, -0.09808422894572298, -0.024692195744542622, 0.038466182059585345, 0.01452705406311521, -0.013062420441821966, -0.0029946265466862555, -0.008265800477734937, 0.01924448361043727, -0.03055140039035671, -0.0035976421090287585, -0.014718539963586179, -0.023046946942681317, 0.03017820201227722, -0.01988058503295281, 0.003528838201712614, -0.002104904073820912, -0.03046563717858871, -0.007692493334737139, -0.0063609072176676554, -0.014352935521639718, -0.05301973338478143, -0.018828633225276756, -0.06603846445082816, 0.00018376495523418212, 0.025633529043152147, -0.030823984537764536, 0.055581686794746954, 0.03720698586945792, -0.026779737588223405, 0.0058555692326898974, -0.023101763029255956, -0.018221859608066694, -0.11008898939159754, -0.01347338876159685, -0.01318741496627255, 0.00038554775823414347, -0.01983213511260561, 0.020227589278699623, -0.06522721381474988, -0.014726343450130042, -0.06322521118528562, 0.0019155097417447597, 0.00204377867236403, 0.0016800222470625236, -0.05909989765322051, -0.04669799906860348, 0.009329903224487157, -0.0031912690093030775, 0.0020794266678768776, 0.06691697750653718, -0.00484072293495754, -0.06269236257431597, -0.026664844249508417, 0.0053670781978763194, 0.010790900405903697, -0.021839340288147602, -0.045373308511014857, -0.029365446012598214, -0.00511019080051779, -0.07237928940752679, 0.04067370566620803, -0.05750696563568004, -0.044510885333827625, -0.01589064602602405, -0.06951429698125211, -0.06212952201444043, -0.04024995439248196, 0.06117248192859709, -0.03338404151127129, -0.03794046249361801, 0.0013399254960765174, -0.052939763442207535, -0.017677789105237134, -0.01951873002906023, -0.009168366896124599, -0.045231935752072, -0.0560479417954907, -0.019601669950370413, -0.03267944365030233, -0.05481072051952688, -0.023311261059567146, -0.018743283611273823, -0.03477377821287884, -0.037057247209027436, -0.023589465022979768, -0.040142580899208115, -0.014882516605238606, -0.016615303226898626, -0.021299787728305635, -0.047352094189351164, -0.010076298303236208, -0.036483031976409924, -0.061219955945070764, 0.005228073786974142, 0.0078510325720073, -0.017285986994947593, 0.053872663658940306, 0.022625703440937613, -0.07353922641916409, -0.023908725364755416, -0.021432595196474242, -0.03171893316953092, -0.03994752783744876, -0.04344904963468767, -0.003418497680468836, 0.007338440260092947, -0.036951438488535916, -0.04554898276872999, -0.020857593984852204, -0.01587774937948458, -0.0038245493856778378, -0.031194139125870615, 0.03790712802751438, 0.007326170387755529, -0.030560463841794065, -0.05068282445153153, -0.05792783196111161, -0.04110063377414658, -0.03927735773417322, -0.05919955816669534, -0.03637532093759565, -0.06159208411112579, -0.061181565320883174, 0.026002642801138526, -0.016986325145373116, -0.07723647705758362, -0.022863009739416747, -0.04611670050086507, 0.007534124089136149, -0.06056066022113108, -0.02815090088044923, 0.036712794923743734, -0.030510779515998038, 0.03296051269815885, -0.020950757895164086, -0.008464120961181067, -0.028943817688595587, -0.0029569738430363732, -0.006629894756588127, -0.023996222802185604, 0.020561431613963673, -0.017901441796192463, -0.04790176748173741, -0.014185416019942138, -0.015709271992176352, -0.018007573993339954, -0.03568415295494104, 0.01822813504537262, -0.019143443707052805, 0.0313761915410629, -0.04088261877495451, -0.009827693712976562, 0.036663351726488116, -0.02584856077361753, -0.019860839016790935, 0.004905946169871046, 0.006149182146334646, -0.0017369560644403517, -0.04325473166308544, -0.04887497078657158, 0.02226786505061201, -0.07518890532489352, -0.08743540207158362, 0.013633327924838403, 0.0020518925274260716, -0.03707971491708523, 0.0095775919492323, -0.06814179268613549, 0.0023685909585469513, 0.016087683843940055, -0.012217151633092498, 0.0026348915148167685, 0.010662216674626078, -0.005051352249615289, 0.007612649296325399, 0.04181090261791918, -0.02108317498308414, -0.018772649258998787, -0.014871933216710898, 0.027993282682404284, -0.07538508514554086, -0.06042165178235819, -0.015417991595155604, -0.0026676312473251007, 0.020723181319955243, -0.03029497902035851, -0.0376961298424094, 0.013909767183542018, -0.013782921561740887, -0.021920040112631857, -0.08333967218342235, -0.016090298870993763, -0.006559297224523237, -0.01205720840643811, 0.012312696745513722, -0.05464638132044948, -0.017012662029722878, -0.07007913002616149, -0.02714740789970629, -0.06875232546701884, -0.04931735206555466, -0.025441933871373886, -0.06005812015747875, 0.0012095418827026282, 0.0015883900919890753, -0.034713729155191185, -0.043427235778643165, -0.0012708715197685123, -0.0008542714629130464, -0.05031845298884941, 0.051197064931932, -0.07333571313292574, -0.05333853416156465, -0.023975522293710604, -0.049662697433329704, 0.052081122461019834, -0.059909091586257394, -0.04086328378668514, -0.019307204687924136, 0.031172102149007393, -0.011609223746097337, 0.03858055593698464, -0.03563983474642832, -0.03057625757451884, 0.004323139153258686, -0.027441840339803233, -0.012595957351510867, -0.012262090636413061, 0.0639552721410804, -0.047160143838837154, -0.04641598133032561, -0.0243135213200897, -0.019025758703671986, -0.0133103129884241, -0.04905579718751253, 0.0048334489544185864, -0.016093223975052504, -0.03950993789015526, -0.060846990572709835, 0.013495465449424938, -0.02414744206975411, 0.003206144993453294, -0.055813704136794574, -0.05019439144913732, 0.009493453806441505, 0.022658476325022096, -0.10466269451355456, 0.020340265254719374, -0.017735430468879154, 0.010170607007683718, 0.03488541673797858, -0.06850887401512487, -0.06187627719812668, -0.03536119086490066, -0.005937168821719244, -0.08278472848433649, -0.015322268041816486, -0.007058289974360142, 0.019973854248800254, -0.020262256608351077, -0.013665824434513344, -0.02835973698329003, -0.010118364232882905, -0.05881668130951722, -0.0608882615448401, -0.06164043233128026, 0.0018295875133523644, 0.030779306033018438, -0.08251425980564264, -0.034518269971880546, -0.0340540754910383, 0.033773889608821946, -0.041121618141080674, -0.05796116913590829, -0.014243525234240256, -0.03406054074195389, -0.007942753420568337, -0.022717874776002785, -0.01043640603770325, -0.016810012927717836, -0.005714588363466287, 0.006319391834469945, 0.020845276739154282, -0.026197211090779337, -0.01451250194180822, -0.04233195593260124, -0.04971139147448433, -0.008255430715871937, -0.02242053920039045, 0.027479349670624133, 0.01918460517260576, 0.04221631613201173, -0.021866899702708217, -0.036228022195007155, 0.008157630142311825, -0.01268211666917424, 0.018048778465042017, -0.02749594770889635, -0.05261946485840161, 0.022398005628160175, 0.03258119255001299, -0.04377409807665172, 0.03296146720785219, -0.029808814654405016, -0.028880389505559073, 0.0037522700252314548, 0.014772410414813867, -0.01663224256671105, -0.062401363235196, -0.03379664967720483, -0.02680661974498605, 0.02368496481399201, -0.019203358186143375, 0.04778519551875814, -0.02430200427009325, -0.02532912040842065, 0.03520657865186547, -0.03798280073003248, -0.06880514444375303, -0.010574259282217807, -0.02381144086767235, 0.05787471671985289, 0.005131100271252857, -0.03965811186360881, -0.049699671813268176, -0.016944289148825533, -0.03640369909892972, -0.05869436750851621, -0.007680841823351317, -0.018625590435940302, -0.03908882358388217, 0.07100444782388632, -0.1009278222699766, -0.011187384215637846]}
\ No newline at end of file
Index: alice_corr_user.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/alice_corr_user.json b/alice_corr_user.json
new file mode 100644
--- /dev/null	(date 1615375815000)
+++ b/alice_corr_user.json	(date 1615375815000)
@@ -0,0 +1,1 @@
+{"43": [0.11403017010113935, 0.1681841878319343, 0.031960831000659586, 0.3449381780958701, 0.16989425366031818, 0.2353568174772804, 0.31660672701417797, 0.34776341635036656, 0.08028529924640922, 0.06421765146298315, 0.3382053817856386, 0.2764180952335059, 0.21374390371381602, 0.2625643094790833, 0.12236630469779675, 0.2511640981057912, 0.3228562353844575, 0.15598535631172122, 0.14598699157173103, 0.22024820958939753, 0.18273647635820162, 0.17839487637304652, 0.3247871355440258, 0.08698964449162848, 0.1517265237579528, 0.1459794876434065, 0.30493895953008315, 0.14617381916185349, 0.16844584925629272, 0.23640457132897175, 0.26464127976663443, 0.2963350378916287, 0.09421413770473305, 0.21295623779279116, 0.2522980964812347, 0.26961733956385525, 0.19471779523083185, 0.2127030074787842, 0.28679402099289936, 0.2990481530260136, 0.12021411461951131, 0.2258062520186139, 0.33566693934675135, 0.09094629326298809, 0.18193922068718332, 0.23486570259130393, 0.2060059505769813, 0.2043396796113702, 0.20288797021014418, 0.06805387879699079, 0.2212674298198252, 0.19456101340600468, 0.2650497077340389, 0.32744398873975994, 0.2983738489456863, 0.1804241923234263, 0.3426609899012386, 0.07740885755407768, 0.2448920139257096, 0.17820278858918834, 0.34826855840794213, 0.3025317218368468, 0.11044659221157256, 0.17665467042333222, 0.11857427281625006, 0.1347152385012719, 0.23162085622297002, 0.14353440434462314, 0.22173797930416195, 0.20735531363267487, 0.14323547897822586, 0.2652558051562399, 0.23858822633845095, 0.21083783790381777, 0.24963434381677277, 0.3210756202254272, 0.042144965992744934, 0.2182308113591095, 0.30147654548691133, 0.15840838523153364, 0.14836846677934873, 0.15902632464524005, 0.3007169681487376, 0.2790250839136702, 0.18249145793059426, 0.16926447654342985, 0.3073897184454296, 0.3420565966734063, -0.02832561093992691, 0.22956552605373068, 0.17616149310738127, 0.018968689972577613, 0.1703964375093881, 0.31949452695911024, 0.2809724689812485, 0.3014169808328927, 0.1643487684266619, 0.3166601383180221, 0.1687720057701684, 0.2534562141222509, 0.2584501926236369, 0.2890010517791338, 0.3207378812914851, 0.2961698097817756, 0.272727220268678, 0.16232720781678533, 0.1741421683157745, 0.1799955937390227, 0.15009688880948627, 0.2482911772330741, 0.06709180589129664, 0.2386437791393782, 0.1897007870766917, 0.322957837277072, 0.25047657422742636, 0.2152247135311751, 0.18679672839213507, 0.2664407698764056, 0.23513520435116395, 0.19016691295558538, 0.29844553687698755, 0.1771383020580925, 0.16517573847182127, 0.3050954027322172, 0.16785352668673204, 0.1222039212606433, 0.20706740140669677, 0.2004750991809704, 0.31092447325282324, 0.09775575117266648, 0.1407549255895874, 0.17811710728941701, 0.2383595968405162, 0.04650234785420651, 0.2903783532669648, 0.3416393310357882, 0.13632467415574767, 0.2498762027782875, 0.3244714050643421, 0.24180667444674336, 0.25964661132659644, 0.08877208789787322, 0.2638359582997712, 0.1251174139054552, 0.30020475971019656, 0.1360472870849814, 0.23731806661780994, 0.23558977120916336, 0.27349231666548535, 0.2572670412883379, 0.2976703332598033, 0.20454024052607025, 0.22239461851896145, 0.3315264277518003, 0.34732096244838273, 0.35096025891444016, 0.12426012595630692, 0.06471869835274881, 0.11608692492691362, 0.17446171446279596, 0.22881250678450082, 0.14180201052281838, 0.17560740711581244, 0.2502952308635587, 0.28939963050668177, 0.25429053961456616, 0.35149194356877983, 0.2742312046599948, 0.32717077848052944, 0.3117600552955781, 0.31157134635946, 0.2088075029216671, 0.11084812070984287, 0.13622844437991147, 0.2436475461141706, 0.23022167095692508, 0.22387861928562283, 0.253393812373135, 0.22775949195308895, 0.2751264043048084, 0.292083841480136, 0.29731263706373484, 0.12490807419576351, 0.12490434150999322, 0.3375126210953226, 0.1715030584103147, 0.2208040781308504, 0.2549440306234711, 0.014290870588950746, 0.2760611542751675, 0.14642560608864058, 0.23091545327303512, 0.11366905736336552, 0.22019399488991742, 0.22506966101429582, 0.15266642744261924, 0.2378493110917319, 0.3041200616381171, 0.35403991312344024, 0.2947597766501351, 0.3565970474771795, 0.30854271123976185, 0.03880764539266344, 0.1512995293331454, 0.2033429868029366, 0.20042897534299772, 0.12369659840376238, 0.15638387287553, 0.21516874399671437, 0.3076686966405701, 0.14200724674547913, 0.18717017659104018, 0.1740536649377862, 0.052503334259725025, 0.2617310828149922, 0.1494974874355685, 0.3508571369975375, 0.21852915964296954, 0.05124274899400106, 0.19216095747352413, 0.15806412924841837, 0.14346185523315938, 0.2207746170452465, 0.22281266097887217, 0.36785389183725353, 0.2547491796517702, 0.30317597722720524, 0.2937956529610079, 0.20776853134241596, 0.2757861279186619, 0.25490595321203563, 0.3479307066570913, 0.30048768624725897, 0.16001903175655366, 0.3144915074860547, 0.1543287740261577, 0.2701377873370059, 0.2697098530761276, 0.12387576973996808, 0.17671763605681537, 0.2809522730337108, 0.22211744594622498, 0.3678202108043161, 0.2695620524838761, 0.2679888022499691, 0.33498610398404005, 0.17437819536417737, 0.10905087227507385, 0.1695375231070753, 0.12289001462252416, 0.05264449349449148, 0.36809061059510667, 0.2653511962914711, 0.20974256033983862, 0.24218793736287816, 0.27320232732567284, 0.29285283129113693, 0.15147235083289567, 0.2488566396810354, 0.3764054254448015, 0.12074662038121704, 0.27944227428463037, 0.1608607472240783, 0.04509599039572815, 0.21546361317210616, 0.0786468266500373, 0.30346809019249305, 0.27841068715342276, 0.006323287367622542, 0.3096210638857593, 0.24601201273056814, 0.1416629249101075, 0.1583681450748531, 0.06929234577361147, 0.2779689488320987, 0.25781728146033545, 0.12758751927445533, 0.2745299855734273, 0.2834546273296207, 0.1656271255053868, 0.3432006068467472, 0.23128776285882377, 0.11610238352892592, 0.30470222512190126, 0.11532652876715604, 0.1642473594725843, 0.049930464233416315, 0.06992068971859854, 0.2959308734851669, 0.08119363410549918, 0.08262893135777542, 0.3076542626909777, 0.33669349998041614, 0.17953097882867008, 0.2502055118933805, 0.2665586267723028, 0.2522456251663288, 0.25918123585049496, 0.18622040347474297, 0.06772487553559116, 0.2535978857079979, 0.14165937385479163, 0.25925532677158963, 0.11947284639201464, 0.20446012631158525, 0.26410318708649516, 0.27155799448521184, 0.1947970968352214, 0.20015533405399089, 0.10997292486357864, 0.2902490858717171, 0.17002066529334234, 0.0631692055793777, 0.06364122444778315, 0.2712785542378578, 0.28795826078020437, 0.13307105921700235, 0.18702293873757847, 0.32933200829257936, 0.2750843775715407, 0.2749768157583548, 0.3034471895332589, 0.1636538655068685, 0.22430322859545193, 0.11310875176378209, 0.19996504730080514, 0.10447453822773588, 0.22882457340097268, 0.1796596030080772, 0.2650263038774593, 0.26912789670229076, 0.1801114112100047, 0.17833238537468002, 0.19474996246617016, 0.3428904607344088, 0.3831280276135859, 0.2285998898930359, 0.3216146991667769, 0.11472873656576518, 0.29130337096401626, 0.17066280224037012, 0.19173957781233153, 0.18354636464809068, 0.2756133458870944, 0.2791622534523819, 0.30989423153126056, 0.1981017243636562, 0.25931208721218746, 0.20809182004275173, 0.2826096046729474, 0.13452434013424103, 0.30081632224660515, 0.235063108517205, 0.19152422918811202, 0.3046514389966838, 0.32075563667987866, 0.25620179640123203, 0.3209336684266449, 0.10319570358602474, 0.27119375634561405, 0.13308280373422465, 0.274743650827368], "44": [0.3139893091797585, 0.2465606731081099, 0.3610315951472438, 0.32901680744464185, 0.3676606206731424, 0.3726216830215787, 0.15090123161166222, 0.25837139422435657, 0.32142208786517124, 0.1677137936379079, 0.20845216066864536, 0.2362283585201197, 0.3461166179206529, 0.3076265352229735, 0.2830497042588931, 0.1717078937905245, 0.24825191409875058, 0.3115270326821025, 0.360046285549089, 0.2813854411135801, 0.2893125611580516, 0.2987681569969212, 0.21286569732692517, 0.21025660642127103, 0.2000466117738424, 0.23215324079999558, 0.3228998066484453, 0.3164459773757336, 0.23016806137058485, 0.27196801775914087, 0.30778530994425324, 0.33869066558183863, 0.3153066428178991, 0.32609316876303385, 0.312314400516292, 0.21898890358226614, 0.2619614204925233, 0.17363326779379037, 0.25392499284712633, 0.3413209325660068, 0.1350921992093946, 0.23331636366083955, 0.2825971116867834, 0.2776753809119032, 0.17087988239282112, 0.15994623723895615, 0.2801080797475355, 0.27501071606831434, 0.3777513263810527, 0.20613834501871395, 0.17738285844644122, 0.18620122502593686, 0.36063422315259064, 0.25283781763718616, 0.25748409552558005, 0.1683981610502245, 0.28451082212114925, 0.24779892802940207, 0.3266300649262513, 0.3328253474793279, 0.3548978020904546, 0.29905483277550626, 0.39772757024469585, 0.29638297675625, 0.2741318119616943, 0.33595477755223113, 0.3016550273046715, 0.1373695853891428, 0.24368478290205933, 0.2862931635735608, 0.2931019221596687, 0.29926990887884786, 0.2739367128977608, 0.30214214253073207, 0.32476820045250143, 0.2913381360952437, 0.29096170622183226, 0.27449258902527696, 0.28012696085779754, 0.15574517730134205, 0.2825785865011688, 0.2300775203152931, 0.25853547209571853, 0.28238341010287965, 0.3140153638640349, 0.39529070745917877, 0.2849520836030939, 0.29438380614998927, 0.29271898784889905, 0.17297769162474866, 0.3748015328511841, 0.3322096816664548, 0.2755177409913432, 0.3480104135102054, 0.2518002605613583, 0.3164808003286015, 0.1527080353459906, 0.28331847670829136, 0.42917240773121984, 0.387185429026451, 0.3848468022073514, 0.26398746835698383, 0.271474559137878, 0.310041510944567, 0.26369626206114877, 0.27045240918427377, 0.28725342042020163, 0.3529902054318998, 0.17786147931855562, 0.24865742489715545, 0.23018484179579976, 0.29300368106705055, 0.12954435377694518, 0.29813425431301877, 0.3691967384352837, 0.2478028850208033, 0.29662520007932713, 0.3531301459698744, 0.21043442603701987, 0.2353250772460932, 0.1563591015595463, 0.35395270573269866, 0.16610102670655405, 0.26583681612331156, 0.2588174632052826, 0.24195721555696026, 0.32929503986035324, 0.29061206320676525, 0.31138025276818504, 0.3090381139779811, 0.36972645165071144, 0.2908060168179854, 0.22524326993801316, 0.28067805017350805, 0.29048029128243097, 0.3012331700391779, 0.3715629269579639, 0.12649171255019193, 0.21439618843560493, 0.24762253574479337, 0.35018268440268535, 0.2780588799428744, 0.32637607446835676, 0.2901949736632964, 0.278839866937761, 0.18787863528867485, 0.36246076395248805, 0.35995577677389257, 0.22078595024565392, 0.27211544533513593, 0.24950834321276902, 0.2611685207578796, 0.294545717304918, 0.14589652010858142, 0.15264388577569044, 0.24653837786040297, 0.32476292553451735, 0.31500734057578195, 0.35987066532714557, 0.255000270145929, 0.38664017646581045, 0.07964170107603866, 0.22852103394712023, 0.2933409954142139, 0.2984080374508848, 0.323361690359743, 0.28096860557898656, 0.20854091612274553, 0.29204558932075164, 0.24681733274508297, 0.32417755406129534, 0.07776167767268852, 0.07960165510017773, 0.29680257259459686, 0.25584683733148833, 0.28449530896148095, 0.30249770726007075, 0.309927828168652, 0.25293570577505736, 0.16243557246303028, 0.16096837335559355, 0.3028372901510476, 0.2490415214776401, 0.36204874863707665, 0.3868322972163872, 0.377266547185381, 0.18515955388319538, 0.3428666565994219, 0.3016880411360726, 0.3301881781525116, 0.33167241434967887, 0.2506333636016607, 0.2448223677273963, 0.23789893651410046, 0.23357556305596805, 0.17096465385833562, 0.3081368216569758, 0.26688022499666614, 0.16296474060115063, 0.23245058678608932, 0.1688852293892632, 0.25151710736820315, 0.2972686103924004, 0.18702034596902647, 0.28404753738167515, 0.2874651558267844, 0.25084144498051014, 0.25696693184872826, 0.24793595099167753, 0.2803209864475393, 0.3403654136146932, 0.13115309612769505, 0.29813457596968046, 0.3040328134720477, 0.3103418232629314, 0.36221641009862027, 0.3050153572410707, 0.30662854172396853, 0.31564828133936457, 0.3853366238847844, 0.2939916077699927, 0.19562714330605427, 0.3308590735238194, 0.20541113693191893, 0.315502649448682, 0.31124325235334394, 0.29499035137796326, 0.22353358474945245, 0.12133091588759691, 0.3300173746549932, 0.3099811501554115, 0.33010882146553455, 0.25372409511901084, 0.3089610079381597, 0.3037066014731409, 0.14391657433733004, 0.24153396503938315, 0.3257368607705629, 0.24775634031187208, 0.2507595317899929, 0.2607484988776985, 0.2777591035732358, 0.35837974385133753, 0.2632155617365323, 0.2581180298972077, 0.31951878337824563, 0.16837347878939835, 0.3402194713937318, 0.31740432567818994, 0.15575232069465428, 0.30272493967241315, 0.36967865231354957, 0.34323562374662175, 0.2594287772509987, 0.318721010105288, 0.3107746190644175, 0.2078838899836241, 0.3944164750278043, 0.34505869236880476, 0.29217475779180285, 0.2800273573842377, 0.33957117273450776, 0.3806797610777825, 0.3190252385544487, 0.3643451349205431, 0.1753173600285122, 0.3073995444092423, 0.2893022364677881, 0.2728479103738053, 0.30232012414196335, 0.2792987491863055, 0.35513922630718536, 0.3267687854703816, 0.3443488803295483, 0.2667112652287543, 0.3468655739840144, 0.38439964479989763, 0.2757628050892872, 0.28706240995068777, 0.34496151946091863, 0.33064063107443453, 0.23379002918665923, 0.3385138597928797, 0.308932573277822, 0.33881501280638554, 0.33588916746191577, 0.3760615644131266, 0.27050755113284636, 0.35192144735756997, 0.3558357347306987, 0.35667426015436937, 0.27583985530656563, 0.3097706513176945, 0.273906478984925, 0.3125802751876511, 0.40362421959189554, 0.35550940074511617, 0.2358958363765704, 0.32203423458192576, 0.3401895644712389, 0.27678553262885064, 0.21085476038911227, 0.3254616764843146, 0.3464583652826352, 0.2790654926687265, 0.19098558653107162, 0.24804599400711377, 0.2889943173427713, 0.33980187275518986, 0.3308971675970963, 0.3525928246108765, 0.3527561632171438, 0.35164652218051357, 0.3233791036730534, 0.2567165891782379, 0.31359603835776123, 0.26343299759450406, 0.28779798960395814, 0.28787047241609465, 0.275752057169015, 0.36999177082749757, 0.15367966022441493, 0.29334733917176736, 0.23878423001079715, 0.2706251259508399, 0.3127501404473093, 0.2467159644227243, 0.24886717343868034, 0.22586061672119595, 0.3096013326689452, 0.2946543670579343, 0.3325230606544388, 0.34748048285543065, 0.3174728185682369, 0.28807321754473036, 0.27894828651928266, 0.33692265154339707, 0.34476070499222095, 0.2931591005237054, 0.3245641137125743, 0.38830467602307117, 0.33823661988486103, 0.28425219402746793, 0.09361418261221183, 0.30235732034720786, 0.18622895184680519, 0.2944141295741074, 0.2862215470544597, 0.3709847516583189, 0.34918654175904357, 0.24893233239840895, 0.3489999620816216, 0.26151317274677727, 0.29781108343621365, 0.33086851910783815, 0.32991266846069484, 0.29809100555499973, 0.32452773726801937, 0.14353456697701963, 0.2066654897252491, 0.35075269762878575, 0.3223690513283778], "35": [0.355681107311671, 0.2659217707109207, -0.019094566973099875, 0.2139352923590816, 0.29433752017819015, 0.11000453585311167, 0.24962221041496888, 0.28257759449659037, 0.31864858465803325, 0.2783180722357167, 0.08716305407902514, 0.27285456580992656, 0.20985565649243307, 0.20156309427639363, 0.30297228560375883, 0.2532548745101401, 0.14522957884239704, 0.29564194227253315, 0.19394133001655484, 0.0021651972612148473, 0.23077901643120854, 0.32833870589582287, 0.2357506329390743, 0.2890597914172829, 0.23492955658701303, 0.2544576664848498, 0.04480515965324399, 0.237361195154522, 0.2943659493573765, 0.26904266840020685, 0.32605349421863944, 0.15627669537658168, 0.2655626534951524, 0.07466810089947921, 0.021775167267366426, 0.25796962619957287, 0.022310676538692845, 0.27973018436193653, 0.3117818290432497, 0.3153217517365836, 0.20273205691689095, 0.3120687860835945, 0.32198899106908074, 0.21854292874501705, 0.15308946090177905, 0.2865433920434059, 0.23483501696794207, 0.3540163748203968, 0.2694676816339, 0.05784989953158701, 0.21705329721233332, 0.28398821409793645, 0.011273430532397245, 0.343595649987848, 0.2771564379689094, 0.3102062370026945, 0.29655614803349584, 0.11800193866906124, 0.04236620633772661, 0.20237849294975294, 0.20069127129144193, 0.2622103972316715, 0.027235025158110743, 0.07195660961539363, 0.08826304394432541, 0.2575179605184221, 0.20423426763468985, 0.34815381497206227, 0.3065769574396721, 0.24261272535739864, 0.29240200499197133, 0.32435141097657927, 0.26495117831883996, 0.11938487413167592, 0.3510083295313453, 0.276961787109417, 0.30689491734177454, 0.31101818643381757, 0.10627071705569416, 0.31627096570501595, 0.27580647432753264, 0.08323639586356643, 0.303543403019393, 0.29015667543760804, 0.28623725521648474, 0.3275458979195667, 0.24442769883865129, 0.25000683587920364, 0.2586347163470989, 0.1243900814912062, 0.27595249443491887, 0.2467917239465574, 0.31117958173661153, 0.0916134711556194, 0.31441568654613566, 0.1882559781824197, 0.35159671555782046, 0.3358442315012207, 0.26630093127722015, 0.30555020330448973, 0.3425775679058296, 0.2788216604453484, -0.0023420359800981365, 0.23190006072922345, 0.3250275539612762, 0.3949258905147076, 0.26142782313779295, 0.250950414646827, 0.1965003190987891, 0.26605852749040315, 0.27730301913514716, 0.2899782906884653, 0.26684065258169193, 0.2240938935246077, 0.2027158817898577, 0.3154143635021694, 0.25181258688857444, 0.06271019371760105, 0.28059262410031555, 0.2616084448843407, 0.21795023084839749, 0.29200440465285343, 0.19352280883286044, 0.024386103548767774, 0.04705642567159821, 0.24754894793938914, 0.22589172736058133, 0.2830110867641809, 0.25269813738108815, 0.17886645107114948, 0.3285667709146849, 0.28295115492614703, 0.3052827978976589, 0.21409911837751838, 0.21016942551169662, 0.09031394410780591, 0.18177446530639974, 0.028369341337036245, -0.0003044149295466696, 0.08240567927832294, 0.2674957019894185, 0.04239183187133258, 0.3145117980611312, 0.26425585050683975, 0.20927264411548635, 0.21406334641736854, 0.30959544394669625, 0.3487571525978533, 0.21147691313948355, 0.2717754954932169, 0.201997899128513, 0.34818601348871064, 0.2724558293702266, 0.008863303973222441, 0.17423085088456275, 0.32263787166004343, 0.2422645619365103, 0.2935675835230312, 0.3649158915883925, 0.2903926327029079, 0.15570936383028866, 0.2261161026099275, 0.3024072766718291, 0.21458878395311412, 0.019911396175720766, 0.28823153485622377, 0.06733231875107151, 0.3060481762641735, 0.011813781134834852, 0.29745956180783545, 0.1308290681184207, 0.18064494699749425, 0.29087074594583334, 0.19984339589201996, 0.3163565028332679, 0.25138108690527083, 0.3111386553529869, 0.3286937249587708, 0.27900567758202904, 0.10091740126550351, 0.26991574919641165, 0.25097170837324423, 0.27155317256988815, 0.33038228160047367, 0.2516217345149011, 0.3406090269310491, 0.27124817105453547, 0.38718954061965694, 0.2437570880202163, 0.24757133681888155, 0.010899806872854486, 0.19186425504350757, 0.2155026799416989, 0.22893802894959533, 0.2518038399517947, 0.09571929513783775, 0.2010467106599117, 0.05725513311041212, 0.3219159110463841, 0.26014477846821965, 0.36243596228692343, 0.2950759641092358, 0.2709640493241721, 0.2769962276407817, 0.33385715453192055, 0.09260629008413564, 0.2572628803832184, 0.2034069303806499, 0.02984994205569575, 0.24454577364263003, 0.31194416629583177, 0.25483479889949373, 0.13224113112414124, 0.3646696915677139, -0.014369177042450818, 0.07247049933520464, 0.29293603631781256, 0.25526983276807597, 0.02183969556686816, 0.25606502499119, 0.3213419762493409, 0.25649331343019155, 0.2802019938164434, 0.27014243756968664, 0.3651393768141036, 0.177643773710916, 0.27764175154987003, 0.24704943704436028, 0.2529655847462629, 0.4171853082087414, 0.2862142686461204, 0.29440964757367566, 0.25916804491120465, 0.16411605589126585, 0.2577530078514182, 0.2761205840428488, 0.2994009605078701, 0.28362768793586574, 0.33939769718449025, 0.33206470331062543, 0.3101233415707933, 0.33540664264476455, 0.2403911454462104, 0.28720621661334805, 0.2976472701871604, 0.2690530355836842, 0.2767878759890302, 0.20921394157326553, 0.26928279221237655, -0.020824630790508433, 0.2255404959891985, 0.29120184916005176, 0.25826348547640776, 0.2876616822289149, 0.27844317770219873, 0.19411141228563777, 0.3033491824491468, 0.3323989337216843, 0.26107292275877153, 0.30139254148110395, 0.20447302243703594, 0.34868967754063257, 0.3376645266924081, 0.2573983573958457, 0.18196993941663017, 0.3194398751527664, 0.03725502995222876, 0.3109290970698052, 0.24177492250462498, 0.3236999027884667, 0.3288642099890818, 0.11875875081539237, 0.2766909152739585, 0.28925497416755347, 0.03578875279448988, 0.19510013219617095, 0.2357616737836276, 0.2407720840070598, 0.21406687254341086, 0.2365617782260212, 0.29073229570936765, 0.273982249748004, 0.06569237004952125, 0.27789976712548775, 0.28923129724454266, 0.2558178754507744, 0.2403591583681589, 0.30530465142251356, 0.3429239838285393, 0.24263137293154746, 0.3397199771367283, 0.18643650598014613, 0.135797892907839, 0.3302877531210997, 0.28175331434329604, 0.2700124503618883, 0.33405801684963116, 0.3700930917867664, 0.25141551484240693, 0.25947210846985064, 0.2654865608799841, 0.2696508672996097, 0.259995660754038, 0.259334846056448, 0.2814431557517872, 0.28436045153946105, 0.28797195110482465, 0.05121776769451492, 0.29755208946990486, 0.3427000013612055, 0.021174537090417424, 0.31083445421348077, 0.3367133351219282, 0.3585503251692032, 0.30805783434905004, 0.27773102548930434, 0.2610206098270667, 0.30349971737813614, 0.28886230617561076, 0.27287168584394866, 0.2586466496170631, 0.26607451296260326, 0.2648234999326705, 0.320913485199973, 0.3553903601227713, 0.17323813690268816, 0.27465221259250433, 0.2488790458235738, 0.2528496973205886, 0.30917813882796497, 0.3409316500794371, 0.2981008592606208, 0.24229869778614357, 0.29450455562200295, 0.316582531740773, 0.32629864874040954, 0.1490337904225916, 0.2989037714541906, 0.21575828035218803, 0.27073709396965095, 0.1989159289689635, 0.2902786214944312, 0.26732730448097897, 0.32383514025001736, 0.2707577900124964, 0.2323246595281816, 0.2509170415977858, 0.2789836045190961, 0.23858652564048288, 0.3015045192811951, 0.3257609003283449, 0.3201332114716912, 0.34437078093659046, 0.09776304882594973, 0.2865875060935323, 0.31257768342838294, 0.14795657133019505, 0.2499394453968933, 0.2434374466511577, 0.2255987642337354, 0.265479531426814, 0.21738365771199922], "47": [0.3348516023685538, 0.3519223474992434, 0.29651336815864343, 0.2026076376576005, 0.2564316186124681, 0.25156523600826336, 0.20253588505583528, 0.40119210775007486, 0.46520435010188355, 0.16590292521511846, 0.23446323343286246, 0.3264014877789332, 0.3440461122544844, 0.36816125203606825, 0.20880901445179156, 0.2926235003248434, 0.2481967666279742, 0.31341796541375094, 0.26823539769362104, 0.3619367192961563, 0.23538139308496256, 0.25166309765140266, 0.17693176911026048, 0.19590347071899522, 0.18967953940127408, 0.2680382109304949, 0.34324723830684223, 0.33507669142036517, 0.09303564750045319, 0.20201671390754738, 0.18828946711117342, 0.15002251542544012, 0.26084869448741665, 0.3447701624561699, 0.3334790089603881, 0.12474213307928846, 0.24222181691565237, 0.3062314788091596, 0.3051983503905741, 0.17232367910230778, 0.3762036245594382, 0.32650450895118777, 0.11954868534652209, 0.16053980877278426, 0.31751014968717345, 0.22552815211371063, 0.09205504214572847, 0.2537527686808836, 0.28338877601851803, 0.20057694298923065, 0.37336395556849294, 0.3836359780737997, 0.40438229520677976, 0.24194488825490915, 0.22014569248963048, 0.4137019444547044, 0.19263854470977523, 0.19294675514467124, 0.39791676535600595, 0.3569687283544965, 0.4043017413123962, 0.33654346365751575, 0.18385038314843707, 0.3074232708484691, 0.2730696806062917, 0.2082930793927628, 0.2822339189172847, 0.33893750597155414, 0.3020926323357213, 0.28969998782022627, 0.30895096659316956, 0.3512233975285204, 0.2917486632020841, 0.15931336195099557, 0.30336105602512403, 0.3243194410829281, 0.285217305801867, 0.367609541241282, 0.20600756501464965, 0.27907664324915604, 0.25876864099387753, 0.23374217211192994, 0.2249410390006193, 0.34254788659094654, 0.3553716496383008, 0.37725193533494894, 0.28027967186985875, 0.2958569727304175, 0.1418537363233576, 0.26420317276279537, 0.2928014233117097, 0.38630888095965066, 0.4553953496497231, 0.3184130016780022, 0.36309719001249224, 0.2544013179954498, 0.21428691653611956, 0.3259032404138991, 0.26441010099348605, 0.3688222977185002, 0.30036705673796116, 0.22115690392198795, 0.21450108818599195, 0.4241302374222065, 0.36400625930460223, 0.3115219371975657, 0.19240974427686838, 0.294270314913156, 0.14963006272432763, 0.07840821864137694, 0.3822699950179057, 0.3153319227868089, 0.28585804669089376, 0.3035274388790308, 0.19236534728812468, 0.41787458614965045, 0.27803100057208535, 0.26207573020138136, 0.21504296452213234, 0.21153372156097194, 0.29785649227462396, 0.38517480576746366, 0.35538905467804505, 0.25935054152245435, 0.3342210970153273, 0.1575354968982135, 0.3038999953487353, 0.3203327034108093, 0.22614499866629897, 0.22793639305902122, 0.2623534728189851, 0.18193550303102363, 0.18239675443873324, 0.12575086707890784, 0.17730435414453946, 0.1736057932319577, 0.25618484278715636, 0.43613674354001875, 0.3270750382255719, 0.31822365976153644, 0.23655310512319772, 0.28322952071720864, 0.2403941984539122, 0.24792177273535804, 0.30776477966105714, 0.3545320637984491, 0.28633305632730144, 0.13115603697416015, 0.18113192050170468, 0.21095723314762221, 0.33353475669788324, 0.30535828455214326, 0.2577186642483019, 0.23653751196589734, 0.18365270975599796, 0.13876249800690021, 0.18940415949613962, 0.2824870694784162, 0.1533825176488302, 0.28703803843645, 0.388572423611832, 0.23050973208969383, 0.2482669900317862, 0.18788065809234913, 0.1665410172113932, 0.19638484263601597, 0.42649771892110466, 0.14372682891293703, 0.1688432589149635, 0.21902022239861613, 0.3007042929396589, 0.19671372737959744, 0.23111863717394515, 0.24653059441422476, 0.22679264847605432, 0.363330878578583, 0.23234030005064818, 0.19021783615724974, 0.2530176005503311, 0.2008832631602941, 0.11291531942731126, 0.3332741135080308, 0.2793479801243665, 0.3833079035146326, 0.2929168922737578, 0.28542809618360987, 0.26079298016618485, 0.3417589720435431, 0.37323172479369315, 0.251840952831138, 0.39705584604424204, 0.34011222465436, 0.05504031418695831, 0.3425898742533487, 0.2863730479618735, 0.3319267762629747, 0.14937045864405174, 0.33796260071405015, 0.259415959756866, 0.3386098137688052, 0.3540377976552679, 0.20316057056658382, 0.26360177825995984, 0.22590368979538367, 0.27754854515229455, 0.2815120388321542, 0.2549870138199634, 0.10722197260353947, 0.2829963669736848, 0.25042907530370123, 0.3755523191281094, 0.37601977347241194, 0.28930495391750755, 0.32535766598169613, 0.2853697789210283, 0.26235773956511294, 0.3944589896675341, 0.20729712573431808, 0.26098564066163216, 0.33051719726453205, 0.24369587684321217, 0.1973160787998385, 0.45774538235012674, 0.3484655091642875, 0.3271040842264442, 0.24112540868081805, 0.295038804002707, 0.22519120440255985, 0.25739280281779525, 0.12396022423323301, 0.25174751324788147, 0.4144266888851145, 0.2201600544020857, 0.2584717735228463, 0.18905121360052832, 0.35952665352702046, 0.2187791284350617, 0.17236479630691803, 0.23700454188061057, 0.35386192543691614, 0.19544138226012747, 0.31470253197245224, 0.21261464443353545, 0.24762107123826324, 0.21870139415777728, 0.37171733467201534, 0.35140077216845056, 0.2538534590278777, 0.16843890569933895, 0.2623126311509619, 0.22581810833629867, 0.195794957710073, 0.3418335878396064, 0.3626371506899954, 0.2975056239928884, 0.20690430243397395, 0.3148815277202535, 0.2498542822368423, 0.35829056416430377, 0.3982292309387938, 0.3318286087681216, 0.30028019131008726, 0.16039961118742144, 0.28414541194788184, 0.2829150837116754, 0.2584083630541227, 0.22201242701978888, 0.33691813618564215, 0.1853360784332718, 0.3711154555217626, 0.29502636413567557, 0.38849010623953056, 0.3986791772486011, 0.34226820624838394, 0.19430075649337178, 0.32726415660075964, 0.3109370991644746, 0.18864253386953728, 0.24131911299383257, 0.2826580402949547, 0.19063580810291872, 0.2865691887593786, 0.2966617947903104, 0.3688099788719154, 0.25257899571544923, 0.3148796209988181, 0.3045908365631414, 0.28891594783552194, 0.2507864237525762, 0.3521994173803122, 0.29536467083772966, 0.4284828371410187, 0.4191049179652535, 0.39485309683390485, 0.265976690101287, 0.14934231255779182, 0.30110592438362316, 0.27927759496539195, 0.15617319230338794, 0.3726909212870325, 0.32211114624817805, 0.18832329897497085, 0.21065484602552773, 0.3237647150870564, 0.32328061471540376, 0.3161543954182798, 0.2363428910517361, 0.3126056403894978, 0.4794278853273891, 0.35946993735337923, 0.2610540370547318, 0.2259181587343239, 0.2572516529295646, 0.32050296371175463, 0.36104069750804474, 0.42100747096129437, 0.2869612682961844, 0.39789432967074395, 0.18133856191996367, 0.2948449291022937, 0.2549509455742656, 0.26684099232777675, 0.2183095427241892, 0.29417454778744434, 0.37696840889082744, 0.4165760134727998, 0.2753992526075467, 0.4604148311917241, 0.2509973626698598, 0.2462217318079036, 0.13433975289387473, 0.27532417201696074, 0.35217252664766835, 0.35684888112251567, 0.3094571502810189, 0.36667210817212686, 0.25957283938641146, 0.13797474217264866, 0.18730566428894888, 0.4055549332604315, 0.20950324618494376, 0.1946935748388542, 0.2627582643913322, 0.2251463264958246, 0.3278333317308926, 0.3038547656482154, 0.4090124977789952, 0.1881131273057204, 0.23726325601652268, 0.17207398166318333, 0.1669302094044272, 0.4448100541279338, 0.3370131724306085, 0.3849566143262181, 0.22238529485992525, 0.19553375923645422, 0.2834288108962921, 0.1942974213867642, 0.35875352830765744, 0.22322440603525728, 0.22702219922042655, 0.2544639911549078], "49": [0.15356843499783984, 0.12623150098377758, 0.2343906798765334, 0.30239856982145963, 0.11989776592123867, 0.04699188977848855, 0.2512270803010585, 0.20053857623371166, 0.32277124342178526, 0.18014232463706933, 0.13329374470013325, 0.28653870527274294, 0.26371850949088854, 0.23162566490587613, 0.1433085758202343, 0.3254374483319657, 0.2830466901286612, 0.2424680810699562, 0.22356223869165137, 0.2543632099101474, 0.21342075506089084, 0.19550182441841474, 0.15184437672323803, 0.18144646169966866, 0.1875838178797026, 0.3020092152535924, 0.15422968858094718, 0.12493428083430458, 0.2064837494470326, 0.27413049875690837, 0.21674793955364732, 0.2322822623617063, 0.15973698917447413, 0.1490003102584987, 0.16580135736074608, 0.2223437618170402, 0.2354239729925355, 0.306833774702245, 0.12296357836363589, 0.253491212249467, 0.21048057377901394, 0.13171264232959579, 0.2960339401937684, 0.2673257056329542, 0.29264680136162585, 0.3257170972046385, 0.14466288547242795, 0.20057417413165926, 0.1752690086973595, 0.17609556304097576, 0.17725930102786366, 0.33828366249722236, 0.30910070288856284, 0.22925028612442505, 0.23953277381079463, 0.30212290340932774, 0.22510076514472932, 0.18059345332592133, 0.2966893859243404, 0.1706098270378054, 0.25245791153609903, 0.20621840380791032, 0.238816976111111, 0.3258620906143842, 0.08855285005938951, 0.31659481526626376, 0.32635603132938823, 0.2785351782455999, 0.12831549158761735, 0.21072259473274815, 0.23457109645533666, 0.23656717029617447, 0.2784322815489883, 0.13813218201090388, 0.2144540282039228, 0.15182690936347623, 0.22944837985631555, 0.3235475053812025, 0.22690861579864688, 0.2068698804421451, 0.2261468016564327, 0.0671320875203361, 0.15813360949440666, 0.1600143284311241, 0.16223967329364306, 0.2455107307405708, 0.1281497136648992, 0.379324734984708, 0.24792454419213183, 0.2950396113761844, 0.1816666437597885, 0.17368653442018916, 0.2348901135985823, 0.2985757650691855, 0.18236105112927445, 0.18604696790627176, 0.20715275345432907, 0.3163345995873679, 0.35557911243367396, 0.20250275467173934, 0.3090696054164314, 0.26127119456663783, 0.3115525898295857, 0.3242408958257054, 0.13471361505385746, 0.26458051363070195, 0.1858263393270174, 0.2437376486356671, 0.08417808912373946, 0.15361628342588293, 0.16800175508711376, 0.3242285661764571, 0.17834323420167095, 0.23642679412714332, 0.22411967918031625, 0.28140760190299935, 0.32836321830816084, 0.18104327859442415, 0.16209232777105154, 0.20122950153829386, 0.30381701816000867, 0.18547889023182892, 0.0824677240865066, 0.13152795567407466, 0.1881781946341429, 0.07426521536160678, 0.23132039464139995, 0.16101539353044658, 0.1763451880050172, 0.1426076963160945, 0.2775623369665286, 0.14654390194214267, 0.1891322292482995, 0.16931699782484438, 0.3326445309389925, 0.2265068144950161, 0.347170296254553, 0.22981135626921664, 0.2611212554720187, 0.31500289763629086, 0.18314892920458342, 0.2461592551253011, 0.07852705395271628, 0.19080955459609122, 0.1585314347366158, 0.08536475682790669, 0.3242506354123805, 0.2211012527259521, 0.1975334623652443, 0.2149835285174943, 0.11623832260461653, 0.32187019025072416, 0.22942027923736538, 0.30589284032324715, 0.28557062740886247, 0.30859654387756447, 0.2732535642223632, 0.23015689596412936, 0.17538134225691426, 0.2620855032093496, 0.19514051678098904, 0.18469212493945814, 0.1534469160418209, 0.2306395297441689, 0.17754982740887076, 0.24835087077898285, 0.197554442508999, 0.15702915464051398, 0.2713613998421179, 0.14192340575292453, 0.2602351616856347, 0.18901874878478536, 0.164013047172889, 0.11117416574624031, 0.18668348865025816, 0.2269212034230739, 0.2070959596019698, 0.11510729218645521, 0.2419599139620594, 0.13824860637307484, 0.3698171781381985, 0.2825927518372786, 0.1816792540981322, 0.23035620335540488, 0.15479710654892123, 0.24223243691625834, 0.23663756288311144, 0.2685582163933614, 0.21948437869995444, 0.1883087958781436, 0.22676524825192465, 0.05919695116508444, 0.3497829346476078, 0.17499720281060907, 0.24613953300784247, 0.1969408026650682, 0.2114713495927806, 0.17185325404812005, 0.24410106918458746, 0.2614534178438185, 0.21279750877233353, 0.27918188336673383, 0.22271258077780315, 0.18672642849231041, 0.23487946860807263, 0.10029360218911199, 0.209129091193872, 0.16862063883989023, 0.1339040107391429, 0.2364893178345591, 0.20694812568980084, 0.2645864020942712, 0.13935724199911775, 0.19601420459490423, 0.30173782898091933, 0.28041360515831526, 0.23736595851580608, 0.27188087767654917, 0.21030197188420482, 0.3114270214139048, 0.17376139156181994, 0.24211947829562835, 0.29845849707198996, 0.26268638548561296, 0.22932629132794147, 0.2282572274469555, 0.3545760161631686, 0.27815066453114057, 0.08146537404558891, 0.10632316329370166, 0.1929565131450998, 0.17300190269041113, 0.15175172620908245, 0.22451205272215063, 0.18004375943822631, 0.27774445182814894, 0.16555093170875554, 0.19617947249592158, 0.22274799881549, 0.23860812357753347, 0.21744536283273044, 0.21927348198422822, 0.25563828279108886, 0.13503203333427732, 0.16162327754865422, 0.23292778397551453, 0.29960646429685456, 0.12246475548562769, 0.2786452322701882, 0.2156327973081123, 0.27396074070950965, 0.22692048629956285, 0.21837704014771384, 0.1932439315445483, 0.24454863014977096, 0.10354313118825088, 0.1897479450964495, 0.3009279571166759, 0.19584766589954103, 0.25482567955941, 0.18891753411809412, 0.22865345815362387, 0.17761477645770035, 0.25396156022634864, 0.225667507594505, 0.11158992078912876, 0.3434116076527608, 0.18320312470533043, 0.22353322431944214, 0.13820954015620734, 0.160622742623789, 0.21864715321566813, 0.2840239900529012, 0.2507032620019239, 0.19037882865644914, 0.20432485966386976, 0.218474564457654, 0.2622230328448926, 0.30213016154122435, 0.21039707423942203, 0.24235206068115314, 0.34385074963635354, 0.3014969788537147, 0.254960110197117, 0.21546674671962895, 0.25562080927448105, 0.23972392569881984, 0.2366179130270855, 0.3002997026483681, 0.20920911714073107, 0.11531501427617304, 0.21017702926198834, 0.1880880748006392, 0.20553194085517182, 0.2876677954662158, 0.24179489529286502, 0.2892972778082992, 0.24227835377340418, 0.23548873761639313, 0.27409107604768934, 0.3132542558675633, 0.19536684559232434, 0.2509569766733254, 0.10725539456619278, 0.09504096245525849, 0.360539173768201, 0.2614227128560233, 0.20239423634150117, 0.3474073009350361, 0.2690776831561066, 0.2236710423791854, 0.2968005459549841, 0.1903212685955885, 0.3041557691281795, 0.15747839176761505, 0.2922983653592023, 0.22717656554523294, 0.219100717171459, 0.16051130809075004, 0.1483342807565577, 0.07985791401502958, 0.34505934822229206, 0.23653976654094508, 0.19012700551106684, 0.19217913727135988, 0.17043490090797067, 0.263996355458839, 0.22335616175163395, 0.19609342844030855, 0.22898632297268484, 0.0695333431978256, 0.2290496923174255, 0.059281952962764, 0.20341452287308612, 0.3476735734442995, 0.19613063241099968, 0.1809944565590794, 0.18580644318635603, 0.1884352809631234, 0.3247611468829866, 0.22386220357966452, 0.2163848245894563, 0.20984619995882745, 0.13790917522210602, 0.24236671715447047, 0.30028862754047175, 0.1736033478715491, 0.15304580050860317, 0.14532113033764238, 0.24049705377186067, 0.27338160779474563, 0.20307924108353995, 0.13360038590801568, 0.24761129992819436, 0.22375237522754848, 0.3625459978874936, 0.10928153547932444, 0.2805844902257194, 0.3096442665838069, 0.19097681699166164, 0.08583727774512623, 0.2065085644988051], "50": [0.2812892960208574, 0.20773468499485487, 0.19794881006258327, 0.258179159552894, 0.1560813721776305, 0.3235656162364647, 0.2120558250016107, 0.16491797134435052, 0.29719277564890406, 0.1983153390512105, 0.19649632055582086, 0.16582370834619023, 0.22057235770271813, 0.18332986618417776, 0.13017300994483874, 0.22917119388401988, 0.17842518051687123, 0.24815337199282134, 0.281539517345668, 0.2783871826820531, 0.19927197057734147, 0.2564230003411107, 0.23983798878446103, 0.20616441310856695, 0.20838502325048486, 0.20539303044788992, 0.2271208077854166, 0.29507116666796535, 0.16523082255614194, 0.19686301788265467, 0.21701319346755932, 0.2982041399455054, 0.34786749126650895, 0.1587131458814575, 0.18322730534241988, 0.2486452533366406, 0.2992085549975867, 0.20394613983625332, 0.21856349697272567, 0.25980285308640094, 0.14139970605890867, 0.22864095261269865, 0.19790328176342914, 0.3123404602695971, 0.18835882922315028, 0.14564067104215364, 0.20357558710404228, 0.2290246534400411, 0.2724573024651887, 0.3124843259663767, 0.23701637773798692, 0.35626033517879696, 0.16927619299953867, 0.26122930039323833, 0.21250059169939575, 0.1872232932512364, 0.2966734062113405, 0.15051137341056367, 0.21220370517214507, 0.20384466719635844, 0.2508886553075683, 0.22516849288184232, 0.21992505251810035, 0.22730641440840346, 0.16800115513751268, 0.2084772008757657, 0.2048540532486085, 0.2544725019806188, 0.2675649573888803, 0.16403856581763707, 0.2526642479683334, 0.21005126523204157, 0.20405407571660478, 0.2289493614335174, 0.2581196099096284, 0.22909760749495467, 0.17602109692370185, 0.2551716928410069, 0.1673532113321257, 0.3296791979912242, 0.17693272552709316, 0.1911710192037667, 0.2743316511809002, 0.25485700471602685, 0.3252171491452151, 0.32578240765055894, 0.30855972402320275, 0.28305741678712576, 0.15491433082199213, 0.17924134093083827, 0.27955694450379326, 0.25335220449607015, 0.21060349799568417, 0.23667225739575898, 0.24796724271384304, 0.17841465281852437, 0.20998616971242742, 0.17361201045608873, 0.2878085514973778, 0.2954399191450365, 0.25636375485631646, 0.1312697589606911, 0.18989457049818942, 0.24640362322448547, 0.19366177971360163, 0.3075565046212487, 0.34696377104471954, 0.24704150822626278, 0.20918123160402807, 0.28969998767033484, 0.3155857843816522, 0.16930525874805208, 0.23549432319294855, 0.2434597022809012, 0.17853397480039512, 0.2558193486263768, 0.21982460501391074, 0.25358206832060326, 0.19702823705417719, 0.1655734793981374, 0.16649821337270182, 0.23653032249229788, 0.20261429533196887, 0.2653991278210279, 0.20436433552204455, 0.18812793500487093, 0.23897270471874746, 0.15999696302938424, 0.1606969342371471, 0.22214994172301405, 0.2751317751016428, 0.22932590339657488, 0.19735662807326798, 0.18388821286184112, 0.10999263403464908, 0.27320305964894476, 0.3811941439616696, 0.19466593483167324, 0.22830372974726204, 0.2138045605705331, 0.2802218602261808, 0.2906260521124468, 0.2671659633403624, 0.19075271418684103, 0.1768391386610097, 0.28058498652430575, 0.2916092408789848, 0.25451336695439575, 0.29881500098227115, 0.20373675442999184, 0.08809896865668011, 0.2064407011159707, 0.1902445259328125, 0.2723166453521274, 0.2573155526319344, 0.15802656415751387, 0.24542777024264617, 0.24583919600145113, 0.13639245709941683, 0.2872448302424441, 0.22376030375003408, 0.162427947019368, 0.18707868669313762, 0.14469348345234825, 0.29837128146673314, 0.1818867023337437, 0.29982314806768423, 0.19749567343606272, 0.15522661976974847, 0.24872100863151697, 0.2268191582418054, 0.22234650531102612, 0.2436454095434254, 0.18821521835946192, 0.15951303314595797, 0.21935733452301717, 0.16434219036288678, 0.264739246228475, 0.23476311586939655, 0.380332138085447, 0.1731465942944568, 0.22364028878853218, 0.3050566832612168, 0.18486065751123068, 0.33541485103935076, 0.2255444906995187, 0.25499013776186585, 0.21458239934402915, 0.2581322880795459, 0.22344317752009416, 0.19259545813699475, 0.2627600985148239, 0.21299476154069655, 0.2282634648255573, 0.12340591858792277, 0.23354214926201147, 0.2943360131455486, 0.18290360558188273, 0.16818059177258654, 0.2041354529005458, 0.29571475736797426, 0.3025464423398656, 0.13599112146349332, 0.17219369014587088, 0.34632132756538203, 0.12787236985645034, 0.2583595634823031, 0.3416068503044007, 0.24239088344228987, 0.24192162982241916, 0.20934521553203658, 0.2627527840883703, 0.1614770699512543, 0.24315874036126, 0.16513048911301725, 0.3088410487833446, 0.19414108481051995, 0.23499933212105012, 0.17881158452741402, 0.31714364980158105, 0.22953418375183562, 0.21967225498585316, 0.16499544611862174, 0.32004650509697047, 0.3174235176289034, 0.28121773632551345, 0.2054365134218183, 0.25084377155413184, 0.2020378923016412, 0.19858941873352084, 0.2687182387269809, 0.190208669746561, 0.22573466691598135, 0.17366575190183223, 0.2220824849491256, 0.23164954568600205, 0.18659546769430158, 0.26271739274095895, 0.2185763130702863, 0.2804419324958712, 0.2591289949075892, 0.1563594597077273, 0.3694949815817701, 0.24697444490928505, 0.2417709801785135, 0.2384931409275034, 0.3072391752897628, 0.17488402605984732, 0.2412729470271303, 0.18387077218193168, 0.23185384880166873, 0.2920789486391401, 0.22247196694130214, 0.189532980255323, 0.27863772057154584, 0.21402028555219735, 0.17826804137312083, 0.28224918051771203, 0.23962746610058894, 0.3064724569463764, 0.2816629248978999, 0.2401429141465562, 0.19303556552272372, 0.22421580796514595, 0.21135756472843514, 0.3262445242633609, 0.3235943009385193, 0.23295215217601947, 0.23649335145222816, 0.1916009673517495, 0.2921767021880398, 0.20233989009313336, 0.170531137186111, 0.22216998230202872, 0.17866148129262638, 0.2825086320165465, 0.16567092960432178, 0.20293200540361, 0.2607296024729447, 0.33388156410845293, 0.21938960278676076, 0.2642746233020772, 0.24740072277799802, 0.21349728801649115, 0.25381956278952494, 0.21764254297699145, 0.19193013874678144, 0.21896277135420922, 0.30803051950420496, 0.19639194435963855, 0.2568683627852837, 0.2658769244986924, 0.3158745801939579, 0.19361913214985368, 0.21233537261901567, 0.2737415046911244, 0.16694701269760806, 0.31901939568086407, 0.18334115433438808, 0.16811159164630185, 0.24294140203663991, 0.21009405191633124, 0.24286944005169633, 0.20574891728887829, 0.24344988294001105, 0.24065222008868764, 0.22530329529850812, 0.2851796934269989, 0.27856400985586194, 0.277611122174111, 0.09811021950416818, 0.13978784202515065, 0.21978971602825106, 0.3367311009357399, 0.2343395344527494, 0.27115119813593236, 0.2739534110422772, 0.15030685317785678, 0.30088572606151986, 0.3134808293828986, 0.2605473207883436, 0.31595929053660643, 0.2038594387866661, 0.2204857803839567, 0.19410250016275535, 0.1736413133763277, 0.27302709827592364, 0.2516269031327315, 0.1978921777634691, 0.2243083937864587, 0.20108911616546116, 0.24539889957175032, 0.37632800524157584, 0.21335839728066378, 0.2912106640267234, 0.2005613675363117, 0.28181743103117696, 0.23278256616377582, 0.2287684154978723, 0.19057074246756323, 0.1794107461998107, 0.20078613713935944, 0.2402286782695568, 0.23453146049890303, 0.2624044095528941, 0.239376930240364, 0.23810684590860506, 0.19584004926245777, 0.3130815540072233, 0.23044234917139314, 0.18720506928854844, 0.2458525841537691, 0.2168970133917271, 0.25089572366072466, 0.2797524428545692, 0.26549644712602216, 0.2484823509707829, 0.204350770619732, 0.1982394724248776, 0.2021636630104217, 0.2190947738840282, 0.2704769073565234], "22": [0.28611841926582504, 0.167487527485339, 0.26312784720627613, 0.16191564559042032, 0.26796639668585903, 0.4108894181149847, 0.3686580607950618, 0.12563264250356587, 0.31819185353043405, 0.23862220711453863, 0.22120633825901642, 0.37765002918126767, 0.28971260824147355, 0.2755568788781405, 0.3298303338652415, 0.20977088092714358, 0.21951773077392278, 0.19804865325391555, 0.1385717694387717, 0.2939355201714891, 0.26718740958638404, 0.19477503975302538, 0.17274881508160053, 0.33300381866930734, 0.20881572688702765, 0.3630538306483628, 0.34652891696650967, 0.20184538793141843, 0.31487474611348915, 0.21818797229271286, 0.3662679090880219, 0.2592379133252791, 0.38318700113969845, 0.19528070800640315, 0.21597921507661763, 0.35452233407151906, 0.1306337608057932, 0.369031909445733, 0.24623903347204376, 0.23742565014609698, 0.2533615370692043, 0.12625605681319108, 0.06808595043999774, 0.1652542241229912, 0.30350490151396586, 0.24701824148346294, 0.20533195615736352, 0.3220791663878772, 0.23112435810368936, 0.40399427495991364, 0.20874754632823284, 0.2863769960513945, 0.318046635697007, 0.2519482516092857, 0.2691847575019064, 0.263112844017815, 0.22393439593830847, 0.3152941905756888, 0.20326782827702436, 0.202858321671486, 0.3070697162691327, 0.32013979206822135, 0.28469077793827974, 0.2569292207659434, 0.2606802228639271, 0.2918144461436728, 0.3574414194807492, 0.23951223961630716, 0.17759031980535459, 0.2601074159058325, 0.3158492138809969, 0.06691646288192375, 0.32253316250537284, 0.2770231862079729, 0.11459011591957556, 0.23727602187157104, 0.28120866629456537, 0.23490481768963206, 0.2098130229821212, 0.3922648583979622, 0.32761048224210826, 0.13903163149542377, 0.2061305518408099, 0.3124122152075962, 0.2606725322866308, 0.31644513953445613, 0.2746136721694721, 0.18916928893985877, 0.12555116931489899, 0.3146308741694406, 0.3033373249948507, 0.16730995657668749, 0.3701200546584361, 0.27733836518023813, 0.21725688710366425, 0.058912838611086024, 0.3530914774380041, 0.3106506414484157, 0.3746184929236409, 0.1801813621365095, 0.232845764927315, 0.09010495953801283, 0.30489532455216345, 0.27175148936297805, 0.11993622614096483, 0.11826636519064343, 0.1651921376079006, 0.14253042686871742, 0.1722177788018911, 0.2731028976182583, 0.3085370545193968, 0.39361309322990534, 0.22567505847220237, 0.2941976742450981, 0.20423855430506038, 0.3385761856520718, 0.33039441490233085, 0.17028883950821885, 0.29998018059995285, 0.18644051733600506, 0.4297251781487922, 0.3309113234495055, 0.22823720412785506, 0.16793947371590007, 0.20393928633399816, 0.18280567680560258, 0.2951698857354437, 0.1598876710300469, 0.12639454615330362, 0.29369702847163687, 0.44067540621284695, 0.24459479656529404, 0.28358660015582215, 0.10540942797508637, 0.0717269349588497, 0.1278613465670268, 0.24130776902182394, 0.2939292139901712, 0.34709967608959613, 0.14363849388149272, 0.34550795685404806, 0.21047567483520105, 0.3576573106938018, 0.30405401116409053, 0.14210996968875036, 0.3120337066138052, 0.26286188010455425, 0.3272128645955192, 0.3130138982264145, 0.2325745926868959, 0.13978619248409663, 0.24902874871960773, 0.22413240635423765, 0.22230549483517142, 0.34562717132181375, 0.3295876355476658, 0.39509972882811983, 0.28742183654015785, 0.326115374419398, 0.31104400769562923, 0.17257141494270214, 0.07065472081140055, 0.30897358250169954, 0.31018201471104345, 0.12730088123155456, 0.27787313696463545, 0.43589512202400793, 0.1676126898889406, 0.2561120805054595, 0.3390177066769654, 0.2778540026894363, 0.30059995668338707, 0.21731130415640737, 0.27698770286157726, 0.31546099246975023, 0.2571041218825689, 0.26235114791068276, 0.40206047863545746, 0.29622644177005725, 0.19495194219033657, 0.2575633898549827, 0.35329083080752693, 0.1502165589507815, 0.36089246990904433, 0.2463947781279613, 0.25848915030210656, 0.3438955285335816, 0.30915255833042626, 0.36064535507579726, 0.1513004477089389, 0.23599370433621658, 0.18986693355196888, 0.26014127267947773, 0.28183141620987134, 0.10235680250531488, 0.17202562716870412, 0.26740438393795896, 0.2643538811972549, 0.42756274114032095, 0.3815491269567911, 0.2555848035786896, 0.18632629759799632, 0.196716558145263, 0.26318522737923167, 0.17039415103325414, 0.2933317372398054, 0.2239924367611056, 0.3007857997873363, 0.10508187760772784, 0.10329842443782687, 0.26678827437364333, 0.36142023952615193, 0.2875525021004395, 0.24048624876959493, 0.3288339971540558, 0.28884547846325315, 0.3633587137171064, 0.2306718105154095, 0.055611620434213284, 0.373269492601017, 0.248460043440789, 0.19670715868749708, 0.13912835490059028, 0.22129175809997145, 0.22899698436569582, 0.29991622753241803, 0.28373960521158986, 0.2780212250000949, 0.3561643052526561, 0.2082697082728026, 0.3075465230845365, 0.26776341539069426, 0.2923394628500604, 0.15810656637660914, 0.3682505761978076, 0.3365294385736535, 0.3937431071637896, 0.3938969418330443, 0.2575987892911758, 0.22371940171981797, 0.18839295597943104, 0.24515948683447472, 0.1542448008541091, 0.32163991396920233, 0.3366387557113352, 0.36686194985929266, 0.2019632459711006, 0.12292150195532152, 0.1641597022377438, 0.32181965434656035, 0.3712945170163963, 0.3613248346878847, 0.3376735927872684, 0.2196250897285179, 0.36965721004671076, 0.1925417211905148, 0.23171467769387064, 0.17528660436081941, 0.08211008280371926, 0.28620168578537003, 0.19293624304177923, 0.27380710399057406, 0.2766330718308157, 0.39188327407716605, 0.24112806670716214, 0.3658469650868528, 0.30404549439568773, 0.41007496857659054, 0.32064464570344603, 0.25464269539126577, 0.1639293467114673, 0.2316830896637091, 0.1624155646505224, 0.30152643077988983, 0.35802547333473206, 0.38520001079130123, 0.17859956322278026, 0.27099321922051656, 0.29864950475622587, 0.3368573736877686, 0.24803933817522703, 0.43963795136962236, 0.24525769608330136, 0.3253510531841827, 0.15076488040471223, 0.301927439114535, 0.1404623344787048, 0.3832179109058791, 0.2739375587131276, 0.3086135656547435, 0.2303805070311523, 0.2305086804289957, 0.3816943577070996, 0.28002654015305745, 0.21794816804757858, 0.3262007519364938, 0.2931265993316408, 0.22184710907693028, 0.2475370889050862, 0.28073049468158967, 0.28301711731191337, 0.1815044014132739, 0.05897517747472206, 0.22543133206306284, 0.20667620732843384, 0.2540731761249394, 0.34226849435331824, 0.3818714294174743, 0.10462174761085308, 0.21975877308945604, 0.24602627670187613, 0.3181213858649347, 0.29697066371146946, 0.2673688511196424, 0.14655141171196084, 0.17515016751372678, 0.21685588594264055, 0.43009962654985334, 0.35259044338675694, 0.23497219639821662, 0.02884235764047838, 0.40192118032409835, 0.3120602491427088, 0.4165602098895379, 0.3427130075408719, 0.15664840834981553, 0.19206834964279507, 0.09983801876552197, 0.3882075201669991, 0.1029268505166336, 0.2045463867827516, 0.23155542545617908, 0.11736648330164799, 0.29488370907376477, 0.40260215258868065, 0.10164050298078066, 0.22085694838555595, 0.2485263935409494, 0.3243698923108837, 0.08296008415217199, 0.2423351848035212, 0.29151696489899737, 0.2805143026977971, 0.2934860165354224, 0.2768624001973977, 0.32484268423807244, 0.24736454984171774, 0.3782384350478538, 0.23556349668705076, 0.35413047338263076, 0.25862619645258406, 0.36420373652146637, 0.2978174091966098, 0.18733374128904326, 0.16178907005384033, 0.2640727885484246, 0.3654214840256343, 0.3419126081857691, 0.12707972966150252, 0.3446920391958007, 0.18035387703565176, 0.17610230752267908], "28": [0.19335226975798608, 0.33473049769405716, 0.2904867095608204, 0.345431040775908, 0.31464534161349095, 0.2325191347821745, 0.2551246605560427, 0.3240676808032849, 0.10064178865908768, 0.28470060269631875, 0.25864558159712897, 0.18305327446624328, 0.11541115772574853, 0.2562162850590619, 0.3101447335725297, 0.05035228474945392, 0.35123060959868996, 0.3551157546547861, 0.25293221345844674, 0.23338144293606825, 0.12384636600327685, 0.2076037729827724, 0.16032936122064237, 0.1985917832330015, 0.2943695540059882, 0.2949410302106017, 0.31467982599825334, 0.19090420643969438, 0.226986026338997, 0.2874172007852087, 0.3545750113150759, 0.33374798061005206, 0.3278547804959159, 0.3494046797888135, 0.3423126748811932, 0.3412447481051903, 0.12744128292756776, 0.13360341315508237, 0.3673076959155825, 0.07000590902487001, 0.38404851687180613, 0.21020476703140767, 0.33993771246292687, 0.18018845366633232, 0.055702781177890785, 0.21609691698361572, 0.10945995198021335, 0.08648741350669661, 0.4056779609169274, 0.318931984691246, 0.2685885376967809, 0.27590689636574484, 0.40349838367692986, 0.20799384912301166, 0.11743097123599722, 0.16450190994587438, 0.1898903472074704, 0.36807010889653247, 0.3263481434627846, 0.38948213403436716, 0.30853147328670516, 0.2635021315214054, 0.21760998015911676, 0.21663058234396387, 0.3279066875918937, 0.3131909677216567, 0.32100158768909687, 0.36553195324760274, 0.19161487890907156, 0.16286907273582454, 0.20320266490784542, 0.3001070442572637, 0.223667956289406, 0.15343269222041048, 0.331337265532694, 0.2974567445180789, 0.2648745816550017, 0.11819790912744801, 0.2570553340850187, 0.4086865527525431, 0.2136187406858704, 0.18150566862903664, 0.19811940637816666, 0.2119116125556685, 0.22255230367023496, 0.3052857932095393, 0.21855160452944708, 0.30388984747097647, 0.34024467055426305, 0.3190399573779439, 0.263560100330032, 0.31086240034148593, 0.2215240159296714, 0.19515071265755107, 0.13056623401242176, 0.09682915912703506, 0.30655056255539626, 0.17617122311434588, 0.2612164122262099, 0.24535158314997246, 0.09431136105261538, 0.15871063944018393, 0.36799326527064785, 0.15175273890862595, 0.1869891919233463, 0.33801497023307236, 0.29316186221447327, 0.3046134832180281, 0.1489197840327394, 0.148466691701812, 0.2510899039748137, 0.3210436160440593, 0.25387379625695383, 0.20897442945215494, 0.34193200558061526, 0.11986607614516713, 0.3404127598297422, 0.3003686436703764, 0.3823714361521171, 0.22294804258156817, 0.33700363354804336, 0.1540978086912313, 0.28356499549610653, 0.24549098624593016, 0.3036167292798378, 0.2998352035385352, 0.15383801635517624, 0.2642888219777548, 0.4072294420964684, 0.1981010387102529, 0.20701528569234798, 0.16553474195171577, 0.1435416304431175, 0.23233628735867376, 0.26689347489072085, 0.19716802750827436, 0.4050215886337541, 0.33317737809738257, 0.15519832599709701, 0.198737409716793, 0.2885688495051822, 0.12253605400896668, 0.12564900872281723, 0.3491082162509609, 0.35376095408020675, 0.31317930756121143, 0.30266764147916564, 0.3963433572730589, 0.2690672569399664, 0.13955071326704901, 0.2695077785659322, 0.1522725794102126, 0.27572210377651846, 0.15792845830018262, 0.32616013298947266, 0.2045517461928838, 0.34685343510578454, 0.1530885375277335, 0.4484954181338282, 0.34608644494148644, 0.3148961426680973, 0.1443225541012951, 0.282138729066248, 0.2476401292071634, 0.10715528365048085, 0.3498136411513091, 0.19141620786129931, 0.15848768433385357, 0.27515860168631084, 0.21016706342395305, 0.33358995432627503, 0.3456076959333851, 0.1873796632294597, 0.288679520662697, 0.2697836747313806, 0.2938212504382195, 0.247476457044224, 0.2365717285344376, 0.2519326161706145, 0.3831100360173266, 0.12042437495899351, 0.2040267512600267, 0.3034141227336723, 0.17015377163015005, 0.14227213748891496, 0.3037489148733109, 0.43628505714009236, 0.16078766993491073, 0.44069812936735214, 0.20997650937182746, 0.28996831805799983, 0.306314792005086, 0.3598919419924181, 0.1528246616374072, 0.25067590597813605, 0.23629925373649233, 0.34889938539157944, 0.29768181444153385, 0.32090484540585934, 0.3312000149316009, 0.344889530778707, 0.32293786179614975, 0.20773591441410685, 0.14315337387785357, 0.15615507677308624, 0.24903610927263975, 0.19382427443294403, 0.16024055307477228, 0.19898015899296664, 0.22353096434347464, 0.308184767370422, 0.15474316990952203, 0.38234989851551243, 0.22615331975495304, 0.15101054641088413, 0.23615378042043916, 0.15527211340395886, 0.34664904667340135, 0.17120219806660428, 0.3187714504769497, 0.3348441011661782, 0.13090747757390148, 0.2767945331019959, 0.13361500356855138, 0.15772066628542075, 0.40719244398770993, 0.2816808159290197, 0.2481209691708675, 0.2778664430334541, 0.1242390315973778, 0.3509318125347735, 0.14600412854855896, 0.3511673550473049, 0.37137412450158386, 0.3362360278768704, 0.28136351307584057, 0.13977835928304116, 0.15698673331645968, 0.2890415376879993, 0.30813848920510195, 0.3857823954918951, 0.37506631953725866, 0.2312333178925708, 0.29097321336883, 0.2410172233364489, 0.2526488283770847, 0.3170542917979935, 0.25791703283195205, 0.3116804850467004, 0.2289497194547817, 0.09308500456782924, 0.3898627943415255, 0.19273815106761763, 0.2659077110324553, 0.1422524753383535, 0.34621526626738935, 0.15880621568747458, 0.1368399896338939, 0.32567975866863863, 0.32226779972547304, 0.19455221923976093, 0.2935329216053466, 0.32809979057003974, 0.13282252744954778, 0.3601235067049502, 0.43291842825567856, 0.364414183866539, 0.34000972044956096, 0.17901325364579315, 0.2612285608633211, 0.32150465617195795, 0.35594885321386593, 0.24777863247665594, 0.30624233291690045, 0.30575839774565594, 0.34984269057653167, 0.2012329836807544, 0.21849509378429047, 0.1301467317169573, 0.2769423821822105, 0.3352329525047634, 0.28482659192941717, 0.23123742494162514, 0.11123561818893629, 0.34839695445476465, 0.29677549549032695, 0.26750320920693527, 0.3024530181538285, 0.34628531754257114, 0.16807841269778145, 0.1994298979420483, 0.2902162184215615, 0.21894269815019962, 0.3156589127279625, 0.20600585639017444, 0.37626148159049766, 0.3565712536647587, 0.406242810475978, 0.2444797288259555, 0.3247661346373238, 0.1870857861189548, 0.2826464914423834, 0.3596893137534259, 0.2611108382218312, 0.28854695979652173, 0.24541784697554916, 0.366540210538902, 0.1822109384892407, 0.3692515300933645, 0.1224327528086206, 0.3386494873021786, 0.3186035998727045, 0.25601457041733783, 0.3356360387849783, 0.26371088351198446, 0.3533075313758753, 0.1725622666980125, 0.39652483824319235, 0.0962625760208108, 0.2117864379807766, 0.40483793531297224, 0.17603877496897033, 0.29894721001718844, 0.019571421251051678, 0.2838944618202063, 0.20694889577223058, 0.3426161825494133, 0.23526422026757657, 0.22125428936259348, 0.36575061759823085, 0.14396041218737832, 0.18744943346302118, 0.16495494891420828, 0.32820047322309864, 0.3716925437017416, 0.30642138911431044, 0.24322963133827485, 0.4103047367603701, 0.26066754155910066, 0.28066665632481785, 0.3319504769812757, 0.2792376241115424, 0.1886098261904406, 0.28776212404224427, 0.29954775993690597, 0.3783625915201116, 0.19613976419121235, 0.28219727627755176, 0.25073824808388456, 0.3297339708432824, 0.2437468499339393, 0.37850423165750796, 0.25232698305272433, 0.3210422594682826, 0.3120699588228867, 0.3066815416565991, 0.3280718631700773, 0.3891941960139728, 0.364244262704249, 0.15876906756207002, 0.145826014123892, 0.30625020144880016], "41": [0.22822995789931078, 0.31569640037221924, 0.15166248594110499, 0.3178920439912321, 0.33595342505147313, 0.3713594263637758, 0.21756439896774943, 0.19408532088201821, 0.18918602727470268, 0.17534760303460897, 0.13318558885538595, 0.12659934029466727, 0.22186034755144535, 0.3446230446451808, 0.28298271563303923, 0.16884360932240255, 0.3022855426261627, 0.2616887710971289, 0.06632969751705622, 0.3263396119910049, 0.09671997781544699, 0.3156852893097855, 0.3095699575591082, 0.20947199688068582, 0.17959520179051808, 0.13606248305026764, 0.22026445830837574, 0.3776490699535028, 0.3685082255588579, 0.2708948096706668, 0.14173031345162285, 0.3289673825808501, 0.21577800982093215, 0.38973685120031876, 0.16548873305713452, 0.1931726184282319, 0.21578459348459822, 0.2676660635668953, 0.3209915212591255, 0.28869213698890284, 0.14275905955012824, 0.2321038448152172, 0.26589404109402065, 0.1341696455622979, 0.20030217828555488, 0.25802861848033865, 0.24688441618361442, 0.29972929701265244, 0.13313925438856272, 0.25859180304054924, 0.162562595268574, 0.20846878227084928, 0.3711931213571033, 0.3759690655298697, 0.2668585994064304, 0.22759968847172868, 0.15573914289097524, 0.2734410739855946, 0.28544024771859033, 0.2899725745394739, 0.29167809468809774, 0.3857713133924448, 0.2247045619973575, 0.06274483052653435, 0.23899200509785307, 0.1639198993216955, 0.13709577886492308, 0.345755101622272, 0.23025653722299486, 0.17187469990414425, 0.2570029588036106, 0.3636591975307291, 0.24652953800678637, 0.18727517160458163, 0.15551266587377077, 0.323811958566027, 0.20963271698104247, 0.2544273581408288, 0.13564579640917726, 0.16798743991319678, 0.17101258828842278, 0.30366891858378314, 0.32346271352903166, 0.17877208989216067, 0.3233901340428923, 0.2968347177876487, 0.2845115729612841, 0.08559412463657244, 0.1903284381462077, 0.152315485125658, 0.22995212814010413, 0.11418446112254516, 0.045663887598604964, 0.2466810947822536, 0.2790940967197511, 0.19706393205417225, 0.39085061813562033, 0.31687017068388296, 0.2003953417193447, 0.37787152292744924, 0.2448034109434422, 0.08309786135372806, 0.3100925325551873, 0.29298296775354243, 0.3351435052066455, 0.3597727527179803, 0.27621321764713064, 0.23314094601214677, 0.09880824302332089, 0.16841684017213204, 0.18340492306894154, 0.22849268255976926, 0.32263964686904195, 0.19654135013721338, 0.3607181831218359, 0.34344748404281866, 0.3341349495445236, 0.23581476745713312, 0.2672043028319895, 0.1640617215318777, 0.43554860285021674, 0.3199507904843497, 0.32504208597815554, 0.19310770321640328, 0.3413493177781788, 0.21386522821317497, 0.1746275532171081, 0.3670389650845308, 0.2851015674776314, 0.10544904311787306, 0.22692156310221193, 0.21573873588380207, 0.3139645056713622, 0.1615635626575067, 0.39289860567673673, 0.43096073122297224, 0.31831244180916085, 0.35909095163284055, 0.31200306149367996, 0.2285832284140607, 0.42113998476049475, 0.40182867102717423, 0.198287566070158, 0.2625394063045762, 0.12686974664101047, 0.2466168499617456, 0.2788663684956426, 0.3860276135424996, 0.24007406332258266, 0.2569858268155676, 0.3505732995435767, 0.163963271875929, 0.27751309798843204, 0.23699655966085964, 0.19330954488713487, 0.1820478329117091, 0.24575732499502392, 0.28805087400521284, 0.35459889429585645, 0.3904757829658783, 0.2409838338233808, 0.15764722411918475, 0.29024910355194095, 0.18172846058976475, 0.28293100056302556, 0.39033771329651623, 0.2724844262632617, 0.1407156534818045, 0.16466432078699828, 0.299574839625062, 0.2744859399858392, 0.21191886510318853, 0.1490419254320483, 0.17722439428401737, 0.2167371773282595, 0.2277284792822397, 0.10750243982725052, 0.39422536932896046, 0.10524544991362524, 0.3149397502789487, 0.2807556347047175, 0.17511200892151574, 0.23782133912406797, 0.33679826218107095, 0.23751055859434972, 0.3407910690839953, 0.2550893464987954, 0.19282487387604227, 0.4414984099824829, 0.356323210665123, 0.3387368642429418, 0.17916780807694266, 0.2054278452228087, 0.2754694877951447, 0.196929510195652, 0.1885627161561311, 0.15917490266516857, 0.13052813029614815, 0.35815910676758406, 0.09987706516074797, 0.08749809986585272, 0.12899586385966816, 0.18008975809302968, 0.30279350364669605, 0.192274064216821, 0.40430225604531156, 0.18553274160740862, 0.2425021872190191, 0.1470106458054828, 0.2675491137594443, 0.33358723486313613, 0.27067841730115194, 0.20087936217162292, 0.23719069581143865, 0.3504372269847612, 0.38883482874499287, 0.287285498224195, 0.247893524527249, 0.1423226425109306, 0.2521092374912182, 0.3606104305203117, 0.24495789806313367, 0.15425673568364381, 0.36703255712039035, 0.2894272542984084, 0.145416734249422, 0.3357271969588139, 0.07797415446414832, 0.12483413570283942, 0.16375613429750446, 0.383560679696462, 0.36128425860944197, 0.35040876472311266, 0.17817385826976115, 0.3263001519020626, 0.19553473768797902, 0.21819292595324236, 0.35037394840610886, 0.257167710976053, 0.14079278427443895, 0.14671915830484836, 0.15812268158789294, 0.19602241808849682, 0.19572258886761873, 0.31547875748930926, 0.3923848217795907, 0.29989908554385614, 0.3053315250017136, 0.22540921361624422, 0.20757680661882844, 0.13801795436685904, 0.21995852728943333, 0.2469068135821521, 0.3791544402901554, 0.3956284416189755, 0.26351374939518696, 0.17493648988739136, 0.10606414829553802, 0.2643110394978809, 0.18806081437161584, 0.36133422430989115, 0.41912686910795766, 0.34460553947958283, 0.3803481676160906, 0.13438953301498818, 0.32972872898802214, 0.20363534140692377, 0.17645631769045847, 0.3033912101867471, 0.3358171534710473, 0.1557312641688303, 0.2698288494904512, 0.30182298122558804, 0.37546889540573847, 0.38448110619063497, 0.2634204929924772, 0.13854050472022034, 0.16213724325961318, 0.34842184247021274, 0.3124852271673262, 0.12318917353662381, 0.24214958336650064, 0.19834731832487193, 0.2583594382535944, 0.29360747089679484, 0.25645618939783715, 0.19040274599986406, 0.3354667166184193, 0.26551906998152297, 0.2500542421378789, 0.16728511745815525, 0.3601867957946211, 0.3317521440674142, 0.150377282152218, 0.2759017485977912, 0.2808573416106593, 0.2802872840651306, 0.24190922203771997, 0.10900755744220604, 0.14921847236528837, 0.41215936705253936, 0.3248821119210011, 0.3591485632460207, 0.1040215289087532, 0.20832824964835853, 0.23577863826141848, 0.353966266743974, 0.4075979538535067, 0.2957054492512406, 0.0864891316846192, 0.18510619122000455, 0.18327153497564638, 0.24553569206551468, 0.31600160928578785, 0.347533046798482, 0.19913393508052185, 0.2954095361347793, 0.358804153802669, 0.1391997121696215, 0.12251619318408687, 0.41843149760690007, 0.31299193967537436, 0.1824993573334582, 0.09588915920307398, 0.11051625267248767, 0.34496546539367695, 0.44333069257434193, 0.33961076081619335, 0.3636818977001139, 0.24535345128355998, 0.21511789489807362, 0.27770132018952676, 0.22212442781190825, 0.1905001056985872, 0.315796992756534, 0.34098988272529057, 0.4128258922326642, 0.2175286799407439, 0.2507731722425762, 0.25543895674963635, 0.304893934692461, 0.4069937873627482, 0.22440759147678277, 0.36839646227287115, 0.32462770826011905, 0.3081204449268382, 0.416556950248707, 0.12192383813551955, 0.26510019153384456, 0.22536527920979893, 0.2297377898356813, 0.17533279745801508, 0.3283781738580515, 0.07773289267997818, 0.24676322631900985, 0.32333701232835615, 0.3277358722401795, 0.18311249115595982, 0.2457838040065441, 0.31981504306820085, 0.1300248321239491, 0.21588832474826344], "26": [0.32648065727176545, 0.22266819264076484, 0.27288912785393454, 0.3091126531836237, 0.34109066222883816, 0.3102774218953938, 0.2389240530602974, 0.16129249427007405, 0.2433364213051152, 0.2042475892578468, 0.16098826989660217, 0.30226551581351213, 0.24709744210344722, 0.21659336750996144, 0.29173699477015147, 0.21566655662680773, 0.2941215111208705, 0.11042348395048154, 0.2754672909804932, 0.2953801580626578, 0.24932938139906666, 0.21155893795769715, 0.203760892941546, 0.211279877449573, 0.2539937099661181, 0.17381094886429194, 0.20396677767379787, 0.2734758702138192, 0.224636446187961, 0.2253157216480939, 0.2281062819705672, 0.14496393429177498, 0.13923929306317223, 0.3044385227766025, 0.2912814537832185, 0.35417839393346473, 0.32985944345228785, 0.2739215646029999, 0.31787503358106467, 0.2589534491527107, 0.2443725851247143, 0.27604235984199543, 0.27927554565655727, 0.22049512287146864, 0.29914070217640865, 0.25351891887847927, 0.2737551017673306, 0.297771608560281, 0.28954207822175715, 0.31688531640060413, 0.21588541360500582, 0.16686658405829985, 0.21040466525574064, 0.37331320394462025, 0.2976631239563831, 0.17779505527395448, 0.29660251605752785, 0.2860058332787115, 0.3160930713628361, 0.29707837383805047, 0.20586591662861306, 0.24401991366333828, 0.2532132543263582, 0.17079588632919498, 0.20626594973812248, 0.13452200440832263, 0.2520239948707072, 0.2939005664282693, 0.23533425354462711, 0.26666337818084995, 0.18560202250181454, 0.22413352394471453, 0.20634540088646336, 0.09071376271059554, 0.29285828905826594, 0.2471465483476878, 0.15337004727854656, 0.3218081278206777, 0.3425258691800861, 0.15958899321768386, 0.2800784211717147, 0.2356114924910728, 0.29371763170900655, 0.21381623440506597, 0.25485780678669767, 0.2751795019349265, 0.2499487602698535, 0.3343456604518655, 0.3348203801191422, 0.1586818096670051, 0.2636571982954939, 0.2032929600408384, 0.29547197420061294, 0.3151009397593283, 0.23646057497235992, 0.3043186713298811, 0.32097685000166, 0.3145491872251546, 0.29657298957376155, 0.26529786647717, 0.0980310404021117, 0.3484428698689341, 0.28872264509745715, 0.2828019932187562, 0.1963604374940631, 0.2154045698855179, 0.30648163637767234, 0.26571510743168664, 0.18910890324896532, 0.2566911923445384, 0.14199528590934532, 0.1860749637756889, 0.3138409337137388, 0.2866272832339906, 0.22865141171620515, 0.29653242340932673, 0.31582928340452154, 0.31794813278154227, 0.2946041660616395, 0.26498997204045294, 0.3799943409719257, 0.21128809702588913, 0.23317017966462023, 0.22380136519733757, 0.15068736050192338, 0.11774389516084632, 0.2634633196228076, 0.2729211711200001, 0.31929534846158814, 0.3002027473676679, 0.2791764692974929, 0.20305285756756355, 0.2073539032564884, 0.14603602329164386, 0.26495942011841284, 0.24552448703087446, 0.300674855630666, 0.3054527373532473, 0.2964333896761757, 0.1923202885297147, 0.326413446982408, 0.2920618325176673, 0.2755663724203909, 0.22801853377344683, 0.23660926540904048, 0.18001503719888148, 0.35803062286885823, 0.34759150332058536, 0.3411404687460615, 0.26089322610159416, 0.17290951980893657, 0.07495083283953109, 0.24562885559590183, 0.33238810061003893, 0.15691050227517314, 0.22340337061912977, 0.34826582933886446, 0.11850313099466427, 0.21848583858746443, 0.29513930402253585, 0.22808996049885763, 0.1344842581221184, 0.29504005491652235, 0.1975307841166216, 0.24091649871146206, 0.24915724596321326, 0.08745952625597314, 0.22109461228370472, 0.2826315449623184, 0.13081974161596865, 0.2658669975994439, 0.1634339037736689, 0.23550633533186294, 0.27306462203072585, 0.23444725378521214, 0.17803913707413238, 0.22536064594089897, 0.2853770813965201, 0.19026076638675038, 0.3016319525102146, 0.2630738722223599, 0.28693014749811435, 0.24014076057109965, 0.24753966934135746, 0.3345364334556209, 0.22045412323715818, 0.21158445818766478, 0.17670826760626202, 0.17070666965414824, 0.20146185255425691, 0.2857782588792133, 0.21019441424929133, 0.2095225653795073, 0.09892545435803239, 0.1457057972027308, 0.13665543318685247, 0.17432940404704883, 0.2476229688879053, 0.2581391119847654, 0.16795781225639358, 0.3799931083628937, 0.34497499177235413, 0.15124975873431926, 0.2725631071382262, 0.1981222539593721, 0.23603115921151027, 0.29491871543219367, 0.223995656766668, 0.17661719092667633, 0.23603800219546414, 0.2936216615334657, 0.3411990703889484, 0.15613983590134103, 0.39756337390140806, 0.3372690370226143, 0.23316649542239531, 0.31905262809318, 0.23415150119360098, 0.2506074925040997, 0.38381995237486793, 0.19818482872093196, 0.1364322405424849, 0.27123835824739756, 0.23500099423464937, 0.29314042451534944, 0.21134125906347553, 0.17745006826670404, 0.26679457668875156, 0.26413182252332085, 0.18542481316213225, 0.3014992824789851, 0.19414857734449434, 0.20267272033941583, 0.39471750941719586, 0.2475902220664688, 0.4001958077905306, 0.2576619476844617, 0.07477440246765231, 0.30761954379572604, 0.26339989460814534, 0.2639862493259489, 0.2513259006462742, 0.1898078531261566, 0.19989829230523934, 0.26215392009377786, 0.2627944308998176, 0.3080022679614191, 0.24366561996292607, 0.19327992459504076, 0.27820456479093497, 0.19226764365276014, 0.33475943802438346, 0.15705179340938918, 0.28379982210627797, 0.16233136179074817, 0.14714122277765312, 0.21213736609257675, 0.26183236923389136, 0.2536417329591514, 0.2615378777454539, 0.2789623709456238, 0.26358474890891, 0.30506320149526334, 0.17595344931029047, 0.2500058197946692, 0.3220857993740054, 0.27709555783944056, 0.3984679319459142, 0.1916158156731683, 0.2554433712446697, 0.2734776152629651, 0.2684522895276953, 0.3338866423677345, 0.2983528120478553, 0.3163501541636558, 0.22398571376085752, 0.32792763123081387, 0.22168131412303377, 0.31246762802792794, 0.27800519808376234, 0.29298413945456453, 0.26816681355408123, 0.3023596503229167, 0.14999826544782627, 0.2936709594368083, 0.30054016461390587, 0.2501762247450295, 0.31240626526568044, 0.31223155633604, 0.2348845526256727, 0.3025760745240559, 0.3707631533104355, 0.2939762545557571, 0.3391682596153306, 0.105368845585493, 0.2861479313128773, 0.2210644013885029, 0.20969021157851633, 0.2517827860408101, 0.09541452728057132, 0.2621307757804556, 0.25136886972467987, 0.1979247529631467, 0.27947942298582196, 0.2940067241896968, 0.2728526598236662, 0.2865758741285174, 0.2973115290546571, 0.24707246799823296, 0.2878909227066788, 0.23759442233618414, 0.28532685231709515, 0.26270501007190705, 0.2691383943368696, 0.3393393268532207, 0.2784413362746226, 0.24698425864211432, 0.2744358054663478, 0.2864624286770876, 0.13727620878673202, 0.3414414725588289, 0.29406178332524485, 0.11004789490398294, 0.32480172318193584, 0.21777975709462555, 0.3315788366233662, 0.24505343377890806, 0.3690866734052142, 0.14469146662645602, 0.29616529015835025, 0.33058675969418116, 0.21200513784536262, 0.24446549225330685, 0.10630189734357832, 0.2394738378543164, 0.37025690048657933, 0.29245055825577404, 0.2322188955076863, 0.27279257473498975, 0.18426150770639427, 0.2795014292474441, 0.27261498637845405, 0.11767510897813425, 0.274877029520977, 0.3510873861610658, 0.22604041637152988, 0.18645297074510925, 0.16039352709350974, 0.26596770546764703, 0.25776678275314596, 0.27677094216199144, 0.132771375518914, 0.28912724017167346, 0.17243562944633897, 0.213204828317089, 0.3139623119886088, 0.06860134601420688, 0.28038656460072725, 0.27348264778535997, 0.3236190918440646, 0.21583000960734663, 0.2657930578357702], "30": [0.13559657755436674, 0.04916105332725071, 0.13382584726586053, 0.22079208543350246, 0.1792318852833977, 0.12351538087117815, 0.36697622132490315, 0.3764021340823387, 0.0574435255894609, 0.03282508533868659, 0.1392381545391137, 0.36392399831554806, 0.30823915723087614, 0.2890522061576961, 0.11520531231042601, 0.1353805651292466, 0.12779597879280824, 0.20317635982894902, 0.24496726020756418, 0.25351455617813434, 0.25338646827876726, 0.2521491909003311, 0.2945934560249258, 0.2513684859238915, 0.26623913733303517, 0.2783364914527853, 0.2802596141965148, 0.27363712036262694, 0.2265560497864996, 0.2934357414340945, 0.34369509671902637, 0.29251191455590464, 0.3025192036892092, 0.36436271333937587, 0.251016383963653, 0.1441378787693216, 0.1692823882258451, 0.2878427248416173, 0.2875077069554964, 0.29468384150588717, 0.28792815254606136, 0.30580834462314366, 0.17305218121344604, 0.23993609394194598, 0.2349180402560513, 0.10560900641525055, 0.2679035086638309, 0.1320700772037192, 0.2632972558227419, 0.34934906818083405, 0.343827371745063, 0.14585075148988103, 0.24658669593130536, 0.2645551428814742, 0.2975811479653077, 0.15591312335955354, 0.18477229820814917, 0.3816095046076463, 0.030792752381337583, 0.16386880208013602, 0.24064988096953052, 0.2192048327735688, 0.3617481188258267, 0.31131744046444243, 0.3112285379889503, 0.20960266541696976, 0.26128264305272336, 0.36130093394128754, 0.3219205090649273, 0.2556382936438238, 0.24937754149506453, 0.3538581447526323, 0.08239544699299944, 0.09457443380852167, 0.2473778680971175, 0.27166330162353736, 0.21908705829951142, 0.1552245834160739, 0.12685509615310492, 0.28906056350444526, 0.3187637762879054, 0.1519936071386377, 0.1292844112194919, 0.22686196799484404, 0.2647179779445995, 0.37899464810798295, 0.4004337223164305, 0.33290444730389207, 0.18344731231573347, 0.11074719486588176, 0.3189695486210449, 0.3000488526421734, 0.2891536693643303, 0.39127425273706384, 0.20887256408349072, 0.349398359144504, 0.32991369206523974, 0.11270673001774, 0.10250673837812938, 0.17851892035903313, 0.15361252786029567, 0.2818493406104521, 0.23327139708924108, 0.2871942913678842, 0.3181167027470919, 0.10285044723164366, 0.136545598943515, 0.3369869171674133, 0.1502539203919327, 0.3274232532249876, 0.18426733796704672, 0.15477497289095038, 0.2831919462487084, 0.29828983669936165, 0.07466534888000596, 0.2943745954089304, 0.25673263263972534, 0.05025852736990621, 0.38207936363769585, 0.3125687921268318, 0.14153950430764736, 0.2270436717042443, 0.08801858159392102, 0.0899935106866934, 0.27144785878394, 0.242752687229077, 0.22161038998832558, 0.2861522184841788, 0.27591182421487953, 0.3688285069923273, 0.39502565262101086, 0.28993288567966596, 0.16570866176237672, 0.22463496607305794, 0.32333252096001114, 0.30200288882924, 0.4042004493832757, 0.04264814749731792, 0.18430054828004175, 0.1938174193421025, 0.24514964439299367, 0.2876455356022522, 0.3122308430861003, 0.2699397510844459, 0.36923767823289777, 0.2935893258478433, 0.3267372336097992, 0.22897610566283677, 0.20082387234642, 0.27095270052070025, 0.3311269021494414, 0.3901339655547814, 0.3074861241909827, 0.28025624215577427, 0.2682872758987125, 0.39815129467378824, 0.29804236995917477, 0.23001540568946738, 0.29675701756069667, 0.34945196071166507, 0.3611535734282843, 0.2450599774017786, 0.06597061376416212, 0.23075250293433022, 0.3174722564317895, 0.24771026591493922, 0.28194514790578695, 0.17108482067867484, 0.1146883691029887, 0.29716717987658525, 0.09028500528889553, 0.17106026006975183, 0.20006065335382464, 0.2566655447053284, 0.32174180963418486, 0.14807300347957392, 0.19099066138652118, 0.272195330610429, 0.27334040354939576, 0.3242318986276384, 0.1845203297760218, 0.27832052462643747, 0.30078266424681943, 0.2041000310840202, 0.2064057537035393, 0.24424975964353932, 0.29977879632473775, 0.35314783843948105, 0.3127650821444434, 0.18566256247317756, 0.3039358960170568, 0.28250814051501716, 0.07431660241026374, 0.08725229355457502, 0.12404952192745028, 0.22061529150842205, 0.18433052908178457, 0.2090368972823329, 0.30548653710528234, 0.2946102147909852, 0.3329080646822405, 0.31783357729897477, 0.03861650348278549, 0.19728976828795297, 0.19328663814887218, 0.21574802743427005, 0.3409595270657387, 0.37641564968295277, 0.049367835155605534, 0.07040974465337567, 0.16218829770468937, 0.27217525367994144, 0.21953535325125678, 0.16826423451552924, 0.2619763286241671, 0.35041269093530114, 0.35047388897354764, 0.380516942193454, 0.3251924104123409, 0.11892634297272449, 0.11407220019084945, 0.22923797314011257, 0.1414253004573923, 0.1895940370780306, 0.2997361156693816, 0.3102917139751453, 0.3549434978006696, 0.2234784589802625, 0.048330308134704174, 0.2518972242465002, 0.03598426604522735, 0.18713090106769806, 0.2411905672873943, 0.3544558611610971, 0.3447885157179422, 0.16148719657832847, 0.26448758617953994, 0.2552437254914247, 0.1689355942976432, 0.0756430796021349, 0.21545816357516773, 0.27056746088571065, 0.1971525174724712, 0.2587384946931967, 0.24649008505710557, 0.30148976854579207, 0.060749939839909735, 0.028039412636903963, 0.36409344191030973, 0.10195796806087037, 0.28907740168147095, 0.1832861608564851, 0.2265695706237357, 0.16904006359704118, 0.27601524610175854, 0.24309997928251076, 0.3480027995044429, 0.11307545326292154, 0.20465059592866083, 0.33148718247961734, 0.20273578720432678, 0.16612085918105418, 0.37572658278233095, 0.14273219756428257, 0.3185945259973368, 0.3010480680479103, 0.19337510048426462, 0.20747705874589134, 0.2981285183921267, 0.18815397106968101, 0.3099806244050161, 0.07963157585544162, 0.17305873366559832, 0.21965958528339738, 0.30851924035401157, 0.3040095066231023, 0.34322008400156645, 0.3266794488540718, 0.2479247542070266, 0.3698797041273572, 0.3087415919678221, 0.10005901222638976, 0.2186881491720361, 0.15994678233723142, 0.18061656625758132, 0.3447732733467014, 0.2882641046399063, 0.2878314705017604, 0.37825653776772483, 0.08389921421381154, 0.14797226037120798, 0.37674294988057955, 0.3714487273939486, 0.18711455059141457, 0.23020002644582382, 0.1048653304881613, 0.22906745749322188, 0.14212905520347885, 0.19112702810262863, 0.2802578834837258, 0.26114833754288697, 0.3546666655970249, 0.22745273658719561, 0.14115431635574485, 0.2909986589544137, 0.30674288724557475, 0.39270550905274726, 0.24815893887312485, 0.3308300040410119, 0.24225681118748663, 0.3016666891644743, 0.14336403122893335, 0.2128197629693996, 0.3566882891050117, 0.240887034789627, 0.36361041320867693, 0.20358988335286407, 0.17282090470162176, 0.32996846059884305, 0.34596179151787027, 0.1840511930474743, 0.2780655891120059, 0.37427281580958516, 0.21200369465359362, 0.33571498289753465, 0.31844911841867124, 0.25242101657208416, 0.3603121139900714, 0.34687248393751446, 0.18967565151316146, 0.12995058627673037, 0.013437345560425341, 0.337217193577021, 0.3606402338634769, 0.330133683709851, 0.2751398429477441, 0.03651252423409486, 0.36819952055947147, 0.3003572177939038, 0.27038797690128497, 0.30817233373876024, 0.2523526037786268, 0.2578710864775241, 0.19999540609443117, 0.3056586253270479, 0.3259891587894112, 0.13073060210823367, 0.3964015156988969, 0.2747966824174619, 0.2592238361695789, 0.3240240654988143, 0.32599285283608964, 0.2466390262686092, 0.15888387488037492, 0.31419591954470955, 0.2910043700113629, 0.3286717009756939, 0.36793669221592135, 0.08070118027653371, 0.3563352591394741, 0.21752452400900196, 0.09421080201095984], "53": [0.6843659132920316, 0.670700314960229, 0.6926788588170535, 0.665851218656275, 0.6649465851220514, 0.6750460577785048, 0.666726213990336, 0.6816843453174274, 0.6746786114839938, 0.6166464690400194, 0.6102503594383841, 0.11636989939122086, 0.623835685244621, 0.6278332849569714, 0.6286802927742846, 0.5858283561365573, 0.6395524438643022, 0.6449556889002349, 0.6402940975236581, 0.5644000176751326, 0.5933782753899137, 0.6101237763818687, 0.6060036933474137, 0.5785875937571511, 0.5839979078997064, 0.6141992903516283, 0.6321378753611125, 0.6528968362398646, 0.646014992656037, 0.6670318237173678, 0.6538373650437846, 0.6620570588596002, 0.6069243628963685, 0.5790587792265434, 0.6305062356072952, 0.666752023338783, 0.6725464170587422, 0.6535560392622852, 0.6420067367715412, 0.6461494222087092, 0.6268919428537005, 0.6714738136018857, 0.6504520857842985, 0.5579051812011608, 0.6040171789104652, 0.6076061533384773, 0.5943812870789169, 0.719071915980997, 0.7108531156219684, 0.6792419561824609, 0.7156885979194285, 0.665778979384452, 0.699093819668528, 0.6546550623774179, 0.05155777023184493, 0.6478652954540085, 0.6625942156334932, 0.6806800485671255, 0.6543669925382388, 0.6556090112984535, 0.6535976235838595, 0.6382927522827752, 0.667188489128768, 0.6135742847297087, 0.6471424560786485, 0.6276680204331139, 0.6568569468731715, 0.6514796347595329, 0.6106614797072067, 0.6172400172350537, 0.08594413227619811, 0.6286501249677696, 0.6277328338930286, 0.6426589283236298, 0.5873156925402556, 0.6448575819924728, 0.6185614974237371, 0.6882241515538426, 0.6747983130460723, 0.6404517568332319, 0.7362374656262783, 0.5095694105769685, 0.5302085405231477, 0.5595705181007925, 0.6435446609207842, 0.7614902586407865, 0.7050059678684506, 0.6905931609625975, 0.6202954270715536, 0.613958700134475, 0.6603719876560801, 0.6942065713935266, 0.7031909372749588, 0.6324352644173076, 0.6544763461122296, 0.6499276568345037, 0.6717066717307514, 0.66518892640281, 0.667155649336138, 0.685509735087751, 0.68027309665916, 0.653773019103984, 0.6716644076559353, 0.6874660691806254, 0.7140312921345826, 0.6961820718276175, 0.6356393064242276, 0.7137611995524261, 0.38413221604150055, 0.6204653457182179, 0.6159818055479281, 0.6317635954283349, 0.5989472863604608, 0.6177613945050919, 0.6657527167850877, 0.6680093149855831, 0.6239489757326802, 0.6396373371765438, 0.6530132268471077, 0.659016010407443, 0.6866750012276231, 0.6990699695973487, 0.5348155040297476, 0.5424958363636836, 0.5585163445709697, 0.5464017611259757, 0.6593700672722497, 0.5846412089815562, 0.6482394233319665, 0.6463361005809052, 0.7574685851650823, 0.5159668217411199, 0.5610941613166424, 0.5586632937122059, 0.6345797203302678, 0.6351229001126687, 0.7534440641478918, 0.6685260776469049, 0.647227844247311, 0.7512641883177819, 0.6992213215053624, 0.6916357010376538, 0.6780930863425741, 0.6791177867645182, 0.6477862629072672, 0.6921898934844901, 0.6644322783088544, 0.6815772068599187, 0.7012410174511522, 0.6334712945285066, 0.623329145905249, 0.6343183765928896, 0.6552749080253853, 0.6516258553253476, 0.6975226016498385, 0.6704880173845161, 0.6941222977758721, 0.6846500593541388, 0.666927430077352, 0.6836555075622831, 0.6199144895610482, 0.46228431861468794, 0.6122683909015458, 0.5800304636962426, 0.627800128953081, 0.6238246044567209, 0.635229589549587, 0.6241230267688014, 0.6409905274430089, 0.6530744290924138, 0.6430260501703303, 0.6362948333187913, 0.551022798153241, 0.586770969512742, 0.5946094052308614, 0.5855879976833106, 0.5895115855956179, 0.6745017744657722, 0.6806848477636673, 0.6872603003188242, 0.6745478341664496, 0.6999411583132531, 0.693002222320838, 0.6974575129933906, 0.7170847330787474, 0.6921780609505112, 0.7144711568615898, 0.7000589741769521, 0.7306603395980374, 0.709167316819645, 0.7030309898587349, 0.6088407394944649, 0.5986724244615634, 0.5877457419824945, 0.59249340813749, 0.5965855363553317, 0.613167780245427, 0.6096808441314889, 0.6928952100021799, 0.6602418516496693, 0.696817990560011, 0.6871293466479113, 0.629761302432355, 0.6399343485709289, 0.6031411057348686, 0.628722470860352, 0.636778328185871, 0.6409093598308733, 0.6344962383662514, 0.618938805348471, 0.6850393457579873, 0.6213583066246403, 0.7275619237964489, 0.7080498876748077, 0.6833322953358248, 0.6958960092312912, 0.6936874901428663, 0.7003547716758283, 0.6949980424041846, 0.6818487714137822, 0.6871998814971827, 0.7123500878944681, 0.6967709656446092, 0.6988097606795567, 0.7079999265236601, 0.672626059554346, 0.6537494101434332, 0.6438323917094304, 0.638421577976823, 0.709576922139008, 0.6651753667210482, 0.7093357026275227, 0.5920037925055373, 0.6858857793806006, 0.6632886349322713, 0.07655547402143466, 0.6604622842246127, 0.6172816022144882, 0.6491136695445506, 0.6622479116167701, 0.6563210326389963, 0.6662755497489782, 0.6562431035006797, 0.6703410067559601, 0.6402042897471738, 0.6648558524811888, 0.6371939216783139, 0.6233292025868997, 0.6237967063537293, 0.5860665214675248, 0.618138171481863, 0.6829673425018968, 0.6563393668221101, 0.6923019554925137, 0.6620283248319256, 0.6796981206858763, 0.6681105438740773, 0.7011830072015965, 0.6748276429602628, 0.615269906828369, 0.6728479185897087, 0.6764898214704157, 0.6808077787302994, 0.6889111608132257, 0.6647211553993524, 0.6948369891955863, 0.63774705836238, 0.6913471745786767, 0.6983016952559802, 0.632038478858326, 0.6530922855731426, 0.6336497562416116, 0.6369546991321673, 0.6396675224656798, 0.660314524076733, 0.6595596996298392, 0.587773814560122, 0.6217059667146334, 0.652777987168298, 0.6394595523573425, 0.644587668937038, 0.7144037380110241, 0.685088708900466, 0.6818106571594658, 0.6393815878909996, 0.6740881998004775, 0.64630198157054, 0.6599795461745653, 0.7041187056247874, 0.620308962842037, 0.6629466030849147, 0.6710907842288578, 0.6894469787097119, 0.6633581172515939, 0.6773584426814371, 0.6968480839560959, 0.663806294296711, 0.6443718160001202, 0.6148104727053534, 0.562238543769344, 0.6626262938979277, 0.6270751938258934, 0.5993285866747886, 0.6409595943315113, 0.6122680443033702, 0.6870753136864883, 0.6906347524430693, 0.6971040879597591, 0.6891883648757534, 0.6843086360891001, 0.6651718873572138, 0.6826496368851902, 0.6578998557572127, 0.643079125651897, 0.670388917306166, 0.6863299168906589, 0.6898092732595863, 0.6558621416016138, 0.61564344134684, 0.6981241663283759, 0.7063081350305866, 0.6985215774409538, 0.6717243584773548, 0.6741942117248675, 0.6824987155496137, 0.5884960791681174, 0.6535532943406738, 0.6550579265642157, 0.6501804864447047, 0.6571716439831797, 0.6494224094739728, 0.656795184544439, 0.6709614576129577, 0.6602415134145836, 0.7666760435950774, 0.7752382123645082, 0.7172527855717952, 0.7179083680180762, 0.6519788390220342, 0.6213444566742153, 0.604145926609628, 0.6330460679028542, 0.6237672109043996, 0.6473348407175976, 0.6522714020172488, 0.6817473168981443, 0.6623371198152413, 0.6511130795372306, 0.6545470118563581, -0.06768802401596896, 0.6777540590470367, 0.6699980846261642, 0.6655565759143888, 0.6607701015829818, 0.5928665376017453, 0.7165188642097874, 0.6248255402008409, 0.628759048695132, 0.6269265118129016, 0.6287339095058734, 0.6490249483400846, 0.6427922688007245], "42": [0.13297044162255134, 0.22884053105851793, 0.29497660532268527, 0.2441389213529653, 0.27413025655560597, 0.31546738031351934, 0.31058496514530026, 0.2146284150224984, 0.27463258441217187, 0.4082531670968265, 0.2493270472692887, 0.06190716120911043, 0.30482238532504374, 0.32332046498618355, 0.2772933253574457, 0.20797433297005768, 0.12026962910540993, 0.17729898339347824, 0.1764272143637473, 0.29041305065096085, 0.28458626071064164, 0.3497503329686426, 0.2808331304558433, 0.17458758561567692, 0.09163884304059497, 0.17935527350155298, 0.15041924207169197, 0.2541426186776006, 0.31728282842841726, 0.3868546856461605, 0.2816511421694043, 0.17801728535484188, 0.1600766279510867, 0.32823307722448947, 0.4243047181504203, 0.2721646444634352, 0.3126665515438717, 0.18708204461222713, 0.2517114294730727, 0.17448214205366158, 0.16981811524295073, 0.14645051930373798, 0.41272028128538923, 0.37195386489661775, 0.2697655927307697, 0.3955684723145136, 0.35995641352883473, 0.4481760626062028, 0.15367962545832453, 0.21443429001626002, 0.17975216670837124, 0.286677992759233, 0.302074984313202, 0.2617740383672547, 0.283233192993184, 0.17109519863127884, 0.24044484027362206, 0.37465589404416155, 0.3222446902140015, 0.21791742519085328, 0.08198489644687566, 0.1295627625382333, 0.2611957288251726, 0.2402026771469073, 0.2522576517961789, 0.2454845537804178, 0.12578824284800294, 0.1428833899979014, 0.3351477256345976, 0.2511855099150927, 0.24189438262292737, 0.13838725044452313, 0.290451596228602, 0.28835167655155153, 0.2987558876273675, 0.31625378734785226, 0.3264730956269911, 0.25623465163613546, 0.26343307575221797, 0.1180409184047895, 0.3257039309859315, 0.09447409775865515, 0.047843989661164786, 0.11945136121788545, 0.3199775750699157, 0.3581927469042299, 0.3787547794398795, 0.33161801684623815, 0.26308926936845245, 0.2381892682701511, 0.24886301298824756, 0.16832220635943307, 0.4163935450439573, 0.37677898016788836, 0.10456624306929564, 0.2595522298518037, 0.13826711116481646, 0.16384988497434716, 0.2695744044741137, 0.3020425068601268, 0.31364250965310736, 0.35016206239544007, 0.23160776066966876, 0.2543558283681679, 0.3370851797961805, 0.31745486801846595, 0.1278397482381301, 0.2107164752079108, 0.05399062606372894, 0.1938526527637241, 0.42888370655188496, 0.22543949899055774, 0.16469997441815695, 0.4265810548213245, 0.3591929635337713, 0.32910872239025957, 0.10495808499772807, 0.22146712448660028, 0.2790990853308245, 0.13969130990900352, 0.26455714401928904, 0.3197860171555231, 0.07498995142308232, 0.23628587930977704, 0.3297067065927781, 0.30131685648140266, 0.21614160133556107, 0.2696620457526268, 0.2726033067629803, 0.16079433365173526, 0.41244955572852315, 0.19277118778247818, 0.19334850386098204, 0.26383618982352736, 0.26553119262146097, 0.3041119432750138, 0.3681955728810107, 0.3563317545035562, 0.31780722582345494, 0.30168258206941023, 0.40859617875890597, 0.3202631995724868, 0.2677896230297515, 0.16501994769607378, 0.22596796721934234, 0.1815318783708669, 0.2862176043025645, 0.265464150175596, 0.2026286741453884, 0.24888798678484741, 0.20080506590673053, 0.3171590384547383, 0.1564353497250755, 0.32190024880319706, 0.14443752059454998, 0.1851638559179735, 0.2991278137754127, 0.27736092215487596, 0.3308767620828261, 0.12431128085220564, 0.28992354936573916, 0.2226150426096398, 0.30530897483650826, 0.22909818754657765, 0.29135202291965867, 0.2276632365160676, 0.19179628197547915, 0.30637846185064, 0.14694267919945922, 0.2818609302650568, 0.27751475938638137, 0.24524771662811984, 0.1632460703961561, 0.2678151901058054, 0.18591622295107468, 0.2869692847755483, 0.1968986314951194, 0.3211980137725994, 0.4147268653813236, 0.3258407240913792, 0.19025662816233174, 0.2831321151468732, 0.30580950056066547, 0.1935876464945885, 0.2567821358228041, 0.25074661694934003, 0.3677878635256093, 0.33583566288559363, 0.3460499885601523, 0.3227636018528428, 0.2426765772739665, 0.30448604203132895, 0.14123401512971648, 0.1398866453402284, 0.3463776222864078, 0.21880492385634967, 0.31074511959814444, 0.37302610345776077, 0.25441058045614817, 0.40917850628807373, 0.3436843231179533, 0.21039968620609434, 0.2820575062302106, 0.2857400747408175, 0.2240720225199722, 0.3762570867260243, 0.12178209359066629, 0.25318673349028004, 0.21710491600950435, 0.08969235410573947, 0.3422916563708627, 0.24948841804032781, 0.2981811186996301, 0.11252551350680819, 0.2085941209872235, 0.3795781508234715, 0.2258004955381494, 0.17081526310060174, 0.1695688193385924, 0.1164492982249643, 0.20457191162769775, 0.28766625908222454, 0.2689616237849957, 0.26427134426860593, 0.3207087468941736, 0.2712089738528373, 0.3698647146393895, 0.33729602630543964, 0.22403211227839084, 0.3121753837379933, 0.25486496149429216, 0.2187233643215878, 0.3801408649965943, 0.3385324441289332, 0.30938499861539065, 0.16770578201538353, 0.30825525692198347, 0.35755602793700014, 0.23214951739632061, 0.23509093201820086, 0.32158282713837644, 0.30336321288188767, 0.13103119243023673, 0.13399429991167258, 0.25341348029812333, 0.2617331526831307, 0.2509342426397983, 0.30711942611831095, 0.2223533577577322, 0.3472717816167187, 0.2854467891077006, 0.30601637770304146, 0.2445037843980727, 0.28151681932224176, 0.3081093143130619, 0.18754220598081234, 0.12154773975075009, 0.25031956656505494, 0.28562721005601743, 0.16299290790812718, 0.28453936794718754, 0.14392700982503434, 0.19818206957982254, 0.33468005288752306, 0.22789923257953795, 0.3000666081504022, 0.1756790412676303, 0.2067884625352549, 0.3023816114506043, 0.14566686037109797, 0.25038634815012, 0.2559513066586083, 0.2683141804362857, 0.12715388282000412, 0.15175447680819237, 0.205765793626032, 0.24190727957533406, 0.19774206703990416, 0.19914198194493843, 0.28705145813167415, 0.28378238894210506, 0.32151322864030946, 0.1930714044856029, 0.4482111662175079, 0.3262194998013266, 0.35395923866224227, 0.2277090333714133, 0.3024383233048674, 0.2708483816438317, 0.2453509638027151, 0.3470823799361768, 0.1538614089795122, 0.2803635117222011, 0.43041716938398905, 0.3313183127390842, 0.23853684062397273, 0.2986263110187488, 0.2113478422486397, 0.2927546062225398, 0.2857907244881094, 0.16868354454895107, 0.24393865847233248, 0.20971919525637123, 0.34790136699026714, 0.22903140091609925, 0.18314516926022512, 0.2985403184881531, 0.34325321987767243, 0.3703351920356902, 0.16495291238429818, 0.2744920752082862, 0.39723311556239244, 0.3708470643289866, 0.17885863578329786, 0.2241019015742405, 0.0778413071835237, 0.26370745262091444, 0.23748872755087752, 0.2587402770494755, 0.2710440450741832, 0.24493368601246904, 0.2862666663685323, 0.19297694934012807, 0.35595488475824816, 0.19541699229184223, 0.27770741859265957, 0.2529939941789346, 0.23131174941695717, 0.25900506001469237, 0.33239866266790236, 0.3739887253499491, 0.1386520272290297, 0.19002030463228095, 0.35558868264808274, 0.3909867181039006, 0.3671897133783728, 0.32714699612854453, 0.21483119475887877, 0.11101395509066998, 0.15402802872452773, 0.3517433059409072, 0.09865627722954017, 0.3004771523010809, 0.2666876524292616, 0.17240780089771873, 0.3007652335182386, 0.2783913272359643, 0.2937656171640572, 0.17060716928338918, 0.24012038895786827, 0.2541268160014588, 0.2914960551134255, 0.1914404641553811, 0.3420483766029299, 0.19161463793016156, 0.35947880477226846, 0.32590365292908263, 0.24149440475104278, 0.2563133687412727, 0.3385473763599305, 0.35743135198476056, 0.25947437050876143], "24": [0.19790553689768478, 0.22710811785916638, 0.2831273799389847, 0.21768690780962435, 0.27036730802197745, 0.143590365299517, 0.18294037856101222, 0.1783198749237604, 0.15674393674027787, 0.2582612819030768, 0.14727150232568184, 0.31814618639138886, 0.14967045513811827, 0.24801086329591995, 0.25885234003506746, 0.21232480902835915, 0.16517216699364065, 0.18554568474204466, 0.1598339757099598, 0.20331834521180123, 0.17897862612624316, 0.278577116714342, 0.1429963197703243, 0.12213543123128281, 0.1017324474265239, 0.1308610201530273, 0.1821769971216753, 0.1972339366624553, 0.19740659530165688, 0.24986336201033715, 0.15190695979945926, 0.1724014415531246, 0.10358513600980995, 0.07763957156812229, 0.24813551872451234, 0.27982370821680647, 0.22916825974695587, 0.31165991680365673, 0.2855595752387192, 0.24374725836179922, 0.19444021229873196, 0.12956696443389554, 0.22564269415176758, 0.13347298431100682, 0.25103488988522776, 0.1994134370224856, 0.17036755487843536, 0.2637123845966683, 0.19474582982842406, 0.10822086339102806, 0.33139487471825446, 0.3260347663539263, 0.2395373469751279, 0.18066711419388307, 0.15011401078798106, 0.06085855982611361, 0.2740503662256725, 0.16497959904529824, 0.1557267825383838, 0.1794003224318102, 0.19464521331310378, 0.10746110557194019, 0.21982976959738443, 0.17899863190020893, 0.1674976920401691, 0.1361407388934812, 0.1528964600457554, 0.24073645033341817, 0.21031562207853088, 0.300690852526878, 0.2674495319877774, 0.20209003084587865, 0.29639456385306123, 0.23044835565337585, 0.13348495503155772, 0.2817086519967083, 0.08383157823383504, 0.29755817279469177, 0.3473700612179135, 0.22356881435348475, 0.2738196162046613, 0.27224938838431645, 0.12966139576234487, 0.1743417198397487, 0.2107107355783217, 0.1543592586893307, 0.03475276855466731, 0.06964595524251203, 0.1404184949297129, 0.16205549471342223, 0.1977002055344568, 0.1319312155968245, 0.22332303533976, 0.051641313140702874, 0.15936352109395727, 0.22411380725014227, 0.15374498115673582, 0.14658063251747713, 0.21311610762075384, 0.24013068719624023, 0.3153501453438446, 0.2743267690686412, 0.13412443229939097, 0.09469674839036354, -0.0008026463123723161, 0.20051208583539445, 0.37950548861040234, 0.3953801882460549, 0.12463347788629495, 0.11529283785904973, 0.17870332268945036, 0.17113482766595028, 0.3636874214002569, 0.32036967535645516, 0.346560664261649, 0.27209973335415844, 0.15856286744788872, 0.2072281716012997, 0.09391771546387198, 0.1767783939892196, 0.1709285659735161, 0.265428786130952, 0.26180127129429087, 0.0804291160017483, 0.019086930615344246, 0.1691801428806647, 0.3365645882288077, 0.18613018257669234, 0.23497833262333512, 0.1470197485980157, 0.27175744728515894, 0.3004000535433247, 0.23173758381416587, 0.19658388309924624, 0.29406884872540273, 0.1535962589703202, 0.13721042267902778, 0.21932471346887925, 0.0744704582875836, 0.06069995200207256, 0.1949476071270506, 0.27134615089359554, 0.28277453372961897, 0.28745357627016255, 0.29561695539319344, 0.06486494118178614, 0.15351713761094823, 0.08454337854419323, 0.12585503375149584, 0.13083318616841416, 0.1460791982310937, 0.28406351996676377, 0.2740369890350601, 0.1694502088308146, 0.19201677250582158, 0.25478156136126545, 0.15467593443345182, 0.18201796488216165, 0.08542574983667961, 0.1098681703140521, 0.24883923709982914, 0.15435935909269868, 0.1402682583286043, 0.17015682814510155, 0.15309577086805926, 0.25924934772872316, 0.1984452312413463, 0.10478889753170559, 0.2717653292503921, 0.2809065570015751, 0.3346232087491217, 0.1348981001142936, 0.2238128408816988, 0.26020574632255944, 0.18991738024402166, 0.0762738003264113, 0.12017140041004391, 0.062460175074459556, 0.214645793763688, 0.11327473030974505, 0.12671643973799382, 0.3177275269684542, 0.3384193473663254, 0.26462982434978677, 0.19505330500642676, 0.19467799214424833, 0.17618423738433037, 0.2270461779672993, 0.42522923994614, 0.3481752095523971, 0.18280334727015984, 0.18808615016173005, 0.17046475131337574, 0.1231478614171666, 0.13954207787446146, 0.2666784856105947, 0.12950785458594619, 0.1695868178247034, 0.23355940988523655, 0.17678342699135027, 0.2161707759758454, 0.3430671301828069, 0.26042760464093395, 0.2141010318346544, 0.1347995089466797, 0.2052740711928698, 0.18784578106007796, 0.13666570116494764, 0.13220198687432042, 0.12520639464311684, 0.12445855819609349, 0.23506790850037024, 0.3298291866486825, 0.3567787799633996, 0.18907055926572758, 0.3122185052282716, 0.15812805025932886, 0.25629084322164664, 0.3253140206833454, 0.243773433074451, 0.15946897290186102, 0.24180713394682954, 0.2391005409001054, 0.3134464230133931, 0.09118348968674822, 0.20960732751901331, 0.246413742067776, 0.1755156293556726, 0.11695781978312311, 0.09812033772168058, 0.13738549343302067, 0.33896450925921134, 0.3128133946196963, 0.19626055641212345, 0.1871176016211831, 0.22704225226582633, 0.2795215768188443, 0.04222009253793321, 0.2872944538732025, 0.25231535052099413, 0.1795221846213304, 0.3598640682462977, 0.16041462684381608, 0.07104839338667983, 0.29584931961133637, 0.2745219160605802, 0.30131943867679245, 0.24711176122985282, 0.3099234984813589, 0.07641702867054065, 0.046616247252729066, 0.15650752483154676, 0.20435457793018194, 0.1315317195828127, 0.2563307627271625, 0.3518049424359911, 0.21068971709356055, 0.27267322752741646, 0.15904277733885722, 0.060037431579857026, 0.17835252511467092, 0.3541719862170675, 0.19240186079371493, 0.19826748084379392, 0.27640930916154477, 0.19683334723542562, 0.21960747406909195, 0.254064765220687, 0.08036017899404158, 0.13505515854501007, 0.26736759044802316, 0.14512437906581974, 0.2367691259585742, 0.09501408658821882, 0.031838911255741, 0.27987936549866893, 0.21505549416194367, 0.16535214620391775, 0.16895356276699802, 0.10068659391240721, 0.2544536222322728, 0.37905198932092965, 0.36458646650927695, 0.18635280438370577, 0.18242550419142772, 0.20221367335460044, 0.15888904241703067, 0.18885856704765916, 0.31996979014315147, 0.20985027347030782, 0.2692637195887928, 0.266666731479606, 0.11421094769794367, 0.08532939431987357, 0.26115204532667385, 0.28008396111120776, 0.297923437058102, 0.3387646825075406, 0.27317264047478856, 0.2717431838135809, 0.195536460459092, 0.2480047518739607, 0.09861303512616916, 0.2545547263338116, 0.27751880067075574, 0.17950767512386148, 0.14309360799564727, 0.16805503360072419, 0.2463850103193961, 0.1707040750547897, 0.2500780109052853, 0.3011003288791075, 0.15138605494450988, 0.1536032512740231, 0.30717424623181483, 0.13522174925006844, 0.09301292636501513, 0.30531282048697905, 0.1521719023191452, 0.10305393318198186, 0.1559238680322331, 0.16919209362939264, 0.18997307645449682, 0.12804752565748506, 0.17438009206613994, 0.1805186927008004, 0.1323143434919826, 0.2779407775636691, 0.10144400793412071, 0.21475880584334206, 0.14606579236273134, 0.1884446671097144, 0.13917987082915778, 0.24844676687836068, 0.42123207953911657, 0.18711501953990128, 0.20509417797301704, 0.049945092060653895, 0.27813337353139295, 0.36387241772098833, 0.1340211952966878, 0.0827905974957253, 0.17286725099797293, 0.11493405455372409, 0.342471987623805, 0.2986955445740717, 0.19431437057695522, 0.15589385168195286, 0.12586460474593186, 0.07916139856469634, 0.2407008631486092, 0.24216871719435012, 0.19980193686034936, 0.3511503054674501, 0.2944237995100867, 0.163940170946309, 0.08922198895993404, 0.2673014358108566, 0.12871012881170585, 0.12436573433077032, 0.19569361010375178, 0.26757800161923245], "48": [0.3551675893476568, 0.3029839426639329, 0.2691616723769636, 0.1206207496644454, 0.012552239608334848, 0.32559820703421627, 0.38658068089439623, 0.27924432200080734, 0.07324450962652737, 0.1196318290196782, 0.23287467665698908, 0.2822216828864572, 0.303721016904814, 0.07015163290305716, 0.37746786788543196, 0.3900805962741682, 0.28460059312753627, 0.22525352563087564, 0.2324280763809819, 0.3753830494018469, 0.305648532301218, 0.2951826834385632, 0.1972370781504936, 0.30385142730691833, 0.3015014598432605, 0.3503062849228447, 0.37878250388663354, 0.3011404320264295, 0.33438488284948303, 0.3714115150506672, 0.29570383514736254, 0.3202851502438718, 0.33518830200434885, 0.12290864887338578, 0.11123465027366145, 0.16044065599140994, 0.26683022089490893, 0.3276994055780216, 0.1188397952727262, 0.13353933341711596, 0.10306131092373856, 0.2685019899453477, 0.23438856270336753, 0.3134210908001407, 0.268138709598159, 0.3315368791929473, 0.29437489209191214, 0.09877408762644943, 0.2210425120857767, 0.3417255558757113, 0.44800368818191755, 0.10922895389109953, 0.06460299240570631, 0.3019664619968205, 0.4085704861590551, 0.32488856076547884, 0.26367767484099786, 0.11459645668153874, 0.20159979495303215, 0.38130083313817087, 0.2246694533058003, 0.40006270680395495, 0.3209164922662687, 0.36366050970274943, 0.08910793481325206, 0.08013597295258618, 0.40929663590554527, 0.32306618898959627, 0.04296512427831905, 0.3457926939700018, 0.25527449667450774, 0.24239122983463626, 0.24497930272144777, 0.36734665422666013, 0.2995918499931306, 0.32916670531529973, 0.30913729063526635, 0.09082509905747674, 0.15775291309319306, 0.30101208488562126, 0.4517951098510396, 0.0986653293132975, 0.08816738510698048, 0.21293105493923503, 0.20117764743585406, 0.18040936501590968, 0.3438588487122324, 0.4243293228505781, 0.253738277849286, 0.2901243870179684, 0.3447880134933692, 0.33067893970571244, 0.3313696373670865, 0.3163745475695047, 0.34380002645649255, 0.10349827451337927, 0.3662550988168423, 0.4063949356725796, 0.3690814443528347, 0.37911978888396447, 0.3998800655177146, 0.29135571485451656, 0.3194863565692299, 0.11495630268809529, 0.1451522647353847, 0.39373244312610767, 0.4172129309017197, 0.42556473615625656, 0.2023738712452383, 0.2926146286420459, 0.3128594918286925, 0.22441916841647913, 0.21589424697875184, 0.3344985336757542, 0.22951019476896456, 0.39634592373539734, 0.38131689680117953, 0.08159211781809257, 0.11082451328671881, 0.12836750670023173, 0.15083350464109582, 0.16063000394134938, 0.25872920322168086, 0.17715354202832825, 0.09216220267412116, 0.3067864966817196, 0.3464050606354432, 0.09201117098022833, 0.0880493842928479, 0.2233514014070444, 0.30352271325694963, 0.060372608455139906, 0.3357056378259479, 0.3012744054645768, 0.3609594466021884, 0.3122088557254297, 0.37251416080266236, 0.17698222695812113, 0.03364468340629478, 0.3779571024164658, 0.3827177211010319, 0.14377113288122315, 0.16114501629748038, 0.2388509044016457, 0.2347860615031928, 0.3028506016038527, 0.42101467340062204, 0.26974611352359934, 0.09323259164290024, 0.20538663303618807, 0.3327214284641184, 0.3729863283238458, 0.35176111726425957, 0.30107373136677545, 0.05745659297233838, 0.3060990688143276, 0.26917619180975805, 0.2855106227519919, 0.26931808166474314, 0.2364877554304346, 0.10918578709913011, 0.2607512485156109, 0.30393578914306135, 0.22025456605526347, 0.11459590161950015, 0.17819392851270116, 0.3953152236327759, 0.10058901364412431, 0.2145380630372501, 0.3162234766368334, 0.3726039771782065, 0.3311286401363222, 0.2550330062779568, 0.2969727160950758, 0.10716506131360012, 0.31759766509425685, 0.37802062502536043, 0.2789507976181642, 0.36243632646191065, 0.05841635586296305, 0.4111205353145853, 0.28223360744530096, 0.29818769906659676, 0.41051475398542375, 0.23001261910970186, 0.3156090056684118, 0.350463651155245, 0.4382539035109758, 0.2583319259546643, 0.3277551096888999, 0.1159733844482558, 0.23064467891355708, 0.182862026469426, 0.3294006569251962, 0.38285468874736267, 0.3172203314572131, 0.3584384624703026, 0.21770978409556252, 0.3968728048298897, 0.09881606835110456, 0.1250387606415887, 0.264128971722677, 0.3043658155246808, 0.26999286986421017, 0.26146138319100076, 0.3812998020857394, 0.33306741286218183, 0.2938034139566092, 0.11778915046877264, 0.20577246822952228, 0.2833992619313439, 0.3589300122400213, 0.42132651005544125, 0.10524311692590656, 0.14632892429046526, 0.34702590704951575, 0.40302082851139664, 0.4036189086754585, 0.45769762570835243, 0.34690853723787923, 0.33694538698283705, 0.3051054156934929, 0.11792209247826003, 0.41479954920478523, 0.3814502296322183, 0.3052100307356337, 0.3709693909895762, 0.11017259812148356, 0.26958797673825563, 0.4052506325781916, 0.4001884126812448, 0.1206397389622727, 0.1956180471140636, 0.3773850796282823, 0.2541403282857185, 0.11162269270006023, 0.13871365567135605, -0.003381142816973241, 0.17260792108644965, 0.31929858556004165, 0.33384643181600737, 0.3743359973452494, 0.381773919284412, 0.0730299245107845, 0.22653064788610186, 0.29774414002967126, 0.39424501529953254, 0.394123000961944, 0.2288826480078343, 0.3407773008789615, 0.3611622482752198, 0.2279758812276352, 0.38408181294794863, 0.3952752690275577, 0.11916009673437547, 0.2075518406500319, 0.37186632511283985, 0.2903224408096983, 0.4287597961289081, 0.2155614368920194, 0.4023916038857773, 0.3677496028587203, 0.3842801956625593, 0.41190094820330003, 0.25053820111991243, 0.17042835452135385, 0.2901880837379948, 0.23014950771760914, 0.37982484355289853, 0.3229165937944346, 0.3113722241872444, 0.018292416026866563, 0.2568119438701664, 0.27035803311727075, 0.3295936819082532, 0.4118447875498257, 0.22818924341197003, 0.2526194804418207, 0.2619798104387617, 0.2903636303465669, 0.3648699819992016, 0.3812934446402758, 0.3714173430289321, 0.2925849157147705, 0.2791036777070334, 0.1118747183451188, 0.3363326970129055, 0.3531028395754862, 0.3745473399171792, 0.09726066590360619, 0.1302524248617692, 0.2444207840792473, 0.37114014146472324, 0.4155342712321063, 0.09541129393087755, 0.04959857828836236, 0.15597584203567655, 0.38016440914906907, 0.21192206382333445, 0.3415553151444974, 0.3391624455856367, 0.05933841297508696, 0.38613096503060823, 0.1965469348220211, 0.28189893641237707, 0.3657865303612813, 0.45649521977674656, 0.40348356645640066, 0.08783585084207264, 0.15725435651551112, 0.20381634390756406, 0.2487645173733094, 0.42856057120551266, 0.31708536960863903, 0.30221572050824147, 0.3739806292033797, 0.3995210463370675, 0.2900109718069549, 0.20496899451977654, 0.3041321221561581, 0.2826348038272992, 0.2457130850700033, 0.40462121420573716, 0.338964819867775, 0.2352015410051038, 0.119671337113974, 0.4057654590226315, 0.33162582039037347, 0.36800801282872364, 0.430151290901478, 0.27095908632799964, 0.2512756294420702, 0.388335689831204, 0.14739792939592142, 0.47332344250024977, 0.44287099841905275, 0.3354252497568977, 0.4535285112178097, 0.38968209731859166, 0.3123392408053267, 0.37487979873156746, 0.3489623343326257, 0.3594027884494982, 0.055350449089219385, 0.387485154930159, 0.37209113972305813, 0.1653442363153301, 0.3247774534652951, 0.3409757495903718, 0.11833854448791185, 0.3633412872303644, 0.35989314965332575, 0.18681704776203456, 0.2752672764245704, 0.345049551886198, 0.18689076927675113, 0.3171670364269706, 0.24993450280137797, 0.35115316046546846, 0.33908037083592685, 0.24912945718917787, 0.402658020888856], "45": [0.3124983169402127, 0.33116875206500856, 0.2505059659029082, 0.23908424235008405, 0.23150046654835985, 0.3690828650635876, 0.2672522578452901, 0.28266974409419626, 0.32351023282100394, 0.2507789169802386, 0.26400405362899027, 0.3416554562767774, 0.28205107954164776, 0.2768053599315089, 0.1680936163312445, 0.16957231259976444, 0.17934463200395923, 0.11290859799957205, 0.28514096473653316, 0.24778422567334418, 0.3248972822355931, 0.28992719979174614, 0.22266250610310465, 0.2842277997924959, 0.20601606125135902, 0.3598999496289073, 0.28455889065063256, 0.213726740063389, 0.1752801286108505, 0.2835964528456392, 0.20938715525551715, 0.1626422670535399, 0.29896317396739175, 0.3204592151586491, 0.228547148252908, 0.2868651138298503, 0.17239153763688986, 0.2755450573021767, 0.22224968383310278, 0.30344269114178146, 0.3093948825870862, 0.3158976157099567, 0.003304267487999917, 0.25800933695584316, 0.11034422785973776, 0.2990529756707605, 0.2218243436560208, 0.3173665238627233, 0.24957344655865893, 0.36911637941359493, 0.33735232219191263, 0.29830809376546064, 0.2104461034838414, 0.27921739062409046, 0.3464289030225082, 0.16295360219479035, 0.12397398226243038, 0.13602267634182982, 0.16522077076609204, 0.312547482131316, 0.13137725769708888, 0.2673601512971812, 0.28763903631123827, 0.38906096034080995, 0.36400436752243914, 0.17738271685793888, 0.2504179161569889, 0.15482437308595862, 0.2253107521516874, 0.23604353136432066, 0.08270751916129206, 0.1085790424811283, 0.3555903925748332, 0.31333141004004333, 0.28712492727744093, 0.17789602844926133, 0.2268242349678045, 0.3100236306767119, 0.38093686701231816, 0.32170605672550373, 0.3569746789012745, 0.22872566452402426, 0.24592870155555946, 0.22060354791415637, 0.2885872381571404, 0.3985795242129321, 0.19195908488392613, 0.18377752818147186, 0.2905239356491232, 0.21556529506365493, 0.3318147045694093, 0.038441432351721774, 0.2281571586854437, 0.37142364269726014, 0.24790934752138302, 0.2898135140972893, 0.3001690120825347, 0.36556791410991546, 0.27169088470418, 0.15388815275307252, 0.3130531939648414, 0.31980204207316654, 0.23283227514336094, 0.27118817044743626, 0.36747205649924314, 0.307772861904412, 0.2958329026090127, 0.29199327105227946, 0.2127652014775416, 0.24663632821634326, 0.12925723947935688, 0.25107265982594207, 0.27126002617190503, 0.3149475016302158, 0.16401850572673618, 0.3049305068219805, -0.05425744908847504, 0.1767245364500823, 0.33215192499208557, 0.23123276024412937, 0.3449866910322812, 0.23716528487109984, 0.28529046827783205, 0.3085749303577661, 0.1312105994261713, 0.2731138009832046, 0.2040914859076373, 0.3512070701863584, 0.1306891024498381, 0.29421557768662476, 0.11843930645360808, 0.3273816198964007, 0.2746408092976431, 0.2321710306011338, 0.3332670764109456, 0.18592561904224572, 0.2521091918779046, 0.2852173916410787, 0.3460231024420837, 0.2880549831331247, 0.3287923689796415, 0.17735270857281685, 0.26163414101486543, 0.2669200236191398, 0.2871319873874225, 0.34945665997439535, 0.2880106783412256, 0.29630212121462407, 0.2943289268377174, 0.1948468123913131, 0.3179904423182695, 0.3593394598005488, 0.30998023736837016, 0.2283260637315052, 0.3038748267313915, 0.27194753841390196, 0.28227368864835506, 0.351683325255807, 0.23892991516827547, 0.21238383385871756, 0.15936347639477402, 0.2542485938246705, 0.3418170139482488, 0.18642144745719177, 0.29373172139973786, 0.32235271143597727, 0.1497808435296539, 0.1725611579479046, 0.28408476592626003, 0.13232235939431677, 0.2844313725116561, 0.26768010828251254, 0.2619131410844523, 0.2582511250775779, 0.22203163427519984, 0.2238733401589703, 0.32416183706617946, 0.303536921738626, 0.1623813926162908, 0.2985309510557688, 0.304168679804778, 0.2892070105301445, 0.2997225118704924, 0.2715909806380545, 0.301408524084552, 0.30315340240732014, 0.42544899032248784, 0.2774349279993822, 0.4176441726012256, 0.18355892903487803, 0.21224917036191707, 0.26577084385143457, 0.32981623615772143, 0.13060022315834208, 0.29055888541894814, 0.22523450295880185, 0.26772378856258866, 0.27097141570653527, 0.3592034732824547, 0.22382417981000743, 0.3523679536165535, 0.12667751186340973, 0.31216937618543306, 0.3347468570303935, 0.2917148250470128, 0.24526812632820852, 0.27361728155182774, 0.23583864446871075, 0.17184907096701138, 0.31922586290380806, 0.2691044468868288, 0.38570988540889717, 0.24445210544752216, 0.37041340430384806, 0.1914918946167576, 0.27045525389217207, 0.2723333937844612, 0.30671693005542305, 0.18494876931720708, 0.30806752420231953, 0.2983097006865208, 0.3330056819777362, 0.2671546053212572, 0.26346897721416046, 0.39576012279702233, 0.27868720017866716, 0.3511355097793164, 0.30234269046573065, 0.19390261000196143, 0.3504867373785553, 0.16935257438158638, 0.28629221184312087, 0.19203644523810387, 0.3096782466798112, 0.1883967309154943, 0.3033614021497964, 0.3314573829210318, 0.28650720126325807, 0.3219917167142385, 0.1770469051189398, 0.27247889944869075, 0.30610685898876655, 0.18348339002775169, 0.30168953003659815, 0.2751732394601797, 0.29529139484829003, 0.14763909857634178, 0.24698221715371527, 0.2698374052721342, 0.18263039730206423, 0.20869507808701016, 0.2983528849704588, 0.27583917978949984, 0.1624039629705889, 0.3353166469459483, 0.35398969287139703, 0.3573139519352138, 0.36605981750978467, 0.30629646912066777, 0.26951477433247867, 0.2901807702781627, 0.33075306944795485, 0.27301098139429286, 0.17643189094562686, 0.35300193526897256, 0.1525446161121612, 0.37968260559321104, 0.3935425335598787, 0.37134106511769926, 0.25438964749270526, 0.14693416876059745, 0.25714839694205455, 0.3842574821878314, 0.2215537036604381, 0.13446590356023672, 0.2131269096077401, 0.3685514586765904, 0.2303195886420406, -0.03795661043088061, 0.33970539501556374, 0.16822848514719987, 0.2123406336295905, 0.21411457322483476, 0.1648447197100161, 0.27754696387413386, 0.259921629951526, 0.3450641584453181, 0.3620443073991871, 0.39782744998915015, 0.28872265683452086, 0.3413099422876647, 0.08895880478675093, 0.13041939980386133, 0.21858279558743512, 0.20125210040148278, 0.2985494056828693, 0.14659480024188595, 0.2009468671219388, 0.3096408319304985, 0.14054409390545686, 0.29052411086634294, 0.2828973385314684, 0.3026404854071716, 0.2912358121247724, 0.2773186464530342, 0.3282132136860264, 0.32430774442149274, 0.35848764693479446, 0.3152033425021248, 0.18129300673540721, 0.30396326208511176, 0.18133070763282236, 0.16831907329912119, 0.31549242889674134, 0.19060404124715621, 0.35682036391843996, 0.2920972583226804, 0.28712011333289894, 0.14149808669586292, 0.3181888461913371, 0.36472892921803024, 0.37973996889342565, 0.27540096016782595, 0.32376185671377805, 0.30332378437275404, 0.2461171942603896, 0.11566304679158444, 0.19565531916658782, 0.23054900746524035, 0.2978985694293955, 0.32922537904517346, 0.25437014936293434, 0.2521485224863052, 0.32930672839609026, 0.41544577274958255, 0.2943210301276344, 0.1412497963689245, 0.2805331580287191, 0.21739918154712298, 0.30174809848351836, 0.3809099451684133, 0.33091030247087183, 0.28979775752794934, 0.32341946052372367, 0.2555861189973346, 0.3918744739377754, 0.34736003804310084, 0.30990772982342796, 0.25349325082283486, 0.2992783389891617, 0.17374233353892327, 0.22525246775632057, 0.3104574229357429, 0.3473081668292879, 0.3434668521283889, 0.24773314961304338, 0.1918164940736658, 0.31946527502602595, 0.2134468828637457, 0.262696936412497, 0.21513437267995564, 0.2973943087147385], "36": [0.24427146730778732, 0.31204342680974995, 0.24570332728511304, 0.34038557689166643, 0.2688184924735642, 0.2603973712222202, 0.30771090085032204, 0.22310515739032552, 0.307773315041014, 0.18595253904568315, 0.22248131298023419, 0.23477808001015626, 0.22237835367017747, 0.11447003281594137, 0.21826795282253192, 0.27630370815643507, 0.23298293528280206, 0.2225833407344554, 0.2536178296630963, 0.2670044827197302, 0.20050425002516936, 0.1379708083656261, 0.08218598918423203, 0.2414151756520649, 0.3042727236317815, 0.35323572337004494, 0.1670817136270995, 0.28733915171561464, 0.2386035269138472, 0.3276864767389458, 0.20582624241999106, 0.20206401514550346, 0.21311834236998048, 0.2292085507393673, 0.13203726240963665, 0.21225256802766093, 0.20217908899571096, 0.27557463341914895, 0.3254378561280572, 0.2364010326948404, 0.22762847414447152, 0.23106390098754626, 0.08675804667562387, 0.15823779328778756, 0.2505979709301272, 0.17953422061755503, 0.23118284867819675, 0.18285756209110746, 0.3011678558237383, 0.23351754495725838, 0.1677022447699643, 0.2681972012325979, 0.29834479410915143, 0.25217651971703553, 0.3079566860538634, 0.20588654805042844, 0.25911558838693655, 0.29469432846301286, 0.22213005189758842, 0.19328184468991447, 0.33173774370135056, 0.30331141945240303, 0.20911302637503418, 0.29741725460099866, 0.12005642091999164, 0.2069457259429041, 0.316690772341566, 0.27152737152436446, 0.3382386431921839, 0.1931009918026606, 0.27823261922380593, 0.26656365664628023, 0.2636469511711614, 0.3187058379629633, 0.2655022467439439, 0.2651373119640723, 0.24466147315422318, 0.3173323941679964, 0.3423790519481916, 0.30794279313805856, 0.22844572228226212, 0.1942780151424823, 0.1920624369321219, 0.3082831380111679, 0.31102465063439144, 0.21876055935152205, 0.2512272421505301, 0.2684793127177926, 0.2196562441318272, 0.32941608875725503, 0.30745741594231163, 0.24040706668925815, 0.2949631749423152, 0.24031922203492195, 0.23809318769501764, 0.3223782648989957, 0.21172090068948402, 0.18601141479084726, 0.3463065452352794, 0.40138892180088553, 0.2625667297835832, 0.2885074542357118, 0.21597667902577136, 0.33787297305180336, 0.3422627949658, 0.2890365399846574, 0.3774830923820299, 0.25391698159751847, 0.16240973087520208, 0.3235189322122219, 0.19574365568241986, 0.3235706744307778, 0.31724848668204403, 0.24009252845587425, 0.2828917152381169, 0.30282852802670596, 0.23771037395348715, 0.2786082371248654, 0.302348180335183, 0.3149054007863396, 0.2892773369642084, 0.07538920077523126, 0.17274767647117695, 0.15757900445997067, 0.19498513655840066, 0.28293968415632426, 0.33719807933950025, 0.37260774148103076, 0.1736998372462386, 0.28081854846704474, 0.2577416403468778, 0.20665784975455032, 0.2532544276336852, 0.2605898477486986, 0.22897663577590713, 0.23936648258981008, 0.23392570113869457, 0.2898690898069418, 0.34873822728817633, 0.3024323533706175, 0.2837221872834981, 0.20166667424400006, 0.3075760596480369, 0.28594637920045524, 0.24802397615988114, 0.37101819239438755, 0.34753677996001037, 0.30339646776569285, 0.2312532101660195, 0.2845938108376081, 0.31430155937650783, 0.2807483912322857, 0.2603258863165526, 0.3621141176184937, 0.3274508844876463, 0.25945817625850115, 0.31478869283466726, 0.31110298400484077, 0.24419289513268552, 0.4093777475309508, 0.36141795596932735, 0.1891478840952936, 0.15881488016318082, 0.32955545920444523, 0.2788990833883014, 0.31602677678184865, 0.18433626663807806, 0.23157353863842317, 0.3551043859298729, 0.33942827216801374, 0.2487284056610558, 0.38836894547944145, 0.10936741061200957, 0.09839369010908268, 0.19973414400739867, 0.2949362456018372, 0.2883814352139955, 0.25611469943677523, 0.15981284488579903, 0.2599096130711949, 0.12723327885600305, 0.31455814130672255, 0.2672137780252093, 0.3412774462326104, 0.13012470399323667, 0.26527513375640366, 0.22448782937138168, 0.15540301333693107, 0.23013880575720175, 0.2624740540448403, 0.2732388642740673, 0.2945952726342992, 0.16463675089739008, 0.33618466055484925, 0.25937816539120506, 0.23188630711853497, 0.17046125697542908, 0.2599511006677394, 0.20448860639250713, 0.08339716084552319, 0.23826472686229905, 0.32459421468464583, 0.1771178558276174, 0.24099062981575187, 0.252690168538217, 0.260365929903469, 0.34484202747428355, 0.26651024691517666, 0.2922719708457139, 0.2758282139097068, 0.350104291829071, 0.16802923838987804, 0.20304195531363203, 0.2905396374996647, 0.2271837140577333, 0.28637471802264725, 0.2441100618104127, 0.306597644188263, 0.19897906678110694, 0.35966096234913547, 0.25953056904210425, 0.27863497003969345, 0.1946273949805612, 0.1797885382767864, 0.3178109006858161, 0.307814399877964, 0.2610667850690462, 0.2622522145545033, 0.21546511457623926, 0.203912979843987, 0.11955307914712562, 0.38360519573283525, 0.32499332226597016, 0.3061203159212279, 0.0771724475751712, 0.1829182959568614, 0.17890687956927306, 0.24825092680767183, 0.3735629205865073, 0.19119929837440422, 0.23470257624143925, 0.24331481136772995, 0.2034555684098294, 0.24845346496805598, 0.20978061744458065, 0.2891971479571476, 0.3660682127880132, 0.2970625122958659, 0.3331729579975633, 0.19298093042971956, 0.2828960255128723, 0.3005083317640981, 0.3154491644992025, 0.29737021330398955, 0.21719431784907064, 0.35865765193348725, 0.17437791253281457, 0.25839167562142756, 0.18961010336975903, 0.22205707728121177, 0.24547334487582284, 0.2992612152977638, 0.261662487864983, 0.22605290050378468, 0.26518380961350324, 0.20886162144848924, 0.23876137978608147, 0.31585936463258707, 0.29733854087891176, 0.20554086716698555, 0.31751167405453634, 0.15321201161343917, 0.2120356308581129, 0.23385658513714586, 0.26885242009855087, 0.23212254454502207, 0.22960005423305846, 0.21901575658034803, 0.31050816338133586, 0.3391388379045855, 0.16258133984015494, 0.4025834253566042, 0.20376695323319052, 0.19480508458382137, 0.2622691983779372, 0.20873034566973314, 0.21910208713731139, 0.2399657106451429, 0.2267786324002338, 0.30996384191618226, 0.24414915443786403, 0.15349318163776846, 0.23536431080653886, 0.3359914131075278, 0.21090758031613543, 0.05823896860110463, 0.18436865382703088, 0.2100088489648645, 0.36476390339370995, 0.3194045214521137, 0.3522334163987418, 0.1752110679160632, 0.18105920664045, 0.16848691728417475, 0.16534791291050197, 0.2713214856130816, 0.0911751090679717, 0.1670959362643785, 0.32261246188346593, 0.2734289781561431, 0.21213818188580746, 0.04215819440285626, 0.23519308363854474, 0.3615843456381741, 0.33332100774984513, 0.16718521778904288, 0.17624878979642114, 0.16781186435955422, 0.1657523848231246, 0.2906417938672173, 0.15868011727494233, 0.3032954131165106, 0.2960568626583758, 0.17720041459249591, 0.09111909688687084, 0.2561746407466182, 0.2886218440343664, 0.3400643725855228, 0.3241086871129594, 0.31317743130991726, 0.27518319549414166, 0.23470545889252878, 0.2805141433020553, 0.3695614318700892, 0.31568613246712307, 0.29878758884343193, 0.25943066075580395, 0.06211024944042182, 0.318595370010759, 0.15745562320725898, 0.2511765297577194, 0.24681299264437193, 0.23121615382820385, 0.19584065430896436, 0.3054071981780634, 0.2830812503580395, 0.24573151513312325, 0.04450957954023866, 0.15367008639889648, 0.2620826841708024, 0.22931929591081043, 0.19174892744140254, 0.30864539850382616, 0.3261992960078575, 0.3507692710813035, 0.3743399475469092, 0.303109846165951, 0.2119006195698333, 0.2996619600132085, 0.3107609084269637, 0.26910984916426556, 0.2184253409660522], "51": [0.13061336421495415, 0.35918323041257727, 0.35302728780765225, 0.16519402103046138, 0.12400558892016462, 0.2419486767381491, 0.32398007118242717, 0.3378443174307483, 0.22585938769703603, 0.2926167248573044, 0.1980237949415752, 0.19443159572722082, 0.17510207230211217, 0.23010737040591825, 0.24277425550126192, 0.19817024560657123, 0.3021160696260172, 0.28463477918221863, 0.16373761474270093, 0.29320012913470184, 0.27734319711680977, 0.2014428817938745, 0.24875870102527808, 0.1309513438502099, 0.36778027319773626, 0.36076720664244055, 0.2673575775975403, 0.1655583329991059, 0.2438368875738747, 0.33115621764532105, 0.29760062069980303, 0.2164390994415728, 0.1935098588257783, 0.21028512363332436, 0.2705042967767912, 0.1341772258739392, 0.21025035879703693, 0.30734684288009134, 0.17322478112242615, 0.29682805566959763, 0.33271615922042225, 0.17684186903458282, 0.19404127797563545, 0.27772900700403724, 0.329538226875035, 0.20937818624421578, 0.16887647136501305, 0.18011652455081087, 0.22013286208674837, 0.27827213101073606, 0.2626160455441365, 0.21259982424337537, 0.1960451235305594, 0.13344396816818505, 0.22255615232554427, 0.31891870548761075, 0.15015005719097357, 0.2860255012684819, 0.1540357537325655, 0.21091307682671048, 0.19784104984810436, 0.17135824456658125, 0.17193874486534175, 0.25214103990132297, 0.3654407132015835, 0.22124989358104402, 0.17451616595766775, 0.27598017039808015, 0.2876275764933418, 0.3091833719812608, 0.21227782222786445, 0.2119639236080944, 0.2511305142488564, 0.1686612166045915, 0.25849315510552145, 0.20202650310297945, 0.14971794346208145, 0.1533810357325523, 0.16486778701373775, 0.298491464642392, 0.20804063117768096, 0.11636426496848931, 0.13358240346016856, 0.1856103349262507, 0.1869461807073336, 0.3247483265438945, 0.25072105499949215, 0.17865379262719663, 0.15803270272514808, 0.15088699314476517, 0.19906154135000548, 0.16849506626068234, 0.1690755918808376, 0.3521436235766633, 0.30347063092600834, 0.2648806717835466, 0.42411637881869224, 0.2276490287067868, 0.17210660187794494, 0.33341349378052937, 0.3390587747888679, 0.2449864931327802, 0.30966229909841647, 0.30643328500128225, 0.34197939953136963, 0.16241247926092775, 0.40324969990063586, 0.31618068359653273, 0.12689862478683028, 0.3456899853487656, 0.14776203504018265, 0.19939152264709692, 0.22037715094192165, 0.15744324427816728, 0.25931935292122477, 0.20565633947301315, 0.31517335395468354, 0.1851068413085114, 0.2359740489426926, 0.20484926887613897, 0.160509504307968, 0.3375489180012562, 0.22705799155070597, 0.17463612521717095, 0.24657303010621265, 0.16779905547300045, 0.26525758996399873, 0.3655343504894428, 0.09663375740222893, 0.1710665107261253, 0.35763421662199274, 0.3186263309644919, 0.18658555833193197, 0.2855188373084495, 0.1878300244456726, 0.025994298537171574, 0.14596599973007945, 0.25707683003993154, 0.26112157711038847, 0.38907762678826757, 0.1717793267844647, 0.22469177955530062, 0.15372651596656753, 0.21341984579967924, 0.19677081458962256, 0.3900291378906112, 0.32394934759245164, 0.170884159287156, 0.35929560865383714, 0.1712757307451685, 0.13755107010840692, 0.2134813846233662, 0.18430222065836907, 0.251456280735534, 0.19408237009546367, 0.33749697328751616, 0.19226984516000353, 0.456401155751528, 0.24657332479093913, 0.22537498522576485, 0.20549581582590096, 0.19622401169769021, 0.19191716861153965, 0.12642865923622684, 0.2654585117498909, 0.1720443712198741, 0.2526526499383589, 0.12256299527206468, 0.35053920506737907, 0.14306422264868127, 0.25807638622122947, 0.3237682012141121, 0.19935074338482747, 0.36047724789200264, 0.22417467014470047, 0.12517582727262463, 0.14503575720615147, 0.16850468067372218, 0.28839140504181693, 0.15856677607402098, 0.3227949656550466, 0.1877589759504039, 0.1429738517363382, 0.20846751502431654, 0.3791958953084136, 0.2379954502163637, 0.1494425075202709, 0.24239247080637955, 0.21430091255238057, 0.23012599268632233, 0.2178508279635958, 0.33756475756348225, 0.33865276986871, 0.20010550352800785, 0.19196004418783227, 0.22527164648650957, 0.14648237046149376, 0.22453238934830697, 0.27734345222941126, 0.21054904457124732, 0.30140981897543206, 0.2421323594538578, 0.27960696276204605, 0.18986284178955393, 0.1636324928664745, 0.1646477066336602, 0.1563212003280619, 0.16300088706503618, 0.2861681624425813, 0.217825656664612, 0.23085067828717312, 0.4000237490848359, 0.2601850245399157, 0.25190241449839235, 0.1971962305950358, 0.29055318216980425, 0.26958796743752805, 0.3421331918719655, 0.3744729277101542, 0.3785029777795428, 0.25735714579248814, 0.2716280817516917, 0.1903913313895022, 0.16110858601383266, 0.3651028902660645, 0.13732153628401442, 0.25885160164850773, 0.2079980959480303, 0.28425828066330794, 0.28916408750493916, 0.2664941487014969, 0.206482947914437, 0.2179997354037833, 0.2818222590542537, 0.2698392726256812, 0.33353045914266777, 0.24973384433652418, 0.2847814444947426, 0.18945084313296265, 0.29920238803788984, 0.17667519492135367, 0.2842589252374111, 0.25887176741272555, 0.2647134455286389, 0.36855220636066494, 0.1824946639688409, 0.42456731824460137, 0.22335512225081786, 0.16261708582912884, 0.23439981480585706, 0.1591983057342957, 0.27817746000913446, 0.21735770625878342, 0.10738654403008387, 0.1257844275298454, 0.2964452711916938, 0.21127830596627212, 0.13100582082621914, 0.3646868667849123, 0.20554137773725448, 0.17694141159605062, 0.17319101776342272, 0.21078365464264628, 0.30245145517925587, 0.19511928986601684, 0.19085418619207475, 0.24325590838117164, 0.35201092111479926, 0.2500410587222918, 0.24003941294023218, 0.2776487056359243, 0.35175055543276007, 0.3895434976746261, 0.13565168855008203, 0.3085619752153536, 0.21420346033792892, 0.16483225025593082, 0.22697178010396715, 0.11934592669838648, 0.16110993829531958, 0.25650106741322243, 0.2602524538894335, 0.3061900476441776, 0.22558012498512003, 0.20079558983432982, 0.34718379639131924, 0.2260828476644629, 0.305540190284696, 0.20719840391530314, 0.3687635274677751, 0.4003104972407289, 0.1619813910420108, 0.21408668483001336, 0.2346165335035678, 0.1718170228650185, 0.24127762861872065, 0.2744822934791397, 0.19835503541067168, 0.4156755698267807, 0.31341251416766436, 0.2663381837060711, 0.19745726756286447, 0.2758940471677057, 0.17294375502022777, 0.33272799379895707, 0.17481303683105423, 0.2615694459090224, 0.33193656395716997, 0.2028449900118089, 0.40600189610073506, 0.39298027030269295, 0.1677880836001466, 0.20255631380793485, 0.22174990432428177, 0.1699647489165158, 0.1487727178587182, 0.19341116471173214, 0.2514640388843921, 0.2025495620678479, 0.25061795249575797, 0.3313237392262237, 0.16959510309385167, 0.1818430039620051, 0.14852868325452862, 0.2677207971095776, 0.3841866639451124, 0.18854755411420715, 0.2282015526916539, 0.1482915460667038, 0.24498249507608078, 0.11220488436900149, 0.2516096713159781, 0.2452388733363624, 0.3101915589334934, 0.25206120886332906, 0.29187068519160964, 0.2506762678357936, 0.18747177595215037, 0.1716732450668308, 0.14455381132164372, 0.20705765513773539, 0.20476140876771898, 0.30234166798825457, 0.18764753219910982, 0.20064493553090182, 0.37887252283368783, 0.19813901980033818, 0.11327303679697205, 0.42655437271764135, 0.12343875516625796, 0.3586599789432232, 0.2555146635260567, 0.20199774412034316, 0.21017565917849312, 0.1307990964008561, 0.1957461690310881, 0.21300968826161346, 0.3162561613731308, 0.22631500347395275, 0.3635265411576577, 0.3162584210263268, 0.1205643265207087], "31": [0.2550444097089856, 0.3188244852211945, 0.3805821131722711, 0.3418994268610245, 0.3143928713713301, 0.2567251120874877, 0.19628166158183688, 0.27452269591243167, 0.27030943837087784, 0.25133698024127393, 0.2678037909892383, 0.36067016224343185, 0.27669115663306226, 0.22923997675203064, 0.3115505213650266, 0.20664008053874, 0.21211427718643777, 0.1629283266351534, 0.26904468836386375, 0.24026237604243864, 0.09521484352889976, 0.13861349069681567, 0.1897534580918344, 0.28013925444445387, 0.30404533948963763, 0.2723899593141609, 0.30326613264746316, 0.2905797420641941, 0.2656530359448959, 0.32895053700055205, 0.22719378105124277, 0.2634464091337656, 0.2816393387332522, 0.2610171443430018, 0.13974407727504742, 0.13732839274527636, 0.296233493638788, 0.3092101205214578, 0.21778504719924, 0.27704669832382395, 0.24715480031482676, 0.31790496058221235, 0.2872706490358668, 0.28197601580294995, 0.25136997048459625, 0.28290248794866174, 0.25288231143815443, 0.2577879131275597, 0.38355796826043237, 0.32476332820091924, 0.3409891271623124, 0.3004012383215717, 0.11569432612897987, 0.2485443249577618, 0.20672085294618928, 0.2747292852146759, 0.08069122483645678, 0.27369974798767405, 0.24664844978538997, 0.28526142958217987, 0.1879636556016878, 0.304767838896056, 0.27572218520207614, 0.2745662395600429, 0.27408683259503835, 0.19583702756306454, 0.16266873387696057, 0.0826975285882784, 0.16059942588600404, 0.2459697194573387, 0.32562568217920884, 0.25285873824660793, 0.09392776954391477, 0.21745051780010763, 0.3066703867964422, 0.292593406205459, 0.16388565174946024, 0.20521484633354856, 0.3402170107960361, 0.3624276632573831, 0.18415667014936504, 0.2561044272891926, 0.24158820655580882, 0.14601317870455774, 0.14130154448426657, 0.10455848313042641, 0.1789096651135518, 0.3171930964987843, 0.28843026216491235, 0.3814483374317062, 0.3066205359868528, 0.32244490507809154, 0.3308889534237532, 0.2742505317639283, 0.04374076086545226, 0.2682968769153256, 0.33166169502542425, 0.3253314892021729, 0.06825406261307965, 0.35737861034902696, 0.2800835387005666, 0.3322865374141319, 0.25370918509436374, 0.40709025588407, 0.35300755658569827, 0.29140399914672477, 0.1223543165803427, 0.21086624279209024, 0.16545334982421817, 0.13492876487630817, 0.2874773862744031, 0.3211897634252505, 0.08867319166767508, 0.1358477032624857, 0.31942474407563176, 0.309469837051999, 0.14509685379297219, 0.2461324366749645, 0.26961354840673846, 0.2521069729773201, 0.35367928941617766, 0.31132974878505254, 0.07247410263003434, 0.2969839814332437, 0.16778108591785207, 0.18483542198280284, 0.1840896295669773, 0.259728274116778, 0.20973454613031234, 0.2568202029432276, 0.23581490378009592, 0.22919674139666063, 0.258776041383513, 0.060024200453325884, 0.18260477578062118, 0.23108273844487412, 0.20892703913287478, 0.22692368737241247, 0.30333851348416774, 0.16652651169518018, 0.3469876144528928, 0.22224510035096548, 0.32436810552723744, 0.3320784770187387, 0.19643347471123618, 0.15973242389002246, 0.18440510830473172, 0.2594582636888921, 0.26168113877486043, 0.2719599692528015, 0.241200576778624, 0.15128446413841337, 0.24420490227425257, 0.23469874060790719, 0.26545411873505836, 0.3375861196540876, 0.3593075433780126, 0.2046315077910745, 0.3817023253456606, 0.3426179167215389, 0.10942854261385473, 0.0427708342126069, 0.25781684517822145, 0.2286085164509009, 0.2223238088949201, 0.2947692927609096, 0.294259822724407, 0.07110348399060415, 0.2511076676516869, 0.28551689345681286, 0.12817184236393514, 0.26859722052176493, 0.3270892790094914, 0.24196856847163445, 0.25100462693840947, 0.2862540720535198, 0.23219246224695075, 0.28396655759429584, 0.22636364793197994, 0.3391628908116432, 0.10870356204294647, 0.1347593300346443, 0.21837076879331518, 0.18448943000942772, 0.32815514920186567, 0.1219632893889705, 0.14317432051795068, 0.29211964825078957, 0.37661886776741516, 0.2425740660062464, 0.26229017241383634, 0.28858325641257, 0.15018836848097997, 0.1717060866173876, 0.12587470019026425, 0.23447175122312422, 0.13763346377873198, 0.19689224458035312, 0.30156355762706627, 0.31792464402493276, 0.2640589428372296, 0.3361410051471858, 0.3033360058947222, 0.1454335646203313, 0.28652939172553016, 0.219009989707044, 0.3146688897830863, 0.3106274715641879, 0.28649823941455493, 0.17611124787657145, 0.27892940616090317, 0.20946821794677278, 0.14729832350798663, 0.30166103948703793, 0.2841453292633666, 0.18318665534504439, 0.33983121362597085, 0.3001686069932142, 0.1362347530772385, 0.2674418750847339, 0.28854943705607766, 0.2574585021070115, 0.27952776515806305, 0.1484028195063901, 0.21089670837774346, 0.08645835334076174, 0.08718719582933769, 0.21844259540151514, 0.0785874906348336, 0.21629172801684446, 0.3218211991306418, 0.32865084955866813, 0.40318030404975347, 0.2446037833398507, 0.2609076066193949, 0.18935804081419358, 0.2850722263238325, 0.22678502098162423, 0.21010454890805885, 0.16399566846746014, 0.31650962337813027, 0.27030273915575803, 0.29825032056992384, 0.2593458388285031, 0.24805145479233612, 0.16968662862926362, 0.19818626553172236, 0.2008692203046271, 0.09693701033667515, 0.22983748482622193, 0.19938782013046677, 0.2754062841465843, 0.2754516394417725, 0.26120084506077634, 0.3596290512094134, 0.2952548958916933, 0.24322421228261432, 0.1314632874567837, 0.13669244721418736, 0.13279818181273617, 0.2951480792529798, 0.2734081130620251, 0.2855244198007207, 0.10168761325989885, 0.270203784362888, 0.2004245827783512, 0.298441701742697, 0.13335942371661125, 0.27915769194653617, 0.33238504361039034, 0.2478173507087044, 0.1776497554126517, 0.34439208279946915, 0.23515229958827655, 0.22043131705818886, 0.30246353937061615, 0.25789862581883455, 0.2615570182976649, 0.13436233154564114, 0.16090242520480721, 0.2891983338830433, 0.06402763985077714, 0.35116176928155696, 0.29769747668182434, 0.1890969182673824, 0.294844817816421, 0.2980212669252452, 0.31253608799849475, 0.25562850441819174, 0.3261200047191898, 0.22269371542347563, 0.22351212114950725, 0.08220516639988204, 0.07172465192442547, 0.144407909182474, 0.09785025509218989, 0.23627953823909406, 0.26936062503116764, 0.32578724163807354, 0.1825589498013152, 0.08604415433710726, 0.1257687728417292, 0.25772590344434226, 0.18915234870817438, 0.2720297173197165, 0.16941561222627374, 0.10865328475257303, 0.17390429681830633, 0.31088120083796555, 0.2625407286090724, 0.29101766018868763, 0.3154701468474979, 0.17818025916506414, 0.11845983072714335, 0.28943227584037673, 0.14825801408189127, 0.26231313845131715, 0.2752976057202677, 0.2990610507466465, 0.33041693841366004, 0.14940512351095128, 0.29023278918720374, 0.2530342681684745, 0.32201548030913224, 0.16583261908671293, 0.31995744595853454, 0.19692599303785835, 0.36092129634381215, 0.24389796551036202, 0.12298495550557098, 0.2166459580878088, 0.15150236405671794, 0.2080948573420151, 0.13864376044157434, 0.28731436839441277, 0.09741934238844788, 0.3045547921849566, 0.3628597079315927, 0.20042214342538864, 0.21667287167589455, 0.22671353162300034, 0.28371421201342095, 0.2890545905751138, 0.1510780788676603, 0.25601564608265287, 0.25034161523878296, 0.2244874777355168, 0.27066835775446724, 0.1274085843989306, 0.10529006935901655, 0.12272205306303796, 0.24835256451157192, 0.31206267723066894, 0.37682501280044045, 0.22436297581891895, 0.26913945836566777, 0.29358520079998673, 0.2867776015093181, 0.23427436928028433, 0.21537748003752677, 0.1303615985756346, 0.33413874506857316], "18": [0.18655674161209318, 0.31712774880817424, 0.25485143595422866, 0.2929265008210875, 0.262205159088819, 0.14650563736362016, 0.2187664587445839, 0.1582941600598791, 0.1993881580996296, 0.21260881146065838, 0.13887643897191726, 0.24847910138013898, 0.26976287374717595, 0.1604357912044477, 0.25402938797845337, 0.25871256577469887, 0.14620162901973363, 0.2618097292609052, 0.21680723312475658, 0.17408166679710932, 0.18092568438816825, 0.1246664616022484, 0.14641582242477166, 0.04465898495767775, 0.04980309050094995, 0.15537123383720333, 0.21823329556399176, 0.2617146028736916, 0.26983513848507423, 0.18879633095214293, 0.21438886188983947, 0.19300680086470576, 0.1716305728831042, 0.11786304215296221, 0.24505803187607988, 0.13274404894491054, 0.09274905302039545, 0.2283169868504471, 0.28437957886030985, 0.25168166568225286, 0.2870007859227798, 0.13244827637847364, 0.05751608005790465, 0.15706570302407807, 0.19505666662335738, 0.07490468075503887, 0.2195798645459943, 0.22145577055859048, 0.21539314680892235, 0.3057113503574621, 0.24240803936455457, 0.10940795346289714, 0.20936851233755496, 0.05815215962664946, 0.260787347302907, 0.22698142737184623, 0.18794785283312432, 0.1845492868860719, 0.14630405536627727, 0.31080838747145234, 0.2717386710819765, 0.19540435912072265, 0.25376522739995977, 0.23730399305018812, 0.20878810539231366, 0.1625968208885195, 0.20807924362450317, 0.24889580543114198, 0.24852978816498575, 0.18031711189595706, 0.20097921613202058, 0.21099504887273923, 0.1993371204380732, 0.051565718335174274, 0.24380848383553755, 0.058244593152699094, 0.030530365855954214, 0.267129619085531, 0.30818594954805917, 0.20543582449548445, 0.256808620656918, 0.0359654663060308, 0.03648883224031952, 0.18358662504616652, 0.2687753237717476, 0.2392429460662549, 0.09007508777196199, 0.17788708630510977, 0.2635227733500592, 0.2869696082438501, 0.14643076158091545, 0.2692260762052722, 0.07360384279239289, 0.2311250813955464, 0.2627830748635335, 0.2537630452941378, 0.2593075779921723, 0.2658727874180251, 0.23263299462719386, 0.32703778955407886, 0.38698547782884674, 0.22747097234374636, 0.1466090015214553, 0.22293783456035074, 0.19822728226734435, 0.16419372884153338, 0.2779694636788223, 0.2186123784793021, 0.13801558408126594, 0.14213023305230008, 0.17151846049519825, 0.26359334954351715, 0.19704222919677436, 0.11455398454120493, 0.22445335245888468, 0.16188106428047516, 0.22078291844331105, 0.2614702629441646, 0.2650946328364195, 0.26886099874256447, 0.1932482143789709, 0.23349363651972602, 0.1801152957302404, 0.18724372781511708, 0.004684328023559752, 0.28174426170585115, 0.07295888490688482, 0.30937088952067726, 0.2916180998113596, 0.2991560367700988, 0.380598828049574, 0.21743358349655995, 0.2823131407705047, 0.18278589692306746, 0.2539866550129982, 0.20070394504430772, 0.053544571405530046, 0.18121710012505626, 0.16470955747597585, 0.30209925260103576, 0.18335059723269187, 0.1328272045356128, 0.18899891220323328, 0.273419904723869, 0.24000765830583198, 0.2811648113297161, 0.27224939771907436, 0.27646879972084076, 0.239706117295359, 0.05922221446350727, 0.3057123048528723, 0.21279333734959915, 0.2168504366614695, 0.25539757454422213, 0.10171241072514835, 0.23535149199052274, 0.20935951547525217, 0.23621821690922223, 0.11538333841104328, 0.21817234785278367, 0.23058502617788199, 0.09534183244233783, 0.11579621240619249, 0.1277756641447192, 0.1688642184336117, 0.2268005546243205, 0.23827541194378887, 0.21054754052161392, 0.1929473714160662, 0.27492012908920027, 0.23238261042202918, 0.23626888167418272, -0.02411394058845351, 0.17816712351986572, 0.009118359692457747, 0.23529640416470834, -0.016055012682273117, 0.17590206289471622, 0.24353357793988986, 0.2664833033341769, 0.1846509820486012, 0.26044816147991656, 0.17316963157162324, 0.2429874631675845, 0.17375250451161, 0.20258007923039573, 0.2669119380721185, 0.2139429615641464, 0.20594241414033698, 0.21766907115268863, 0.13846226998978914, 0.20574065041394146, 0.2557550587876404, 0.08231049281173772, 0.20780688516036472, 0.19843350902953577, 0.17543109790978031, 0.21834927266355658, 0.27585369385496716, 0.24116490997643886, 0.16008571501925214, 0.1758091840260834, 0.1836047058838793, 0.17440605965410108, 0.05076986386526622, 0.21636019003814164, 0.18528828013278714, 0.13721145622019504, 0.18044744197333046, 0.2762893981276428, 0.24224851529850294, 0.1892792078054275, -0.0015233764473862937, 0.07769003208504034, 0.21346959036854452, 0.06882760701613459, 0.28987364122992015, 0.19720620783391585, 0.053332625468060904, 0.21422865156998297, 0.318790937446362, 0.1840284341919134, 0.30467874266197076, 0.25802830429762713, 0.24535481634996623, 0.18249183866862673, 0.3788623864298507, 0.2612825529683933, 0.10572717815391766, 0.23892576223071596, 0.08426378505991383, 0.21223657024031342, 0.2705712039228194, -0.015403036864229627, 0.14481701200896469, 0.1878652182262456, 0.25829081911232576, 0.28984162859427737, 0.17125328148757726, 0.2743859070073547, 0.2584613451823222, 0.2342456414688126, 0.19695103305744446, 0.20477136644127802, 0.21052729191848593, 0.2710191274497894, 0.1033227270651668, 0.2800768858743681, 0.24210007966248492, 0.288261509873924, 0.28361755152624374, 0.22725679619445158, 0.18659313395689586, 0.01915471549312322, 0.25922587918898404, 0.1745873727324579, 0.34551886225014117, 0.29891743656000686, 0.038675962161913525, 0.324324492886653, 0.18389063633232222, 0.1896144973943626, 0.16519952864046047, 0.1461285317144388, 0.17660116802195114, 0.20772514869427772, 0.07355735471395161, 0.2990026011369333, 0.20102776042100684, 0.18518900910790245, 0.14635098007068742, 0.18214272256802785, 0.25106023642309744, 0.2376290558250893, 0.2351146790264321, 0.23403063167691576, 0.26390122760011736, 0.1904175592584473, 0.25501902536994214, 0.018464326681043346, 0.007355552624983917, 0.2313075619658195, 0.2031025716479774, 0.23680001915800958, 0.23697294896333387, 0.07567904584607205, 0.23636805274990763, 0.09655595749693731, 0.14268971290924157, 0.23036933699462087, 0.29714970014129555, 0.07159366477404161, 0.26763107150546456, 0.2159025624034843, 0.21305574194164456, 0.31123172439914004, 0.16725770530355547, 0.1821430749387412, 0.16031841728442353, 0.2595525191320325, 0.2197504214480002, 0.2856669963515088, 0.24610195190328654, 0.06190552921743131, -0.016251718745873847, 0.1584399338536664, 0.27231792580585185, 0.2781672265885572, 0.278495355002617, 0.289634306743421, 0.23076244684456348, 0.21330205581688766, 0.02268610855825825, 0.22098602425091668, 0.2348852381698174, 0.2787118002419559, 0.30634197878003455, 0.20918238898708985, 0.03307574000195855, 0.23719274395591647, 0.34527092256613456, 0.20529238594906252, 0.23133815964140234, 0.07967354558584341, 0.22915459581492317, 0.1669589793958181, 0.24581127602794772, 0.18695806576910834, 0.2576015489099506, 0.0515265266845579, 0.2523051190734382, 0.1889116771310302, 0.24132511309726343, 0.2239923904169262, 0.313882123459607, 0.2564883481644929, 0.36170443838453137, 0.05535284093607344, 0.2011890887323603, 0.2799240395357682, 0.24608654924272017, 0.16818504552944127, 0.16153822241002755, 0.07660669433419309, 0.11194445889705432, 0.17652325538219035, 0.21733964512411483, 0.10319383996760494, 0.2066175052836636, 0.251950789366206, 0.02615241967561528, 0.31051968315933515, 0.21117012942873606, 0.21529491772020243, 0.21782967243823675, 0.29705620863853516, 0.10753849989257472, 0.2308329494260472, 0.23297335089483986, 0.21347062546815312, 0.06303608840161509, 0.273388366837516], "39": [0.23523106469445873, 0.34939181516402923, 0.12452741224700932, 0.10311311250447643, 0.30049307995118, 0.14023877234184692, 0.2971119393669564, 0.28734721856798034, 0.3038619436133352, 0.1944037197448446, 0.2709283941124235, 0.2824921912551894, 0.2911314784398581, 0.30764710253989813, 0.011879613528302867, 0.27943478305983266, 0.3132098377859289, 0.21501232789403354, 0.03897770574257667, 0.2199703909325234, 0.3185634430200429, 0.2785540360123663, 0.34194424280404034, 0.2256251014383882, 0.26208884179546055, 0.32349030108589477, 0.27436371756334343, 0.29041793671094385, 0.28428009565634543, 0.2486145048752668, 0.14810391358103558, 0.35841848004553384, 0.2058895777387516, 0.3017616022410194, 0.28919495628663866, 0.3186256016765926, 0.2921785327352844, 0.28986775621343863, 0.09861045405754044, 0.32872099276365213, 0.32582260052569434, 0.3515045233419393, 0.3296095566194677, 0.33624844131447323, 0.28510535920818686, 0.2904453132527574, 0.15963124005948745, 0.2356195376106545, 0.03709246835566258, 0.25890949228022786, 0.3363655822490239, 0.21876949082965494, 0.2622511799048556, 0.3135644620910114, 0.2541583780878962, 0.2895254636385613, 0.2911908078350007, 0.29931370744779523, 0.30485359944393736, 0.1351389525326643, 0.203634413809052, 0.2736655150412606, 0.3589766901015125, 0.029234026069476227, 0.2513150932804503, 0.2914351230274828, 0.3017142530115999, 0.25591485096349237, 0.32645711939703104, 0.28678476521289875, 0.2095447499705701, 0.2629173570305238, 0.22354095929845028, 0.2965148997298133, 0.16380749718688287, 0.23057175836519658, 0.20787664590040236, 0.058311277881670204, 0.23414109397722715, 0.3150550724937557, 0.3307039767605542, 0.18243539956144714, 0.21692992361409216, 0.044598627242957316, 0.2950415918977661, 0.41094156399176995, 0.2734142316553373, 0.3140763568881898, 0.07811896641111724, 0.11091951168969642, 0.2653951689141346, 0.2578004862269655, 0.2031020588809513, 0.37668213360129443, 0.03343201145797168, 0.35778113307530723, 0.34213971065109955, 0.11693522301977088, 0.17664063552149548, 0.3300386406075427, 0.34911971753653204, 0.24484372048969982, 0.32563641515109615, 0.3362426911636755, 0.3357660641002966, 0.285003253678421, 0.35785328993171617, 0.15569009816883783, 0.21495972607235447, 0.2566726178983054, 0.2427643074521305, 0.05864197674715082, 0.27684141806474816, 0.12313346882151074, 0.0027529388974050404, 0.16310402026521814, 0.26931564356933585, 0.18527078024437005, 0.37409620535878657, 0.06165702413340497, 0.39716360300539977, 0.149019749692554, 0.17796490596907116, 0.24834764459848507, 0.21771791143715097, 0.20700176015070734, 0.3355625207007856, 0.29350781257135117, 0.25638634755216516, 0.18608664846149411, 0.11421849751731582, 0.25978880678525895, 0.10523677910353756, 0.26487539914416447, 0.3040720704257962, 0.05537244544394001, 0.410470943529475, 0.29287276909807514, 0.3091627956191476, 0.3683544579160538, 0.1471862019890666, 0.38209946357647145, 0.09887070964110008, 0.24283158594341928, 0.27033365816853433, 0.2151224700080166, 0.250923319975553, 0.38587651747357554, 0.28564745883962067, 0.18555901394059976, 0.22174593012872687, 0.27839297804727176, 0.35549332991618804, 0.2943132730980878, 0.33845870361293134, 0.3339371172360671, 0.3322929896525517, 0.28639095400300274, 0.3019509546583716, 0.2638973876269947, 0.25647305098267564, 0.1488921260554296, 0.221166235161731, 0.08930747796846525, 0.23137138713421634, 0.2807453266856055, 0.3521384502427298, 0.25551324676620885, 0.2807622841676836, 0.24433132412128045, 0.2873359607851418, 0.18015640881816258, 0.13651793277980767, 0.2382664345865216, 0.09314417766468272, 0.239351920145919, 0.2903096450723458, 0.13133323817042622, 0.25022661638902366, 0.3594601995004828, 0.1875050590121582, 0.12978515998635712, 0.2848163694043271, 0.14897748693357013, 0.22213082882875188, 0.381797340898288, 0.1501125586040786, 0.26529233029186094, 0.12813600186314525, 0.29573455453225406, 0.3560662333256874, 0.2976120622878016, 0.3092280330785864, 0.15483816473715264, 0.25744950417503, 0.13654630909183543, 0.188430416307758, 0.20471107626586887, 0.22256768650159509, 0.1760425758304806, 0.22583266974603358, 0.16058299581306681, 0.19710094774400758, 0.20659029856331496, 0.16633483616186145, 0.22311875637273595, 0.30737113365414215, 0.25276255742273823, 0.04597798408646391, 0.12239358192531774, 0.32803726839141, 0.2676142873419129, 0.268763216826183, 0.2594699087776131, 0.30373005547043563, 0.2333670070249423, 0.25912558946060904, 0.07809388162898366, 0.3862111431978294, 0.3663831907385867, 0.28524530060599235, 0.24792619241677394, 0.31136022243469846, 0.2795175470388763, 0.2438088896499906, 0.3772480230114366, 0.29867736814634077, 0.24098474247928622, 0.23774232122801464, 0.33140595938091066, 0.32916298427833873, 0.032771778812337164, 0.34465808508193263, 0.3562610681517559, 0.25436944769120345, 0.28414722851376856, 0.24922600806919878, 0.2960136852364939, 0.011795562463223008, 0.2805466904668475, 0.09531178832447455, 0.2756663027909097, 0.2973686933499795, 0.28954062946399783, 0.268923320120367, 0.22596300679038578, 0.16110912375124847, 0.30750694676066415, 0.2735342503092344, 0.252351067618672, 0.3083465574498771, 0.35793312771311026, 0.16081610777215355, 0.3098725146031527, 0.30944967492933145, 0.29356740681240534, 0.3234050153053475, 0.2838595443477834, 0.2828710072379323, 0.28890350567518835, 0.32767405746539435, 0.28490207469692047, 0.24438085847407176, 0.1849825225729701, 0.2594376738615204, 0.28006383071380964, 0.32963164856400834, 0.28240139010852316, 0.20414831968220526, 0.13489255678709391, 0.24875661727247358, 0.24877743212082518, 0.28464027291964095, 0.3131410840984017, 0.26265532240871803, 0.3122137506338315, 0.24224662235518496, 0.32453249608205825, 0.1796480788252938, 0.3947080209666824, 0.2720304801429465, 0.2852415895144268, 0.36316954452342315, 0.266302528044127, 0.08646216709848821, 0.07500264889309848, 0.26477666618150525, 0.3358146978617398, 0.20815587798479077, 0.32301808540793464, 0.0968856350017516, 0.28131777621728743, 0.12700788460869122, 0.2604945978475822, 0.2758980948263502, 0.33400540213232083, 0.26983511579425745, 0.22157343406153288, 0.2630951653104667, 0.26773030800112074, 0.242659766161192, 0.3012612478822837, 0.2700726083770859, 0.117463914983738, 0.32190186003802235, 0.22069236698742226, 0.3703309555132205, 0.17521873198416377, 0.27157638305929727, 0.12792660575132997, 0.22555406864870908, 0.3631910005211331, 0.2884028712019001, 0.14813515094738205, 0.3065996331477647, 0.2563076860867764, 0.28154801224100134, 0.24442134481259106, 0.23510479406395263, 0.3206682057202476, 0.20857820032257277, 0.012223103769570217, 0.3947513347337751, 0.3326452593546224, 0.23229981838627498, 0.3199662200355225, 0.27458008023976105, 0.27968290053967476, 0.1386234648876683, 0.34918809745812224, 0.21762039328572114, 0.1969673530810968, 0.2752518329074538, 0.298076419098624, 0.2862746326857818, 0.26296352077438623, 0.4238235903111659, 0.29539854961841494, 0.23056664739832308, 0.3068761475888808, 0.2670108564354867, 0.3148970687535129, 0.2507725296035645, 0.32871077292637363, 0.3185709246641773, 0.07321966965460526, 0.28442002406184175, 0.28348526151561276, 0.36931515749765775, 0.2793854197592311, 0.30603638174022846, 0.20855700456394438, 0.12772509459481882, 0.2736196702705094, 0.30719602455833644, 0.1421168910598522, 0.2969123096158922, 0.15857216049864897, 0.2515889418070062, 0.11431660397333969, 0.23868129842596403, 0.2916743702636588], "37": [0.19052845989076878, 0.15980514587580974, 0.047034763476271405, 0.3517762216538552, 0.22202358440300674, 0.3247664670142522, 0.3307937196871773, 0.2687496120979557, 0.2683894703971923, 0.18376629958427673, 0.053665166291772384, 0.3547171584612233, 0.3864610715453984, 0.29482683015956784, 0.24325775284075382, 0.26810622544619894, 0.2146781421062827, 0.27248078418933713, 0.2624092519420571, 0.17284625666768252, 0.19286882474681769, 0.07776112667499366, 0.2984495811037665, 0.24435722308936372, 0.11159522114114319, 0.195603245135086, 0.3105400063709478, 0.3153210997011478, 0.2609579588589899, 0.24834972122309892, 0.3416784525011463, 0.3555002454570951, 0.3225539264737441, 0.3392087981492529, 0.2502947235415083, 0.17706787611065697, 0.28455502355386497, 0.2588998987891471, 0.3074215043527889, 0.3403419781012537, 0.22154661708431445, 0.2997394394292471, 0.17076340723000885, 0.23041708605546066, 0.33935984950175213, 0.23447740147896143, 0.26481140735552167, 0.2720721054811981, 0.1499051068649816, 0.08467068070336142, 0.33662557943832516, 0.325990706204882, 0.17749295790861747, 0.1999780771735648, 0.07419960373837846, 0.20252698261926977, 0.33452758589067394, 0.19596539289173792, 0.29028284412296973, 0.31749829548621267, 0.3215085092944606, 0.3060761926283935, 0.3172726970486921, 0.22242723963043193, 0.3310839308713287, 0.28554832046453754, 0.1468623024326337, 0.1729244725547929, 0.06796663443683965, 0.33046308553847253, 0.3626132139663605, 0.29063018271955404, 0.2639693107977946, 0.03867343112801904, 0.25265803410166615, 0.21531307077257564, 0.2173222733499032, 0.2599300377670121, 0.2753715225334864, 0.3630198783681536, 0.22345953351646847, 0.0858253413492836, 0.22483014397112266, 0.2934688032676427, 0.27354508520156173, 0.21338499720197335, 0.20238456738008798, 0.2283793754284707, 0.2884228378286262, 0.3440208583014325, 0.30992775975514886, 0.33707634243848, 0.37757509395677036, 0.2792473593016244, 0.16187453322416387, 0.11355076219264015, 0.2563915579431062, 0.3147235941513392, 0.307168730797966, 0.23836525235868913, 0.35678991704575436, 0.3011557946360509, 0.3396364468288513, 0.2054390779962785, 0.2828237939850711, 0.31395114835724836, 0.2686477339852715, 0.08030675295435243, 0.22055267863605674, 0.3387167149746347, 0.18741452190723581, 0.3393161947563964, 0.3122748186515624, 0.3441118263641859, 0.2759428099033218, 0.2502072007215937, 0.24470727701982722, 0.27030702888156727, 0.2592979324714965, 0.35934603371697593, 0.202360311362859, 0.2588219907618176, 0.23236625702498473, 0.3063920271960947, 0.24908487324560916, 0.21537358540070123, 0.2170443585548227, 0.31148261467830624, 0.13143694201487918, 0.09793040652390861, 0.07082385400594697, 0.1299733854213965, 0.20262576744655023, 0.2960220371006537, 0.3876284046107635, 0.12638141214447637, 0.37925974794687856, 0.28257024444238277, 0.30613840901593364, 0.33125607724890277, 0.30915020296621115, 0.22501399138480974, 0.34131722403321396, 0.17430777980807646, 0.23759131554340226, 0.08662176972796817, 0.1477289798268612, 0.2917798693114181, 0.3258909501067239, 0.2918709483308942, 0.10499516185228117, 0.1946132536147473, 0.09075400017890697, 0.28406774494921777, 0.37083420798862826, 0.31645632346854424, 0.3580774069908192, 0.3366287045384244, 0.2522507485207991, 0.17264246909151, 0.14816171162345654, 0.15503024979413096, 0.11474265919198924, 0.2739625709182879, 0.28026507985185206, 0.2183216168184088, 0.3467757399300854, 0.11278043219543012, 0.2583768413389307, 0.11535131327420314, 0.2957616124963744, 0.2733052990427905, 0.32490270205843935, 0.2531094075792038, 0.15243891139900512, 0.2833214167241828, 0.07906899830515887, 0.2475147322772006, 0.38183490524769387, 0.2718064239648717, 0.29699339336676944, 0.09693170348496156, 0.3297526814221767, 0.1457013812145921, 0.2197353082727338, 0.28489389126134823, 0.06228161887845388, 0.3514690452814975, 0.2876009888454981, 0.32329641098582534, 0.07276071431976161, 0.13031616547369082, 0.2028880043583038, 0.3264658632074946, 0.3042892616349248, 0.2407470984101747, 0.04270061557814673, 0.1567451655476877, 0.05257554693926335, 0.3225990050080469, 0.30826689404775914, 0.2202921486404358, 0.26323281089863027, 0.2238184735737638, 0.21302828402892585, 0.28452698595933157, 0.31795155410207276, 0.27102308064134223, 0.3470651879733085, 0.3099703546208238, 0.36226329825226783, 0.288790349472771, 0.3453696749862316, 0.14508380988239894, 0.3618914649420724, 0.2769608816424219, 0.06381606778415577, 0.283986162736005, 0.24455213821211327, 0.17508358527144408, 0.1672046351584075, 0.3316907902670862, 0.35638974158688397, 0.3672894695964316, 0.387992844968286, 0.22938095315521925, 0.34905890215956514, 0.3696215458981533, 0.26065668779186985, 0.36721556933672095, 0.31196811874915353, 0.2981213830403505, 0.24431113627670573, 0.22185252798091865, 0.3139571078932199, 0.33046827505073006, 0.0749060862367171, 0.2649390292760711, 0.32291122460027477, 0.32063787012296624, 0.28045207110809167, 0.29996203303270425, 0.31513912406347794, 0.34769925230248855, 0.36946822366442156, 0.35588006211418377, 0.3410739563436681, 0.19695179619720105, 0.2506741532894934, 0.2120546154464797, 0.31091517992743073, 0.30509767666906285, 0.305471573955577, 0.06861080092583519, 0.21316951842682333, 0.3553150264513984, 0.357887520262299, 0.28376786553520306, 0.10015223675612116, 0.2205266253048579, 0.1886148203488433, 0.1386773333264193, 0.34375389923384797, 0.36750082987065563, 0.3226787878338401, 0.3275326406337184, 0.11922214802529789, 0.2772796510891782, 0.2563362293086256, 0.22137570014591249, 0.3313232776407857, 0.30439043074895783, 0.0934209827117221, 0.06573206192618422, 0.11739123631041379, 0.2573206245810513, 0.28258686727429877, 0.3045435864021827, 0.1815874315838285, 0.3345619282346745, 0.11532004223387052, 0.23788458290928394, 0.20091175023805732, 0.11963468378047581, 0.3185339140726753, 0.31214224887961256, 0.23411187467291403, 0.3410541443167619, 0.32860127445125786, 0.1857018497434479, 0.12064202705314377, 0.2453916974337248, 0.31619911041242604, 0.24227606693426001, 0.32381110667250307, 0.3057839091358238, 0.31578716699569753, 0.041863794241597044, 0.2983644696593723, 0.19695997088422196, 0.41579215080946413, 0.2194942961963832, 0.27693639535892817, 0.18151725195003443, 0.26861510782439624, 0.1052050264564497, 0.34626164961308387, 0.10951140591869463, 0.2823952802783056, 0.1484958110012541, 0.26681058252277406, -0.0008046612888060755, 0.15105422588620568, 0.3025910894940709, 0.19870996011798242, 0.15041260142174198, 0.20300874303395333, 0.3104319797851954, 0.22842979831394317, 0.30678032848537395, 0.23875395989757753, 0.1779551610550029, 0.11815842180729376, 0.30820125576342344, 0.2534713621120601, 0.20970609523553693, 0.38542665722532465, 0.0786822291595343, 0.14329535399940166, 0.17569399168168745, 0.3069352224421539, 0.3463707656389418, 0.37847191926242546, 0.3017066714654718, 0.34152170444841606, 0.23761274386527584, 0.2677208321435662, 0.1424071871806851, 0.08242306618149069, 0.33970698978911323, 0.30503118799663315, 0.2769993744102221, 0.26008798275256567, 0.34071995805362293, 0.2985050635570559, 0.09793515751596331, 0.2844431915766646, 0.24653315229074357, 0.2116907848864522, 0.08711658341908718, 0.3254217382985338, 0.3464281129017124, 0.15063546773625594, 0.4013256158386049, 0.17001938534436983, 0.31223315274441854, 0.2722667053653717, 0.380919305953451, 0.18649897355349118, 0.3153297525164536, 0.30559585624170615, 0.12965937057544855], "23": [0.15048780762122527, 0.2784763875868352, 0.3514827165624139, 0.23429609336676252, 0.2621607704321238, 0.254015216242522, 0.1476552307733328, 0.13774363826221314, 0.13672803060974062, 0.20647808351082256, 0.23697125846862765, 0.2632012839699373, 0.24972254923687146, 0.28259169510965393, 0.20938069108534937, 0.15114524250289388, 0.12615615052778456, 0.23498242844239361, 0.23976117630229082, 0.198707547763308, 0.25884876568516585, 0.28039341798867207, 0.20523010069036854, 0.0920826437928238, 0.1042089787319408, 0.13291711360345126, 0.2229881663287687, 0.1443689760083709, 0.24359438601947084, 0.1513966442529261, 0.21418375721508576, 0.1413139019658984, 0.156024802424137, 0.148885708221995, 0.21149539600019043, 0.18798804155344478, 0.24820840839296462, 0.20351660674791652, 0.1534166578068108, 0.35709807962843615, 0.15328064660419838, 0.27839850470642497, 0.2668467307456152, 0.2761117850132174, 0.08613928814133599, 0.19584038484734706, 0.2059063838962955, 0.26490117067046987, 0.16972831123874632, 0.2406948098607957, 0.3655657195106817, 0.23539526755796067, 0.3364882716951593, 0.3019255941514473, 0.13802871757619994, 0.11192420904593323, 0.1383278637090876, 0.15712872860970353, 0.27339022495428517, 0.26064992150759286, 0.1934921110886216, 0.17888738768890466, 0.13462366005367238, 0.17896794940590763, 0.23900443917050446, 0.156609601687993, 0.17556395593469473, 0.17749524404305883, 0.30207307786821525, 0.24823105055838857, 0.09760518164015387, 0.33390700066907564, 0.1424359912498532, 0.16265593286923963, 0.1701261513833614, 0.24396974062709195, 0.3210951688974127, 0.22446694675125872, 0.26975660422695813, 0.21696414397987607, 0.18545587178324313, 0.054034778224601406, 0.07450956634379338, 0.15563557055475574, 0.19946972824730433, 0.24666272902184624, 0.30808117222390247, 0.3521319578838552, 0.16405691457139907, 0.27901984517474737, 0.16781608541972404, 0.13857247013245375, 0.2858348116638087, 0.2487251903130982, 0.243011493158557, 0.21793281118360489, 0.22573636412091028, 0.2262874586620676, 0.164227767165594, 0.09572810225144394, 0.13358470131388236, 0.19427749444208117, 0.23649329995230256, 0.12993658819712017, 0.17843382451669348, 0.09926554967545612, 0.2946281785143714, 0.20435447386400182, 0.16160479389013185, 0.2662885261886648, 0.18092076967424936, 0.10116913222422694, 0.17248986413293213, 0.15536154567469937, 0.14803455411139965, 0.21267930299684915, 0.05470535615558111, 0.2927469696381926, 0.25636286587535473, 0.2615495051625526, 0.10546900449122001, 0.2310685793955795, 0.27046853506222523, 0.0546994133386377, 0.20675572732411984, 0.21651705595815193, 0.25324344855308717, 0.2542937493622423, 0.21678070586827877, 0.2763476335351363, 0.2793060648709878, 0.1965986537911921, 0.14539173652600648, 0.17197951047047963, 0.24704462174070105, 0.25041029475301835, 0.2947194343675825, 0.17260633030581263, 0.2547183679860561, 0.20911082655585697, 0.1446490328638905, 0.2665742402432002, 0.29843120857491445, 0.2793432690326718, 0.24243034431786298, 0.2171853208377953, 0.18555002946351154, 0.27133378352326704, 0.22063843088784524, 0.21213232169608612, 0.2648848886300383, 0.1905446633464009, 0.184141576345108, 0.19844305182163163, 0.2234655148157388, 0.1876254439780617, 0.17718676081304308, 0.20533797808965695, 0.2579059957459745, 0.23975839623719203, 0.36275250360368483, 0.20997560788042163, 0.2801434139994211, 0.3387909525555339, 0.14089482311563478, 0.17915675168164222, 0.20995358465918518, 0.2478243462588325, 0.25915123310100013, 0.28658937321790096, 0.26378232955332015, 0.16739119080382822, 0.29172572701703475, 0.1467358348029523, 0.18475156839614174, 0.15261875932217156, 0.22543867478524546, 0.2777890303985595, 0.26254293983635013, 0.3017879172080453, 0.18005909627249303, 0.2222066279279492, 0.2632162844761449, 0.24078795932603006, 0.22728280469389975, 0.23691109517473694, 0.20496673405990018, 0.21939732841895046, 0.14611328006231478, 0.3415404272509269, 0.21913746872120607, 0.24846523637930837, 0.06738957083801747, 0.29514620693625476, 0.10584761925911372, 0.10524281808956089, 0.22693836777473606, 0.2009002101207049, 0.19713524192168164, 0.2617201115491236, 0.16910313436068303, 0.24543823962691008, 0.20604935465925667, 0.2650615990659885, 0.14206007536042162, 0.21850719657423778, 0.20894289065849062, 0.23334045522666494, 0.1356557360429512, 0.13956028978680307, 0.2431541436361089, 0.24563255006870957, 0.33294615385366455, 0.1263685782344583, 0.17343779490720215, 0.23202879999213608, 0.24565721080153718, 0.12178778788464131, 0.2788122994541936, 0.18667081989224837, 0.21440498354118975, 0.2645191739217844, 0.18996711270523453, 0.24700401104729622, 0.3034452449865425, 0.16010386192261034, 0.2583568376561395, 0.2797882848389623, 0.20992878729754466, 0.09628405086653394, 0.17405382236172526, 0.15156790640290488, 0.1591578330315048, 0.18818598500294378, 0.2814707450019546, 0.16574396253545265, 0.13684847026362892, 0.11627898302216452, 0.1781337190032968, 0.22282048083860592, 0.12013729716749103, 0.21093806380335442, 0.34053734864929325, 0.15685993678436347, 0.20797988572244433, 0.20522679270757602, 0.17439767880443416, 0.20112212521422043, 0.26436028999378364, 0.18303343498606547, 0.1529939150111218, 0.33584275221499255, 0.2661359192338301, 0.18396466914484125, 0.30259571802468493, 0.15774721979822773, 0.21805116209110062, 0.2829611525524469, 0.29847050159074173, 0.198837129012167, 0.28164139444755193, 0.19459133635718542, 0.21465174326252562, 0.1844133373990116, 0.19383093453181827, 0.24638893197152306, 0.18799044320147043, 0.1890422232248861, 0.24375865497347793, 0.2094850673151969, 0.09481696113453306, 0.15374459367686133, 0.28436269183555324, 0.3332379534623764, 0.12841415106355553, 0.278563890203365, 0.22577271221372217, 0.212357392405989, 0.1155614986885939, 0.2017584315846029, 0.253330978255989, 0.33796534511319765, 0.3006082611292065, 0.15030079471910637, 0.11241051250115203, 0.2651689097618914, 0.19539795404781904, 0.19165088070812178, 0.2970168902643199, 0.27968008893121593, 0.2922306582656777, 0.20935103761581447, 0.19481493511576398, 0.14823496360064364, 0.16070721394454135, 0.1654562377119444, 0.2434189783098981, 0.25470093251502374, 0.2536502678974918, 0.22588347963682312, 0.22654131667499325, 0.25620541712070977, 0.09384890803282471, 0.24209469837205375, 0.14927744124168937, 0.3202529445029965, 0.26213189863838504, 0.21037414516656006, 0.12682006029782747, 0.20172001577494325, 0.2459717608507693, 0.221261581831187, 0.18079686000512574, 0.2053489837568122, 0.18262229475205308, 0.23514198323572044, 0.26660347090008274, 0.34177031593876334, 0.2541955468894756, 0.1856353968683921, 0.2441652000746851, 0.1360297049194301, 0.2238804939190172, 0.30046022108778503, 0.22746081590528255, 0.16073935813146686, 0.1553874279372821, 0.17516815489316578, 0.25507001988696093, 0.2547696111191129, 0.1584406761009342, 0.20486263459873985, 0.2758458270483662, 0.14515803897929241, 0.25538174201089414, 0.3050698404752621, 0.25898891368908195, 0.19130950605258584, 0.26432460391890417, 0.1834571970588198, 0.1854175762764853, 0.28726099830032586, 0.2652629768621752, 0.21943144035304352, 0.26605731196824445, 0.22648157229473992, 0.3981134631978425, 0.34020806160669287, 0.1979564558864009, 0.3501780409894424, 0.23105138280664667, 0.234946985222951, 0.23175145211889855, 0.25468777780048624, 0.19944760406880727, 0.22528071837850303, 0.2073714620503671, 0.14728303441801474, 0.28127813612080327, 0.1694378023857021, 0.2484967958437017, 0.11428667916892704]}
\ No newline at end of file
Index: pereira_word_corr_user.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/pereira_word_corr_user.json b/pereira_word_corr_user.json
new file mode 100644
--- /dev/null	(date 1615528350000)
+++ b/pereira_word_corr_user.json	(date 1615528350000)
@@ -0,0 +1,1 @@
+{"M04": [0.135670218131284, 0.3464328878080602, 0.18512367803906227, 0.14488089265312704, 0.16348065642017245, 0.14795556862440226, 0.1968332582667413, 0.23886915034757536, 0.2547286217358025, 0.23352772351113202, 0.26564333834243076, 0.26332565891065374, 0.29135166831871717, 0.19819628022471306, 0.14800943786203086, 0.17648267561883918, 0.3577236224622553, 0.20456668216129492, 0.2625788587567465, 0.3292651640237493, 0.24519748629153365, 0.09275522635502884, 0.18063464518710656, 0.18053822086842722, 0.3019478955536523, 0.11684677795273832, 0.1907259058328482, 0.034242511229871125, 0.17341487110474127, 0.13954156496003547, 0.24379319191285456, 0.2711207658738839, 0.25089922111988167, 0.08528058219405778, 0.2591901011560665, 0.29082997287114987, 0.1282208441019948, 0.19939895225596593, 0.271372333669491, 0.3250821123610187, 0.20226954889124346, 0.22706169902216486, 0.6276071515299795, 0.2497746219709422, 0.27150658720899645, 0.2727291770568692, 0.17221804874977234, 0.21761818209586145, 0.14547587510427176, 0.23432074675996428, 0.16755449679343726, 0.219594290934575, 0.21716405329013633, 0.13946639611258618, 0.2982255993143712, 0.28341776143668096, 0.14983621983056783, 0.23694565921341593, 0.31662054672946816, 0.08991790907022856, 0.24997655377608166, 0.18484404582438585, 0.22709210141879146, 0.30777897401337795, 0.1625647058762863, 0.31098346392305193, 0.2863231133663809, 0.25625519127780727, 0.15583720057650705, 0.3971099889222859, 0.27453244472410887, 0.28354835809275414, 0.22734860625492523, 0.18348033921581106, 0.36244024316182827, 0.5013168185849258, 0.24272266744700632, 0.20406374516724246, 0.2160353097751184, 0.28695625759502685, 0.129782245393772, 0.1020303045186459, 0.19660306436554484, 0.22838725489955775, 0.1511981453613788, 0.3602353176973712, 0.2658063749319107, 0.24932794839985756, 0.28330563027995836, 0.2495992845423069, 0.27634933906571535, 0.2449708233664205, 0.22720401990306593, 0.2746549262642502, 0.20098230805087738, 0.15388108117064853, 0.2720668813067615, 0.32182239812628394, 0.11376102356263645, 0.3388393860592659, 0.18202951919623467, 0.23965624019747078, 0.22258174881844156, 0.27198228372575795, 0.3767824338346932, 0.2744070012539679, 0.12543972083849858, 0.28872979307841246, 0.2218535189919836, 0.38629546045356894, 0.1784687217009878, 0.3049162060532967, 0.16965938591815946, 0.21521324819272825, 0.20403383108848824, 0.38708131656765143, 0.28598517674931395, 0.1705852074058338, 0.07174038486084806, 0.2613931397128177, 0.3322197196542995, 0.15662644305559506, 0.43016185387395384, 0.16583088719253652, 0.05140993102396625, 0.10226023255601394, 0.27153645713608776, 0.14291630790338258, 0.2579957883647804, 0.3048882771003597, 0.3543499237324681, 0.15942379240218105, 0.4201880628136159, 0.14195803677753713, 0.3145510804621095, 0.24653691515039525, 0.16184860511393628, 0.31425831912066393, 0.36238261140944444, 0.2629346618766394, 0.23409211752788092, 0.3557606698067696, 0.31134307411810885, 0.1817714431981009, 0.20511676085823505, 0.09943738261085269, 0.4029874228221512, 0.245236602500065, 0.2727072827713129, 0.1723426171417697, 0.324652985647871, 0.1747529133257787, 0.1642155020436529, 0.25223499673147376, 0.10545585652628914, 0.2001256785163042, 0.3396140170730537, 0.3205366867207214, 0.3340001129125281, 0.32538713243747086, 0.386761036327511, 0.19997494594745757, 0.18842577929110674, 0.2167292169562795, 0.1493971786186521, 0.1295625643777774, 0.15204659196477469, 0.22025255784972997, 0.21975908914226108, 0.20965650481516088, 0.17216686576081927, 0.2368198925154497, 0.2512974351831335, 0.2313051786056368, 0.29806033892765477, 0.3856947068733614, 0.2959688903905711, 0.19347654569220138, 0.24871667228579633, 0.15808437335477857], "M15": [0.14000893581240023, 0.22798061710474882, 0.20057514069768284, 0.10193690192793314, 0.25224672935547804, 0.2147176906792231, 0.28797010092094444, 0.3089619021883398, 0.18812837169483188, 0.19626413042049254, 0.24607933223403197, 0.14315725019195563, 0.25694809535532503, 0.2932953566538251, 0.2680316159661862, 0.09950263340379019, 0.34900919684650317, 0.2045108067155043, 0.27094321614265177, 0.2522415487853146, 0.1980351204147682, 0.11927216975246951, 0.238091600689232, 0.14919989550563417, 0.29520055826975594, 0.3755164060058906, 0.13242202506303424, 0.21065611204437326, 0.240501946588512, 0.18001301508011813, 0.29965186122199494, 0.2738344503966189, 0.17044144951626997, 0.19297034873124252, 0.16705549171163994, 0.3139766776413474, 0.20324144099372293, 0.08665139106560173, 0.18434278100066195, 0.16904576292062146, 0.20374638510382306, 0.2947011498534629, 0.3207155413199929, 0.2618459137384902, 0.2599935919963823, 0.286667288654744, 0.24924496732548895, 0.109491930302667, 0.1472782796186698, 0.33032917786490923, 0.23454855765319885, 0.13622291915130078, 0.2057171945778288, 0.28034018939160915, 0.2950754736340258, 0.2699683794598664, 0.22125764663832992, 0.28582769161326577, 0.3201636141812639, 0.3227774676288207, 0.2076147524538794, 0.2657025091646037, 0.19401600714002856, 0.15976410497405907, 0.17665801194221506, 0.09431316696270504, 0.1926184230268421, 0.20220626169632572, 0.25356008366767874, 0.3141437991699404, 0.25020319934910323, 0.29627743319103844, 0.2521859785650231, 0.3218325730147976, 0.21639736452185077, 0.3428593363395324, 0.19790585770338326, 0.2782323660308892, 0.23521824361269356, 0.2624840118985529, 0.25439236585082725, 0.18951236146508954, 0.07603486557418651, 0.18635796425374623, 0.09687113876190658, 0.1310606430254049, 0.22367923799093145, 0.21155837070057296, 0.17330113741992037, 0.21895985731123957, 0.29578051150079715, 0.21814622456962945, 0.2461656885313424, 0.28103535849869277, 0.12246442492162489, 0.24354233093665553, 0.2797587183235247, 0.2830648442999608, 0.23977498074335524, 0.12578669554150926, 0.2200544424654706, 0.14391172973046834, 0.05556557053821575, 0.25113463416675447, 0.27460351009001766, 0.16335489791402782, 0.24556274590480295, 0.22976570355182696, 0.16117037366066855, 0.3909257195507693, 0.26101164686585065, 0.2070574401823176, 0.20402082392728066, 0.1350934301077153, 0.23308110565842877, 0.24372760214185699, 0.3483410392747799, 0.13706478482012524, 0.1936032365246012, 0.24077332288228698, 0.1531964552733282, 0.21824717799021573, 0.3334258614395657, 0.13477035683969188, 0.11064393836164473, 0.2432766221931202, 0.0154968375917349, 0.15921422912577257, 0.37312133000165537, 0.2584292801895892, 0.14297837903554164, 0.10308753192190175, 0.28468455691766353, 0.12423435613088896, 0.2547025739639563, 0.31692268258289436, 0.29459500191354976, 0.45335608756198714, 0.3096682679261089, 0.169492056125129, 0.27485788843680625, 0.31800272181834294, 0.10572632681991366, 0.2613631399305785, 0.19896771804072552, 0.3006786064451267, 0.3789245905548421, 0.2980394703837066, 0.1803541752605582, 0.23622863818388165, 0.24322358397611402, 0.13375153621993818, 0.2679934999720195, 0.10340116370819406, 0.2522218726129159, 0.13763330639088878, 0.14839828233070984, 0.11836795358153283, 0.17548229268143747, 0.3110402711185113, 0.29740507258170895, 0.07514742178268273, 0.11955837012490773, 0.14654366019311418, 0.22125398585197212, 0.326982050081225, 0.3031680600841215, 0.16687680858001847, 0.20881894021854516, 0.16758388674832791, 0.21020083184010785, 0.2931382696382235, 0.3260846558790206, 0.1345119016105765, 0.37307440352039595, 0.3617594776096081, 0.19538433428343052, 0.24926953361657428, 0.25155713584971606, 0.33872135694451194], "M14": [0.22861532810685567, 0.2722624581278529, 0.3285846693954845, 0.16922433312163657, 0.18440244369820605, 0.21098480432713848, 0.296444309924022, 0.21623718318805843, 0.21749060295499845, 0.2577566901518912, 0.13624531256487743, 0.1828199905313145, 0.22405535547853797, 0.21542506152976956, 0.19620646907387607, 0.3068679036256922, 0.1758520023158712, 0.29660950046056733, 0.23303381384246116, 0.3397246197490067, 0.19298936339893463, 0.22028932590502295, 0.11211810711005452, 0.34530386087551146, 0.26390456073212104, 0.11628811659705383, 0.2394923188895032, 0.1351102688616944, 0.3641743976589187, 0.15200694935926226, 0.19890838147032633, 0.13620609616597765, 0.2663909825371705, 0.24056664033452205, 0.20879541893904843, 0.4303502761053381, 0.25397761121621515, 0.22515432232885413, 0.13201622420864514, 0.14035569055118305, 0.3208573349437924, 0.18859908940389916, 0.45031591235750396, 0.1528337453770709, 0.25364360946731773, 0.2126292410592586, 0.1951556392643638, 0.12270273390716832, 0.2518992248410426, 0.13936838605554852, 0.14483128050507427, 0.30630052355183923, 0.10410508218225369, 0.24201664874527432, 0.2599333468543411, 0.3725173110182415, 0.10667010613212503, 0.27702253313804204, 0.4262963459469416, 0.1420566202172255, 0.2851769123796433, 0.17626599250515232, 0.33022737171483124, 0.2970043120854249, 0.20038311055087074, 0.24732671818506627, 0.2990906874061436, 0.19839591942057305, 0.19303790619510727, 0.45015479761448407, 0.3472953190250204, 0.29272008522009596, 0.2218649645677107, 0.2922750257193007, 0.08097592020461616, 0.24794751846038293, 0.1813780319825307, 0.28119929790930037, 0.16899200077616378, 0.19217684041291389, 0.1126577250929207, 0.10729555501452534, 0.24096611540443277, 0.18573642812039326, 0.08432574451153046, 0.26101439013095973, 0.29879259115960116, 0.21397286786182892, 0.3551628892445771, 0.2582322615766861, 0.28971376862522424, 0.30615770105211204, 0.21973657893602835, 0.290740167836925, 0.3890014016141649, 0.28484401707211243, 0.3471759269589585, 0.3208442073932044, 0.19134928205609952, 0.2625166682325221, 0.27252953067698504, 0.1741005781351669, 0.053921646273366805, 0.1686972534675153, 0.3827595771809001, 0.2124698776721943, 0.28334649378793886, 0.11576221340796616, 0.1409543364236961, 0.19276796095278087, 0.22093076782762597, 0.1432965948178294, 0.27324449378931776, 0.15050834685129227, 0.1438998208690566, 0.2821296048302575, 0.3278260945607741, 0.19365003358523897, 0.2117304130400752, 0.16868116960328905, 0.29358633071472523, 0.3144357682630307, 0.4378797766414956, 0.2663730227048559, 0.13463168139372733, 0.21809845139398054, 0.2134358586879705, 0.19003113756745438, 0.32504394512852874, 0.1712685395874499, 0.21597788087585715, 0.07068449888782635, 0.268841624313665, 0.14432279656337135, 0.28200885261313186, 0.3796642883321656, 0.17251949975486258, 0.40537860334629616, 0.2905885119232623, 0.1588914606035277, 0.26849003386363035, 0.27244072815807935, 0.24079021458060906, 0.3084957376027031, 0.24849856697075212, 0.23066034959003293, 0.367305496963717, 0.2609954826442341, 0.22665977070233848, 0.28834862414511125, 0.21406207390754106, 0.25906944724922276, 0.2337348030388199, 0.07875627032588667, 0.2732978380310512, 0.3307981965884347, 0.34013379470857763, 0.16184465461806144, 0.22640939883673034, 0.17250421698919685, 0.4213885960794561, 0.23619269144626504, 0.17909886387123136, 0.2276282136713657, 0.15932653296979898, 0.3006703004683501, 0.2379295575898769, 0.14893651249424195, 0.21412311395998426, 0.2135267982512666, 0.17702304555800588, 0.1446357998124836, 0.20046716309099702, 0.1843571543955998, 0.33838168862352874, 0.30465413043968886, 0.1047954947485384, 0.33099850998979247, 0.28055142554775403, 0.19926540368608475], "M17": [0.2412121989703843, 0.3300580016119112, 0.16116649460530588, 0.10625495312233636, 0.3660191413930462, 0.22623297830409392, 0.25346553276247374, 0.16530029574582872, 0.12581525140349, 0.19099405185277005, 0.16989292852978066, 0.16473629217410185, 0.16491102011438266, 0.20581105226782284, 0.15599856699023923, 0.23330341376866431, 0.37955955358389876, 0.1331814072346433, 0.4217612293776826, 0.14685378711161756, 0.09639667291589807, 0.30046850384739615, 0.10924629802371008, 0.3426079302458706, 0.22240921153328536, 0.345979147491763, 0.14063019732621465, 0.25410897666839877, 0.27708423514231456, 0.20110731738502022, 0.20394434094589342, 0.20440693480507108, 0.14314423733186665, 0.25719087341636165, 0.276125928031777, 0.356054761645219, 0.15146236159783982, 0.1465176201041315, 0.34811754628302316, 0.2792601333986265, 0.2081266904220452, 0.34085734763489267, 0.5370371617610774, 0.2814590093740332, 0.1838022717733468, 0.295701902547356, 0.1850591443330408, 0.18758342916614693, 0.2079459250758236, 0.169891074929364, 0.058725939015357144, 0.2586699990332872, 0.12079688304890972, 0.10040419668708436, 0.2649748860190976, 0.3013996484971369, 0.12766151809184115, 0.1661457413701399, 0.27976220443927424, 0.2366344358181492, 0.197922815100509, 0.14120595355975912, 0.14332058334090853, 0.16501802729116327, 0.186362130523359, 0.2594201756934027, 0.25103347965793593, 0.22702610530271922, 0.14647458413690292, 0.3675048875397996, 0.17412793344171942, 0.16884506047027492, 0.2735247369185185, 0.1759697363318026, 0.26116606024723127, 0.29607404834451456, 0.2941285103503184, 0.14032274755315707, 0.24626464530535302, 0.14240522286725235, 0.21502280657217032, 0.2657993775836069, 0.24978790669149922, 0.12384577987713477, 0.2509509912973839, 0.34567417386813865, 0.17035362866335713, 0.11384664436556007, 0.18643280927946518, 0.1821779753537141, 0.10961217205356169, 0.3851147191145568, 0.3611475545683241, 0.2565393635768762, 0.19938377744884614, 0.23379642289952873, 0.1511187603941203, 0.3627263251740178, 0.1928624005837939, 0.25248088170134825, 0.2602243539425085, 0.24212776298179267, 0.23992579494800717, 0.19176844996979842, 0.3261183110785242, 0.2563538005622352, 0.24791059991730952, 0.23094525802754903, 0.17300058236806268, 0.2389751271805617, 0.268242124895465, 0.32621958052827804, 0.1904953752388159, 0.31698629840679055, 0.12439765580726019, 0.2180785639546737, 0.25433545539968083, 0.34008613530706955, 0.2129352112646299, 0.27098537340762, 0.22265118979823934, 0.05865656473953744, 0.43952390947795317, 0.22706834491127878, 0.2515541936202441, 0.18319433539936508, 0.07940742299973617, 0.19274081701446663, 0.1405683787372987, 0.14412718940120206, 0.37018250185793106, 0.0929461361116386, 0.23431423061645307, 0.211087527774617, 0.21658357042961932, 0.3896514803771824, 0.3056595952315395, 0.22033186734159668, 0.31785077096300074, 0.1509289206156085, 0.15720761770995867, 0.2754618274668265, 0.07090313872543362, 0.24245895625282146, 0.1684408793156769, 0.1375181456871218, 0.31084611552595437, 0.19714857971810795, 0.19960432524899568, 0.23792354847195102, 0.2948960113572975, 0.22060565777913008, 0.21661839223109405, 0.1293805426594035, 0.33381645915583585, 0.20895968269361181, 0.2660664954688433, 0.21384212024181723, 0.2896245873061077, 0.28776923696109785, 0.1580734491162706, 0.26378006178537994, 0.2549111304410766, 0.22590908458972286, 0.20002677765395194, 0.12312489717220157, 0.27304749144183044, 0.1012839157757294, 0.15130749185943812, 0.2500061217039683, 0.18587476018132457, 0.27758069616323267, 0.2836287034245287, 0.19488833535536784, 0.2972475060716794, 0.33968239660431754, 0.24869798186381098, 0.24578775169597103, 0.20737744357359036, 0.2599604856843793], "M02": [0.2515168446985301, 0.13392886557520037, 0.2752816362235813, 0.06868915713171284, 0.20715558128367195, 0.15435878358570132, 0.21730011057215773, 0.12435238328010217, 0.19029462448220993, 0.18819449203952732, 0.20948028260333026, 0.17146981271804435, 0.18435370802898274, 0.12864902265374745, 0.15053247116669558, 0.25735376667574966, 0.10163534016788145, 0.15168133413823326, 0.3600628799679248, 0.2755494468012902, 0.18117507512655967, 0.28780042888584456, 0.28834078003503066, 0.21880954574636696, 0.2153097784825701, 0.19353985517298392, 0.16660390687555235, 0.2264125727885843, 0.2845427880271533, 0.2767656511160847, 0.20142441876565054, 0.2390771921185973, 0.15213945937968362, 0.20451305090256866, 0.2203997408080829, 0.3455270946105789, 0.17652136042129704, 0.2868969407947766, 0.22543834517465544, 0.23342605186146387, 0.24989992545743434, 0.258854816102342, 0.25223511909620566, 0.23398987541738067, 0.09852393024681053, 0.15618464707659122, 0.2883998815252153, 0.1531817960791899, 0.22820273313334147, 0.26377075462147875, 0.25463759927824053, 0.22551980968913518, 0.27807096831141687, 0.2690876660952434, 0.15800740315275072, 0.38533751338708205, 0.17943155632695004, 0.20363562035527263, 0.3040481671175565, 0.2132993250652351, 0.13005819246402034, 0.16064823770028944, 0.32975941597424807, 0.1820635512640063, 0.2520269580254913, 0.1202882587743496, 0.21972875094487018, 0.2277359922822161, 0.2298358123603999, 0.30698949258617597, 0.30606076347401256, 0.17308031187740433, 0.14476261278045646, 0.20128377923749152, 0.2942008880332578, 0.442536403623263, 0.296888917306109, 0.2590877932769311, 0.23930677410054915, 0.26159315411825096, 0.18649021278653355, 0.2565763785868616, 0.21095714824439063, 0.19759343103225735, 0.10395620203180439, 0.24735655309506246, 0.07235158221773337, 0.117601241035996, 0.17981259608837397, 0.20499207970072847, 0.21803022359789764, 0.3466586948450772, 0.2702454621927763, 0.1405425493123464, 0.37232885370929225, 0.2459890621802557, 0.19576060692514238, 0.19679935942563004, 0.24926164443392299, 0.27645964943239887, 0.19594717939699866, 0.12220093164302122, 0.16406096066321238, 0.27588949665594675, 0.24984505694492012, 0.2793330184936715, 0.15075141542570428, 0.2489517043230063, 0.1687757118729897, 0.2901642073325384, 0.19760474446880413, 0.1470236990977414, 0.28691354588939283, 0.1648398414592559, 0.11904488362883613, 0.1973556603656722, 0.14555767073390863, 0.21211941538626583, 0.19346368499233543, 0.2243183792303957, 0.18505409982556253, 0.16305632840996465, 0.25889176493680666, 0.2068837643357036, 0.18496102227106026, 0.16230716403062048, 0.1975210788680854, 0.23087799199300493, 0.22556449983695093, 0.31832955226879595, 0.22677424290927267, 0.10663693892453699, 0.35386361492274876, 0.31401237293451073, 0.2959304683836513, 0.3320360883175934, 0.23011152149441716, 0.31835100753424644, 0.14102291519057367, 0.27004784940496374, 0.11845581008220386, 0.22474934643609476, 0.1922322086793267, 0.2719132513167641, 0.2637787193942318, 0.2580920145668176, 0.28676388467135105, 0.28955022619341375, 0.23340712273600533, 0.22273716111678551, 0.2850394553712751, 0.26762355027029516, 0.22814367047869213, 0.17222145082154006, 0.153942454846661, 0.3137045745598693, 0.25769959416091653, 0.1499435386880509, 0.20219074021595548, 0.20275931408717662, 0.3172423227876074, 0.22647274436806578, 0.2556702927183032, 0.16134595246826963, 0.13258613084692988, 0.16633821298538082, 0.1989285855514792, 0.18584256429784007, 0.1335237772023902, 0.2384270568473001, 0.167356111110889, 0.22764231812852803, 0.2270452903007977, 0.13253855837899953, 0.26540848248982085, 0.4545949022518522, 0.3227042221894105, 0.20554909641690547, 0.2303979698991046, 0.13209425980289483], "M03": [0.16559366168646872, 0.1343239851854948, 0.2902370494331679, 0.15179332909260154, 0.24894179633638977, 0.29917848060547786, 0.20351664211375586, 0.17869622891673767, 0.20109699020775887, 0.10864609482764043, 0.2027018459282721, 0.2954645635632226, 0.3128896777595685, 0.25406122529902936, 0.17326691186466944, 0.38118646520484395, 0.2150794610986046, 0.35368798525597944, 0.23370679417252774, 0.35412162995948787, 0.1465144873538305, 0.11734605683949828, 0.23381540113655008, 0.29283863511921615, 0.12265850557277805, 0.3616034242796299, 0.21775977966379564, 0.24068562594648782, 0.38017232777045457, 0.1766379121022552, 0.20248428587899667, 0.4413740235358119, 0.2996398709631689, 0.08008585977007565, 0.36100968945130996, 0.39320923634048405, 0.17507655185388085, 0.3047807535885562, 0.12108783116824914, 0.2427952208748427, 0.3716770082802568, 0.1954556630120452, 0.4556346538878885, 0.2389737025971973, 0.2813306404117853, 0.36065033174275857, 0.30191443477583363, 0.09055614263886042, 0.23375441431841337, 0.1412918235870647, 0.26551653038296813, 0.15310769201223445, 0.13744828437853476, 0.3023511005034186, 0.23382966433903984, 0.3064678448595409, 0.1282429014854864, 0.08515857592036971, 0.4372056824432396, 0.3362095554273822, 0.28158504060275896, 0.29735195258578795, 0.20261278763557902, 0.10774886966738506, 0.26183829455774865, 0.23377558329040884, 0.3378626904611518, 0.22721052131288855, 0.2785602559406016, 0.19741475569889191, 0.14888073418961145, 0.342114070238508, 0.16880678229811646, 0.2280422749324416, 0.16625739864160446, 0.37243279663933776, 0.32030131311215365, 0.2642040762298936, 0.3246937236567857, 0.2779614637176596, 0.21546919834912606, 0.29689268841100686, 0.2769520031555605, 0.24547709781562532, 0.15850107835143346, 0.3478172257298431, 0.25307183514740267, 0.28294158017587023, 0.3190733215930314, 0.18840151538687439, 0.2681631728544648, 0.16056121163921355, 0.3842032930666879, 0.2656252809789332, 0.21573089584220234, 0.08173824629403546, 0.4803006355921188, 0.3383187170400525, 0.24252181300826925, 0.2303027757768515, 0.2942595853371347, 0.19768232369759964, 0.1407654970650504, 0.2303422943782165, 0.34081369959386276, 0.2611682435838946, 0.19523291903172799, 0.2999885451725863, 0.17175950354048744, 0.4857751677384825, 0.18021323006781012, 0.17266665712596152, 0.07238953715607209, 0.36590054664216076, 0.14513434660471866, 0.4057716062167274, 0.27566145837806694, 0.2583317123782599, 0.2259616186676441, 0.1868229276393186, 0.4587914893618879, 0.3026277731371086, 0.2330338617495142, 0.16778532883871408, 0.13174208872153198, 0.2589257947132431, 0.16024107051750044, 0.2706489691658698, 0.36560891558757247, 0.34657683561619607, 0.36928936572693427, 0.1688840211847194, 0.19285313810998067, 0.1379426935485717, 0.22809912717122255, 0.41672294457860115, 0.15838048548174705, 0.4890088671287229, 0.41212944953613256, 0.31431399003554256, 0.2613868282736505, 0.33993677639133985, 0.18447564056138172, 0.2778167919188065, 0.2193443811205523, 0.104427728357096, 0.328944320344888, 0.25248584289842474, 0.2575185653249829, 0.11250549470338289, 0.4281098891865839, 0.2487413473065094, 0.23454052648340806, 0.23447857567869157, 0.3846493792307137, 0.4126674223040516, 0.27972421033508893, 0.1389677321237401, 0.14593245792974097, 0.36551477544037747, 0.4181944994879972, 0.25954977640202526, 0.3390684006491826, 0.22184928991378192, 0.274604623045817, 0.21862792221426106, 0.18702240280125101, 0.1480206745020948, 0.25055535287333536, 0.11756034629979085, 0.2957113408042901, 0.2068154257279656, 0.4020125174568606, 0.2760945779822879, 0.3413371306667645, 0.5029195862527257, 0.24314009916094187, 0.14166436212814107, 0.18265029574294203, 0.3614678221897948], "M06": [0.2093111453444512, 0.31463312074660443, 0.1291705808386922, 0.019650408936089298, 0.37463580057415763, 0.16086655472249353, 0.2652945670415393, 0.2927609344723026, 0.2948278789773617, 0.21241566722501, 0.13132230868244568, 0.11946435637003587, 0.30153205003943073, 0.3000908860828793, 0.24451756993282273, 0.2619081880089779, 0.41257668877981946, 0.21805900478023213, 0.3133871976246586, 0.3314062615155601, 0.12247145818860107, 0.17850821999740554, 0.2715783297568245, 0.11990369429179168, 0.27851117091061794, 0.13477655193402205, 0.1739594308741567, 0.2639157982880143, 0.2284261317799739, 0.19019915255647815, 0.18669729682425268, 0.2095159291233378, 0.2097166971252056, 0.2487756526041039, 0.3252067338656519, 0.22751957519016397, 0.15204910081916612, 0.25178628171379625, 0.3039088986853654, 0.28775417177275203, 0.29585725146868, 0.3617779857607571, 0.4925701631814234, 0.3478197865442879, 0.2354261445358742, 0.3515412575008092, 0.3018918099799349, 0.19158761500961738, 0.16960324269620888, 0.3803316417413607, 0.21644215022361393, 0.2837854297532891, 0.149163469779825, 0.182804222623958, 0.21814001269073305, 0.056839543112068576, 0.20695002379363342, 0.20543580651835733, 0.21042922617467813, 0.13413175608852929, 0.2988357457227624, 0.2947522602757608, 0.3345087654626568, 0.3076248199405635, 0.2214168741638287, 0.1594592362839348, 0.2838403006456297, 0.1832011642682642, 0.27760501106376173, 0.35142048701186823, 0.23638828811693274, 0.30621402576045326, 0.2455109760959114, 0.19302202448237293, 0.3968542920410566, 0.3611751716909567, 0.3163443909358588, 0.269358894475218, 0.3209753493414462, 0.27658547698873254, 0.18295140474472535, 0.27945796624327973, 0.18582217007019386, 0.17175742972190117, 0.17865538535244405, 0.12627426071175255, 0.2835591751922804, 0.26754979132317597, 0.3414837391950814, 0.310044983043605, 0.3164921634872452, 0.2581106257087968, 0.21580402596801676, 0.1937994976906436, 0.17708540162123068, 0.15877212672730734, 0.25784590219752734, 0.36745995785603336, 0.2618762176216195, 0.19274004136230943, 0.2772898550257589, 0.158077341924837, 0.11536970497503984, 0.1282423554644034, 0.38301227466412585, 0.18820381821855084, 0.29741973363467344, 0.2915735737929917, 0.13472676485551613, 0.2001569850954064, 0.2478469564989597, 0.27022187993111574, 0.1557461753071148, 0.25154897144653604, 0.08895688957691289, 0.21790542772072982, 0.2174386980173088, 0.15607390379780112, 0.21962037855539743, 0.24219053793631853, 0.3280349762730536, 0.20058839182016516, 0.22711542717335803, 0.2710860331635092, 0.10613833798402479, 0.2546959893277445, 0.3687178363580374, 0.29167703882284, 0.37134895420036307, 0.24980179136468691, 0.3639557840734707, 0.10400287524907581, 0.3289930873897415, 0.19764537510810307, 0.3004114959891399, 0.11915329176554308, 0.27649986432393503, 0.38251702756472544, 0.27803290277923226, 0.148720199888801, 0.17093516240675122, 0.1428588659065091, 0.18356462941184862, 0.3378479252140003, 0.3171392040005343, 0.060203271804694765, 0.21440017644657994, 0.18519982065916818, 0.18853826624118109, 0.27121368664572887, 0.40407246891041815, 0.3118654441102703, 0.13397374613277124, 0.19636174119667016, 0.1089229339307937, 0.3165473919871639, 0.3039355195932868, 0.2908158299805016, 0.3387724898106415, 0.1312671204602849, 0.17762710331207637, 0.2452108018879079, 0.3353911605689149, 0.24835496302189927, 0.139842508706943, 0.2940631011574549, 0.05594358610850256, 0.21921450735902945, 0.15468412166437576, 0.2614967449483742, 0.24849517066205898, 0.09749386136466832, 0.18911464708860504, 0.2425798628944794, 0.3622231020897076, 0.44891206213729856, 0.31956263399910184, 0.40566926747998755, 0.14830623843139032, 0.16442710717384024], "M05": [0.0903986359427209, 0.18430775434608235, 0.19560575211983122, 0.15832073231405047, 0.32702547222011163, 0.19042143833207528, 0.3418645687350776, 0.32566124584197054, 0.17958321931051913, 0.1974599144916198, 0.10649682352992484, 0.1978490626257825, 0.3023973587784288, 0.21313487458679664, 0.20577766562430172, 0.07864866722801318, 0.5062524301162686, 0.2781029923228672, 0.26813096830493066, 0.3249147589052824, 0.19256249714522147, 0.2651824772821114, 0.20036680105575647, 0.2647077922383354, 0.14201121240682027, 0.2456942927356352, 0.15653984363566706, 0.13670442301552888, 0.2820929017368992, 0.20095055870376863, 0.3274452751545537, 0.26957626429317816, 0.19843821279739876, 0.23257046692205452, 0.23989964157403768, 0.3462577360009703, 0.19807037154676044, 0.29230782754466217, 0.17843834326467867, 0.29243332087609, 0.21179635300893399, 0.31734284077193226, 0.3333598410886283, 0.21127049593704456, 0.18081653069825426, 0.2579380863110807, 0.15192859480802975, 0.17717093229362385, 0.14078868926069463, 0.3163952064540042, 0.1402287543292291, 0.2665050145979606, 0.2428378440706018, 0.24904073847736877, 0.16908153497590206, 0.3028234710948328, 0.19048326499843807, 0.19037901023438344, 0.3873032463427305, 0.15291206036170257, 0.18938886719758422, 0.11064697081448985, 0.24828770448370224, 0.294950630689402, 0.19907627212144904, 0.15791709242393043, 0.15985686323431464, 0.27176112856715817, 0.29793084764167904, 0.41976365444682234, 0.2805695435721073, 0.29001028007803314, 0.24838648450496134, 0.20560982414536566, 0.3007378397930094, 0.36041148202853657, 0.2729529157837202, 0.21041367881847758, 0.284912408994471, 0.13096154323580195, 0.20571932431427675, 0.16188448155937413, 0.24468468845779956, 0.06885742014384894, 0.12178566263782457, 0.20599595641726917, 0.26933476600237743, 0.10342316227749945, 0.3367929601818914, 0.16246051195395464, 0.17941408335522452, 0.33454055659752585, 0.2992739728308433, 0.2470924114720798, 0.4137086043302768, 0.1879201474080117, 0.39182142414349325, 0.3138274744104738, 0.1653398034561493, 0.21348389954258168, 0.16265865440215813, 0.20529020993700245, 0.1885564642218362, 0.14290697767210486, 0.23531689792962948, 0.2112491787739303, 0.1967276971131468, 0.26753616094527666, 0.1268906239651527, 0.3248984652725028, 0.15392221750698812, 0.24383640473842577, 0.19309427123192352, 0.2706425266420966, 0.3308546627057405, 0.25491356151886163, 0.168704811801551, 0.20478151473410916, 0.2179160780133148, 0.14380442992166062, 0.2636498961649386, 0.2795714756541981, 0.3900722210470532, 0.3094017557529383, 0.10552223859252821, 0.23090955960883308, 0.030076350673369178, 0.17988211055073658, 0.36995214863137194, 0.17074424439317645, 0.1153568969641661, 0.16698040789352023, 0.28252306533850574, 0.21673118985238723, 0.1956649051382455, 0.11700001307310925, 0.29622919084534544, 0.21581498776484082, 0.40169474173090797, 0.12863006881171263, 0.20683326944536065, 0.3189480563281362, 0.19660091565425905, 0.3922089078887063, 0.2756482661655396, 0.17951446427077833, 0.17217954127426816, 0.2651952327529784, 0.1541217360402325, 0.17314329579829343, 0.21660138248021596, 0.23740152771108552, 0.18423947280305747, 0.20085766539751262, 0.34141271147658436, 0.1881804101754225, 0.31255521331597186, 0.23096620403011553, 0.13961451920302717, 0.11376614998819773, 0.3186181351875794, 0.217655905269303, 0.3084655571984632, 0.05438555734253847, 0.23325649644535387, 0.12205758807639161, 0.27375733304258093, 0.10725988434455754, 0.10463019958983016, 0.2566871588382816, 0.3021482260969649, 0.3161336965998496, 0.13393094785263648, 0.24213170097447068, 0.3884500214567742, 0.29811084154455914, 0.27264222735328314, 0.2608295721644778, 0.21503556579434313, 0.3425577184242506], "M07": [0.15912436328051305, 0.3003155617080489, 0.1955168573569687, 0.1548493873439669, 0.24499345138610343, 0.1325395508337929, 0.3714104117266752, 0.16842955940350682, 0.1449248506491849, 0.3314683153713592, 0.23753943169743708, 0.22449256512324767, 0.22687353161069154, 0.3232078986028184, 0.20082007117911058, 0.23661830190384803, 0.5443643658656433, 0.23441026048160848, 0.2020657592421721, 0.3261525589289137, 0.23484315005195824, 0.294916720195176, 0.3110229963414912, 0.29584223485570044, 0.2555845952398809, 0.3366502072086488, 0.1926328582988077, 0.28185674042750947, 0.2810149637661007, 0.21129932653220948, 0.33349884159496823, 0.34224128256825, 0.2908762857637343, 0.20833319518409874, 0.114577888937973, 0.39232828011824006, 0.21167646800826737, 0.2774992343054205, 0.23810287469490363, 0.25732138881308514, 0.24725078862406438, 0.2620510502567994, 0.548880156501468, 0.12320424467503548, 0.344931857175255, 0.23179687074783228, 0.31820898117963836, 0.16942641189621468, 0.21508919453994985, 0.24375034574307597, 0.25305660482091724, 0.24294103589031152, 0.0967758307162154, 0.35250150461503915, 0.3161557570018227, 0.30590588686494957, 0.21942620264924523, 0.27361940123871586, 0.330850427581658, 0.2797483612644694, 0.2754423693764728, 0.16470949088738446, 0.2474604537729085, 0.15324460638506165, 0.17961666063520668, 0.2896255489165384, 0.11804425186738977, 0.2867879229981949, 0.1266576052059517, 0.4929253271018428, 0.192364759052669, 0.21691610227131863, 0.2613820171254132, 0.23943304698601983, 0.09615991197893745, 0.370408788101334, 0.29388061473621024, 0.13628447192760934, 0.28162722373396976, 0.15125570664692495, 0.17597961434715112, 0.1356235338429455, 0.20377318803979147, 0.2708591042501656, 0.2787228516911085, 0.13395479713316014, 0.13577139433943505, 0.20010045439776128, 0.3007408108752441, 0.2333760448451493, 0.07058525951262572, 0.42611393225911176, 0.18577753724942056, 0.2605856862518244, 0.25780444253052986, 0.28117615969356996, 0.4198539919789993, 0.35432740737902435, 0.22879038537036636, 0.0918545697918219, 0.3161609179103435, 0.21788059431697987, 0.1756159212362916, 0.14030715679739594, 0.4259185171244239, 0.1259016632342907, 0.21477249936148776, 0.2645104206396754, 0.23191370373666131, 0.4197700077675483, 0.25463085139003705, 0.16132533233361177, 0.13381461159005423, 0.13534047564177756, 0.29212322917728484, 0.3803257418732292, 0.17390782806598443, 0.2726803376093695, 0.23970069749978637, 0.3432622448553407, 0.4008924765022365, 0.14750180196848311, 0.3382554571211822, 0.24867419199566784, 0.2468895285782952, 0.18287167113798664, 0.3682463499456542, 0.2341475116411221, 0.19841879225331885, 0.2588514555900779, 0.28157658443497496, 0.0796093307808981, 0.2690332636479402, 0.3699979202319636, 0.22699316569785818, 0.4241458916008496, 0.2445019033105156, 0.3072935459252838, 0.1513097224523647, 0.28151745595693545, 0.23037167530415634, 0.17398421104704737, 0.08640471178224313, 0.21337031416847235, 0.2878050329863428, 0.3138916799011052, 0.4034274992225513, 0.3028734685826598, 0.20981377062241055, 0.24716025206452258, 0.19128292136958833, 0.34749167578248796, 0.13685591094417085, 0.07501520677657149, 0.18336213524983383, 0.10912048607053061, 0.22168424497751635, 0.21370629700298097, 0.15060046672811966, 0.18801801634722834, 0.3901589203456415, 0.10745670416698315, 0.21114274576294567, 0.14663650200827846, 0.19081302224805088, 0.3567666937069621, 0.18549147323682305, 0.20759224613672828, 0.22948882547862107, 0.16210118507943433, 0.09614631825195867, 0.24833830885083055, 0.23125618433707582, 0.2121326135943649, 0.17767084564123609, 0.3920029909069051, 0.2998237983833135, 0.303755666548748, 0.288358084302307, 0.2454574614231108], "M10": [0.19114101379082019, 0.3623415412977692, 0.1790734527024595, 0.11731077052156351, 0.2966831420959621, 0.15651407291108224, 0.22395080936861878, 0.26267670698070966, 0.28109920455348153, 0.28287270779651047, 0.2194500048840759, 0.1916170530069875, 0.22869468601806822, 0.203241476505948, 0.17505289821298414, 0.3331354582652293, 0.37967798820237925, 0.21036108870600936, 0.44442894496055707, 0.3176336502468169, 0.2967055480612376, 0.10526952279691365, 0.2684487850264078, 0.17289089478736294, 0.20062841995155126, 0.13370792448979377, 0.2443863101297982, 0.2821930214399636, 0.3066690253367852, 0.3505707827441702, 0.153451848261362, 0.3279339391840206, 0.27577460562539763, 0.23404412260247007, 0.24778734378746653, 0.26363876697577887, 0.21018099069540505, 0.2797779767577293, 0.28414160520599463, 0.12103266805458493, 0.3256732223254926, 0.15856598352242252, 0.253912343055816, 0.295136240721441, 0.1910064131032687, 0.25998510471954084, 0.24287492980222108, 0.11335995904339323, 0.16612994957391797, 0.16183738223938526, 0.14103999069561438, 0.2812454595179007, 0.23683956090686506, 0.08661388706135716, 0.15824409605282597, 0.271734625616115, 0.1847786607771896, 0.2565859409462589, 0.16804451648917987, 0.19422494259882483, 0.16709782203398227, 0.0814636203127036, 0.33393311173189355, 0.1471078184680128, 0.18970932371752408, 0.2647862524281659, 0.2957477463288909, 0.24340329514286857, 0.14766221551630773, 0.3976656518022509, 0.39511035106997333, 0.21791580955411222, 0.19995123658549846, 0.32093423700886486, 0.33553573728990377, 0.41007137173477276, 0.26464715839119723, 0.21366851250237182, 0.18479459384539515, 0.17146333952355888, 0.21982557183981177, 0.13163015421508092, 0.18920844945575566, 0.24653191695851007, 0.2181851001856958, 0.19169970398725658, 0.17565064866999555, 0.26835113281776896, 0.24005286269407755, 0.19557010784398643, 0.22311206027599648, 0.31045979015977226, 0.27356023243549854, 0.3366483222492503, 0.4521777070932297, 0.2488601568387257, 0.1825485378536771, 0.2824925624488729, 0.1240990505740126, 0.2475318095717634, 0.19958281553227256, 0.2183195717142242, 0.2176284222429988, 0.21692789932932993, 0.2564478424133147, 0.2013722181640054, 0.37686038674089867, 0.12567158535716558, 0.20847329865536557, 0.3747392425720831, 0.22501523938592416, 0.3215969275721294, 0.1654495027408641, 0.11592527732132232, 0.1987886463751461, 0.2264053028714583, 0.2783627060546001, 0.19049488648371646, 0.1873970158098429, 0.13722142714872135, 0.30548873771862173, 0.36710513294582897, 0.45211455276533674, 0.1736059149513337, 0.1481583354563142, 0.16742477308135045, 0.3662505373332849, 0.2293743488483551, 0.12990202796292966, 0.18647094865515185, 0.1893333242968242, 0.0947461467228206, 0.16930510979314184, 0.3393163771205298, 0.20745419075846278, 0.3350045359645127, 0.3624855840441095, 0.17782737392873751, 0.31304277909914363, 0.1839685004798738, 0.13930926742998156, 0.28447795538377224, 0.31021792678307153, 0.278940971125616, 0.16830241469028667, 0.24125936084862704, 0.3596018666371923, 0.3900010219429976, 0.12525455752564654, 0.2514097307302187, 0.3770114217086333, 0.23127182738539342, 0.31764545252755483, 0.20513560940055123, 0.3123871240575765, 0.4108079278394662, 0.20153401863581244, 0.12681812978072846, 0.15527065942157153, 0.3371933812443937, 0.32871598280630404, 0.15367575660052005, 0.2951968832339148, 0.13512414488024319, 0.14900227112225808, 0.24495100661429098, 0.14759392901616172, 0.14595224475020505, 0.19569733424975566, 0.11868644283358604, 0.2312347919607902, 0.2390662015412685, 0.3786368805365476, 0.2485354799594114, 0.41231065635364805, 0.4652297660921212, 0.18071138210925075, 0.22336429373163288, 0.2603794897906231, 0.3040884154825486], "M16": [0.19968668463910125, 0.30653286899118254, 0.24352003540900477, 0.0783629984694286, 0.18715004487502074, 0.22838014050319952, 0.34855912315407506, 0.1868995015576056, 0.253053617506845, 0.19004150521148372, 0.20508224057355706, 0.14029175076609698, 0.2541137419004544, 0.15283313684626987, 0.17209633846217096, 0.2955388605390562, 0.14456027832144538, 0.20851682860321588, 0.3615362913712839, 0.21656312811048736, 0.29094578084988926, 0.2959232797812984, 0.24732734173158355, 0.2982486898568773, 0.22000441150030065, 0.30148681200920835, 0.13466586371259728, 0.16119020386203273, 0.1233677820892705, 0.3095272374314106, 0.15733498224319584, 0.20568825905258215, 0.23800187337121506, 0.17456736378249219, 0.17941669721703293, 0.37820505239926117, 0.19594250787968245, 0.34332167037461825, 0.13489934140717713, 0.16383156007590913, 0.11883796807467367, 0.307803512926991, 0.5720104837486636, 0.2851553289196088, 0.3074095052483587, 0.2622628201285207, 0.23704963223656825, 0.1606450049043513, 0.10494990356667855, 0.30911478332104353, 0.23667393926801117, 0.304191288810052, 0.13726884310215565, 0.09728789556962213, 0.2588335144582878, 0.2665374556553085, 0.21602479101588784, 0.13111935169816924, 0.2806782853367986, 0.32388340676445126, 0.16899013953257336, 0.14698518866237256, 0.21599634825054456, 0.17359756965211606, 0.2382144868668426, 0.134214178762909, 0.19739920086647486, 0.2858267124511451, 0.2276705226980722, 0.3215452723831678, 0.22747885073714488, 0.23744201751297114, 0.16672037531438738, 0.23448212016159867, 0.2372012964865402, 0.4681267551734784, 0.21467764713495552, 0.26639253832172677, 0.2668044915376202, 0.09821541333798117, 0.16614130269885985, 0.25311434237203323, 0.2742238648454166, 0.22511553966051168, 0.23406676090260284, 0.2858503737013152, 0.217793769261871, 0.12159074225102258, 0.2598905316543492, 0.20413136545457003, 0.1634067714482642, 0.2008252914967468, 0.37146442582543077, 0.2873991672459811, 0.20233426862928824, 0.2106348253801696, 0.23105783225578252, 0.23603975580885717, 0.24392298538354937, 0.166873055715867, 0.10162382376614773, 0.09726582521895567, 0.19994068530598064, 0.14904725998059662, 0.3657833360385994, 0.1386497218872164, 0.2648451426073643, 0.14231134469864362, 0.2265114229704599, 0.2474364461330971, 0.15378398811602476, 0.3118822630653066, 0.24479466900846716, 0.27811127197806323, 0.182421244843984, 0.29903308786264726, 0.31662163227981144, 0.24423239652892592, 0.19627982419707693, 0.19789411919044803, 0.1493954100577819, 0.28513844202776056, 0.32080139190589385, 0.11646699931739925, 0.1885002191650159, 0.1927336928835031, 0.25253924682937895, 0.2249815140938955, 0.21507286436285009, 0.12204270713991386, 0.24206528115675388, 0.1396861210626516, 0.3153386298719223, 0.33992357594839295, 0.25686757705535607, 0.27388067532514304, 0.18104697279595744, 0.4087537370930066, 0.2985952037939648, 0.18026042859945754, 0.13581177170674014, 0.18237992235147518, 0.23281298015188548, 0.3137975028331922, 0.2414665091042404, 0.2527821657463619, 0.26551433018120424, 0.3313964689807142, 0.2239245335965309, 0.2063754914350111, 0.38633450092858007, 0.16995032762114395, 0.1477472995097425, 0.1401424692568101, 0.33261191584174393, 0.2944099667473256, 0.31142335938615445, 0.18948523676521611, 0.20509472773874182, 0.3682918689446813, 0.19356062702754268, 0.25297243600804115, 0.2655126040767032, 0.15026635012407938, 0.11731167396857999, 0.2956660720642206, 0.21760691246946165, 0.1449600665029536, 0.17528518128931242, 0.19689729826046717, 0.2135299359402422, 0.21830551172793258, 0.34578770302803624, 0.24343872128009136, 0.1877227101229087, 0.39224471706032665, 0.21273936281424116, 0.2899885008652565, 0.15276570407234558, 0.1768978603130449], "P01": [0.18954813449171062, 0.22982322098066169, 0.2020217370636401, 0.17262667682558058, 0.3027863559544728, 0.1910443034452155, 0.24246236884578629, 0.1466441608423783, 0.14479941944558838, 0.12791576740402483, 0.20826541966868814, 0.15722019416382807, 0.25788335526739065, 0.13865865532918675, 0.22802112222164475, 0.24339647295297337, 0.36797726339964565, 0.2021530267533817, 0.33934226168663495, 0.10692546489517112, 0.19099830181566818, 0.13596030842605336, 0.244719548377273, 0.19237756419686383, 0.11682622460464874, 0.12420175219485913, 0.21495871784286427, 0.1269062386577544, 0.1521822060651478, 0.17985147780189198, 0.27171115296797865, 0.3027837465812063, 0.2492324786881886, 0.11963153698132786, 0.24915173873043056, 0.16847429163431266, 0.18955510461425332, 0.19845467216893428, 0.2760728871632258, 0.17792265529794712, 0.1511521584097205, 0.14056193699124941, 0.4296304233804068, 0.24393136342588814, 0.22576022849065608, 0.10632682343780604, 0.2842552292247318, 0.19178638247207055, 0.2882807284942695, 0.2114322937183942, 0.23193169434239463, 0.1444877726058281, 0.20054572328649176, 0.24724914984811178, 0.21591532291183424, 0.19723448782776934, 0.1421394722487471, 0.23450843343055, 0.24894319732731807, 0.2451983327173021, 0.2422682601451815, 0.1936707561669127, 0.16620817557396644, 0.12741756103099902, 0.19226722631550056, 0.2697314952659276, 0.1928167351845413, 0.24873328213666215, 0.21335913006350546, 0.30083608270542894, 0.21474572155060628, 0.1848179485877358, 0.22449994960074732, 0.30382394824577, 0.2777149933020849, 0.1938756219071709, 0.2128609967402797, 0.2313539233294168, 0.2357893074745853, 0.25064370527850444, 0.22332678793415883, 0.1488700334147463, 0.2262681672497651, 0.1241669705709779, 0.17789997571750404, 0.261750703486104, 0.18101455460073496, 0.10959784011004368, 0.2015718673912616, 0.287037060319445, 0.18302372048868512, 0.33049959517763344, 0.26900605398366234, 0.252644119372465, 0.18560163611750843, 0.10212564718026183, 0.38303500584925043, 0.21230566040738902, 0.12926663893110568, 0.10265222218601, 0.2098043717402737, 0.23039192096233155, 0.14923934199517802, 0.16654815440152543, 0.22862774523421733, 0.21674457102129313, 0.27964346171359367, 0.17742183366182795, 0.1816189236916814, 0.20767020221002336, 0.17131775609335095, 0.15341270402402546, 0.21665802272997056, 0.14919419829842973, 0.24105609181519683, 0.16746377443622662, 0.3667591845399244, 0.25749817476026393, 0.11248362410175122, 0.22477826880234902, 0.2566850083537622, 0.2884520490323239, 0.4175975767012578, 0.17768659757397792, 0.21124952042230752, 0.2694106442034331, 0.2935988915604457, 0.14883415770153602, 0.28356023292547805, 0.15257379498060072, 0.2908335735726583, 0.15706600383028016, 0.3510737760806174, 0.26883415276385486, 0.25098973130332786, 0.20706083007229956, 0.3232357176153948, 0.2895224250508842, 0.23897561399492884, 0.22989696418242206, 0.2985003738882745, 0.243518826106997, 0.16143956297247603, 0.30993247346932534, 0.20112347703386116, 0.20833281841382195, 0.11473614136347829, 0.24834057197791035, 0.18001529297195795, 0.242058060682824, 0.2696610416754109, 0.24173131153996905, 0.19647576131045744, 0.19200831781856542, 0.3141586108281423, 0.3941746341919581, 0.2539229138502773, 0.1395406419479806, 0.19359896788920228, 0.3298703278235275, 0.21908151349975757, 0.13821115776110807, 0.18069403207490847, 0.09996699403894829, 0.16625891701813217, 0.08728420462918891, 0.1791020974047021, 0.14596277039817174, 0.16865037527671223, 0.1319596635998674, 0.1913705021278408, 0.10087384260908332, 0.3139792357832865, 0.2524681832449438, 0.19931103805430597, 0.4262981934280705, 0.20538418644521414, 0.2999637651164642, 0.2528414899453229, 0.3151660024283799], "M09": [0.17849321139017066, 0.2053595890927473, 0.20652371154472837, 0.09267551566404075, 0.3365549116329523, 0.29771513091505786, 0.18480967950250304, 0.30784437943367676, 0.1729154580151834, 0.18352202613969626, 0.006157400809338795, 0.2364302976539095, 0.1838752999396054, 0.18242037064993435, 0.2681091070587075, 0.3351222301888563, 0.3594440047645746, 0.2606821091104428, 0.28053054478047273, 0.20260188855987496, 0.13953483446338916, 0.10014386088356696, 0.11954898669494426, 0.2528056653859408, 0.12912833695158996, 0.26866536234821525, 0.23811373004283753, 0.27905079635438224, 0.2570247588143494, 0.2014106495193377, 0.21746108161591055, 0.3438223723439933, 0.19478435718524414, 0.1991486242136212, 0.10964311059536945, 0.22138642547294862, 0.13174799440558155, 0.33204195663637825, 0.2965417728141192, 0.2952014931731243, 0.2922350935294072, 0.25996673344364185, 0.1159284775620302, 0.3546861591215158, 0.3345091409349446, 0.27322311061500915, 0.14032436050094704, 0.09497209853727058, 0.17456110041358736, 0.2843967348770972, 0.0813827678267207, 0.14610060196595764, 0.31899307199868404, 0.3064138263382679, 0.1266577585052121, 0.14651263376830703, 0.2811404334707403, 0.16598539182565014, 0.15012339139452596, 0.30467211835994307, 0.1549316791955304, 0.14968266280105394, 0.2709018941746113, 0.18550654005576464, 0.1933452732093568, 0.2326369178402478, 0.2170201560518189, 0.2133254041416752, 0.21757413517660515, 0.4270601362377729, 0.26719238853383037, 0.21711876853022805, 0.23568007235963473, 0.2555331235692009, 0.3366762268879966, 0.2648885859814901, 0.22210627155620655, 0.2178266758247289, 0.2531545483391735, 0.11037458311381115, 0.2562696751482552, 0.26725035881643694, 0.08060968501385976, 0.08360844932884914, 0.1279597720390687, 0.3011372052154329, 0.1562277141800891, 0.2139616403582736, 0.18474567624683996, 0.21232975518419853, 0.30381123865166737, 0.3623561386035276, 0.3727333359358361, 0.2640186244249097, 0.1081713045126692, 0.2085923100147303, 0.37142967547105415, 0.3104982715894569, 0.14392172305931272, 0.1835365295902619, 0.12446183588319552, 0.23936450145480223, 0.15814091338091488, 0.21265619752151352, 0.2761645745662351, 0.20321471125314472, 0.30223212405615035, 0.08287114791401796, 0.06527764457589481, 0.3945381695005499, 0.1913732600076525, 0.17577439000578007, 0.15831942829768275, 0.21188841638339065, 0.23273619511000393, 0.2913114810520981, 0.15271959223083656, 0.15856150493966062, 0.1412964688353006, 0.17461393294860572, 0.14196310007687066, 0.29439947605112105, 0.35175877796608207, 0.2783543433907042, 0.2824276670697463, 0.2555378987195695, 0.15862688812947973, 0.13256923459806808, 0.17458568795584953, 0.28374873844570064, 0.28365287907572156, 0.15782026964436893, 0.39383750755791386, 0.20068080618587955, 0.2505652331108462, 0.28249249433126306, 0.24626715250961856, 0.25649322165806004, 0.2699841205725952, 0.2145210116423807, 0.24508884996269964, 0.27002144022311075, 0.22842004765302873, 0.289755887152534, 0.09334923654700157, 0.25992644179009716, 0.3260608280889307, 0.22569849389102145, 0.16302004244491525, 0.21328087157589665, 0.1423661189773022, 0.1929348257771534, 0.25711289887451566, 0.18344880346526196, 0.3739686740626799, 0.42082091777549435, 0.18573188044461844, 0.24823359405411557, 0.21450410419091037, 0.2655333264971706, 0.1788772703666673, 0.22236136786053906, 0.18564827475216644, 0.17814061353355798, 0.20525012970703466, 0.15303553210862128, 0.17375763226818405, 0.1738302820224564, 0.232635834121221, 0.1933801346106742, 0.08318225803932917, 0.23397819306799542, 0.3343355347160099, 0.13448789669018582, 0.1669565813319526, 0.38659101189264694, 0.169232973904028, 0.2245272428478946, 0.24160388707475577, 0.27914939928105553], "M01": [0.11471442767365345, 0.2067703970716361, 0.3351561322556325, 0.12924864868320213, 0.28406805316974537, 0.040022520268096655, 0.24842719139829944, 0.33467875618447684, 0.28768723899956505, 0.32859280365763166, 0.2011821351503914, 0.10153282658592198, 0.24470943958633137, 0.23042434588216745, 0.17829879044998956, 0.3446408830629524, 0.4152657723615235, 0.2732517218614615, 0.4029179870933187, 0.2965215131727211, 0.2441685334163592, 0.2854898831288572, 0.24670890017340896, 0.18305133966297282, 0.26423664873507186, 0.09727959061754014, 0.10337284585533528, 0.2030325526568517, 0.41274512393572854, 0.31173408293980115, 0.27265349070228434, 0.3643014873830706, 0.22428358978108032, 0.2631595719243453, 0.13302252797902975, 0.29136375751979354, 0.28301591362942163, 0.3831854098260667, 0.16965229505565213, 0.20727233860137462, 0.32909939104981245, 0.23992095764369648, 0.5694212891959454, 0.12615024730960278, 0.3509075006768256, 0.3184246877945697, 0.2801611178954593, 0.19850184923828657, 0.2593567674780984, 0.2849058938354072, 0.1552173775572868, 0.20929292399721036, 0.19463135536564602, 0.26875256012741244, 0.2071412371071825, 0.36820113763645934, 0.17516266537591638, 0.20813103120926593, 0.36050524690933206, 0.2236705936169546, 0.32794413153463786, 0.10351382063960292, 0.25283408098149535, 0.1995617845822515, 0.07319437568477596, 0.21110384130754828, 0.08927366931528427, 0.14875512231229576, 0.1937938742358672, 0.33319072865984983, 0.28421459556927914, 0.1632427382466282, 0.16117479890670144, 0.15447828081265122, 0.32821898697813234, 0.42192344043758717, 0.32613109764331655, 0.17711441373348058, 0.35021585732246663, 0.15815535723165816, 0.23100335714128953, 0.12581443175543863, 0.2758464455904516, 0.1334719386999288, 0.24801459541515514, 0.2578049671272867, 0.311248424368666, 0.186392425080514, 0.2927090540350291, 0.2108554030189936, 0.1533431916832625, 0.22393936666207848, 0.3900900998589438, 0.1970338933669767, 0.47656714747222756, 0.09472187808480173, 0.24894202854841094, 0.2523572698311993, 0.08036949777667757, 0.31713467869430756, 0.1566754217000205, 0.21012161945541225, 0.14584412027111704, 0.2431421349439564, 0.4316381226630973, 0.17133566408232356, 0.1521451108817043, 0.29249945879823097, 0.18986852758378103, 0.4064074232966488, 0.1883677266290722, 0.282112035928449, 0.12345256181637576, 0.166488960434148, 0.14639057541201372, 0.31308635323897743, 0.2780226688356189, 0.3349233882643851, 0.22118859608536162, 0.24920237803985767, 0.2565355930105207, 0.41019015330041186, 0.2430666168097075, 0.27156497952059316, 0.25506155323515944, 0.2213969907042674, 0.2797695631881497, 0.1639573578376584, 0.240631488381306, 0.22680769997918393, 0.3039123440174279, 0.16959332624814097, 0.38008839791604565, 0.37227624485627736, 0.3158960324409252, 0.259119187363866, 0.32316748094946685, 0.2932683731872161, 0.38151579269783376, 0.30720805037150584, 0.18235765541316762, 0.34754588579084056, 0.16168757076611856, 0.23793713932326127, 0.22376304509276512, 0.12325723333272257, 0.3722844483809014, 0.30638482927103566, 0.2428330994382363, 0.24973939022538227, 0.3798974854681284, 0.2024841292998493, 0.19449450227214576, 0.19261899769478125, 0.22304257999491545, 0.16769168847070623, 0.18727292969676984, 0.21931514052388354, 0.2087549393658803, 0.25231126691070244, 0.31374411488176424, 0.17693167191388723, 0.23339940708094373, 0.15527087091472636, 0.15779098564861455, 0.36026239099012086, 0.11352146298689375, 0.24171227034684106, 0.27378012955740694, 0.2586419826490164, 0.1261203157039444, 0.24265344231108021, 0.28441965223534216, 0.24533823870513877, 0.3502941592916762, 0.3676539483649537, 0.2839865415213003, 0.35884008463868394, 0.13449957998134887, 0.20417656386375754], "M08": [0.139362383094205, 0.19884334305560844, 0.3647092686124795, 0.05674333196195396, 0.3698223052614406, 0.29466260092163815, 0.3988855182437864, 0.34779798033876025, 0.2303355297407281, 0.2643517156467664, 0.16118897722083256, 0.2774449089989418, 0.3085021840509739, 0.0838520351614055, 0.20170010968741675, 0.20691056323659016, 0.4573019917262763, 0.3082550288501705, 0.4575410376592465, 0.2733347996850801, 0.24298584082819516, 0.35701159891432466, 0.29424523947006415, 0.36663927943703944, 0.08868494439839035, 0.17895212401388016, 0.14314538938019516, 0.13936607326334496, 0.19605127459246763, 0.37852177218131144, 0.3039333757581647, 0.24330588014291474, 0.27057034384957046, 0.12864844208366613, 0.3131846553377749, 0.39783064481385516, 0.18918704812753379, 0.3366885771944665, 0.20163856702032734, 0.2849521297332769, 0.25584748591884043, 0.42948929469993957, 0.5609004674845929, 0.29340113114188393, 0.2208954906097575, 0.1299758116906564, 0.3008231671657961, 0.1973479966428075, 0.1385320463053753, 0.4221234178149376, 0.18294449605546126, 0.32320144427949843, 0.30740552677485145, 0.33241581634218575, 0.04327637077381331, 0.197407337961745, 0.3077485359435758, 0.0776869008481891, 0.42897572546126206, 0.1949632989136331, 0.2708469009461372, 0.1634699480605952, 0.3760225669693634, 0.15307012512926768, 0.26960184695545214, 0.3181395057016202, 0.18167047783227155, 0.151136541056705, 0.10727431768307728, 0.43113888258181676, 0.36674548368007265, 0.20250926474674147, 0.2337512051227507, 0.30767213373055396, 0.32448541967363753, 0.2879714746226774, 0.3852741579092654, 0.25734187745717024, 0.3836932495313783, 0.1555840617913649, 0.22685355135747048, 0.17287332491920948, 0.13818577240760177, 0.23864547368081904, 0.10424155050363385, 0.36654098395291956, 0.2792494897330368, 0.2705332182824922, 0.3037064397117072, 0.34254716476328895, 0.27522481269678506, 0.43178170182583153, 0.2773061157984804, 0.1921308566218545, 0.46684441488663564, 0.11202726251678917, 0.44235087686979846, 0.26111867265115635, 0.2983692615914076, 0.11737284705336112, 0.10562591479512251, 0.12595104808990307, 0.08283429700397522, 0.136321824786021, 0.3620766119342333, 0.1343811337629712, 0.29080111796497315, 0.1939809808830645, 0.2120326284504096, 0.43954761445503737, 0.29051259123649414, 0.1841334738730038, 0.20596625110552874, 0.3308435069778546, 0.11034586961010186, 0.19677264885418433, 0.25187540018667826, 0.33035472356799644, 0.1368637166026408, 0.27930066338248244, 0.4318339796504217, 0.27851417819064067, 0.3265661547475826, 0.2615805898571083, 0.23345087599403266, 0.20303662475920697, 0.18706746473246505, 0.28409015725483955, 0.38159870952540575, 0.22292487589925045, 0.20974531381892383, 0.19953129588844284, 0.12740978452004695, 0.2700227602863304, 0.12340504146339537, 0.23975208336533838, 0.20066523926107846, 0.48444602605234466, 0.4677615109833201, 0.16209468305697713, 0.15701272814936382, 0.2802161308137892, 0.3356729031149013, 0.1686419336962145, 0.16581466373594123, 0.19519048344380352, 0.1750945830238784, 0.36832642941762284, 0.17530688097535824, 0.30608811474194886, 0.08177878183812137, 0.20451955763182517, 0.28070051241642824, 0.14039052436918514, 0.19496880795833693, 0.1937614541825859, 0.35466641798739756, 0.2750441575576947, 0.3042551212460168, 0.10059496187778788, 0.3412494631606242, 0.1590012334955467, 0.2307244907728155, 0.28040377647197334, 0.23523496464588148, 0.3661403128584089, 0.22119668404726883, 0.0695733487391954, 0.12814643768712103, 0.2778961521967172, 0.31239819883292, 0.3387834841775264, 0.12251259700892937, 0.27758399341454293, 0.21857856130889916, 0.39556266040333055, 0.08553828279827475, 0.24943939176864785, 0.25248568111423003, 0.24072807052407666], "M13": [0.18716452144889867, 0.21420783797162793, 0.329885390874135, 0.10001630394967502, 0.26663031741750143, 0.20818974934845572, 0.1876054874402924, 0.31417389152050873, 0.2953776560378217, 0.27520755095501453, 0.11801265160946073, 0.3022004230537978, 0.2492787198684618, 0.294413714212779, 0.1647466695229261, 0.16721064399274743, 0.23774105706261253, 0.28663293926965827, 0.24372713683524297, 0.29553886023126313, 0.26460506266635514, 0.26981214765601136, 0.25409375286082514, 0.24323629136465996, 0.2665602670114481, 0.34258909296429135, 0.28505906161132194, 0.2409244099507468, 0.30276442710865786, 0.2746114851342279, 0.30855634488904154, 0.2253404621159945, 0.276000652834754, 0.13236420124992562, 0.23513844542047146, 0.18424105450935632, 0.15170314242818198, 0.2275233209213358, 0.14508274808821223, 0.3351969390060197, 0.21278049068544105, 0.3659377396417213, 0.17063314800915055, 0.3122037377215521, 0.1258127211942734, 0.2818444501195836, 0.21453912747343926, 0.19809641354258078, 0.1864308541826153, 0.3756353466522784, 0.22151020703036223, 0.17871889215928718, 0.2028039206284377, 0.051503173565771096, 0.2880822607542726, 0.17456715674597073, 0.2585410480910895, 0.12950686336037168, 0.16200547154628903, 0.19606230476134845, 0.24354447207949179, 0.2198843409486218, 0.3174993047215005, 0.30531259257548254, 0.1937320171224574, 0.06556127489363663, 0.16009493386432824, 0.25425831988166686, 0.1576494171369434, 0.3983064488730841, 0.2705190164604656, 0.27697117198932414, 0.204531976613201, 0.29720691731294285, 0.241004009106796, 0.1535287934774979, 0.21402655905618806, 0.2798991742691761, 0.21578308445776262, 0.17653056315935298, 0.255622962842386, 0.21575678465681253, 0.2834791687810271, 0.1065158501505491, 0.18968839337099497, 0.34001764135633467, 0.20255084584542546, 0.14971685121792375, 0.2857547345827503, 0.26547004565442195, 0.08977331021862782, 0.22895555488662167, 0.2377334190219246, 0.3230792915887557, 0.3848940320841032, 0.19137575457635717, 0.4105470624004252, 0.2805900504870908, 0.1898058157351486, 0.24687774981643612, 0.253128446316827, 0.297827337481519, 0.17904334240520595, 0.16609379600951174, 0.29210233440205174, 0.11912777268014806, 0.13382145131387774, 0.20522314522812257, 0.21389839351982318, 0.36748191451953593, 0.28361925521614884, 0.25972522220412714, 0.13329082976480394, 0.15987751295502178, 0.28729501927351314, 0.26789555389029956, 0.20211163192747966, 0.2857128343140601, 0.12245568022154588, 0.1579770550222211, 0.3666961804357026, 0.1943692757074751, 0.20906111842322395, 0.26507120675902196, 0.2974701995096349, 0.25878966895470806, 0.30190643176972753, 0.2795977554444838, 0.14311315029279337, 0.15605351497644565, 0.2814174783551041, 0.14222968151260992, 0.29850117412325977, 0.3998147323153626, 0.21633819172498428, 0.3367653069284291, 0.2709927098181026, 0.1748392403352964, 0.23459658958864366, 0.07858478917158132, 0.12035196224262255, 0.2975021871630305, 0.1999303319972592, 0.12805170332317772, 0.28863024585957525, 0.269945780596242, 0.25128484575627447, 0.3142453420253039, 0.23159593303363987, 0.1985298178245355, 0.26108441897225726, 0.2939636848474513, 0.2964870640106861, 0.13629434450963032, 0.341764001482624, 0.245969352467848, 0.183196717015614, 0.29658370751246993, 0.09801171414744322, 0.33435164516164767, 0.3544851018506317, 0.2628381635874926, 0.12052296396047946, 0.1691140242915055, 0.2542678343694048, 0.23879563170892118, 0.1962404222691197, 0.16871160091415127, 0.23258076854760099, 0.14447515152177803, 0.2190011630458453, 0.20592731000481806, 0.20197030547791708, 0.30921108541986303, 0.2824645585771863, 0.41851425408636145, 0.2904482942505831, 0.3033797399208293, 0.27560812452386635, 0.3505885616373527]}
\ No newline at end of file
Index: log/day and time:2021_02_23.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/log/day and time:2021_02_23.log b/log/day and time:2021_02_23.log
new file mode 100644
--- /dev/null	(date 1614114726000)
+++ b/log/day and time:2021_02_23.log	(date 1614114726000)
@@ -0,0 +1,1684 @@
+******************day and time:2021_02_23*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+******************day and time:2021_02_23*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+******************day and time:2021_02_23*******************
+******************day and time:2021_02_23*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(2.0909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9163, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4150, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.8056, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4617, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1800, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.0378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3966, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6227, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.1371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.9397, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.9173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.5750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.1838, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3911, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.2860, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.8661, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2902, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.6346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3023, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0233, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1445, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5247, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.6945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.2117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9722, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :3.312436337056367
+Validation score improved (inf --> 3.312436337056367). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.6196, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6454, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7007, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6377, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6404, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6122, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2302, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7138, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1690, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8182, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1838, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1088, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6096, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6218, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3051, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2488, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7879, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7266, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8901, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7773, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6401, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8622, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :2 | Validation Loss :0.9955668591934702
+Validation score improved (3.312436337056367 --> 0.9955668591934702). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+******************day and time:2021_02_23*******************
+******************day and time:2021_02_23*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.8117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6345, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.1462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3487, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4714, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1941, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2957, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1775, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.3173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4773, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4768, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9432, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6201, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.5278, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7970, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9882, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8277, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3073, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6840, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7989, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6550, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5317, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2381, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5053, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4135, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6283, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :1.8100368872932766
+Validation score improved (inf --> 1.8100368872932766). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.1269, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0449, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6108, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0347, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7946, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9409, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0147, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9231, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9339, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0229, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0283, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2377, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4232, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0443, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2263, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0254, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6565, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9265, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9946, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5351, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9624, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :2 | Validation Loss :1.319531392791997
+Validation score improved (1.8100368872932766 --> 1.319531392791997). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.5693, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9682, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8517, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7821, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2257, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5245, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1077, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7444, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9480, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7692, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1360, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5271, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0440, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6392, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8922, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7645, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8094, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7680, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8125, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7166, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2541, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7214, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7941, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7515, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :3 | Validation Loss :1.0121640550053639
+Validation score improved (1.319531392791997 --> 1.0121640550053639). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.5161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5451, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4981, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5369, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9399, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8003, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7077, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7065, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2288, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9603, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7472, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0305, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7532, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5187, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6183, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5440, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0882, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6413, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5181, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6437, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7774, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2576, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :4 | Validation Loss :0.8017130967067636
+Validation score improved (1.0121640550053639 --> 0.8017130967067636). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(12.1575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5209, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.6013, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.1982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.4150, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.7816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.9754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3409, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.7823, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.9779, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.0348, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.8610, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3829, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.0919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.1827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.6332, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.7616, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(14.2312, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.0937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0709, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.6435, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.0745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.4725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.8434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3444, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.8430, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.4494, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0293, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.2613, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6402, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.1942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(14.6346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.5586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.1386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.0421, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.8960, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.0676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5100, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.8378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.3450, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.5807, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :5 | Validation Loss :7.742127698400746
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5639, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5902, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4587, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5415, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5356, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5476, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :6 | Validation Loss :0.48710918102575385
+Validation score improved (0.8017130967067636 --> 0.48710918102575385). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4205, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5369, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6015, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :7 | Validation Loss :0.4255755148504091
+Validation score improved (0.48710918102575385 --> 0.4255755148504091). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4205, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5669, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5740, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6373, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8150, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6296, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :8 | Validation Loss :0.3494769305638645
+Validation score improved (0.4255755148504091 --> 0.3494769305638645). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4598, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1602, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4249, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4331, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :9 | Validation Loss :0.27930704180313193
+Validation score improved (0.3494769305638645 --> 0.27930704180313193). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1731, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5208, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1302, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1573, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1598, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :10 | Validation Loss :0.2222887201477652
+Validation score improved (0.27930704180313193 --> 0.2222887201477652). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1163, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1460, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1241, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1433, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1311, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1114, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5106, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1483, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :11 | Validation Loss :0.16865813197649043
+Validation score improved (0.2222887201477652 --> 0.16865813197649043). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5000, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1701, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4877, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :12 | Validation Loss :0.1856680334262226
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0884, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4359, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :13 | Validation Loss :0.1928424188948196
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1692, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0556, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :14 | Validation Loss :0.12419399643397849
+Validation score improved (0.16865813197649043 --> 0.12419399643397849). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1283, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1508, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :15 | Validation Loss :0.09875682644222093
+Validation score improved (0.12419399643397849 --> 0.09875682644222093). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(6.1474, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(13.7749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.2075, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.9848, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.0513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.6225, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.1550, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.8485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.5329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.4200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.2468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.7078, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.7960, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.9216, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.0857, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.6784, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.9575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.9863, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.0783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.2550, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.2572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.7752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.4033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.1423, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.9750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.7083, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.9885, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.3304, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7319, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.0481, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.5128, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.8384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6360, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.7346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.9278, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.9683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.8764, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :16 | Validation Loss :7.450107579645903
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0597, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0598, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :17 | Validation Loss :0.10387489645053512
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :18 | Validation Loss :0.1179574373299661
+EarlyStopping counter: 3 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0734, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :19 | Validation Loss :0.12874214189208072
+EarlyStopping counter: 4 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :20 | Validation Loss :0.08904030773302783
+Validation score improved (0.09875682644222093 --> 0.08904030773302783). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0887, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :21 | Validation Loss :0.08731844972657121
+Validation score improved (0.08904030773302783 --> 0.08731844972657121). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0445, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1028, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1203, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :22 | Validation Loss :0.14080617155717767
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1030, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0455, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1141, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :23 | Validation Loss :0.09148173066584961
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :24 | Validation Loss :0.12374767013218092
+EarlyStopping counter: 3 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0419, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :25 | Validation Loss :0.08042675175744554
+Validation score improved (0.08731844972657121 --> 0.08042675175744554). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :26 | Validation Loss :0.12924537759112276
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0563, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :27 | Validation Loss :0.12871415670151296
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1616, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0407, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0429, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0388, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0441, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5649, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :28 | Validation Loss :0.12439397382347481
+EarlyStopping counter: 3 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1225, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1455, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1584, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1474, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5640, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :29 | Validation Loss :0.1383256786705359
+EarlyStopping counter: 4 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1162, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1269, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :30 | Validation Loss :0.12771692693881367
+EarlyStopping counter: 5 out of 5
+Early stopping
+Predicting for OOF
+[1.8100368872932766, 1.319531392791997, 1.0121640550053639, 0.8017130967067636, 7.742127698400746, 0.48710918102575385, 0.4255755148504091, 0.3494769305638645, 0.27930704180313193, 0.2222887201477652, 0.16865813197649043, 0.1856680334262226, 0.1928424188948196, 0.12419399643397849, 0.09875682644222093, 7.450107579645903, 0.10387489645053512, 0.1179574373299661, 0.12874214189208072, 0.08904030773302783, 0.08731844972657121, 0.14080617155717767, 0.09148173066584961, 0.12374767013218092, 0.08042675175744554, 0.12924537759112276, 0.12871415670151296, 0.12439397382347481, 0.1383256786705359, 0.12771692693881367]
+time-cost: 459.3679034121179
Index: log/day and time:2021_02_24.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/log/day and time:2021_02_24.log b/log/day and time:2021_02_24.log
new file mode 100644
--- /dev/null	(date 1614167797000)
+++ b/log/day and time:2021_02_24.log	(date 1614167797000)
@@ -0,0 +1,1566 @@
+******************day and time:2021_02_24*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.8117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6345, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.1462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3487, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4714, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1941, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2957, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1775, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.3173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4773, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3154, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4768, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9432, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6201, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.5278, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7970, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9882, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8277, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3073, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6840, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3460, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7989, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6550, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3211, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5317, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2381, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5053, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4135, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6283, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :1.8100368872932766
+Validation score improved (inf --> 1.8100368872932766). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.1269, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0449, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6108, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0347, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7946, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3279, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9409, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3208, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0147, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9231, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9339, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4362, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0229, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0283, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2377, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4232, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0443, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2263, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0254, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6565, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9265, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9946, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5351, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9624, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :2 | Validation Loss :1.319531392791997
+Validation score improved (1.8100368872932766 --> 1.319531392791997). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.5693, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9682, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8517, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7821, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2257, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5245, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1077, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7444, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9480, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7692, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1360, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5271, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0440, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6392, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8922, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7645, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8094, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7680, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8125, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7166, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2541, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2806, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7214, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7941, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7515, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :3 | Validation Loss :1.0121640550053639
+Validation score improved (1.319531392791997 --> 1.0121640550053639). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.5161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5451, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4981, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5369, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9399, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8003, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7077, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7065, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2288, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9603, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7472, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0305, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7532, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5187, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6183, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5440, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0882, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6413, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5181, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6437, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7774, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2576, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :4 | Validation Loss :0.8017130967067636
+Validation score improved (1.0121640550053639 --> 0.8017130967067636). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(12.1575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5209, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.6013, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.1982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.4150, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.7816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.9754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3409, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.7823, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.9779, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.0348, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.8610, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3829, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.0919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.1827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.6332, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.7616, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(14.2312, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.0937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0709, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.6435, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.0745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.4725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.8434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3444, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.8430, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.4494, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0293, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.2613, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6402, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.1942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(14.6346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.5586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.1386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.0421, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.8960, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.0676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5100, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.8378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.3450, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.5807, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :5 | Validation Loss :7.742127698400746
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.4192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4328, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4193, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5639, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4133, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5902, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4587, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5415, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4661, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5588, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5356, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3981, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4300, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5476, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4305, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4086, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :6 | Validation Loss :0.48710918102575385
+Validation score improved (0.8017130967067636 --> 0.48710918102575385). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3932, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4048, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4062, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5125, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3870, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4106, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3979, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3965, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4205, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3807, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5118, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4705, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3912, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5369, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5085, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6015, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3640, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3988, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :7 | Validation Loss :0.4255755148504091
+Validation score improved (0.48710918102575385 --> 0.4255755148504091). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2793, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2874, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4205, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2905, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3398, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5669, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2461, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5740, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2457, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3533, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2486, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2431, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6373, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2320, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2726, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4432, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8150, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6296, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :8 | Validation Loss :0.3494769305638645
+Validation score improved (0.4255755148504091 --> 0.3494769305638645). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2723, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2340, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3101, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1541, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3114, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3107, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1917, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4598, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1630, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3047, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2016, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1602, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2477, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1459, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1644, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4249, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3424, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4331, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :9 | Validation Loss :0.27930704180313193
+Validation score improved (0.3494769305638645 --> 0.27930704180313193). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1409, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1731, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1890, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1216, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3282, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1294, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5208, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1779, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1556, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1302, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1573, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1598, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2624, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :10 | Validation Loss :0.2222887201477652
+Validation score improved (0.27930704180313193 --> 0.2222887201477652). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1202, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1163, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1699, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1460, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1241, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2420, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1433, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1000, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1311, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3899, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1114, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2042, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1208, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2417, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5106, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1483, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1224, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1180, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3261, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :11 | Validation Loss :0.16865813197649043
+Validation score improved (0.2222887201477652 --> 0.16865813197649043). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1078, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5000, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1299, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1701, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2441, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2739, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0971, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3858, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0955, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4877, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0894, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0763, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :12 | Validation Loss :0.1856680334262226
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1957, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0805, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1801, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1257, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1355, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1012, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3764, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1964, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3420, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0884, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2038, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4359, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :13 | Validation Loss :0.1928424188948196
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1265, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1692, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2245, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0992, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2804, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3038, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0803, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0556, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2068, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :14 | Validation Loss :0.12419399643397849
+Validation score improved (0.16865813197649043 --> 0.12419399643397849). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0673, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0830, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2126, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2263, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1283, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1015, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1508, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1124, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0835, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1910, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :15 | Validation Loss :0.09875682644222093
+Validation score improved (0.12419399643397849 --> 0.09875682644222093). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(6.1474, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(13.7749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.2075, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.9848, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.0513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.6225, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.1550, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.8485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.5329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.4200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.2468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.7078, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.7960, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.9216, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.0857, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.6784, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.9575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.9863, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.0783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.2550, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.2572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.7752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.4033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.1423, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.9750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.7083, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.9885, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.3304, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7319, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.0481, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.5128, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.8384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6360, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.7346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.9278, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.9683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.8764, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :16 | Validation Loss :7.450107579645903
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1196, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1060, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0597, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3116, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0666, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0598, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1033, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :17 | Validation Loss :0.10387489645053512
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3143, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0717, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1705, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1218, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1899, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1142, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0785, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :18 | Validation Loss :0.1179574373299661
+EarlyStopping counter: 3 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1821, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1047, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1726, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2352, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1997, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0734, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1405, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4215, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1362, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0741, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :19 | Validation Loss :0.12874214189208072
+EarlyStopping counter: 4 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0507, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1156, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :20 | Validation Loss :0.08904030773302783
+Validation score improved (0.09875682644222093 --> 0.08904030773302783). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1168, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0887, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2459, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0866, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1437, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :21 | Validation Loss :0.08731844972657121
+Validation score improved (0.08904030773302783 --> 0.08731844972657121). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0445, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2027, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1822, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2043, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1028, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0443, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1203, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1232, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4118, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :22 | Validation Loss :0.14080617155717767
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1030, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1418, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1391, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0455, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1141, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1108, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1235, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2076, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0573, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1254, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :23 | Validation Loss :0.09148173066584961
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1408, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2221, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1968, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0831, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2227, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :24 | Validation Loss :0.12374767013218092
+EarlyStopping counter: 3 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0450, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0419, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0886, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0449, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0828, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :25 | Validation Loss :0.08042675175744554
+Validation score improved (0.08731844972657121 --> 0.08042675175744554). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4898, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1464, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2020, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1900, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2085, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0490, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3733, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :26 | Validation Loss :0.12924537759112276
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1352, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0935, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3335, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0867, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0464, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0906, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0705, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2709, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3009, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0563, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :27 | Validation Loss :0.12871415670151296
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1035, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1080, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0493, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2243, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1616, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0407, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1034, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0429, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0388, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1992, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1274, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3023, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0441, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0948, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5649, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3345, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :28 | Validation Loss :0.12439397382347481
+EarlyStopping counter: 3 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1040, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1053, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1324, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1225, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1455, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1584, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1474, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1436, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5640, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1112, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1357, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :29 | Validation Loss :0.1383256786705359
+EarlyStopping counter: 4 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2541, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1162, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2037, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1457, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1472, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1349, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1338, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0944, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1269, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2412, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2671, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0508, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1519, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :30 | Validation Loss :0.12771692693881367
+EarlyStopping counter: 5 out of 5
+Early stopping
+Predicting for OOF
+[1.8100368872932766, 1.319531392791997, 1.0121640550053639, 0.8017130967067636, 7.742127698400746, 0.48710918102575385, 0.4255755148504091, 0.3494769305638645, 0.27930704180313193, 0.2222887201477652, 0.16865813197649043, 0.1856680334262226, 0.1928424188948196, 0.12419399643397849, 0.09875682644222093, 7.450107579645903, 0.10387489645053512, 0.1179574373299661, 0.12874214189208072, 0.08904030773302783, 0.08731844972657121, 0.14080617155717767, 0.09148173066584961, 0.12374767013218092, 0.08042675175744554, 0.12924537759112276, 0.12871415670151296, 0.12439397382347481, 0.1383256786705359, 0.12771692693881367]
+time-cost: 431.6616191507705
Index: log/day and time:2021_03_07.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/log/day and time:2021_03_07.log b/log/day and time:2021_03_07.log
new file mode 100644
--- /dev/null	(date 1615130026000)
+++ b/log/day and time:2021_03_07.log	(date 1615130026000)
@@ -0,0 +1,1164 @@
+******************day and time:2021_03_07*******************
+******************day and time:2021_03_07*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+******************day and time:2021_03_07*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+******************day and time:2021_03_07*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+******************day and time:2021_03_07*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+******************day and time:2021_03_07*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.7184, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4727, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3530, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6437, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7806, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.1530, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4101, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3302, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2011, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3481, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0155, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.3230, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4624, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4818, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3255, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8320, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6508, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2361, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.5003, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.5485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8006, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8998, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0062, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0641, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7320, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3242, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6836, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7275, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3273, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7044, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3420, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5708, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2535, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4708, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6003, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :1.797884666401407
+Validation score improved (inf --> 1.797884666401407). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.1929, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1926, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6128, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4154, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.6378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0702, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9981, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6764, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.7048, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.6769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9976, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4437, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0256, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2802, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1017, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5247, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0746, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2162, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1535, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2090, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4493, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9961, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.5644, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1098, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2098, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2686, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9679, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.6088, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :2 | Validation Loss :1.5330162164957628
+Validation score improved (1.797884666401407 --> 1.5330162164957628). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.5674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9245, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9666, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8215, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7314, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2268, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5253, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6815, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7411, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7192, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7865, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5280, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7717, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7104, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0448, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7086, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0488, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7774, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7418, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5189, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7971, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7736, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2549, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7170, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2787, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7659, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7396, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4034, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8235, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7465, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :3 | Validation Loss :1.0139505474463752
+Validation score improved (1.5330162164957628 --> 1.0139505474463752). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.5216, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5610, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9760, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6866, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5137, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9899, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7906, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7036, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7056, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6905, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2410, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0321, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5317, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6743, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5390, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6679, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9803, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4823, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1009, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5154, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1107, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5686, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7441, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6662, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3912, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6133, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2620, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :4 | Validation Loss :0.8060482228579728
+Validation score improved (1.0139505474463752 --> 0.8060482228579728). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(16.7973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.9993, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.1819, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.9016, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.8881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.1049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.6806, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.7627, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.4319, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.4977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(15.1491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.8937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.7399, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.9548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.9705, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.9769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.6137, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(19.9322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(11.1953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.0416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.1200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.9498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.5855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(17.9099, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.9783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(16.2425, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.5830, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.4475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.8710, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.8225, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0116, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.4119, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0854, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(20.2344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.4614, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(16.4871, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.9521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0106, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.1425, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(14.4342, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(13.7749, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.2438, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6133, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :5 | Validation Loss :9.758272782615993
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4311, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3961, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5347, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4142, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4169, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4079, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5573, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4377, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4116, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4476, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4641, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4800, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4461, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4112, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5431, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4354, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5303, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4279, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5436, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8304, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4991, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4273, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4125, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3892, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4047, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4070, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :6 | Validation Loss :0.48381596414939215
+Validation score improved (0.8060482228579728 --> 0.48381596414939215). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3854, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5041, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3630, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5630, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4517, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3951, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4203, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3887, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4640, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3821, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5130, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3896, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5006, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3709, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5882, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3859, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :7 | Validation Loss :0.416072820191798
+Validation score improved (0.48381596414939215 --> 0.416072820191798). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3203, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2578, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3172, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3723, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2397, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2391, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4888, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2324, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2367, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2218, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4818, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3201, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2334, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2306, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2254, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2585, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2299, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4339, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3315, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2600, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7015, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5415, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :8 | Validation Loss :0.316544817517633
+Validation score improved (0.416072820191798 --> 0.316544817517633). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3450, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3428, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3275, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3368, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4050, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4719, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2145, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1762, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1692, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4188, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1665, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5326, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3145, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4032, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :9 | Validation Loss :0.29212020143218664
+Validation score improved (0.316544817517633 --> 0.29212020143218664). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1467, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3260, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1732, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2010, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3578, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1614, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1532, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3214, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2800, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1236, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3334, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4427, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1376, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6024, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5656, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2017, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1668, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1719, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1351, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1661, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1873, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4648, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :10 | Validation Loss :0.2332876844574576
+Validation score improved (0.29212020143218664 --> 0.2332876844574576). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0902, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4669, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0951, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1195, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1027, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1704, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1469, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1804, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1184, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1612, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1805, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1337, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0979, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1374, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1607, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2415, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3054, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5247, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1119, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3384, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :11 | Validation Loss :0.16808221327221912
+Validation score improved (0.2332876844574576 --> 0.16808221327221912). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1984, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0996, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2197, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1760, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1650, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1141, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3814, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0873, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1424, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1331, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2001, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2075, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0857, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0976, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3884, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1851, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1384, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :12 | Validation Loss :0.1528867319550203
+Validation score improved (0.16808221327221912 --> 0.1528867319550203). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1194, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2132, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1966, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1843, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3635, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2124, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1268, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1736, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0984, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0904, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0834, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6134, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1028, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1493, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3817, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0819, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7213, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2199, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3097, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4334, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4879, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :13 | Validation Loss :0.1989638330819814
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0487, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1256, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1174, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2142, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2805, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0845, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0669, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1333, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2994, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0627, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2230, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0836, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :14 | Validation Loss :0.12269523415876471
+Validation score improved (0.1528867319550203 --> 0.12269523415876471). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1626, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0708, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2746, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2612, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1757, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0663, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1404, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0960, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0871, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1321, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1280, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1776, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2436, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :15 | Validation Loss :0.11223778015245563
+Validation score improved (0.12269523415876471 --> 0.11223778015245563). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(6.5538, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.6647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.3708, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.2128, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.4829, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.5627, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.3105, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.0454, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.9052, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.5860, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.5860, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.9527, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.4869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.7912, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.0342, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.1838, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.8302, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.9694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.4977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.7038, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.6684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.9285, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.8562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.1933, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.0152, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.9215, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.8868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.6930, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.5539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.1652, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2016, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.9559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.0096, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.7622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.3677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.4037, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.7621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.9414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.8925, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4182, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :16 | Validation Loss :7.46326540345731
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1382, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1152, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0865, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0661, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0920, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2801, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2489, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1149, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0467, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :17 | Validation Loss :0.08639154907154001
+Validation score improved (0.11223778015245563 --> 0.08639154907154001). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0989, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3935, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2918, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1211, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0898, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2664, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1057, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5319, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0541, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1921, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2136, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1270, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2347, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2382, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1669, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3147, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1335, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0565, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1403, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1309, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0683, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :18 | Validation Loss :0.14159460495347562
+EarlyStopping counter: 1 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2532, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1690, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6557, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1143, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0718, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0578, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1889, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2587, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1069, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0853, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0728, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0563, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4088, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1524, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0769, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :19 | Validation Loss :0.13556665781399477
+EarlyStopping counter: 2 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1295, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0662, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0860, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0591, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2194, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0745, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1086, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0561, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2024, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0524, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0947, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2715, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1032, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1700, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0604, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1382, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1370, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :20 | Validation Loss :0.10207536784203156
+EarlyStopping counter: 3 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0598, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1231, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0675, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0531, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2351, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0871, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0588, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1289, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0447, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2823, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1579, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0627, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0476, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :21 | Validation Loss :0.09323856671867163
+EarlyStopping counter: 4 out of 5
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3415, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2396, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0777, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0784, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2623, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0486, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1247, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3803, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1531, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2879, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0855, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0949, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0540, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1322, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3940, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :22 | Validation Loss :0.13982120901346207
+EarlyStopping counter: 5 out of 5
+Early stopping
+Predicting for OOF
+[1.797884666401407, 1.5330162164957628, 1.0139505474463752, 0.8060482228579728, 9.758272782615993, 0.48381596414939215, 0.416072820191798, 0.316544817517633, 0.29212020143218664, 0.2332876844574576, 0.16808221327221912, 0.1528867319550203, 0.1989638330819814, 0.12269523415876471, 0.11223778015245563, 7.46326540345731, 0.08639154907154001, 0.14159460495347562, 0.13556665781399477, 0.10207536784203156, 0.09323856671867163, 0.13982120901346207]
+[0.6484295299345261, 0.451209082590273, 0.5366780706705421, 0.5619472053100341, 0.8733961360308947, 0.03590885474295388, -0.1949363463701229, 0.549189731237324, 0.5905456919828694, 0.4749007280965949, 0.6991757984724364, 0.47417657316692796, 0.4595369108455408, 0.6244689942646023, 0.4960076253418534, 0.5684623228049227, 0.7569481183109209, 0.6054738363044371, 0.8073850775088425, 0.7686440955184202, 0.669694153890629, 0.6001746239249625, 0.4702267972931328, 0.7868869974708348, 0.4636080259878193, 0.5900551646594765, -0.17065592626145434, 0.8123712204398628, 0.5135503021329633, 0.4286716820692922, 0.828069282177305, 0.8295085182681061, 0.7371663414231351, 0.16423342782564646, 0.8134288248230646, 0.7544499948990709, 0.7808379499041282, 0.3188070778820812, 0.6472758496888296, 0.38472218912550826, 0.4509658704203919, 0.626248114120839, 0.7051284572599309, 0.7673827234874043, 0.01629783809865644, 0.783862753980348, 0.8029536107615807, 0.7771372141176599, 0.8433382967175049, 0.09086102127483853, 0.2948688966008414, 0.7569770073322714, 0.6414205494155125, -0.19637465514764463, 0.07022389845349847, 0.7010250867410153, 0.6933435405678189, 0.48842590071295594, 0.746589063358646, 0.9950477208355903, 0.6954491420911263, 0.8383994877386564, -0.05690424746744698, 0.32417485387417594, 0.6770774815305158, 0.5679340983435041, -0.003234485258168705, 0.8054459255664457, 0.6898703157497518, 0.4849199770586722, 0.7920080802298255, 0.04788658248635738, 0.7866671322473259, 0.621313388805112, 0.5970585145446013, 0.04113767035711513, 0.5140543423271915, 0.634884422506063, 0.6227362230424677, 0.6222882481082511, 0.8102734292596152, 0.8457888974140672, 0.8391893718808193, -0.1879505886317482, 0.3074307091291339, 0.5545979916238772, -0.005761156648996887, 0.5026065184883173, 0.4591328423836537, 0.8928512861606142, 0.45221023281924805, 0.6792260939158604, 0.3855593046003021, -0.03514400454761816, 0.6911041361507937, 0.7401273081327739, 0.4971615298520433, 0.7064360616442596, 0.5479934225326559, 0.025309925487572087, 0.7884717979591415, 0.06056950598088306, -0.21496261595518948, 0.775736663136711, 0.5256961581270536, 0.8198751720391874, 0.7405377450248312, 0.8371603972873908, 0.7719351941817889, 0.2760782599004987, 0.6196447623152505, -0.2611728550922213, 0.27808279003256214, 0.6071222440522885, 0.7687365988602541, 0.5135678073031122, 0.7752315897102311, 0.6882069658685568, -0.02577216215438292, 0.7347096117885853, 0.5271014119106846, 0.6505764443270822, 0.7593605484434359, 0.7105758585903796, 0.04074938706729489, 0.7169813796581858, 0.8009213304701939, 0.8921394924212416, 0.7595630193969742, 0.6562003255744829, 0.7920769522766988, 0.6524851161726346, 0.6415275098812561, 0.8750111867529797, -0.02807222356099385, 0.21195661183017506, 0.18441525166177677, 0.038920275871968606, 0.7364157850523958, 0.799151306345796, 0.8102846404106576, 0.7287369912607897, 0.4576172085504061, 0.7070121768298133, 0.6720533275193117, -0.03191361850149132, 0.7904300589330312, -0.13217844662747394, 0.4595165727240246, 0.7843309279447499, 0.6629326732915876, 0.49676661052710636, 0.513206996384926, 0.7011922187840027, 0.4937188922643264, 0.6830845419236902, -0.2342611838991506, 0.2916522547108041, 0.8733852142590729, 0.7694876189655045, 0.5365262050131056, 0.7337947432517561, 0.782314797675638, -0.03755799046888489, 0.8286699096125677, 0.6454999160438633, 0.29483056451621453, -0.060613917014128466, 0.7171320524167986, 0.5197412465828134, -0.21012326543675225, 0.8451327729641659, -0.061536933536290944, -0.04647193581760208, -0.26225138751805366, 0.8418008084132217, 0.5863892292427838, 0.5856868462524402, -0.07079114729518043, 0.1928549727690591, 0.024248419111907383, 0.7055992280663519, 0.0667676401989124, 0.1631479966611696, 0.7451438923820095, 0.6611132993677594, 0.22934119253604363, 0.8251947020801763, 0.3616255641068154, 0.6445976514228714, -0.21715843072544655, 0.44329809399894654, 0.8273934718401074, 0.7142863396324192, -0.053724305329916136, 0.49278115880071754, 0.7432753129590631, 0.38100494860524936, -0.2449708312665304, 0.6926818385494027, 0.7795226300908226, -0.3522069648969434, 0.3984308936174742, 0.2297165115297634, 0.7343217696796208, 0.19329179146488717, 0.7360152817610263, 0.8161732434697403, 0.549086991724747, 0.037739101205021705, 0.4853775261239527, 0.8316231408596779, 0.8491585242827124, 0.5296319826486711, 0.9965584624720021, 0.8337305427720073, 0.35797757462751306, 0.7307784651098002, 0.43095373822624594, 0.34701703412868967, 0.7297805586903632, 0.4188309158431336, 0.46184011682853154, -0.0010858926839863317, 0.4819737145128519, 0.7812780578274665, -0.055700741359146634, -0.34834806792868833, 0.8058974408414994, 0.18716178696278873, 0.7246532850365707, 0.8062503706306023, 0.6273537123725652, 0.3343120454289351, 0.05457648546143157, 0.7249110075461606, 0.6847976083627858, 0.00892486865912807, 0.380939629746757, 0.8175145911895744, -0.29979958720330896, 0.7707381124816194, 0.37195955205177644, 0.7082441278497079, 0.8275796761876784, 0.7197409550199575, 0.07365787432213056, 0.46063389691533163, 0.771332632851586, -0.04364196843370534, 0.023221859979488366, 0.5593441871578629, 0.503411880871233, 0.9997803174747912, 0.7767626407818241, 0.7728424382258569, 0.461143671225776, -0.018859997587553152, 0.7904354529668561, 0.829653707429099, 0.830751221338755, 0.7463827584857526, 0.3928383468095485, 0.5678520624516645, 0.33695623366155114, 0.6966994107621559, 0.6738348066031588, 0.019909015213867037, 0.6988764105975074, 0.7235330342096807, 0.7069942373641092, 0.10556473942580889, 0.8980192407461378, 0.727048149933327, 0.6011845291640027, 0.79437524343193, 0.7365426558148948, 0.8904602744146769, 0.6999384217846376, 0.7193185305575429, 0.37171397148057816, 0.6274217346577924, 0.11901796028209938, 0.5449330488775767, 0.6040822323290956, 0.6931035996781825, 0.6882798866800571, 0.6435305540031385, 0.6369721288102316, 0.6652786386670652, 0.32334794955844515, 0.7529445458988753, 0.6269922733184462, 0.6799204305431641, 0.38222555989397367, 0.7054778508929179, 0.5494291094111216, 0.775669253558456, 0.5447193418011024, 0.7155959700509044, 0.8892858937844568, 0.7922566122032872, 0.03792455784529757, 0.03602144830909265, 0.6897737342858401, 0.5283903167489679, -0.013724063905017118, 0.3755002832011484, 0.7305991156934397, 0.16961411665389978, 0.12094162652702134, 0.5767094712469113, 0.3287166513849344, 0.29718374702052414, 0.4745392390303521, 0.3198996669709022, 0.643714299282937, 0.36298853866342773, 0.8134085975723456, 0.4694090677851007, 0.6076283509820439, -0.12015519419962949, 0.8846620022967339, 0.7191755740528214, 0.6838711607599343, 0.73905399481952, 0.6322248577474743, 0.036577359601722564, 0.5861429360737436, 0.48069345102735844, 0.5839493270640127, 0.6863275630173109, 0.7810525162688133, 0.02380112329203391, 0.6742291664335797, 0.40957601875443106, 0.7182905537843448, 0.568071825146359, 0.489157691756887, 0.7320342113338413, 0.06989539348491848, 0.01396450566755195, 0.7195744606082946, 0.4801236211039853, 0.7672496410220964, 0.7388355346898077, 0.8634921330877683, 0.4260476272878113, 0.40715434340291173, 0.7045294201771758, 0.6442011297306899, 0.7245743984931461, -0.12694978414441713, 0.64765053377885, 0.7705129507549664, 0.7337739681529123, 0.607314533648269, 0.13538922472311585, 0.20007278199373857, 0.6888954166514826, 0.6532853126774459, 0.7699086964568967, 0.8418816550536409, 0.748194411343279, 0.6608575445414442, 0.7077364532129867, 0.23596164974463604, 0.4438925556823994, 0.6738599815257809, 0.769013128528943, 0.6643640451955779, 0.4575839345183356, 0.6289170610948667, 0.6185434135218674, 0.8327954733355541, -0.06497776108813619, 0.9190164825997631, 0.7578961046270175, 0.13745602977270346, 0.7360114515626307, 0.45557166271813115, 0.9984415043444586, 0.36819633854640205, 0.03327596531362988, 0.39697668668791464, 0.6662973648974053, 0.8365932351832176, 0.8508280316395543, 0.5246261247875297, 0.8519000091743306, 0.6847770488588064, 0.7034862791406702, 0.48859604725182537, 0.5337861589172028, 0.4784818478946439, 0.8105395415050363, 0.4497044404266254, -0.03516650194600932, 0.47981556458746155, 0.8572679873000331, 0.469007844105762, 0.7541303392619404, 0.6298616113394296, 0.41762482161384523, 0.5668818329179537, 0.22929255627923223, 0.6945953042284776, 0.8836978579669725, 0.7580447958844527, 0.3353254621172288, 0.2575091961946301, 0.6570131091952429, 0.8030449452179924, 0.7386794627454394, 0.8450209956483231, 0.06710142845270714, 0.5622155614794451, 0.8270560905840649, 0.6942200795671508, 0.4613043388519782, 0.7423396176683537, 0.5566877035557758, 0.4236892546900743, 0.6313752251895466, 0.11725941969012904, 0.8291546640014303, 0.7948694742214819, 0.8320128076233592, 0.41776035642646303, 0.5054234222336532, 0.4482673109512285, 0.38254666445000163, 0.4349768597679898, 0.7357393590394611, 0.6601739100338677, 0.8203413487528411, 0.5147277945386599, 0.752080363806399, 0.8459077082588246, 0.7491901658824445, 0.7816002427784301, 0.5407639353667767, 0.27972954738435035, 0.6594221109968051, 0.5366484746067182, 0.2470979240140391, -0.20456789105393738, -0.0332420807016684, 0.5359789403149688, 0.5581728039964176, 0.848740127403591, 0.8049152374766385, 0.504554184889132, 0.460979683142307, 0.6455224312861555, 0.7312561093789584, 0.5909852560589367, 0.8935491826032346, -0.06545465677056853, 0.44788836119947195, 0.706252913456998, 0.8461630155975084, 0.722344857275135, 0.7960490929159316, 0.528322330162551, 0.8536453156462528, 0.8000407625931566, 0.7529786225615516, -0.20305836037266195, 0.6607796704105007, 0.6508811532149574, 0.8299132855887077, 0.6840430431774497, 0.8006581009206291, 0.8010113025230234, 0.8320330015053212, 0.47233047818196744, 0.6275759192443829, 0.7419072607303138, 0.6551889071107311, 0.7991501326869895, 0.4306545923817057, 0.29059534172213686, 0.7343248301501367, 0.6045612257041661, 0.7263343437582029, 0.5182111562801467, 0.6998138248202421, 0.8214045070693903, 0.36262331949102, 0.3683287949009002, 0.817345036244163, 0.8729010112924981, 0.841999305223882, 0.7060847155818956, 0.6669661254581122, 0.5166655429100702, 0.4571500658953294, 0.7643776122227088, 0.13859258639101504, 0.7802874744142434, 0.11068164713076492, 0.6755349699919243, 0.5808046377430057, 0.33498245687424205, 0.8985893438018139, 0.47703386191769215, 0.6004527340628321, 0.7478624361171569, 0.8955211255065255, 0.567518909000281, -0.1565081376853379, 0.6719618965498084, 0.4124760933751392, 0.7594823453590481, -0.02280863105990577, 0.817614167342985, 0.4145689046898221, 0.483002038023918, 0.7219684632981822, 0.687143960118371, 0.7388272934945083, 0.8019380131779932, -0.19116800651298782, 0.7513984193704613, 0.6682132566801625, 0.696137522967792, 0.5179997728385382, 0.08137730698913814, 0.686213683589416, 0.04853208552832338, 0.8185738109403574, 0.7992598831233187, 0.83973732401517, -0.16782151454100566, 0.7616782474681592, 0.6830708971551172, 0.6210230509664373, 0.7190627336690019, -0.05384534170683988, 0.7405381751547067, -0.39756829147225803, 0.09641348416303497, 0.8399179176159473, 0.7635959956342031, 0.6987360369572109, 0.8400111371456884, 0.8265715694119026, 0.729112452660891, 0.8776297516399661, 0.07625117360827989, 0.19932928475834208, 0.5669896837941022, 0.8167525097611444, -0.04234584640264078, 0.48343840677084365, 0.5047242297907838, 0.8103350301570253, 0.528575324463445, 0.6812441410553429, 0.6285379053988289, 0.3888171000869891, -0.02420391803481109, 0.8057614011036436, 0.6803885874159972, 0.767648794585883, -0.1544590113433112, 0.7722895606651679, 0.4730812954766444, 0.7188930330737697, 0.8449813330665961, 0.7215715637609512, 0.64989459167526, 0.6682527519366718, 0.8269870823812582, 0.7512133524261347, 0.08601580391875215, 0.6027714383418378, 0.5193125860332861, 0.7590375890673612, 0.10485929075357779, 0.7908426853347004, 0.41915062825231025, 0.4083332454587216, -0.04457592342976483, 0.7825595262976515, 0.7053604971509766, 0.8205028446731054, 0.5839493264497048, 0.7758441576512597, 0.44174371101971066, 0.745867788069636, 0.7402997592878456, 0.30386909966668163, 0.5488293634420569, 0.7778841991384994, 0.7932569686297841, -0.04258434997964983, 0.4892999916007879, 0.6218827584230855, 0.8832162072025709, 0.8477507006181917, 0.8782399937240767, 0.2267146861565144, 0.8038043215313578, 0.08216322615610563, 0.47355535626784423, 0.7627587401990342, -0.01420686640825134, 0.011240085741226568, 0.6154292173758008, 0.5892843957828874, 0.754025917004856, 0.7409884544233869, -0.04210607520948701, 0.6480424389575276, 0.7604899042620962, 0.5376105766122597, 0.6567499195593642, 0.7890082499610724, 0.16516943559382483, 0.44324260563201867, 0.6986066961953105, 0.04730742201984286, 0.7494221805985216, 0.4497606627533988, 0.8063657345843616, 0.7761481037546021, 0.635645319920176, 0.6749456113012153, 0.8144968634474804, 0.36317136969508784, 0.5161057450042479, 0.16177319735906381, 0.6761333514152056, 0.7324307847973716, 0.8632446121318829, 0.44719418623944673, 0.8242339555692001, 0.8615944000652416, 0.6885822961567424, 0.6862128242675828, 0.8341392219350481, 0.6219561647526383, 0.868679181142494, 0.631483634480391, 0.7355165182114931, 0.7530045046555855, 0.49593714807088635, 0.5748429147697804, 0.4482764394899349, 0.6875231064084696, 0.6618990353815871, 0.6011044157050074, 0.1745243698260542, 0.766905663620262, 0.8380074887710718, -0.09545248989728618, 0.5429131784948485, 0.5889688635193671, 0.7613890630872431, -0.1823896968795878, 0.5318025211510541, 0.8222999029508465, 0.672794427233839, 0.6556889887034053, 0.45455437386689057, 0.5416931296721371, 0.11757805564751414, 0.5238350813819774, 0.03775781929780102, 0.1809129034200556, 0.3424033385581469, 0.4722731517770526, 0.8234844322058663, 0.39297995480938863, 0.7549038934327942, 0.460973314568626, 0.6606277269704083, 0.5287507884402449, 0.8617902568663628, 0.7157673791461645, 0.47051434635878986, 0.6234772182976412, 0.8107972903598984, 0.5056879004655234, 0.8631232266267346, 0.7053129055702766, 0.23200873098018876, 0.8654092580158356, 0.5429131860013364, -0.1823960124875421, 0.8943843944911896, -0.1443998779090172, -0.07674826231984148, 0.7520937528769182, -0.016292243204012017, 0.8384780924921735, 0.8621243698920672, 0.44558064788000046, 0.6188815195131772, 0.8350227607040758, 0.6382275924047736, -0.025434069355874788, 0.7971941472705264, -0.1104440954220359, 0.8212948076068075, 0.8583146468036252, -0.13042771267993603, 0.8332432233391405, 0.7729200656590007, 0.7581078915834392, 0.6655778191779814, 0.6992346959083529, -0.3839396506972115, 0.7419559586485414, 0.6946418780315935, 0.9304687527936151, 0.5676125845741021, 0.5988239446885162, 0.859292684773034, 0.8037985645882463, 0.3663710782713099, 0.6641721400433896, 0.8096832689388969, 0.6413816693740412, 0.7185647204476054, 0.4084823262312354, 0.7413044064874463, 0.7056040598861183, 0.5982279901981306, 0.8560798637212138, 0.7991595159828139, 0.8388155031083633, 0.6878241351618314, 0.7306792332531978, 0.7411975295665657, 0.6756852463352256, 0.902470772014111, 0.5561238425525616, 0.5066789313674043, -0.04373731361933848, 0.7257343470193974, 0.9564606921823251, 0.7547769048477493, 0.8419705970262723, 0.5459112682528048, 0.7847041041661534, 0.9188935233442596, 0.839997554810142, 0.7829811674952304, 0.5719171861503998, 0.6446867477709772, 0.6589538079876109, 0.7471558149404763, 0.5519965701555645, -0.12538507254727693, 0.7620026669585522, 0.6082865395599028, 0.8180012404157717, 0.9997803171255916, 0.5204053612358354, 0.7737048643384806, 0.23499092611937425, 0.4219943208377271, 0.7575876759179525, 0.9767200192083201, 0.5355397561500873, 0.3822786385011162, 0.7032992434003176, 0.3886487860736126, 0.9725242503957793, 0.7421395786452372, 0.5034950808930588, 0.6122132007859526, 0.2575243364507584, 0.8359045452384167, 0.5631095482195324, 0.7676775075804295, 0.4608052923305102, 0.029603963281941162, 0.041149249170686644, 0.5474160113227223, 0.8354885259226811, 0.896309057302631, 0.9016688540093196, 0.8242582655256545, 0.4603491286284507, 0.739378010140555, 0.6259115438610074, 0.761223719247516, -0.012302704231378022, 0.8296253982772142, 0.8364011228316244, 0.7173656973630907, 0.8254750286033655, 0.08364544378999964, 0.7327422287390014, 0.026107583765606842, 0.06177413649127874, 0.8686537435694136, 0.7767687727610567, 0.7771443583574325, 0.37703803232611893, 0.680717478345255, -0.3194464375165182, 0.8491826630389371, 0.7345116187631099, 0.6905080438353483, 0.818326436973756, 0.47219362152471545, 0.8365932186753756, 0.8506944810811887, 0.869691757265414, 0.497845914788844, 0.26641530758773835, 0.5941964018809653, 0.7777836202150028, 0.687119249238098, -0.041325707555281053, 0.6549938252529377, 0.7402013906003356, 0.4796367296429915, 0.4794052192864357, 0.7721468040515471, 0.8511078088158098, 0.6830525006596144, 0.5601872469931729, 0.7973059198489887, 0.7883153138561028, 0.7847699809003198, 0.9944040588277899, 0.5480763573430216, 0.6091281507913879, 0.6988075937292654, 0.8390465991713824, 0.5372218491929879, 0.7453244316241102, 0.865385298552826, 0.8018516181415495, 0.6832376693491421, 0.7801115187744083, 0.68341407949436, 0.7539706479933306, 0.8927801532850238, 0.33997282044071414, 0.32905579368085164, 0.7077906709221117, 0.8318052308933718, 0.23681606646374917, -0.010006444035167832, 0.310877461195235, 0.7889505397520031, 0.7053105813038826, 0.8201311702682026, 0.6833036712303308, 0.7127553766180414, 0.7099736419194259, 0.3269191727889205, 0.5036938217787886, 0.4530212886105435, 0.819941977653233, 0.7781869362815786, 0.7391848716850109, 0.0024471577085725454, 0.7687424395512509, 0.7219323332063462, 0.8530700417971048, 0.8089118052340211, 0.7392087332925179, -0.006864368980766016, 0.7490361886927276, 0.8008767518988418, 0.7603951173364986, 0.7571148429890265, 0.7884754016682975, 0.4727627649610759, 0.659816022309627, -0.015853415384330823, 0.5616057777481164, 0.8421155128990105, -0.17820637836546535, -0.073309932257564, 0.4446095732424144, 0.5440138195196846, 0.7300646664836821, 0.8620150024074474, 0.7171902009398758, 0.6657071976267956, 0.714143312639541, 0.822727526945682, 0.6969235506221011, 0.48187325577918577, 0.667608631439162, 0.7569362838868616, 0.8751904721836337, 0.7793531820794586, 0.813726533730579, 0.7875170548030606, 0.6594821297691857, 0.7077021219781279, 0.4037970566938148, 0.5262994831002724, 0.7052651586740571, 0.7235713819223718, 0.47270832288134734, 0.5686812042939071, 0.6935170092383217, 0.5104324699989751, 0.6386551811982188, 0.8143247542566849, 0.5872871654657952, 0.46092121397915675, 0.48200093481808676, 0.6629012642957942, 0.6744164393103004, 0.6412134535864921, 0.7215353500839438, 0.6913967203405541, 0.615853449005054, 0.6615153427164048, 0.8208450734154876, 0.7371100677946801, 0.7258665413338492, 0.372487374086278, 0.46974277524460994, 0.7904675080422011, -0.08870345683443473, 0.6647378057757424, 0.2004700767215085, 0.8392178517751758, 0.7091224986769298, 0.5231593033870218, 0.8742749700094354, 0.020783146171763568, 0.7626554099135995, 0.22727916687291044, -0.20651323352940854, 0.8857674741322832, 0.50670621176674, 0.6320464378279816, 0.4189656133950318, 0.20772249574308657, 0.4576874018715997, 0.6628643692368977, 0.6766414072793105, 0.4192892821988234, 0.6056663316369172, 0.7383715762458009, 0.7603492257680199, 0.44012752838692354, 0.844954069873827, 0.3421360919982186, 0.8205319806849206, 0.7254919093290798, 0.4877240919100446, 0.830848185035305, 0.654361028846536, 0.6373375511233549, -0.01661941465537374, 0.645444798871941, 0.48159723312821195, -0.12214535420784943, 0.6233005052462893, 0.512116739668663, 0.770110411262191, 0.7341720085011354, 0.8181553665277493, 0.6657623722065154, 0.2961086656353321, 0.6273568235070862, -0.20359803349419534, 0.6911725822916134, 0.7316796264530648, 0.7578990654781006, 0.3735282903374769, 0.7935858207435521, 0.3331324395987084, 0.0680192314212548, 0.8229684721129125, 0.34801348208763727, -0.21960922349712403, 0.6838051248959875, 0.880996664702269, 0.46146249054688115, 0.7545363178232647, 0.020063798917958096, 0.698504125590993, 0.7041483205412177, 0.9127822661586087, -0.3564933132517978, 0.8328748395347176, 0.8781169231768766, 0.27208233563457235, 0.8433895164331608, 0.6037073327440353, 0.254274365767632, 0.6733542334362858, -0.048431194143885616, -0.21668653225506382, 0.4648410109206028, -0.06395564363110653, 0.5645967481409686, 0.5214540621697934, 0.758749556546978, 0.8619133862796232, 0.6841701668917263, 0.7500717926705873, 0.33598665170228087, 0.8540518052474233, 0.30752737914254297, 0.7468058529591797, -0.0456099796412391, 0.7469361263687697, 0.5741208073453343, 0.8096209519030917, 0.6948459060605222, 0.7974028574706669, 0.8245050829154561, 0.689037476897568, 0.7713103934691882, 0.7873246212708507, 0.7389694707511896, 0.736843911625898, 0.2776169983631147, 0.8266046667803223, 0.611617493527428, -0.06546485822295758, 0.45033689823945133, 0.8472169022174678, 0.23914957097810852, 0.7638826348734208, 0.6773072244205666, 0.8839364477504008, 0.6391830899168731, 0.7438046613826025, 0.6532805219215846, 0.8311986316968072, 0.9023663526897567, 0.7770227404687364, 0.7897710461120827, 0.011135016295698633, 0.6985678814872259, 0.6911089286201327, 0.3966110291015693, 0.5736234824975505, 0.6314544519863248, 0.031407320212108236, 0.7825545327715965, 0.7097865789871478, 0.8602516161794226, 0.6625654644083072, 0.82786229063083, 0.6344806868726521, 0.43533953915901835, 0.8409895403510458, 0.494257266748445, 0.8702376180725073, 0.7521209291008598, 0.4628021048826845, 0.06328656389866467, 0.022371859348807782, 0.054246008637539984, 0.9891173042962886, 0.7731213209723032, 0.4159136219307289, 0.7960750766132292, -0.2237001234213673, 0.8788750033336699, 0.4831694109502885, 0.4825380260083733, 0.21183090187908363, 0.20984474829208144, 0.10445889276523605, 0.3319637550130162, 0.3671749134023301, 0.7436718884023479, 0.5132272596915164, 0.8229211413881473, 0.7879435077470126, 0.8140946472351199, 0.5616624527030177, 0.7789169002372383, 0.658002817340549, 0.66642934984515, 0.7366791091594983, 0.7497559522955238, 0.7585262927405011, 0.5103964816782453, 0.6216940875373068, 0.863996418490059, 0.3466169379241822, 0.4887488141366937, 0.4465016561536991, 0.6860497473828586, 0.6455311628649819, 0.8589335611571219, 0.5425848299113448, 0.7428793237490541, 0.6490810304136899, 0.7406080680763684, 0.7707006902904991, 0.1342680530916536, 0.03576802054467589, 0.852421475294833, 0.44394647382148417, 0.7632119103444431, 0.5838569341998293, 0.7650542038652245, 0.7426020430120837, 0.2853056407522313, 0.6580963564199527, 0.34012349199782993, 0.453897432775975, 0.7812701236271565, 0.46645913968419356, 0.16509099913230454, 0.48526603566399124, 0.8394402167532733, 0.5333905420439162, 0.46513710152082594, 0.10260680711074431, 0.4889947667494992, 0.7251983496918857, 0.8521161527984961, 0.7399651737651418, 0.6476483185365014, 0.6523715194027123, 0.6846506793681307, -0.06821502834584948, 0.3940444443238317, 0.7942185050080429, 0.4836222026525643, 0.6348844130232223, -0.24344766932019019, 0.4201216918988919, 0.7709277861003744, 0.7522282749332273, -0.007671472395749735, 0.8366540453656247, -0.059991668264270326, 0.829686821845495, 0.7396319974327323, 0.7554671907392877, 0.6540445504946096, 0.547494266573972, 0.8276615690040072, 0.7339759228373679, 0.6300005273935305, 0.49421163763598946, 0.8320128166501997, 0.7978636676533217, 0.4358240707920337, 0.6513579967876059, 0.6964514789974727, 0.7949882876396214, 0.7889494813262643, 0.7410926563042721, -0.2281181237449803, 0.8046426008853325, 0.7457978567442888, 0.7349999412154211, 0.3718108689178041, 0.6741472530918974, 0.42367533502410326, 0.3379641640615968, 0.8816022879745024, 0.21365873722697462, 0.4186188022440145, 0.49117024802038484, 0.8478379926990712, 0.7896452350127035, 0.8640778596088488, 0.6785045684776039, 0.8621705941934016, 0.8646903508884815, 0.8824283447768961, 0.6318989603547749, 0.7471252879052301, 0.5337927613222714, 0.8115064973805787, -0.014048607810408582, 0.589467383780671, 0.5604333245319526, 0.853783878896767, 0.45446009896937395, 0.7644406948557673, 0.7326241298409129, 0.7721299034597875, 0.8440800443125035, 0.8521850738291221, 0.7608058060650387, 0.6802537637046907, 0.789502881469047, 0.7489211704612148, 0.6433608403320535, 0.7469098663921101, -0.21731699300784726, 0.44117344615838927, 0.7577363977137577, 0.8285921915992469, 0.6282812698622722, 0.8169363014363995, 0.9210721184098265, 0.7549463252793945, 0.837165652205129, 0.8668847848185611, 0.5340512450486041, 0.683845379172357, 0.7121239048954386, 0.34675571348047807, 0.519286869579317, 0.5368918106058203, 0.03290148771147271, 0.7154613312939553, -0.4653152102997009, -0.028394234581102525, 0.5201123803541663, 0.7395230417783827, 0.7699183932783833, 0.6660494075743468, 0.6199972794750769, 0.8108274406287423, 0.29662664068297284, 0.5019395748119743, 0.5762912751367154, -0.29413008243937455, 0.22258952875029717, 0.7894000527238921, -0.02542438650124978, -0.04258187545474374, 0.6965273591075533, 0.7765742507034434, 0.5852080130920196, 0.6777755126390897, 0.46237465705004105, 0.48115466382494454, 0.33811237791281906, 0.0337259913287685, 0.09301534541363064, -0.03009839066728301, 0.7916038149506841, 0.6481001125598971, 0.8666707133778941, 0.7480496444742335, 0.8020684055441838, 0.7389204522371745, 0.6818643753648227, 0.778104542086597, 0.030260847766504475, -0.15403354974738362, -0.24824980237627006, 0.6650715581382648, 0.6748536138406662, 0.5717299277714898, 0.43731508991208756, 0.41155160927156115, 0.521929111727668, 0.7482488987806529, 0.796191562759486, 0.8097641159950143, 0.4309838590977391, 0.718765391854153, 0.6928219306556381, 0.6870707942616606, 0.35631186132127607, -0.06900785802162951, 0.7773786953097778, 0.9892738640899482, 0.6216997912947407, -0.07853789752087763, 0.5672248276217198, 0.7911531903070189, 0.11270905466241302, 0.5403054321925448, 0.7864740229777277, -0.32755138520038113, 0.5411054625313612, 0.04864010033827963, 0.8937475507438633, 0.0820723284455894, 0.7992243468272864, 0.7597832710162324, 0.5951891709228441, 0.4029137011095308, 0.6214884048284959, 0.8152284507185611, 0.6190250129540291, 0.7755491244862641, 0.6131675220032509, 0.4533799407622717, 0.05761490776579214, 0.3513386005450474, 0.7055000991039422, 0.8775894095867611, -0.18702753776618822, 0.674595168788561, 0.7109645776953453, 0.7709694225096497, 0.8845606868101409, 0.6742174575492584, 0.8066158449390542, -0.03055974081985864, 0.8396690320329966, 0.7270619479675775, 0.5464992376637916, 0.3285094679994878, -0.2646505091546947, 0.41620071040859385, 0.6578549225744369, 0.5299765658196494, 0.3449659039989081, 0.6293959363754614, 0.8447520056832194, 0.7313521537064772, 0.743093617135451, 0.6569214687447136, 0.857837177404633, 0.7693745139037834, 0.8507654087414612, 0.5879233599814336, -0.019178938509084618, 0.03576088949269531, 0.511297957475452, -0.006721913642746322, 0.6752518490001786, 0.5123719919664349, -0.23630264128014197, 0.839262301766808, 0.31102155490605865, 0.6623577069721898, 0.8187637855490614, 0.7665181080975492, 0.6861596842350961, 0.5648376783624496, -0.01489131284161667, 0.6290093649688105, 0.7475654774106736, 0.39710931632874374, -0.194904258058513, 0.3058416714263526, -0.229942620219246, 0.716103901305591, 0.8234394263599413, 0.9611883331604959, 0.4814831164235766, 0.7026356845297708, 0.4468983839164871, 0.46311539559678727, 0.7419499437925708, -0.006952035965792084, 0.8834429064489985, 0.5115630447654387, 0.6500579979034364, -0.06166535284886695, -0.049077940942946076, 0.6774613902081486, 0.41912391043381697, 0.491816783182677, 0.4816440973311053, 0.7316582226234016, 0.47848616353749407, 0.4463443384789752, 0.30444747416804757, 0.8505149952870005, 0.4831376720279878, 0.6742334800154963, 0.8477399359592606, 0.7127683724458452, 0.6441194464283675, 0.8451381961940934, 0.7365900958671711, -0.041874682106271446, 0.7899551532679165, 0.8214387708717933, 0.4241338956830637, 0.818573186120374, 0.6053934140649343, 0.6607796792981493, 0.8452507287826445, 0.706533663266088, 0.12312904849762635, 0.07029089250010734, 0.44673461447240626, 0.05240633691806753, 0.6684831634328002, 0.56313356246634, 0.15013511788233666, 0.5409339101301968, 0.7358200242117655, 0.07416737691660054, 0.7604067363820899, 0.8345592230049363, 0.37729820043990664, 0.5922248757146464, 0.8354278892271516, 0.6158675424017214, 0.8755822416342093, 0.019969511169182844, 0.4658815818175923, 0.6977766298283303, 0.7302637564554136, 0.774379157475294, 0.583473648500558, 0.8056693406234173, 0.8304598959533063, 0.6707179666156023, 0.4745894566353935, 0.9243565896313816, 0.8532419294768472, 0.7018089308351421, 0.8215431556468982, 0.49261068889225884, 0.17594048234476256, 0.7225432814959674, 0.7826377833165732, 0.8251659419252921, 0.10204068898990233, 0.5173104513046092, 0.7608393225008867, 0.7891116779169702, 0.7662256818471467, 0.8026230217348952, 0.7028147894878859, 0.5973145705615847, 0.8023611895733833, 0.7253041606957669, 0.6766521239913995, 0.7971718205510937, 0.6840589996842207, 0.8457764713837033, 0.24334206874757225, 0.7886046708376807, 0.23596165612828296, 0.7991676839643482, 0.796669257952661, 0.6324435237925975, 0.8023048390665044, -0.022819735130529536, 0.6113499862557549, 0.7596609495298494, 0.036577370302355146, 0.7726423692839784, -0.20396933550378188, 0.7421606228477892, 0.4382975925528768, -0.10534918341669983, 0.45344571420896485, 0.50336106747984, 0.9146829746752866, 0.6904642879957289, 0.6247834139945526, -0.014570293702454891, 0.8801274852695214, 0.7800788879713464, 0.7344442573563011, 0.8127676960038944, 0.5450712703764287, 0.5522225316714632, 0.777218361547378, 0.6374903635475784, 0.8001313015975045, 0.6922296244539202, 0.8836371236020867, 0.7289639568293707, 0.7973510894259886, 0.7370937382033029, 0.4502416048899396, 0.6173653279104763, 0.781796143777606, 0.651079069905548, 0.695239905080542, 0.40515170727421707, 0.6756562736027547, 0.5628942750885045, 0.7373492922696816, 0.8581575232654506, 0.5635248615757023, 0.7753436131035519, -0.15872632513582063, 0.6847340824248833, 0.548259783739691, 0.8350323713695809, 0.8674981893723597, 0.6793030478147848, 0.30566029013025187, 0.9400346856044217, 0.7840378942186106, 0.8850026775362406, 0.5699752682047352, -0.18637812947832175, 0.40374865406063337, 0.07531780865056205, 0.8745007396217586, 0.4887244824160571, 0.7808497912166802, 0.6019013875849102, 0.13493990104594863, 0.6688836723569859, 0.713388577052175, 0.823002265631077, 0.6586947192876214, -0.07000017760226268, 0.8006698635164989, 0.4608884835961536, 0.5288543149031874, 0.8205285650491212, 0.4077560689308417, 0.8721366048761107, 0.741464802206705, 0.9239683499369561, 0.8004166165701677, 0.6688820969225993, 0.7807400888272218, 0.8598906666475695, 0.6292373023064756, 0.48071826319327465, 0.7969794675378175, 0.8310315139753338, 0.7132964215098221, -0.18662162205247773, 0.6687991251108887, 0.5243386984997587, 0.745212717811533, 0.4304268981470092, 0.09715857401935413, -0.19625716408465704, 0.9037816730101963, 0.5163601442201929, 0.939665251081391, 0.3363625420827127, -0.07070743650384032, 0.7720029730109013, 0.6671824042793889, -0.11398862427312086, 0.38006095185689776, 0.10963978498861429, 0.7194767519629909, 0.5114423559610314, 0.5576808249121729, 0.8860681537696996, 0.4280233628812582, 0.7497053222953677, 0.6588059072336695, 0.5745825804039035, 0.7750692159950242, 0.8481802128974538, 0.8088365927513357, 0.8085882486216239, 0.8013763571377669, 0.6848005524515118, 0.9829330894183103, -0.10066667370837158, 0.8296419102379587, 0.7329504785544446, -0.21277302371937484, 0.7167995959782132, 0.22180890063852343, 0.2163583450083411, 0.7488632095681352, 0.7565883722596497, 0.7737242421909568, 0.855990669984255, 0.5353727962216459, 0.7397163494516249, 0.7750034005652855, 0.7241529699967454, 0.8462611356338859, 0.7292289275546144, 0.6853243911064361, 0.5154442785022701, 0.5801096280640745, 0.5119371773021875, 0.6625792560914209, -0.0740823972398392, 0.7701676473155669, 0.5028134734850308, 0.5980925396321024, -0.012762453862420874, 0.10084127314211724, 0.6258875212285795, 0.5238286618565449, 0.3733566932627317, 0.8086071362744529, 0.3610333873793961, 0.6037818411254939, 0.442028323020905, 0.6972310654742373, 0.9391661793173642, 0.8258803512823486, 0.7835633291742995, 0.7237795765530706, 0.6128853086493911, 0.4190924198019243, 0.7447373096234269, 0.7439261248034973, 0.7980664754210585, 0.3602211637780741, 0.7313997434806762, -0.11023884116766192, 0.7085294263659604, 0.6216940659062581, 0.7390662905755688, 0.5754510448895822, 0.8234494241966378, 0.7788298592245946, 0.7828272425744117, 0.5841005823966482, 0.4552805802225598, -0.03318577196855316, 0.5209835120834982, 0.6408081137204656, 0.796567921483692, 0.878569686778486, 0.8501965051450876, 0.5228636842308825, 0.5288502431920586, 0.7029805369958187, 0.7075096359443391, 0.6688354088619296, 0.4993934974785404, 0.35673431056190025, 0.6508457890777645, 0.7185014792486998, 0.6213142372729253, 0.45059142673870894, 0.538336923394997, 0.5423467706843997, 0.6371607744170374, -0.05692710803551421, 0.75416925921765, 0.30621910371726746, 0.8689652275408752, 0.6764154288699693, 0.7099056088487747, 0.3790417584379008, -0.2442819949316982, 0.7264433953038714, 0.2787304691396421, 0.7758840085098367, 0.6899178681956616, 0.4695579601867185, 0.5093742300925668, 0.9179744727275322, 0.7577715161333598, 0.7898230076964878, 0.9520682768171098, 0.8166779919839886, -0.019339666142735697, 0.5155627663127458, 0.8140107047155455, 0.6836937301548427, 0.5422469492675712, 0.06025830734216421, 0.7761820541130539, 0.8035746555067819, 0.7515420109695476, 0.7240466150827837, 0.5841360825339839, 0.5508953270329957, 0.6687757183986752, 0.5052941977445294, 0.7845656305477376, -0.0001849681019009342, 0.7701687623689649, 0.8419056174750829, 0.6807572394554617, 0.8841880628439888, 0.8225123812637493, 0.7536906261396693, 0.8223853360088794, 0.4443968682732321, 0.7206790438537828, 0.4880734384457369, -0.07284001862235098, 0.4113291880982067, 0.587746680701331, 0.44606894904803024, 0.5167346440875009, 0.505521463181702, 0.5049541108291818, 0.7911036185623957, 0.7467358071561838, 0.28041719983662644, -0.06953416998255972, 0.7971836862279774, 0.7087246098624612, 0.7538975765098352, 0.5007618998195387, 0.6509836764398205, 0.4651769660103234, 0.7515037099829412, 0.8801935455076532, 0.5129381032637966, 0.5005712771706278, 0.804630099376766, 0.3133021086082304, 0.8663940287724143, 0.8025917646588825, 0.4688834333328843, 0.034015535566566876, 0.7511743123139619, 0.7384885221658056, 0.8069107639626373, 0.7006664972567017, 0.7674295599076802, 0.726578682215724, 0.653002460925111, 0.6095682145992211, 0.7781238196580574, 0.778546634343494, -0.30326335131138454, 0.7744431532826512, 0.7430067482358386, 0.7230693932476718, -0.045356655495166216, 0.5013208425588264, 0.47618123619743097, 0.3776686907369064, 0.6469904245426803, 0.7503481226074185, 0.8282903265975428, 0.7627986553554216, 0.5791515786434749, -0.025482051653038216, 0.8009334089636563, 0.6701656732234853, 0.6098794526237428, 0.6667777621311679, 0.68463640052523, 0.7009072536972469, 0.8606138842107327, 0.8242748427898228, 0.3306613001660572, 0.4718547704233114, 0.7411997913355673, 0.4971997403138182, 0.7630852715202173, 0.7522728562169313, 0.46389276342328895, 0.6988177631329885, -0.03779963237579238, 0.6500580046783385, 0.8273156612819166, 0.7036443815355393, 0.5180705967759284, 0.01994809992010663, 0.7792248582582572, 0.10336516328145005, 0.012589735011843874, 0.17230538206723175, 0.7504926450530279, -0.0847482553963974, 0.42423364337502845, 0.32730250120968735, 0.7029021102984214, 0.8351684859282525, 0.4410106044594843, 0.07911325962371811, 0.5901042862315706, 0.5498796899078858, 0.6398541175126781, 0.5027778067691719, 0.7263448581240427, 0.7769600680036556, 0.779215942578437, 0.7819261439072461, 0.630617269490031, 0.4248190035806696, 0.6866585696907352, 0.28293176844337203, 0.6675017717444394, 0.8020718169794628, 0.5253163519407424, 0.7954985208748518, 0.7329187337384829, 0.2837450378903966, 0.8624089435226878, 0.3590197159150302, 0.7141297231469669, 0.7497179773147444, 0.8225123859168585, -0.27650477310866195, 0.7214342630529469, 0.8191584154461748, 0.7470757632632161, -0.1666046716418604, 0.4772898231456916, 0.20815792416116208, 0.7579223461597746, 0.6068631005872883, 0.7540917213095799, 0.8078888180450842, 0.7766745274061364, 0.6061150724868419, 0.7125740116745585, 0.8422419058391569, 0.7733432909319893, 0.7546552884938247, 0.7575423588187586, 0.7643982325375162, 0.8106250980554923, 0.808790611256041, 0.7740277908486255, 0.8625143760405175, 0.732989798730859, 0.8213891012580465, 0.7986893703133112, 1.0, 0.7598796690224819, 0.0685277707928799, 0.4965964721627326, 0.9272363884300139, 0.6821585095220206, 0.4701231203650268, 0.9882141189404173, 0.8437630186293649, -0.031858344413644324, 0.5279636125798454, 0.8793832600244087, 0.7114562380548354, 0.6797408736037469, 0.6411430453661947, 0.6200504098551542, 0.18304010178817312, -0.004658079039521636, -0.3273052053506124, 0.7424870294600991, 0.7701104270347844, 0.6593424717182493, 0.541046500259295, 0.8211594885240406, 0.4778512685555356, 0.5226028128281079, 0.7175132167741202, 0.7510825337392454, 0.5865325641907913, 0.6295369870508692, 0.4714565190513766, 0.7367766814824708, 0.744944671532115, 0.8445295873871501, 0.003330069139493961, 0.48021000107743517, 0.3904788253551022, 0.8739397147797167, -0.14501355463815963, 0.19473946371934583, 0.8237919099257827, 0.5629249721821782, 0.7649278599896306, 0.7119266934633824, -0.22284578042169406, 0.4048087453664932, 0.6901354820418651, 0.7889690200162386, 0.7310403872557513, 0.5209612585623642, 0.5396074118964321, -0.2013944918408106, 0.5586074640133383, -0.02034230087299671, 0.5862937066863292, 0.5890319448625363, 0.35414099630935403, 0.2119081853588928, 0.718273984841832, 0.5469227900219911, -0.05266423491891051, 0.6773984057938056, 0.6834926753710798, -0.37374504181985807, 0.04758732502569648, 0.7158319809354692, 0.43767022945050743, 0.4671120196331418, 0.7679724954617941, 0.5185403585340354, 0.6554667412175776, 0.8004619650208055, 0.3049246417587971, -0.0791159792332946, 0.540108065143746, 0.849055843676016, 0.49100947908022236, -0.2639800690604092, 0.7859120507714432, 0.6794146417599403, 0.49937302190307736, 0.6541024628654594, 0.8433862885529244, 0.4879574177511824, 0.8127288112042222, 0.7206561146447262, 0.6456376817364737, 0.5506609898283716, 0.7548274289373529, 0.6924841617120387, 0.7458766812924095, -0.034459697637453865, 0.7402042819559118, 0.745638262460402, 0.8559737994813928, 0.549656627009075, 0.7402105778425118, 0.8545154345717506, 0.801933507344913, 0.7761145447546401, 0.7529618026948675, 0.4997184597525582, 0.8728310629108609, 0.9012441805130251, 0.7641505440102855, 0.3747240893613413, 0.5104140814141956, 0.7615885310521988, 0.6609850469721936, -0.08461736238905045, 0.7931672013878789, 0.761299804770602, 0.057794264877400345, 0.4891523709200753, 0.7953442850204974, 0.5424149255246309, -0.17651018260010187, 0.7044783593228673, 0.11548840927982952, -0.014334587993011487, 0.7736055254981526, 0.3684281693105272, 0.044631891656982475, 0.5368660243551431, 0.5960440250080227, 0.7713104058580506, 0.4815577153530613, 0.30173209699004233, 0.42629278745667115, 0.5553589778010471, 0.3992743449900622, 0.6978414509515521, 0.7403213694195601, 0.33060911061978765, 0.7296091151460127, -0.04112454687777056, 0.8678607427617276, 0.7218561209839257, 0.37044318658334147, 0.658997713713732, 0.6237149175939366, 0.4779217939404957, 0.7585015604518278, 0.8704188897958899, 0.8063464085423327, 0.7716733257736506, 0.7478253878805354, 0.47232239368587337, 0.7962046590014294, 0.6670054966567572, 0.7117685214578373, 0.4975726517755063, 0.7295823195322564, 0.7824123965942505, 0.8271412655165497, 0.7422431628557759, 0.4635034770109838, 0.49263166029029054, 0.6001276173063929, 0.3913276275249878, 0.5558420816151907, -0.20518682721918374, 0.6649533028112389, 0.5472307358402105, 0.5915576075544627, 0.8736160111459986, 0.051616935230432356, 0.7676816443790396, 0.6815117157943958, 0.2988971011424313, 0.7733885416244304, 0.7010374803877727, 0.7906555831379317, 0.6750444800072715, 0.661306567069617, 0.8113677285482543, 0.6618345370978437, 0.8457472574398974, 0.4925274487647575, 0.8625781550786515, 0.8915011351670963, 0.16575700569188082, 0.6506979498133091, 0.2822023955319043, 0.3838519272213918, -0.2458048739635573, 0.5292830915657564, 0.7605657456195519, 0.5756441492486108, 0.790665679315778, 0.028222335557092183, 0.7535797849489528, 0.1587253380410168, 0.698273322539904, 0.7677715057223798, 0.7473614786471684, 0.7237244022920981, 0.6440331041666398, 0.7548118669906259, 0.7887080715203624, 0.6866062847774868, 0.794675540920845, 0.7648205376640026, 0.9226276466681679, 0.422901521824171, 0.44233532095429834, -0.009214070948712001, 0.47842215940241595, 0.8574563099536916, 0.6227162305766389, 0.8168829822308111, -0.011931653134308957, 0.8857323939634973, 0.7956582187034202, 0.742367677574236, 0.7846962808568035, 0.6707648657911793, 0.7882006223183347, 0.8976352734770741, -0.05029725335165252, 0.5359087529864385, 0.7979569157107319, 0.7893367331341392, 0.552681306059609, 0.727378124661527, 0.850913230955926, 0.7587758751467714, 0.019876025377523136, 0.8224072641663304, -0.0647778848843142, 0.7547739749566004, 0.384875390135824, -0.04898955719993733, 0.8439126114881443, 0.7417047597043102, -0.07608895842858059, 0.3822002303741476, 0.8682926176628153, 0.7812486526979563, -0.07842665831445925, -0.040352638991261874, 0.727905912180837, 0.2131438361027887, 0.07842111340107993, 0.7268099489252827, -0.007975097458122343, 0.5194748487913232, -0.012072790923671103, 0.5314303039206578, 0.9999999999999998, 0.7138960546625223, 0.5370955779382508, 0.0003650184713605481, 0.6484438220419045, 0.43287867635772254, 0.7526954150362324, -0.07030585374096743, 0.477501759144244, -0.05653621348680222, 0.7602453252690489, 0.5406394476278836, 0.7580579903664703, 0.055353421818847934, 0.6350210894943538, 0.7745569835467351, 0.7942473032196569, 0.710964572836453, 0.3800207245520505, 0.6834886069575774, 0.7131226049063945, 0.6972342442412336, 0.6860300192629873, 0.9399605719198078, 0.4223512787278433, 0.4129385325246735, 0.7991884276056631, 0.5983118256184654, 0.661887719882011, 0.6267023524339375, 0.7617120976938931, 0.4727542477206911, -0.009486149241681192, 0.4932867640841978, 0.826139090572745, 0.8584084602771498, 0.06630187870389664, 0.6067928573249198, 0.8008358578418042, 0.6636861103773711, 0.6324297872100761, 0.7230296322737128, 0.8531323831652329, 0.7478816030803419, -0.013724055881023933, 0.5824746503589928, 0.45314500111642875, 0.5045853071630743, 0.42488335179998, 0.9793886437377968, 0.9934132300545813, 0.5324157839608061, 0.7185896145754109, -0.04560998471913659, 0.7540051868259462, 0.7645769011463028, 0.8405765172790178, 0.0747082362614989, 0.4890476235934007, 0.8638461187544785, 0.7729138759143446, 0.7120695801795178, 0.5645161873262201, 0.35838459158300995, 0.5199069094265286, -0.18426689182497222, 0.5050054763922952, 0.7800860246428146, 0.7968129726896858, 0.6688300951308701, 0.7755777576577743, 0.5697078729437078, 0.6460587464247086, 0.5400511626098218, 0.7212939786891872, -0.04280767149492059, 0.7402387867284123, 0.4583018843459379, 0.6481850247146923, 0.3016119764536415, 0.6841737766726228, 0.08129549259560707, 0.8732609890668355, 0.4693130785760515, 0.818835841649089, 0.7423342710648773, 0.7717764271803114, 0.7296064872310841, 0.46610404362185504, 0.1736126882989631, 0.6838105338214591, 0.40474067900522787, 0.17321203795707404, 0.8502369194769855, -0.023418298600002885, 0.743893623159807, 0.7690446430660534, -0.17567916411494724, 0.7551961881856392, 0.4043104214099337, -0.13581343729092551, 0.7956686682071301, 0.7270041223941827, 0.6593955442502719, 0.34434565867179956, 0.7152530490731388, 0.7768536737808365, 0.4569900844595782, 0.6862659368934168, 0.2525251018848965, 0.5197412465828134, 0.5276949136766337, -0.23196335300244542, 0.6304016569976754, 0.10235160747891556, 0.7216128775714742, 0.5581618100958474, 0.7653137334776292, 0.5842983414551038, 0.8556874513500596, 0.8504538707875042, 0.5294373574330121, 0.15419420127090533, 0.09220323945378099, 0.07153415056976513, 0.4034002659303399, 0.5804347890065854, 0.3627543477185408, -0.22370011626644634, 0.7063897280754026, -0.01441578695170087, 0.6786805708371525, 0.3228074626525722, 0.26394800129213986, 0.505281329028088, 0.6054870382426495, 0.09797142721100502, -0.2636640670871219, 0.5032882947675276, 0.27218616958465724, 0.7030213983664159, 0.8274765084907422, -0.08689542406312432, 0.2592191136444304, 0.7506060089780826, 0.041754798576347535, 0.48417240102542397, -0.08892207129544946, 0.5398809447925715, 0.19473947301463554, 0.16874828361500344, 0.7459194044578253, 0.6846564273539527, 0.8393303059575693, 0.6682922000392957, 0.4329675055780344, -0.06217879396220857, 0.757704577038585, 0.6252394928174003, 0.7866529330222242, 0.8305274774526541, 0.4603570720570362, 0.5695523691027835, -0.015442105039132825, 0.9981296059170948, 0.8753903180761428, 0.8239853299871678, 0.5192868566270108, 0.8206540953587971, 0.45227868648987934, 0.9029689564495768, 0.5910997419753682, 0.8335765519343119, 0.781066182888253, 0.7003983729502488, -0.0343185482636306, -0.05793655971078553, 0.7880032235768801, 0.7114777312949475, 0.9016142478935739, 0.5176165680463203, 0.8227221558191984, 0.8769295624118935, 0.8934557544373174, -0.0986718225595561, 0.6059828411174973, 0.7131727058856255, 0.8303828942957023, 0.9220607461656136, 0.8132541756652496, 0.6797539162348984, 0.9169160228449602, -0.31715150517081125, 0.37489472823425196, -0.22604018873372017, 0.6753364502231776, 0.7103251274853738, 0.838210923442042, 0.8440488390240276, 0.7609910139303556, 0.7243797712599773, -0.21372029105386336, 0.7332057422785141, 0.8920938757564951, 0.05513268598570171, 0.8208567502021852, 0.0033767251537634075, 0.8342153341672096, 0.11548839174819127, 0.7289175886227848, -0.10413347602756581, 0.4956259405021938, 0.47568578145399465, -0.13472123607095665, 0.7702115748680076, 0.2703975514860243, 0.6690029739662661, 0.15431586657848462, 0.3669468681519169, 0.8748643228071618, 0.8355726182939935, 0.5922062965683352, -0.03826792868768406, 0.9482008646318584, 0.05626947598486778, 0.43213938261437634, 0.5737965516269896, -0.05071382516820124, 0.07336842478683299, 0.024778342041029824, 0.7520388717136547, 0.8263779677662684, 0.6086140198144824, 0.7112626277389135, 0.7019868512322993, 0.48198008225865374, 0.6964095713749412, 0.7671733351452453, -0.22468002465023137, 0.7547665360513636, 0.03372598934788864, 0.7438863494252931, -0.31865587300897663, 0.1738591322707455, 0.5615592850289396, -0.04918177399202952, 0.4635966542410366, 0.6032809647777632, 0.7654051286796876, 0.5492194628036557, 0.38764626155064547, 0.9102735575709714, 0.7332666467661583, 0.7392940415124214, 0.6689088831929497, 0.9017924720924005, 0.7915555519745364, 0.7514645391448583, 0.6848241498703791, 0.003309603211521505, 0.8746546845503108, 0.6415729661055849, 0.6683447212428101, 0.7769897824970227, 0.7140575641250451, -0.2901931239963769, 0.7846176619298368, -0.015862686415555466, 0.7954632070148517, 0.6020887820392808, 0.5429660279381003, 0.8960417328078741, 0.6458789083099533, 0.9278946122621664, 0.7798529774957251, 0.6429719495080432, 0.9253980056272696, 0.45729347152271727, 0.3701998431082608, 0.8165182619764801, 0.8650883268645, 0.934781284556495, 0.7339761579961037, 0.11558510389094855, 0.45105618621608234, 0.4729190804424613, -0.09804091270112975, 0.2932628015886366, -0.04369706465650749, 0.11853482248331752, 0.48590752927415976, 0.7122698004580621, 0.624847573064849, 0.760082891863966, 0.5744081570630252, 0.8072853544910222, 0.47792484619680164, 0.0028753064045976265, 0.09947173826360028, 0.8012369227086289, 0.35329586508464184, -0.019975322306985593, 0.7912092511358126, 0.7876571443450678, 0.8364457559330793, 0.7246693471770297, 0.7339424376009437, 0.6358272384710321, 0.30888705319874515, 0.5258881169105862, 0.8524085877709489, -0.08739423937499356, 0.7953649364327848, -0.057874913718046664, 0.6251752054999348, 0.6627292229935073, 0.7314493642917679, 0.5506509202379146, 0.19172121504075496, -0.04123825338713471, 0.7691489080363905, 0.6650168034687529, 0.5407548390617042, 0.8724577203331997, 0.7947095623669268, 0.37804896757897666, -0.20085943876852608, 0.7810468230788752, 0.7602656259761973, 0.8115001679409611, 0.48097396612896176, 0.7250731461840296, 0.7323133146722735, 0.6256207662952366, 0.5615291764702817, 0.7316542085513698, 0.798775361318497, 0.4811744829313148, 0.5987732343077519, 0.42975809774933954, 0.7400802432984674, 0.5322040338379681, 0.7572116110279024, 0.41056653614911676, 0.7459618332589851, 0.8671836485703805, 0.7949702601912114, 0.818592461190279, 0.8064733119546993, -0.035053777642475144, 0.7513080902107104, 0.332211897813285, -0.10184164472278755, 0.8676947169206102, 0.7811914918452312, 0.6405951767124797, 0.7447197213969181, 0.5053784281484325, 0.5987069483031664, 0.8818525841702041, 0.5128345487446639, 0.5739827419403558, 0.8875770231486777, 0.7835688104747165, 0.7440341747139357, 0.28317408268254224, 0.7439323680911163, 0.6036305703229627, 0.6839332791431613, 0.8416867604299172, 0.6337587175460546, -0.019337344153434802, 0.675865455069907, -0.31967640734537267, -0.02738303159688974, 0.710716613946276, 0.7706628154237829, 0.7490144494825635, 0.6433519344653855, 0.5273193943295736, 0.47113552195298825, 0.7365090254955855, 0.6236152853981942, 0.4425151558081165, -0.03508482393306698, 0.7108958823015094, 0.12933968327458722, 0.8122314786862275, -0.12140967545141687, 0.5593865555387513, 0.054474946715100246, 0.5069762870613143, 0.8103964957623928, 0.5195058566916356, 0.7572889612332224, 0.8261823338969492, 0.517132320564091, 0.7667643694695755, 0.35101389311561404, 0.7859204553528757, -0.18064944959540594, 0.2541318363220046, 0.7894732061176697, 0.8569523657972248, 0.7985001146565728, 0.6218554410273931, 0.7440608919557707, 0.5428535701640309, 0.7358550259697952, 0.8287156850658381, 0.861216806282944, 0.9003531175924026, 0.24337048973948025, 0.7635566739159388, 0.4890294994651932, 0.43276122428115144, 0.49011172976216416, 0.55896499369939, 0.7211344813276249, 0.3312841183116392, 0.8494491947844242, 0.7981222946165208, 0.4875088459318964, -0.3367956336990335, 0.5388575830947262, 0.47471128623602427, 0.5576231159237124, -0.20568874754603358, 0.32527176846317224, 0.8247206183190995, 0.6196071584194234, -0.03682873298339927, 0.5665176945245791, 0.8130512160731692, 0.656559507016161, 0.633803359048128, 0.7151309629332997, 0.7178330211748309, 0.783674065913334, 0.7775779036023407, 0.8354774290681852, 0.739065383544258, 0.8191213705365145, 0.2965565806590299, -0.1950527131306974, 0.5321378895131067, 0.7650575464195354, 0.7173051460104516, 0.8197598899793348, 0.5639287938466535, 0.6313820729627367, 0.6480830180433742, 0.7510402389340807, 0.7154025215715583, 0.8891221470842025, 0.6761668357727845, 0.6661277776451644, 0.9999999999999999, 0.8713932452142862, 0.750858444965485, 0.45676334904630705, 0.7920429847299376, 0.8059310571359886, 0.0556951470253892, 0.7941842963304677, 0.8722296962338504, 0.5332336347420508, -0.13681202731829284, -0.18365056309862202, 0.7875388572782935, 0.8873062782784965, 0.7218815912555916, 0.31923175731181175, 0.8272972377389712, 0.8833275007138124, 0.6497678372993021, 0.38454315503884995, 0.4620968317955869, 0.7410664297060059, 0.6724804344278446, 0.7142629443175122, 0.1712493764228008, 0.7188731343208667, 0.8898575262823505, 0.7926172858405353, 0.5507785114233181, 0.6682663612422485, 0.7754226246291415, 0.09087241993568795, 0.34672767981693736, 0.4153295962063752, 0.7713977139435179, 0.6873323599962209, 0.7095787832494027, 0.6723936665207347, 0.7858890209446656, 0.6935170204158605, 0.7210677673979694, 0.4657636850029217, 0.772715055362136, 0.5085366195909656, 0.9477262298214956, -0.03788653989486721, 0.9118748695478354, 0.021701707059323477, 0.8137556884221412, 0.5211635810635219, 0.6663925031370149, 0.6761038297041526, 0.6523268184560189, 0.7824174434948854, 0.5846550541483092, 0.6490415493037068, 0.7872571428558715, 0.5652720988438806, 0.191843386138725, 0.5935586891324504, 0.8320020302423374, 0.5225883982687296, 0.41218489050543666, 0.48821284934853204, 0.7604332093486347, 0.2677767284384732, 0.8386421241292981, 0.6055244770265509, 0.6595796854000445, 0.022441061936314427, 0.6611235268631251, 0.6072770484673885, 0.571102814194357, 0.833961969867036, 0.8921640294043517, 0.021458885832993504, -0.008653457822632625, 0.7397114764630487, 0.5864544726523273, 0.652264083214035, 0.49179861192338825, 0.41178881235746856, 0.8018886288092182, 0.7401867487786727, 0.5945077788723585, 0.03290554681547421, 0.4573289408877221, 0.7926173365596344, 0.7994085201877318, 0.5441073030694432, 0.6462153205843515, 0.32215279704192956, 0.7344086290576862, 0.6858911768437825, 0.9331393735967608, 0.9058201471688643, 0.5695569908479045, -0.04602175764720306, 0.6899685750070463, 0.68301268600636, 0.7747746852031635, 0.38929746427210754, 0.42190024140477617, 0.8104872207326189, 0.8876342617243417, 0.6387108746968279, 0.22633087747295025, 0.7257823368779944, 0.6792250667037273, -0.3558400446019357, 0.9854625619070665, 0.6819417089361032, 0.6928870142800782, 0.5974982354249533, 0.7040002698383476, 0.7717353050916667, 0.6479437807849379, 0.5732914093936404, 0.7438762974171352, 0.5511165348813883, 0.8758763431793202, 0.7478031005358143, 0.5974372344595451, 0.3771522626279958, -0.335233144401484, 0.09330417268923932, 0.38761375654354807, 0.5905749909781315, 0.7676681395857674, 0.7803753038396343, 0.09576589106691713, 0.5938078667519057, 0.7775246205764238, -0.17608605001420038, 0.727378038276, -0.07562773992071864, 0.6835629510784529, 0.968726084202175, 0.7538089018279344, 0.8839939345448597, 0.4684574369134373, 0.7222575970657582, 0.7550893840484983, 0.5396895754366309, 0.33951841769984, 0.7924869330306026, 0.7256003146070287, 0.741255558994377, -0.05771807483876697, 0.6951544895660786, 0.8182881978798576, 0.7797568701821357, 0.6953223719861056, 0.6805247465653281, 0.7931805559264379, 0.223920152253937, 0.6248220916325287, 0.7338852874941543, -0.06133224630637842, 0.7941297535543967, -0.047998256013933524, 0.07586916878508822, 0.8577940657132056, 0.8928662014436041, 0.7625184567903762, 0.7893115722048535, 0.8183978907482421, 0.3177277548213325, 0.46888342744961253, 0.697102135399469, 0.4249032917397637, 0.42760099431861726, 0.046093779922920526, -0.0059528170222805585, 0.8247419184195763, 0.7431133150866154, 0.028707872488472813, 0.7119204905494422, 0.4098714288793518, 0.8011699224072075, 0.6743380595056878, 0.8222649481092579, 0.7627995645047378, 0.4624552474605248, 0.5908066406553155, 0.39626871039765, 0.7398845398683228, 0.3716135276507938, 0.6783260442494052, 0.7644635509661702, 0.6859278857679706, 0.7345057254574273, 0.004155358576094652, 0.783683812478257, 0.694223784726356, 0.2686433244502281, 0.8954377700240318, 0.654660616781337, 0.3208408871896564, 0.332409380944236, 0.5323374868301184, 0.05118483988848673, -0.012852229287432926, 0.7172544200052797, 0.8723814117518668, 0.6864376523897755, 0.786347635861658, 0.11571183778656079, 0.34310506417854014, 0.8390980190954858, 0.8080842908151755, 0.2832823343805137, 0.2175078435792667, 0.44487849257623774, 0.7461022815701023, 0.7950366960519443, 0.6560953623973943, 0.8387692917151592, 0.553790970209104, 0.2672830796933707, 0.454990852784619, 0.6739287003352552, 0.5423076860082436, 0.7389986240206213, 0.8620496843764617, 0.6726014435221775, 0.46092142650066575, 0.754896366582622, 0.6517570455977498, 0.42744743977371774, -0.04645994718625954, 0.6632333627555863, 0.742132327441241, -0.007534320898673216, 0.6174734205215705, -0.025706025612996793, 0.4469778098096776, 0.5128345340771613, 0.4115601731084713, 0.8105798578163229, 0.43597095556819343, 0.5108184198580467, -0.024613633793922986, 0.66325250342422, 0.47700359307639, 0.33400201718490713, 0.49556252686151525, 0.6396370366252119, 0.8168006072492056, 0.6317919683641658, 0.779145203704148, 0.686929882057275, 0.8167232709175141, 0.7430431451470648, 0.06588917365509578, 0.1627650183819727, 0.8232957343769387, -0.061706498098782744, 0.4559898706860525, -0.048461085536909136, 0.10969384591563994, 0.6296072527270381, 0.8055311188651246, 0.7269930813854194, 0.7385589335263646, -0.13285941163085957, 0.4629936924250265, 0.5742372103498207, 0.6653280150301458, 0.6402309562081128, 0.7763392002497275, 0.2649089802871148, 0.7008836781145437, 0.7259874406656223, 0.48337275544169817, 0.0018398585456658148, 0.7324961760496533, -0.011258717720607487, 0.5797866177598311, 0.7289030739075244, 0.6892221763012387, 0.4038231792377475, 0.7274096293672208, 0.845089598087971, 0.7643122319931732, 0.5159105565506305, 0.7527915907174034, 0.5714396004299135, 0.7927388526063186, 0.7211591727718383, 0.8227680846031248, 0.7026400695938346, 0.6218481549104461, 0.7357357230995281, 0.7413915094302207, 0.43611047042129064, 0.8994625295974061, -0.22455634225554896, 0.5488672327401889, 0.9080820404549055, 0.49023271742843416, 0.6471580357914218, 0.7660549878529004, 0.7287871936565363, 0.7312351460641197, 0.4173211027951716, 0.8864472455737252, 0.7111264444003269, 0.450762476635503, 0.7848534833400527, 0.5766577616160511, 0.8956467930930663, 0.823102864712882, 0.7069886346788127, -0.22317791132344822, 0.8289653867755453, 0.7496154588975065, 0.399484898914613, 0.8221358774478914, 0.7180903023933248, 0.46073900968207177, 0.6912093155030123, 0.6636869316186572, 0.69491665655034, 0.5830368787541702, 0.7927069441753508, 0.4043134942929734, 0.7786114024982493, 0.5939829303519817, 0.6409618142567247, 0.7637656946042942, -0.3196967124090802, 0.3638014183183579, 0.712006290193502, 0.7816152676145719, 0.3483294380895005, 0.6313820619236971, 0.9272018926028962, 0.8304551217290128, 0.772720559447232, 0.7439897353803528, 0.39529383903735105, 0.023207127236590405, 0.6485422727073291, 0.7568802230599716, 0.7774781563152401, 0.7396307646452829, 0.27224381041816725, 0.7279663776053378, 0.001688564048511156, -0.17920731984437527, 0.6968940250575215, 0.5285887948350841, 0.5658920103572815, 0.7102996039454507, 0.6176862808326063, 0.7668570301269292, 0.02028993246636755, 0.02857960963898346, 0.49353564271754047, 0.0006595399243029011, 0.22410802192330945, 0.6266725646332865, 0.6574022982501728, -0.09662530677499145, 0.7119207411642998, -0.2233109365064815, 0.7282991629773302, 0.04118824492479676, 0.7526973900817141, -0.0029092418022210924, 0.6752402785831354, 0.813799848020562, 0.8901243371631776, 0.06740028968853332, 0.6216940671183505, 0.4470844610623496, 0.8311755363461001, 0.3757985270036303, 0.751640800035261, 0.7936391093142591, 0.84280360114567, 0.5197662470450374, 0.7564953741920867, 0.6479177663775381, 0.8044218514340564, 0.6059227164769989, 0.4636120164495193, 0.689017611134019, 0.38376192786504626, 0.7145387513444867, 0.8254441157453111, 0.46717828305159614, 0.605877786179814, 0.5713185897198039, 0.4176526015055571, 0.6810350807212763, 0.2073165927400567, 0.3716476770688681, 0.4850204316403519, 0.6562003376631089, 0.7562827850277856, 0.780359286626772, 0.7110558572921614, 0.12712205610271493, 0.0220459352462909, 0.7679649621882042, 0.9074669823107706, 0.48133490481552704, 0.9563091890017454, 0.7364157618036082, 0.556816279222401, 0.7511062457613242, 0.019551996073167346, 0.6704976761870638, 0.33400201728300893, 0.6756498590080953, 0.72352912914563, -0.17065739758312537, 0.6723618277425473, 0.026213509908504587, 0.3581856294794877, 0.11663593218508261, 0.7256244819789905, 0.7817235270756197, 0.02607125275902233, 0.6365714925238093, 0.5416620452154284, 0.3838424095499018, 0.48613327963767133, 0.8172719511244142, 0.0169194390700082, 0.4195083998499308, 0.5391344188352001, 0.7237157179593264, 0.8909751521465781, 0.03910266909557848, 0.2871839298041904, 0.6784787757153309, 0.7274030397921774, -0.02778923577382058, 0.6998613895217558, 0.4744382354831434, 0.8327684959948691, -0.023873491945299693, -0.194904258058513, 0.6630850916043093, 0.45566566500801264, 0.5412329087971346, 0.8018701872758212, 0.8482518285633499, 0.6789420107206642, 0.05960593224681028, 0.6816749724164265, 0.7870996541661989, 0.6818448002099955, 0.2969948345943188, -0.050485514295496706, 0.8708811493263949, 0.09513118770432803, 0.3638460667452889, 0.6780331185576189, 0.7747684412316173, 0.05620118668599049, 0.667826970377094, 0.3400327587241689, 0.4775017579098287, 0.7106606431666702, 0.7814028256732065, 0.49603366242566055, 0.7258334986050526, 0.2158561545832832, 0.7135572428854768, 0.7376061593900686, 0.547515031219984, 0.5017309152159157, 0.6623409406624811, 0.768979293993985, 0.6484526918497553, 0.3674290816982446, 0.8016207306934642, 0.2715323272449246, 0.7876347230569364, 0.7907721317068355, 0.09195418811644185, 0.6988380527902053, 0.5303038670396962, 0.748850954329789, -0.20679331255591232, 0.8191795032975046, 0.8052694741820052, 0.9353176261957371, 0.5949752204471629, 0.29319415307735175, 0.6415750187638019, 0.5801096336219749, 0.8428091638509411, 0.6254687407435316, -0.18061347841013764, 0.7283497180240053, 0.42422095359115686, 0.41852927315321414, 0.6386673871097973, 0.8467021003440385, 0.32406137550238157, 0.8199909382822651, 0.5492320367043128, 0.5964485365221838, 0.7734476854577846, 0.7636314634283893, 0.5347568913799645, 0.7816418638163776, 0.7011221219514943, -0.09219683838023965, 0.35519707624227503, 0.6620581145743234, 0.4691213186790148, 0.8466348061530433, 0.6421525775380699, 0.695655170146855, 0.8082756232483115, 0.44740219808598936, 0.6885881132463033, 0.1502726340180781, 0.7314072030983528, 0.8540061094435493, 0.8341298837048687, 0.5401871073762087, 0.5566207470849026, 0.6983460950314563, 0.7172347706523485, 0.6655594677221559, 0.7356642558085664, -0.025771002709542905, 0.560505971902608, 0.7708290741442833, 0.8768305261257366, -0.05543627661496034, 0.8094659384099488, 0.8226500124225665, 0.48492795996505345, 0.5104523100459991, 0.7304838565178552, 0.8398291675397921, 0.7141824912413833, 0.8110496121495676, 0.5999018480943994, 0.7429380557920777, 0.7282011881396876, 0.8722855535156442, 0.5243171947111879, 0.7123700207300506, 0.5081322171512176, 0.673036392948932, 0.7457351704629598, 0.8509093737843437, 0.7944209574726028, 0.7393507487292892, 0.1365211693302558, 0.7288047473345816, 0.7352426832240186, 0.7134921846583315, 0.7605754148662547, 0.8140896068850262, 0.5142939628450397, 0.8519499812320872, 0.43396911290910384, 0.6290834372763379, 0.5134531026800907, 0.7388006177600789, 0.8583104835589934, -0.15425340723391007, -0.22696252221542457, 0.6678453634296264, 0.481954143932431, 0.6648849913853562, 0.6993020119218116, 0.4052959300213363, 0.7486342250857708, 0.5241275058130205, 0.6097817672975144, 0.6333068898513546, 0.4876555133210829, 0.3619908157727728, 0.8216287883689173, 0.15734836257168255, 0.4925534497368308, 0.40944912706315867, 0.7527079689849243, 0.29345962457689095, -0.377820480241612, 0.6953844564715557, 0.6904069828274306, -0.03964555210363288, 0.6431393698712916, -0.06271949463254005, 0.45133475396692585, 0.8263041301944009, 0.7594955189400812, 0.4205357386318116, 0.01721389344824802, 0.8497647225274226, 0.7288524498081654, 0.3765893513445532, 0.4358240810418741, 0.7310704946016227, 0.7901542438249328, 0.7303735542556515, 0.7990398611150691, -0.07569584263026104, 0.7426023286852877, 0.6117733500849691, 0.6621633283135889, 0.7848470062407318, 0.7526557576029633, 0.48099941789838824, 0.5933016498274963, 0.9990552698308208, 0.9808584611850927, 0.7576228563300419, 0.2709724801886826, 0.7447865818345898, 0.6635288823078938, 0.25648399413189465, 0.38938453135274215, 0.4353167841662804, 0.7573869626293284, -0.12064555631396591, 0.8275901325395401, 0.126791982275102, 0.768742439327037, -0.04975535131148307, 0.7661198667624178, 0.8017837083569778, 0.7144138320504206, 0.7660190417192088, 0.7948374260150763, 0.39710931950761963, 0.7308203632091418, 0.5912178479335979, 0.7012113550097349, 0.5614718347417118, 0.06814918758764395, 0.8587401073827551, 0.1227958701349146, 0.6636717565987166, -0.050954577875491826, 0.699967963929894, 0.7994560440318881, 0.6548887412636072, 0.6738132872795468, 0.450818248785268, 0.8690662635229275, 0.7474449948362759, 0.8170593843344849, 0.6651083769642581, 0.8015435201113948, 0.46062235943101776, 0.7753245782529028, 0.7622531229472284, 0.6762809611065038, -0.048439037191531295, 0.5443943645595211, -0.03223495232187344, 0.8199122861640947, 0.7519427552790883, 0.5630582033397573, 0.5590380157796365, 0.831247062747573, 0.5898297368702804, 0.6374294969005858, 0.7994388101219518, 0.5555328001575305, 0.46811838712302706, 0.7699092984685242, 0.4403726920574553, 0.7845560398725856, 0.4575234984006407, 0.7780998776308454, 0.5526111500523839, 0.5594707904222068, 0.4200022009974992, 0.7546965219086691, 0.4140669900163928, 0.827463799926492, 0.6945187784916129, -0.012665016821316061, 0.48874883385666196, 0.6072653920499479, -0.25770801682583727, 0.9214354398865928, 0.422137036103853, 0.8535060306215044, 0.6554169039517764, 0.36175999310840007, 0.709306779335305, 0.7027315065291988, 0.5059484908442444, 0.6138944516295829, -0.24516244517420094, 0.41644362923348416, 0.4783581747426014, 0.6903277140815192, -0.06080485316993655, 0.06944219071276636, 0.8513420513299703, 0.6366262756122222, 0.6595344681686615, 0.5159048328415271, 0.7939221227768661, 0.5227223792112882, 0.8719845919061848, 0.6172039196745028, 0.7526438670440321, 0.6854069932602442, 0.5891087936613885, 0.5483518304829365, 0.749753969803148, 0.8211646162134679, 0.5218476140773002, -0.004447259184089481, 0.7795037353982089, 0.4797274183448042, 0.8290091211872301, 0.7025222755420191, -0.10477287587310384, 0.6618106508983431, 0.8904330066101797, 0.6737175599969317, 1.0, 0.8209304141508493, 0.991401233840685, 0.7925574895930145, 0.01904546223144092, 0.48597454790848527, -0.009214064156499283, 0.7732862476192578, 0.5546603468149965, 0.8340740513282124, 0.7511438475627634, 0.7665075625961272, 0.8175552927091321, 0.8942022240676325, 0.4968455822592685, 0.6987252854221535, 0.14783821474481953, -0.23293629292734824, 0.7500517979783115, 0.46744876984191175, 0.7249853545372599, 0.8008531703724661, 0.6432932982367886, 0.7378826284517905, 0.5558911133860667, 0.5992123727776746, 0.8025583456883321, 0.597220627201274, 0.16416298808307303, 0.507084071202726, 0.6464803288724639, 0.702260709655815, 0.7619857265071409, -0.01312100662633994, 0.6720769088126574, 0.8162149891223183, -0.0022095716816660786, 0.7322978875420255, -0.04108309076175969, 0.3982430340913145, 0.7221762961220888, 0.5194504169404781, 0.39735400741239685, 0.7894340852370476, 0.6556759726160579, 0.7073614700551317, 0.559638095994092, 0.6999490746803815, 0.6746332873668828, 0.7710359965726931, 0.5991474501760143, 0.7229539251241206, 0.6101036662938926, 0.6430380686947866, 0.8635984057332061, 0.7941440508906815, 0.8637648297166663, 0.6775230688760493, 0.6774613717170199, 0.6401543736917338, 0.6833216010922547, 0.7273117770320808, 0.8201023843178133, 0.5392637687812656, 0.5555492019859625, 0.7035623900099636, 0.5685037942430924, 0.8668652090797901, -0.1982230418801764, -0.11084949280859518, -0.17357985663357517, 0.7987999986847193, 0.992589799624695, 0.5366898898598057, 0.6964459077766896, -0.06306354746802491, 0.7770489204613494, 0.8421155029555942, 0.24159295276391854, 0.4199372813669489, 0.8235622517676413, 0.8334004953284667, 0.8479497579234786, 0.7458535760160632, 0.6524604771968776, 0.7779019467463844, 0.529258296616528, 0.6221563432360383, 0.7953039129413872, 0.9336078227724487, 0.011483756383797216, 0.29318887669374327, 0.7089514001372714, 0.8640314203421363, -0.0243883253101813, 0.6197623812870694, 0.6593341953175461, 0.8539739503803074, 0.48368731941916776, 0.7085109607444634, 0.8995578718201749, 0.40094201414243813, 0.4442616257654437, 0.19846922119917473, 0.6946615692892638, 0.4688839385961098, 0.8723360045403303, -0.03834288990544112, 0.03593929202535041, 0.6739252479980388, 0.03470609977481188, -0.030654417205177004, 0.8276810366375965, 0.8334989791169984, 0.5711590120645189, 0.8043141362176098, 0.3139294594463023, 0.41880266426557866, 0.6420301287813743, 0.8451875497336211, 0.3300577046247491, 0.727826651365717, 0.9104554777840344, 0.5707843918228912, 0.6502469621250729, -0.18500524450520853, 0.7835431735039822, -0.2485517931538768, 0.7065140227829471, 0.48772822022438006, 0.7411771019205048, 0.11075093521718665, 0.7554381447788104, 0.28750216787372795, 0.3765675302255545, 0.6307323034784418, 0.6335656005862623, -0.07278304944943853, 0.46945116006013043, -0.19435391966592333, 0.8122078264110871, 0.5065028185062026, 0.7397855198973119, 0.7212321549601165, 0.7433712401470718, -0.3652770300812506, 0.783388073027542, 0.40156392971914334, 0.826148589968998, 0.7482327237010654, 0.6538306527575183, 0.7453131088254978, 0.795692206540094, 0.46542424517549325, 0.7187742231199128, -0.04475584286249992, 0.7273146067918521, 0.8024843625866039, 0.7115860942793362, 0.815961587853442, 0.26993034173051755, 0.7507201574022843, -0.05706425185125005, 0.01931817503568982, 0.2974597523282337, 0.3766807207418441, 0.6817849790186911, 0.7083342620696208, 0.5080668701029805, 0.10427329872423075, -0.2376457525320289, 0.4600810051537724, 0.49429152302973683, 0.5264280941458027, 0.7557202570749787, 0.5744347976704386, 0.8812575558950454, -0.07856105207428345, 0.20937163203741505, 0.7012584642956791, 0.13387863108158146, 0.7827040895665717, 0.6808489242001537, 0.7037736807769894, 0.6026835777254802, 0.5891135048428193, 0.491716546172198, -0.039908888937781176, 0.6389051808649172, 0.7027364015075966, 0.4200625753502077, 0.7623015660875182, 0.43909933442443017, 0.7660549766240115, 0.35000337039319485, 0.7661251354923891, 0.81766944366453, 0.7123020469908532, 0.6946416435047479, 0.6545333028933917, 0.8002211299134004, 0.5358727147167507, 0.6678149930199097, 0.02146521619698121, 0.28436170999350613, 0.4113825404408521, 0.6381497337600415, 0.7958528826510854, 0.22874433399092883, 0.7627550496926941, 0.3297402960572701, 0.5483797572168464, 0.3984928567133417, 0.38041162518631083, 0.787576104254232, 0.08251237357826101, 0.005435376321474511, 0.7077671770994259, 0.08795584774488828, 0.6519985407262836, 0.7744158231078083, 0.7479622780907688, 0.6704623548429517, 0.07967562875194692, 0.7647669596720645, 0.8767881302841116, 0.8608504629987157, 0.3843275054757626, 0.832746504598751, 0.789413481926555, 0.6804587886640019, 0.802526595745213, 0.8708811502077664, 0.5909958344031206, 0.5519383588155904, 0.7795744493527931, 0.5752636060916305, 0.6308192348136595, 0.6777130216722231, 0.6718296736202651, 0.5448056240590188, 0.49193953600255946, 0.616629510713722, 0.7652117096065407, 0.7827249277441214, 0.5316905661038696, -0.08297425585520861, 0.7527990402747338, -0.0920609663886601, 0.09477641170349749, 0.24629867818858814, 0.19016678856286545, 0.8248105042345525, 0.026523571794991402, 0.53309418712022, 0.8043371957698615, 0.8759764092695567, 0.40717222370081313, 0.7099632813651002, -0.016612117454430343, 0.7761897668804082, 0.6999630445365903, 0.6809015185859302, 0.7609057630897985, 0.7664715935520773, 0.7283507443561567, 0.6175222045184409, 0.5823993461960414, 0.2954738865241224, 0.8225692001499632, -0.09866139849082248, 0.4263204383733272, 0.580895897408715, 0.7406234791695038, 0.43560782563460543, 0.4095760162690078, 0.7247227150960248, 0.10418663317940512, 0.6605946321271005, 0.7898370317504358, 0.7486340217900314, 0.8678013453595367, 0.5179121040819333, 0.4028962048648703, 0.3644225719384659, 0.4600652096753401, 0.38682251246167526, -0.07461049765155803, 0.8342024897137531, 0.8714710700782349, -0.009304034977536377, -0.08604586378562999, -0.17212652886186772, 0.7666383522736326, 0.8311246231169808, 0.5540492041149794, 0.46964119577849806, 0.8418179574995241, 0.8258803605541493, 0.7775490321771258, 0.7110024477257735, 0.8857673177433273, 0.8320326810148289, 0.8040626957222856, 0.640764606566094, 0.7334099255701969, -0.1283697569372106, 0.6962097466486633, 0.6753575455001712, -0.0771981404900812, 0.7198887801279108, 0.7297240185759553, 0.5954098594297366, 0.909290029030067, 0.5750362779342272, 0.7373138262617707, 0.7037617446980022, 0.39393886485457874, 0.7070047604613615, -0.00017512973979983304, 0.46765531731117055, 0.6130461951740483, 0.8173997404280999, 0.6081820253068606, 0.7417106488974109, 0.7474450074344962, 0.7281941270212197, 0.8623030469146226, 0.45820726260008804, 0.7247536059274622, 0.7344266211954252, 0.816993883111058, 0.7539702821697828, 0.71619382002687, 0.6585900356785231, 0.2814034242371753, 0.8935900620996485, 0.8212376660903516, 0.6640711229076598, 0.732423768994844, 0.6588031772364594, 0.5797164850073084, 0.8490208564377839, 0.7925045749267637, 0.7225006813968793, 0.31501622966935583, 0.6873824144776001, 0.6852808889704044, -0.027644773561930548, 0.6612328938916028, -0.031844727200509376, 0.40815981122946027, 0.3803073986436839, 0.8574449873685128, 0.5129104635350284, 0.7083704817952939, 0.8790893132476927, 0.3241748251350129, 0.7172332811095616, 0.724987284509604, 0.922425499954825, 0.5793255384796265, 0.7689503936790906, 0.42650461391343814, 0.1644297682070991, 0.7705368269485551, -0.08906427693473555, -0.00148285495910181, 0.41407462530333383, -0.03071122286998958, 0.7457387809607833, 0.7771819251658808, 0.6263977208449705, 0.7118751942538952, 0.458695478097016, 0.3840089674763887, 0.4176668424500791, 0.4385575178937966, 0.7311587150363961, 0.7588104938327145, 0.09955656871202886, 0.3794547369064162, 0.2673243787288511, 0.5020004723392147, 0.6166195850066666, 0.8193410197211918, 0.6383389277134395, 0.7264675087546216, 0.7442477959115064, 0.42993541504518723, 0.8963090586308231, 0.06366505955775889, 0.7157378287249291, -0.022248072078868048, 0.8232361350892133, 0.8840109159014764, 0.7003871033640579, 0.6968972691884795, 0.7343156784134739, 0.5109104873068752, 0.2950812004384519, 0.8279839450478833, 0.3884243915350726, 0.7502636270666436, 0.7285651056885496, 0.8449450315975153, 0.3236326083276458, 0.7857982156284603, 0.6473365817232044, 0.7668754940821212, 0.7446324406382899, 0.42352548439946325, 0.44571558601016636, 0.5693927884360633, 0.27976147893010195, 0.06009432655000642, 0.777419385792855, 0.6577854764010191, 0.4988042863069456, 0.7529284573833434, 0.7310502113823422, 0.7348781881142051, 0.8403855114061269, 0.8868164366348913, 0.4733737896749317, 0.8246206858412404, 0.8402855557508485, 0.3773707479157476, 0.8312325841876295, 0.3097267080920381, 0.5310110837748017, 0.6147925638893662, 0.4214867579412389, 0.7753436190202427, 0.5818481087050212, 0.7736788867461023, 0.7921199323142601, 0.7242931520141379, 0.5993367093484357, 0.7218183299803304, 0.46396310091616444, 0.9176641275087775, 0.5693553921815837, 0.314734018363471, 0.43745666271357114, 0.6775986300263718, 0.5215611659403979, 0.7695984152889799, 0.8510976236220693, 0.15482955900493964, -0.00790575013559154, 0.6705806716489129, 0.8270537928928152, 0.7179120785800368, -0.054508028216413686, 0.6511503309385221, 0.9886057315559119, 0.7869806622043148, 0.674742669413417, 0.9723880298735603, 0.7917150085786814, 0.7215276474258341, -0.10068388383029514, 0.15542075789129592, 0.712884489113089, 0.8182466338226584, 0.8054592432698725, 0.6348302459430293, 0.7090063548402333, 0.053495425841156595, -0.32730519722722773, 0.8494737339120746, 0.6901197991577966, -0.3676187988683416, 0.8134239767994536, 0.8230222354195612, 0.7732381317616684, 0.38709117320587355, 0.7925389742325581, 0.5118070543885559, 0.5598627290523122, 0.6806979192080711, 0.8385369890828336, 0.4697975425092992, -0.04875151492031542, 0.6433990434933494, -0.23411110987811443, 0.5841005814358999, 0.47562039602611067, 0.6968189800836436, 0.7260208692234725, -0.05095810669754812, 0.45131509601665865, 0.5522796070955662, 0.6679105372912815, 0.46713355823352065, 0.5005177531522836, 0.7476429044745067, 0.7903518892711409, 0.7416690792998797, 0.02033006694924797, 0.4268691756271827, 0.6304154676467714, 0.7824832887692627, 0.7474070019455674, 0.6684758927022485, 0.8392522878578742, 0.7865896254022867, 0.5283662333026191, 0.73139009738132, 0.6775391000669266, 0.5403788033945549, 0.7250032266990692, 0.3820474520604985, 0.44916903143490217, 0.8731907594478703, 0.6436575788972407, -0.030099208213088688, 0.018321358612810847, 0.615307208283812, -0.05243127001363708, 0.5716739574700048, 0.2446479979577137, 0.8001553126198758, 0.43387085600856207, 0.8626575761565333, -0.026027423107969492, 0.48206502429730774, 0.7627276239504572, 0.05381343635268573, 0.003390612181169246, -0.08638961629573667, 0.6299681340932871, 0.4440606260024802, 0.514162196587556, 0.6806832852416803, 0.866138411772621, -0.04799827657296344, 0.8178846008927992, -0.05950226416837445, 0.7263372346193697, 0.3742403447650018, -0.07337311686877765, 0.3292427459560284, 0.14022929966956826, 0.8178994329879746, 0.8138288564619579, -0.036956500452740196, 0.7466988998267112, 0.5926846941033347, 0.8333993259242043, 0.6849447012495457, 0.5429534878941303, 0.531623948060235, 0.6788784005486231, 0.35402438420910853, -0.15962769180015438, 0.13187791096180917, 0.5503044941753629, 0.496340659219377, 0.7596455321803225, -0.08019285206104472, 0.8606854506389681, 0.6323066803526799, 0.7794888308917727, 0.6016806288176028, 0.678506240480579, 0.7830249869747147, 0.8650929333834722, 0.3566942753124898, 0.48273074352197215, 0.39587482462508067, 0.7008776119869954, 0.959583657798232, 0.8210726714884966, -0.020391075600961237, 0.4426785280994971, 0.10491465541531222, 0.7805763284249956, 0.29795419801169387, 0.842604638808103, 0.5675254297582014, 0.1573483521413223, 0.7392779892360846, 0.8594820626446743, 0.6181973777568056, 0.8631768545180024, 0.8648885054555556, -0.18693511034955163, 0.8174560871472798, 0.993023936291611, 0.7400318155730214, 0.3892194500369851, 0.19799231166722864, 0.29153214080338213, 0.7260636926780899, 0.6919993920651081, 0.6546338142968888, 0.725512304427574, 0.652653255638541, -0.04130445632573151, 0.7301756547035236, 0.5109537051022843, 0.8260482391521418, 0.8793622845906173, 0.7327419172023837, 0.8303255521805132, 0.345436859310829, 0.5339234939420209, 0.7673850985922055, 0.7755119480948672, 0.09122110690540321, 0.6580529172593054, 0.33361090231971413, 0.813335626872791, 0.4099618613204145, 0.4151316641328491, 0.6361488463798232, 0.44395954181978525, 0.04766843711917656, 0.12407027039375083, 0.7347208890625633, 0.7261418350636848, 0.7586610477961091, 0.5467844339920319, 0.7542612617939841, 0.7364948926969653, 0.7843252221585565, 0.7829549550011052, 0.42285492021286447, 0.14557071246497952, -0.15064221083164386, 0.8737779643157136, 0.5847198360737409, 0.5391812671211886, 0.8305205010980643, 0.7882040156665998, -0.04897385754574306, 0.5591663288413483, 0.70627311528676, 0.49436706936631714, 0.5584143138356515, 0.5967431730330284, 0.6651159632161233, 0.7945763457145367, 0.8384727028229461, 0.27700605441898896, 0.7770489206340987, 0.4052906370621101, 0.8256608277360679, 0.8439937220736203, 0.8026279516936965, 0.7206575343017174, 0.7849485404667761, 0.895632787830922, 0.6827675338126381, 0.8451596940501078, 0.09563397581629655, 0.21676582147644968, 0.47829943277082654, 0.49169276174471777, 0.4798032062720974, 0.7721520654309276, -0.27236493056032574, 0.7316894384368481, 0.5111707634640118, 0.8340740551202693, 0.5408901638626061, 0.8739672660089912, 0.5897302882017486, 0.4416127099898372, 0.8168226812019957, 0.441172506619942, 0.8808773762061405, 0.7617750244143688, 0.788534465570546, 0.8312378102994994, 0.4804672973933467, 0.029277014338951843, 0.7450371101275891, -0.11474164989675051, 0.4606223740625913, 0.6558413630627015, 0.7514635243793489, 0.6408535994189934, 0.34268127319708663, 0.8308739599844218, 0.5038532005969285, 0.5025886825635228, 0.7233116041293152, 0.35215284848590006, 0.7497442960495766, 0.3592535492057156, 0.75934082490596, 0.8054601122948077, -0.08686246597197811, 0.8243392655320597, 0.8440940291421366, 0.5251119139974973, 0.5308256399683711, 0.826382065835132, 0.09858890839468175, 0.7636778344907253, 0.7728612897317093, 0.8084051579589278, 0.7791669397004094, 0.5213656584706138, 0.3425706772792269, 0.7415752866991884, 0.42815251508128804, 0.8048996301114252, 0.29961282916241394, 0.7970118741933369, 0.4821551639643652, -0.1799924231107404, 0.5070989115646816, 0.668578315241533, 0.7423584674294204, 0.7349970632945192, -0.05788205130249518, -0.23449188547869276, 0.7093332063280716, 0.6422693724354466, 0.04820878730748174, 0.7685028598922846, 0.9001216509144953, 0.7872548050076856, 0.42702445407321105, 0.01336725371253286, 0.09186848258193255, 0.7992598781603869, 0.6738013480490387, 0.8096591583379232, -0.12447194181179701, 0.4810256520133631, 0.8693600629131826, 0.06823008886902002, 0.08591447317134414, 0.8087963131539001, 0.7485735822174057, 0.7371386773786015, 0.0759427530369429, 0.5108221426483354, 0.708664498485411, 0.009507679886993541, 0.8066101722419893, 0.8300485083749376, -0.2376457423564151, 0.3271717493647281, 0.6832973568618277, 0.7081321147330649, 0.8032283284634137, 0.7674493179004889, 0.47138079518631315, 0.48543163638978465, 0.8975008061930574, 0.374734232872884, 0.7094818962128817, 0.6856396670568015, 0.039425865552862524, 0.525718149154542, 0.6083937900246303, 0.7221750423710995, 0.8038311378032862, 0.796155807581651, 0.6055514852480836, 0.43734463023079473, 0.6075764138391312, 0.712705369934326, 0.8028629999055601, 0.7453213137901006, 0.8193383084290989, 0.47809773732097877, 0.7348134833516867, 0.018860001333509884, 0.512311587303542, 0.9939258384827889, 0.5022986253515567, 0.5082664016196721, 0.7627708233402796, 0.8335200105319842, 0.7280941268697578, 0.39341767619413215, 0.7773291985755488, 0.8389914843835151, -0.02365049742018603, 0.7094079201549458, 0.5086797458851212, 0.8797929376894081, -0.05105863136206338, 0.4826685293654209, 0.8393094734932546, 0.6873763542711372, 0.7503261992405477, -0.01710813164424611, 0.7999807735966162, 0.1374380009238061, 0.7530479558404573, 0.6777177239810392, 0.8217768765367569, 0.5310123753903675, -0.31995399797416546, 0.6945391131243559, 0.8722285721564037, 0.6911370106308072, 0.9069872496195811, 0.7606084183806692, 0.43472145090017333, 0.5951692465129388, 0.7182865001878592, 0.4613717460153093, 0.5220541861128061, 0.7849753970776426, 0.6384746726350135, 0.046323962868625175, 0.7134569342592523, 0.48820209584302043, 0.819000723302635, 0.4133625356975624, 0.6409327722548258, 0.6397617334519071, 0.7006107244776626, 0.5935587127532718, 0.6584313346647913, 0.7767240431227839, 0.05742794358752934, -0.051538501568960955]
+time-cost: 345.711832113207
Index: log/day and time:2021_02_22.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/log/day and time:2021_02_22.log b/log/day and time:2021_02_22.log
new file mode 100644
--- /dev/null	(date 1613999384000)
+++ b/log/day and time:2021_02_22.log	(date 1613999384000)
@@ -0,0 +1,2459 @@
+******************day and time:2021_02_22*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=186.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))
+tensor(1.7946, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0495, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0152, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1091, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1936, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9454, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.6381, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9930, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9467, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8829, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1292, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5016, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8298, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0006, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0672, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6248, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4328, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8633, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8353, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3003, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5474, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8121, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1296, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8240, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.7721, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :1.289648832215203
+Validation score improved (inf --> 1.289648832215203). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=186.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))
+tensor(1.4179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8432, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8977, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6207, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6401, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5352, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9988, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7439, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6550, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0244, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4563, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9116, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4214, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6956, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5790, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6281, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0715, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9073, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0075, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9885, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0364, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2839, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7603, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1334, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6906, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2367, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0890, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4268, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0300, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1488, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :2 | Validation Loss :1.0648955437872145
+Validation score improved (1.289648832215203 --> 1.0648955437872145). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=186.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))
+tensor(1.3371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7525, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8202, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7460, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6298, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5767, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0608, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9459, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7174, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6425, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3844, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7990, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6274, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5642, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0124, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9743, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0010, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7171, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6401, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6024, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1801, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5422, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9589, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3435, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0760, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7997, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0147, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :3 | Validation Loss :1.0113986280229357
+Validation score improved (1.0648955437872145 --> 1.0113986280229357). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=186.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))
+tensor(1.2907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7385, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8238, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5993, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0436, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3947, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9326, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9274, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7053, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5395, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6918, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6236, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6214, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2333, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6654, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5926, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5069, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8343, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9111, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8976, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9411, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7065, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6385, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0365, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7461, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4578, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0949, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5279, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1230, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9991, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9444, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9222, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :4 | Validation Loss :0.956120048628913
+Validation score improved (1.0113986280229357 --> 0.956120048628913). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=186.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))
+tensor(1.1040, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6739, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6474, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5409, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4679, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1882, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4115, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8291, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6390, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2354, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5128, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8653, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7279, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7281, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7670, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0096, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0920, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9768, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7865, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6455, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6041, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :5 | Validation Loss :0.7995202349291908
+Validation score improved (0.956120048628913 --> 0.7995202349291908). Saving model!
+Predicting for OOF
+time-cost: 81.466587092254
+******************day and time:2021_02_22*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+******************day and time:2021_02_22*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.3448, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7941, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8776, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9967, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4693, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9169, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8330, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2804, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4529, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7998, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1365, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5146, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7871, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0905, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9972, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1012, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7353, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7297, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7037, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8985, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2702, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9629, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7236, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1261, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7099, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8304, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7351, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :1.1139532690462859
+Validation score improved (inf --> 1.1139532690462859). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.0762, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6163, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9563, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6328, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6481, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1361, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0213, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7315, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5573, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6241, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0204, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2133, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5972, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9646, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7974, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6235, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9024, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6675, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9854, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0268, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1036, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9339, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6269, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6974, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9205, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9640, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6130, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8776, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9531, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6547, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9200, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7680, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :2 | Validation Loss :1.0025386434534322
+Validation score improved (1.1139532690462859 --> 1.0025386434534322). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(1.0100, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5837, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9231, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9266, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5951, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6224, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7558, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0653, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9829, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0659, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5391, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0570, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8323, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7806, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6005, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8744, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7372, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0556, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5947, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6818, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8891, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9216, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8273, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8180, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5631, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6328, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8807, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7511, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :3 | Validation Loss :0.9517118114492168
+Validation score improved (1.0025386434534322 --> 0.9517118114492168). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.9126, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8057, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5594, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5978, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0152, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7183, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9594, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5091, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8667, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5431, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6969, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5298, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5190, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7172, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5682, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7724, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8275, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9073, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9080, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8000, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5584, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6289, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7771, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5858, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7597, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5007, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5397, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5871, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6774, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7889, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6708, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :4 | Validation Loss :0.838318486576495
+Validation score improved (0.9517118114492168 --> 0.838318486576495). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.6684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4667, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5020, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5101, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4608, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4400, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4607, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5614, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4801, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5174, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7838, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5258, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4053, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4199, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6469, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7925, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7290, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7263, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5048, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5142, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5325, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7132, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5326, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6009, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4338, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4480, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4949, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7495, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5195, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4315, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5362, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5034, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4562, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :5 | Validation Loss :0.5368731021881104
+Validation score improved (0.838318486576495 --> 0.5368731021881104). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.4327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3198, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3135, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3178, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3199, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3418, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3196, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4616, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2968, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2807, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4241, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4574, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2830, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4342, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2819, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3118, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2818, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3204, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3208, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3288, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4172, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3270, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3978, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2839, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3036, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3216, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3089, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3654, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3015, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2870, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :6 | Validation Loss :0.3413455810235894
+Validation score improved (0.5368731021881104 --> 0.3413455810235894). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3627, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2770, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2829, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4444, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2929, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2330, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2405, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4398, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4115, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2731, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2408, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3861, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2848, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2940, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2920, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3314, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2610, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2423, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4228, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2814, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2297, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3372, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4051, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2654, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :7 | Validation Loss :0.2976347091405288
+Validation score improved (0.3413455810235894 --> 0.2976347091405288). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2403, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2428, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2184, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1978, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2774, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2147, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3299, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2466, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2122, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3074, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1979, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4407, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1908, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4056, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2133, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2365, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3412, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1971, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2039, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4209, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2919, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3974, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2099, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2265, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2083, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :8 | Validation Loss :0.26147110079941543
+Validation score improved (0.2976347091405288 --> 0.26147110079941543). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3022, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2114, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2140, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1616, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1813, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1803, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4591, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1773, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1613, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4119, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3018, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2071, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1645, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3281, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2229, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2372, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1819, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1602, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1680, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4284, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1741, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1975, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :9 | Validation Loss :0.23763930473638617
+Validation score improved (0.26147110079941543 --> 0.23763930473638617). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2554, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1480, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2019, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1387, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1649, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2700, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4834, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1817, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1530, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1230, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4764, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1227, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4267, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3013, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1643, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1303, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2844, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2130, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2269, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3952, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2242, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2236, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2041, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1194, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4191, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1398, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1836, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1599, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :10 | Validation Loss :0.21925333692975665
+Validation score improved (0.23763930473638617 --> 0.21925333692975665). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1976, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1126, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1624, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1641, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1138, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2101, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1729, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1350, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1272, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4222, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0962, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3728, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1308, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1159, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2205, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1714, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1733, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1850, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3438, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1106, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1206, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3930, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3629, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1450, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1470, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1279, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :11 | Validation Loss :0.17870351267249687
+Validation score improved (0.21925333692975665 --> 0.17870351267249687). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0983, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0921, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1093, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1153, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1134, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1567, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3324, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2903, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0974, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1430, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1400, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0813, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3084, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1334, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2820, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1073, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1243, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1061, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :12 | Validation Loss :0.1457341452655585
+Validation score improved (0.17870351267249687 --> 0.1457341452655585). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1167, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0713, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0891, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1354, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1223, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3283, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1215, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0734, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3221, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0588, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1830, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1087, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0773, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1255, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1237, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1312, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1315, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1068, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1050, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2982, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0941, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :13 | Validation Loss :0.12447443094266497
+Validation score improved (0.1457341452655585 --> 0.12447443094266497). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0990, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1006, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0757, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0779, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1044, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3205, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1212, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3155, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2673, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1427, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1098, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2395, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1129, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1062, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0887, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2906, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2579, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :14 | Validation Loss :0.11513002969972465
+Validation score improved (0.12447443094266497 --> 0.11513002969972465). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1313, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0975, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1332, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1021, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0818, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3226, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1666, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0719, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0529, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1056, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1121, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2460, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1123, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1083, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2984, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0477, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0732, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0699, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :15 | Validation Loss :0.11436956092391325
+Validation score improved (0.11513002969972465 --> 0.11436956092391325). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1147, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0549, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0584, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0727, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1242, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1059, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0480, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0467, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0738, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0526, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1099, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1154, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0938, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0996, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2843, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :16 | Validation Loss :0.11504490406292936
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1139, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0535, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0890, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0915, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0533, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1221, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0959, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3137, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0702, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0459, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1074, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3059, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0444, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2588, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0487, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1282, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1013, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0988, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2294, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1045, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0933, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0442, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0588, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2808, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0429, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1113, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :17 | Validation Loss :0.1054413977848447
+Validation score improved (0.11436956092391325 --> 0.1054413977848447). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1276, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0900, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0925, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0534, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1284, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1379, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3353, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0793, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0461, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1198, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3252, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0459, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2740, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0674, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0489, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0574, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1037, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1075, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2442, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1070, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1049, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0587, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0815, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2672, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0802, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0652, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :18 | Validation Loss :0.11104392195525377
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0823, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1096, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1038, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2636, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0764, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0452, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0934, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2560, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0435, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2172, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1076, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0875, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0930, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1965, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0924, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0432, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1018, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :19 | Validation Loss :0.09355350543299447
+Validation score improved (0.1054413977848447 --> 0.09355350543299447). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0488, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0809, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0832, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0533, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1120, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1064, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2549, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0421, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2188, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1358, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0762, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1111, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0892, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0941, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1951, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0946, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0825, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0495, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2389, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0809, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1016, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2134, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0494, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0730, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :20 | Validation Loss :0.09352582717395347
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1005, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0591, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1058, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0780, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2165, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1207, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0582, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0448, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0504, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1109, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1685, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0430, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2000, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0732, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1020, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1823, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0520, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :21 | Validation Loss :0.08604109959433907
+Validation score improved (0.09355350543299447 --> 0.08604109959433907). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0889, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0686, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0537, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0924, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0568, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0740, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1937, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0851, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0486, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1860, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0407, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0543, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0433, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0966, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0827, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0754, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0788, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1465, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0790, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0408, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0486, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0628, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0539, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :22 | Validation Loss :0.07861007750034332
+Validation score improved (0.08604109959433907 --> 0.07861007750034332). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0848, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0547, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0419, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0776, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0484, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1763, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0402, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1010, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0424, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0477, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0870, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0734, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1393, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0457, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0396, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0400, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0893, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1498, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0604, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :23 | Validation Loss :0.0745796698105076
+Validation score improved (0.07861007750034332 --> 0.0745796698105076). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0477, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0518, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1017, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0916, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0797, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0434, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0844, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1229, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0585, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0878, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0817, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0850, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1759, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0854, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0473, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0407, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0517, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0691, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2120, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0733, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0411, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0936, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1922, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0483, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0682, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0569, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :24 | Validation Loss :0.08584532263162344
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0700, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0453, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0551, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0888, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0747, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0413, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2018, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0396, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1710, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1144, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0659, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0928, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0863, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0808, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1582, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0811, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0389, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1848, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0393, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0896, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1706, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0555, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :25 | Validation Loss :0.08020532803367013
+EarlyStopping counter: 2 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0480, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0519, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0442, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0846, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0538, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0923, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0679, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0423, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0479, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1725, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1491, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1007, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0510, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0468, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0952, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0774, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1385, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0722, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0746, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0415, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0463, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1625, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0942, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1478, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0581, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0503, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :26 | Validation Loss :0.0750525228517211
+EarlyStopping counter: 3 out of 3
+Early stopping
+Predicting for OOF
+******************day and time:2021_02_22*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(4.5524, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.6958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4562, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.3735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(10.9535, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.7175, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.4748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.2886, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2445, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(13.6961, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.1196, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(17.7019, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(19.3655, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(13.3893, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.6999, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.5416, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(19.2695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(15.8155, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(18.3138, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(17.4378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(19.7025, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(14.0407, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(9.8780, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(16.0887, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.2574, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.6852, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.1442, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(15.6566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.5766, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.8984, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.0662, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(17.4688, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.1158, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(15.8300, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(8.3250, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.7966, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(12.7859, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(17.9163, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.6514, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(16.2405, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(16.5277, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(19.3803, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(19.5329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0395, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(7.9548, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.7563, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :10.770071273264678
+Validation score improved (inf --> 10.770071273264678). Saving model!
+******************day and time:2021_02_22*******************
+Starting training....
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(2.0909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9163, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4150, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.8056, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4617, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1800, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3289, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.0378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2869, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.3966, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6227, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.1371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.2509, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.9397, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.9173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.5750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.1838, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3911, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.2860, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1677, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.3528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5564, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(4.8661, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2785, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4973, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.2902, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(3.6346, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.3023, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7683, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.0233, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.1445, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(6.6828, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5247, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.6945, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.2117, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(5.4720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8897, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6251, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9722, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :1 | Validation Loss :3.312436337056367
+Validation score improved (inf --> 3.312436337056367). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.6196, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6454, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7007, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6377, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6404, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6122, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2302, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7138, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7546, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1690, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8737, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8182, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6375, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1838, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1088, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6096, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6218, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3051, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.2488, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7879, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7266, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8987, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8901, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7773, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4599, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6506, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6492, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9164, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6401, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8622, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :2 | Validation Loss :0.9955668591934702
+Validation score improved (3.312436337056367 --> 0.9955668591934702). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.9347, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7889, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4280, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6155, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8181, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1814, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8566, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4920, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8248, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8558, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9574, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0310, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8895, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(2.4609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7633, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1821, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9356, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.7711, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4107, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8395, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3368, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8384, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.9364, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6297, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8187, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9030, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8397, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7592, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8259, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4291, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9246, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9386, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.4951, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0606, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9373, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9060, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :3 | Validation Loss :1.0892849849618
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.9119, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.6236, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8597, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1522, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7910, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3515, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9302, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9337, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8958, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8179, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.1872, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9585, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8976, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7793, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9031, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8203, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9318, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8334, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3197, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9578, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9004, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8152, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8191, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.8653, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0366, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0144, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7363, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8995, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7370, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0448, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8574, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9516, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9320, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.3883, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9239, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.9228, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8580, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.5641, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :4 | Validation Loss :0.9916795751322871
+Validation score improved (0.9955668591934702 --> 0.9916795751322871). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.5076, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5433, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6569, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4912, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3924, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4109, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4089, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4756, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4167, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3902, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4965, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5739, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4257, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4393, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8102, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5139, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7576, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5399, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5726, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0986, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4231, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6817, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3905, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4382, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3992, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7968, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4892, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3949, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6740, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5201, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6373, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4024, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6553, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4309, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4466, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3904, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4252, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5069, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6913, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :5 | Validation Loss :0.5187206708866617
+Validation score improved (0.9916795751322871 --> 0.5187206708866617). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3939, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2675, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3601, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3536, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2909, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3464, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4335, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3213, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5131, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4217, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5952, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2661, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2907, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2932, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2760, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2657, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2603, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3976, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4213, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2901, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2706, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2659, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2803, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2913, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3959, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4590, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6840, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3666, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4082, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2911, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3738, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2957, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4220, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2924, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3235, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2981, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :6 | Validation Loss :0.3586926525053771
+Validation score improved (0.5187206708866617 --> 0.3586926525053771). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2563, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2271, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2678, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4781, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2547, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3501, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3431, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2653, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3028, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3910, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2307, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2272, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3194, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2505, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2618, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4639, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4352, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2295, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4401, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2356, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3388, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2268, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2264, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3121, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2337, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3616, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2359, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8281, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3069, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4387, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2448, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2888, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2481, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3100, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :7 | Validation Loss :0.32420875002508576
+Validation score improved (0.3586926525053771 --> 0.32420875002508576). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3475, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2252, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2961, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2637, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2262, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2293, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2841, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2424, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2240, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3890, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2343, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3127, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2451, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5316, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2414, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2285, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2507, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2744, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2390, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2426, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2292, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2687, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2593, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2667, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3656, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5879, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3528, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4410, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3382, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5039, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6486, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7035, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3455, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4265, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3050, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2511, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3225, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3471, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :8 | Validation Loss :0.32809816560019617
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3443, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2189, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2277, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2288, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2401, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5435, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1835, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1778, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4268, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2161, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2720, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4555, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1927, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1883, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1716, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3686, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2081, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2248, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1735, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2058, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2055, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2965, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2103, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1718, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1750, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5165, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1865, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2253, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2933, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3477, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1785, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3757, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1684, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1902, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2012, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2029, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1914, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :9 | Validation Loss :0.25039403108151065
+Validation score improved (0.32420875002508576 --> 0.25039403108151065). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3019, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1380, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1708, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1648, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2575, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6088, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4440, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3632, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2529, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1656, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5034, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1691, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4189, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3385, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1696, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1642, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4156, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2404, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1388, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1500, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1653, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2482, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2666, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1439, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1666, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1790, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1413, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1791, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.7143, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2840, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1450, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1458, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4013, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4446, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1448, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1364, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2559, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1989, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3095, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1507, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3577, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2930, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1972, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1596, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :10 | Validation Loss :0.2635927725097407
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1844, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.8344, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3748, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1636, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1552, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1876, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3020, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1502, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6884, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3312, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0675, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5160, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4663, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2953, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1929, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1777, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5654, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3098, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3110, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1789, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1792, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2609, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2399, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5556, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2583, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1892, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2881, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3895, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5697, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5121, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3753, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1620, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1768, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1673, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4039, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2765, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6300, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(1.0544, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1945, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :11 | Validation Loss :0.3582996894483981
+EarlyStopping counter: 2 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1404, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1002, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1071, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0693, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0654, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0786, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2860, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0814, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0840, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1115, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0710, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2499, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1089, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1896, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1088, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1378, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1808, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0978, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0821, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0932, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3545, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1369, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1026, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2128, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1736, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1542, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1137, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1336, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1561, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2513, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1233, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0856, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0880, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1018, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1319, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1341, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0972, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :12 | Validation Loss :0.12372399234901303
+Validation score improved (0.25039403108151065 --> 0.12372399234901303). Saving model!
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.1933, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1252, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0736, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1177, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1317, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0714, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1449, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0862, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2270, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6387, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0980, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0839, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1663, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0753, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2849, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0829, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0704, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1603, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1523, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1194, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1039, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2439, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0910, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.4230, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1327, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1428, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1277, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2005, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1497, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0943, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1329, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0731, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1432, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0761, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1298, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2779, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1348, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :13 | Validation Loss :0.14448995693870212
+EarlyStopping counter: 1 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.2050, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0767, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0726, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1531, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0816, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1275, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0742, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2617, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1753, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1066, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1471, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3739, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1097, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2868, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1794, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2950, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0751, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1157, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1054, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5388, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0799, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0905, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1755, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1371, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1429, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3122, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2109, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0961, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3343, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2647, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1406, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0752, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0842, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0826, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0783, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3190, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1510, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0798, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2116, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2521, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1063, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1486, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1838, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :14 | Validation Loss :0.1649181118801884
+EarlyStopping counter: 2 out of 3
+HBox(children=(FloatProgress(value=0.0, max=185.0), HTML(value='')))
+
+HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))
+tensor(0.3060, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1072, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0981, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1635, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1533, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1796, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3219, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0775, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1462, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1046, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2663, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1824, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1238, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.5441, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2048, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1090, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2571, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1572, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2278, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1244, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2144, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2256, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0595, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0914, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1961, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3181, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2312, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.6695, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0675, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0810, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1503, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1330, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1241, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1512, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.2228, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0781, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.3405, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1420, device='cuda:0', grad_fn=<AddBackward0>)
+tensor(0.1042, device='cuda:0', grad_fn=<AddBackward0>)
+
+Epoch :15 | Validation Loss :0.17404202217965023
+EarlyStopping counter: 3 out of 3
+Early stopping
+Predicting for OOF
+[3.312436337056367, 0.9955668591934702, 1.0892849849618, 0.9916795751322871, 0.5187206708866617, 0.3586926525053771, 0.32420875002508576, 0.32809816560019617, 0.25039403108151065, 0.2635927725097407, 0.3582996894483981, 0.12372399234901303, 0.14448995693870212, 0.1649181118801884, 0.17404202217965023]
+time-cost: 232.26156597332252
Index: src/com/util/alice_ae_user_correlation.tsv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/alice_ae_user_correlation.tsv b/src/com/util/alice_ae_user_correlation.tsv
new file mode 100644
--- /dev/null	(date 1616247294000)
+++ b/src/com/util/alice_ae_user_correlation.tsv	(date 1616247294000)
@@ -0,0 +1,8327 @@
+user	correlation
+43	0.11403017010113935
+43	0.1681841878319343
+43	0.031960831000659586
+43	0.3449381780958701
+43	0.16989425366031818
+43	0.2353568174772804
+43	0.31660672701417797
+43	0.34776341635036656
+43	0.08028529924640922
+43	0.06421765146298315
+43	0.3382053817856386
+43	0.2764180952335059
+43	0.21374390371381602
+43	0.2625643094790833
+43	0.12236630469779675
+43	0.2511640981057912
+43	0.3228562353844575
+43	0.15598535631172122
+43	0.14598699157173103
+43	0.22024820958939753
+43	0.18273647635820162
+43	0.17839487637304652
+43	0.3247871355440258
+43	0.08698964449162848
+43	0.1517265237579528
+43	0.1459794876434065
+43	0.30493895953008315
+43	0.14617381916185349
+43	0.16844584925629272
+43	0.23640457132897175
+43	0.26464127976663443
+43	0.2963350378916287
+43	0.09421413770473305
+43	0.21295623779279116
+43	0.2522980964812347
+43	0.26961733956385525
+43	0.19471779523083185
+43	0.2127030074787842
+43	0.28679402099289936
+43	0.2990481530260136
+43	0.12021411461951131
+43	0.2258062520186139
+43	0.33566693934675135
+43	0.09094629326298809
+43	0.18193922068718332
+43	0.23486570259130393
+43	0.2060059505769813
+43	0.2043396796113702
+43	0.20288797021014418
+43	0.06805387879699079
+43	0.2212674298198252
+43	0.19456101340600468
+43	0.2650497077340389
+43	0.32744398873975994
+43	0.2983738489456863
+43	0.1804241923234263
+43	0.3426609899012386
+43	0.07740885755407768
+43	0.2448920139257096
+43	0.17820278858918834
+43	0.34826855840794213
+43	0.3025317218368468
+43	0.11044659221157256
+43	0.17665467042333222
+43	0.11857427281625006
+43	0.1347152385012719
+43	0.23162085622297002
+43	0.14353440434462314
+43	0.22173797930416195
+43	0.20735531363267487
+43	0.14323547897822586
+43	0.2652558051562399
+43	0.23858822633845095
+43	0.21083783790381777
+43	0.24963434381677277
+43	0.3210756202254272
+43	0.042144965992744934
+43	0.2182308113591095
+43	0.30147654548691133
+43	0.15840838523153364
+43	0.14836846677934873
+43	0.15902632464524005
+43	0.3007169681487376
+43	0.2790250839136702
+43	0.18249145793059426
+43	0.16926447654342985
+43	0.3073897184454296
+43	0.3420565966734063
+43	-0.02832561093992691
+43	0.22956552605373068
+43	0.17616149310738127
+43	0.018968689972577613
+43	0.1703964375093881
+43	0.31949452695911024
+43	0.2809724689812485
+43	0.3014169808328927
+43	0.1643487684266619
+43	0.3166601383180221
+43	0.1687720057701684
+43	0.2534562141222509
+43	0.2584501926236369
+43	0.2890010517791338
+43	0.3207378812914851
+43	0.2961698097817756
+43	0.272727220268678
+43	0.16232720781678533
+43	0.1741421683157745
+43	0.1799955937390227
+43	0.15009688880948627
+43	0.2482911772330741
+43	0.06709180589129664
+43	0.2386437791393782
+43	0.1897007870766917
+43	0.322957837277072
+43	0.25047657422742636
+43	0.2152247135311751
+43	0.18679672839213507
+43	0.2664407698764056
+43	0.23513520435116395
+43	0.19016691295558538
+43	0.29844553687698755
+43	0.1771383020580925
+43	0.16517573847182127
+43	0.3050954027322172
+43	0.16785352668673204
+43	0.1222039212606433
+43	0.20706740140669677
+43	0.2004750991809704
+43	0.31092447325282324
+43	0.09775575117266648
+43	0.1407549255895874
+43	0.17811710728941701
+43	0.2383595968405162
+43	0.04650234785420651
+43	0.2903783532669648
+43	0.3416393310357882
+43	0.13632467415574767
+43	0.2498762027782875
+43	0.3244714050643421
+43	0.24180667444674336
+43	0.25964661132659644
+43	0.08877208789787322
+43	0.2638359582997712
+43	0.1251174139054552
+43	0.30020475971019656
+43	0.1360472870849814
+43	0.23731806661780994
+43	0.23558977120916336
+43	0.27349231666548535
+43	0.2572670412883379
+43	0.2976703332598033
+43	0.20454024052607025
+43	0.22239461851896145
+43	0.3315264277518003
+43	0.34732096244838273
+43	0.35096025891444016
+43	0.12426012595630692
+43	0.06471869835274881
+43	0.11608692492691362
+43	0.17446171446279596
+43	0.22881250678450082
+43	0.14180201052281838
+43	0.17560740711581244
+43	0.2502952308635587
+43	0.28939963050668177
+43	0.25429053961456616
+43	0.35149194356877983
+43	0.2742312046599948
+43	0.32717077848052944
+43	0.3117600552955781
+43	0.31157134635946
+43	0.2088075029216671
+43	0.11084812070984287
+43	0.13622844437991147
+43	0.2436475461141706
+43	0.23022167095692508
+43	0.22387861928562283
+43	0.253393812373135
+43	0.22775949195308895
+43	0.2751264043048084
+43	0.292083841480136
+43	0.29731263706373484
+43	0.12490807419576351
+43	0.12490434150999322
+43	0.3375126210953226
+43	0.1715030584103147
+43	0.2208040781308504
+43	0.2549440306234711
+43	0.014290870588950746
+43	0.2760611542751675
+43	0.14642560608864058
+43	0.23091545327303512
+43	0.11366905736336552
+43	0.22019399488991742
+43	0.22506966101429582
+43	0.15266642744261924
+43	0.2378493110917319
+43	0.3041200616381171
+43	0.35403991312344024
+43	0.2947597766501351
+43	0.3565970474771795
+43	0.30854271123976185
+43	0.03880764539266344
+43	0.1512995293331454
+43	0.2033429868029366
+43	0.20042897534299772
+43	0.12369659840376238
+43	0.15638387287553
+43	0.21516874399671437
+43	0.3076686966405701
+43	0.14200724674547913
+43	0.18717017659104018
+43	0.1740536649377862
+43	0.052503334259725025
+43	0.2617310828149922
+43	0.1494974874355685
+43	0.3508571369975375
+43	0.21852915964296954
+43	0.05124274899400106
+43	0.19216095747352413
+43	0.15806412924841837
+43	0.14346185523315938
+43	0.2207746170452465
+43	0.22281266097887217
+43	0.36785389183725353
+43	0.2547491796517702
+43	0.30317597722720524
+43	0.2937956529610079
+43	0.20776853134241596
+43	0.2757861279186619
+43	0.25490595321203563
+43	0.3479307066570913
+43	0.30048768624725897
+43	0.16001903175655366
+43	0.3144915074860547
+43	0.1543287740261577
+43	0.2701377873370059
+43	0.2697098530761276
+43	0.12387576973996808
+43	0.17671763605681537
+43	0.2809522730337108
+43	0.22211744594622498
+43	0.3678202108043161
+43	0.2695620524838761
+43	0.2679888022499691
+43	0.33498610398404005
+43	0.17437819536417737
+43	0.10905087227507385
+43	0.1695375231070753
+43	0.12289001462252416
+43	0.05264449349449148
+43	0.36809061059510667
+43	0.2653511962914711
+43	0.20974256033983862
+43	0.24218793736287816
+43	0.27320232732567284
+43	0.29285283129113693
+43	0.15147235083289567
+43	0.2488566396810354
+43	0.3764054254448015
+43	0.12074662038121704
+43	0.27944227428463037
+43	0.1608607472240783
+43	0.04509599039572815
+43	0.21546361317210616
+43	0.0786468266500373
+43	0.30346809019249305
+43	0.27841068715342276
+43	0.006323287367622542
+43	0.3096210638857593
+43	0.24601201273056814
+43	0.1416629249101075
+43	0.1583681450748531
+43	0.06929234577361147
+43	0.2779689488320987
+43	0.25781728146033545
+43	0.12758751927445533
+43	0.2745299855734273
+43	0.2834546273296207
+43	0.1656271255053868
+43	0.3432006068467472
+43	0.23128776285882377
+43	0.11610238352892592
+43	0.30470222512190126
+43	0.11532652876715604
+43	0.1642473594725843
+43	0.049930464233416315
+43	0.06992068971859854
+43	0.2959308734851669
+43	0.08119363410549918
+43	0.08262893135777542
+43	0.3076542626909777
+43	0.33669349998041614
+43	0.17953097882867008
+43	0.2502055118933805
+43	0.2665586267723028
+43	0.2522456251663288
+43	0.25918123585049496
+43	0.18622040347474297
+43	0.06772487553559116
+43	0.2535978857079979
+43	0.14165937385479163
+43	0.25925532677158963
+43	0.11947284639201464
+43	0.20446012631158525
+43	0.26410318708649516
+43	0.27155799448521184
+43	0.1947970968352214
+43	0.20015533405399089
+43	0.10997292486357864
+43	0.2902490858717171
+43	0.17002066529334234
+43	0.0631692055793777
+43	0.06364122444778315
+43	0.2712785542378578
+43	0.28795826078020437
+43	0.13307105921700235
+43	0.18702293873757847
+43	0.32933200829257936
+43	0.2750843775715407
+43	0.2749768157583548
+43	0.3034471895332589
+43	0.1636538655068685
+43	0.22430322859545193
+43	0.11310875176378209
+43	0.19996504730080514
+43	0.10447453822773588
+43	0.22882457340097268
+43	0.1796596030080772
+43	0.2650263038774593
+43	0.26912789670229076
+43	0.1801114112100047
+43	0.17833238537468002
+43	0.19474996246617016
+43	0.3428904607344088
+43	0.3831280276135859
+43	0.2285998898930359
+43	0.3216146991667769
+43	0.11472873656576518
+43	0.29130337096401626
+43	0.17066280224037012
+43	0.19173957781233153
+43	0.18354636464809068
+43	0.2756133458870944
+43	0.2791622534523819
+43	0.30989423153126056
+43	0.1981017243636562
+43	0.25931208721218746
+43	0.20809182004275173
+43	0.2826096046729474
+43	0.13452434013424103
+43	0.30081632224660515
+43	0.235063108517205
+43	0.19152422918811202
+43	0.3046514389966838
+43	0.32075563667987866
+43	0.25620179640123203
+43	0.3209336684266449
+43	0.10319570358602474
+43	0.27119375634561405
+43	0.13308280373422465
+43	0.274743650827368
+44	0.3139893091797585
+44	0.2465606731081099
+44	0.3610315951472438
+44	0.32901680744464185
+44	0.3676606206731424
+44	0.3726216830215787
+44	0.15090123161166222
+44	0.25837139422435657
+44	0.32142208786517124
+44	0.1677137936379079
+44	0.20845216066864536
+44	0.2362283585201197
+44	0.3461166179206529
+44	0.3076265352229735
+44	0.2830497042588931
+44	0.1717078937905245
+44	0.24825191409875058
+44	0.3115270326821025
+44	0.360046285549089
+44	0.2813854411135801
+44	0.2893125611580516
+44	0.2987681569969212
+44	0.21286569732692517
+44	0.21025660642127103
+44	0.2000466117738424
+44	0.23215324079999558
+44	0.3228998066484453
+44	0.3164459773757336
+44	0.23016806137058485
+44	0.27196801775914087
+44	0.30778530994425324
+44	0.33869066558183863
+44	0.3153066428178991
+44	0.32609316876303385
+44	0.312314400516292
+44	0.21898890358226614
+44	0.2619614204925233
+44	0.17363326779379037
+44	0.25392499284712633
+44	0.3413209325660068
+44	0.1350921992093946
+44	0.23331636366083955
+44	0.2825971116867834
+44	0.2776753809119032
+44	0.17087988239282112
+44	0.15994623723895615
+44	0.2801080797475355
+44	0.27501071606831434
+44	0.3777513263810527
+44	0.20613834501871395
+44	0.17738285844644122
+44	0.18620122502593686
+44	0.36063422315259064
+44	0.25283781763718616
+44	0.25748409552558005
+44	0.1683981610502245
+44	0.28451082212114925
+44	0.24779892802940207
+44	0.3266300649262513
+44	0.3328253474793279
+44	0.3548978020904546
+44	0.29905483277550626
+44	0.39772757024469585
+44	0.29638297675625
+44	0.2741318119616943
+44	0.33595477755223113
+44	0.3016550273046715
+44	0.1373695853891428
+44	0.24368478290205933
+44	0.2862931635735608
+44	0.2931019221596687
+44	0.29926990887884786
+44	0.2739367128977608
+44	0.30214214253073207
+44	0.32476820045250143
+44	0.2913381360952437
+44	0.29096170622183226
+44	0.27449258902527696
+44	0.28012696085779754
+44	0.15574517730134205
+44	0.2825785865011688
+44	0.2300775203152931
+44	0.25853547209571853
+44	0.28238341010287965
+44	0.3140153638640349
+44	0.39529070745917877
+44	0.2849520836030939
+44	0.29438380614998927
+44	0.29271898784889905
+44	0.17297769162474866
+44	0.3748015328511841
+44	0.3322096816664548
+44	0.2755177409913432
+44	0.3480104135102054
+44	0.2518002605613583
+44	0.3164808003286015
+44	0.1527080353459906
+44	0.28331847670829136
+44	0.42917240773121984
+44	0.387185429026451
+44	0.3848468022073514
+44	0.26398746835698383
+44	0.271474559137878
+44	0.310041510944567
+44	0.26369626206114877
+44	0.27045240918427377
+44	0.28725342042020163
+44	0.3529902054318998
+44	0.17786147931855562
+44	0.24865742489715545
+44	0.23018484179579976
+44	0.29300368106705055
+44	0.12954435377694518
+44	0.29813425431301877
+44	0.3691967384352837
+44	0.2478028850208033
+44	0.29662520007932713
+44	0.3531301459698744
+44	0.21043442603701987
+44	0.2353250772460932
+44	0.1563591015595463
+44	0.35395270573269866
+44	0.16610102670655405
+44	0.26583681612331156
+44	0.2588174632052826
+44	0.24195721555696026
+44	0.32929503986035324
+44	0.29061206320676525
+44	0.31138025276818504
+44	0.3090381139779811
+44	0.36972645165071144
+44	0.2908060168179854
+44	0.22524326993801316
+44	0.28067805017350805
+44	0.29048029128243097
+44	0.3012331700391779
+44	0.3715629269579639
+44	0.12649171255019193
+44	0.21439618843560493
+44	0.24762253574479337
+44	0.35018268440268535
+44	0.2780588799428744
+44	0.32637607446835676
+44	0.2901949736632964
+44	0.278839866937761
+44	0.18787863528867485
+44	0.36246076395248805
+44	0.35995577677389257
+44	0.22078595024565392
+44	0.27211544533513593
+44	0.24950834321276902
+44	0.2611685207578796
+44	0.294545717304918
+44	0.14589652010858142
+44	0.15264388577569044
+44	0.24653837786040297
+44	0.32476292553451735
+44	0.31500734057578195
+44	0.35987066532714557
+44	0.255000270145929
+44	0.38664017646581045
+44	0.07964170107603866
+44	0.22852103394712023
+44	0.2933409954142139
+44	0.2984080374508848
+44	0.323361690359743
+44	0.28096860557898656
+44	0.20854091612274553
+44	0.29204558932075164
+44	0.24681733274508297
+44	0.32417755406129534
+44	0.07776167767268852
+44	0.07960165510017773
+44	0.29680257259459686
+44	0.25584683733148833
+44	0.28449530896148095
+44	0.30249770726007075
+44	0.309927828168652
+44	0.25293570577505736
+44	0.16243557246303028
+44	0.16096837335559355
+44	0.3028372901510476
+44	0.2490415214776401
+44	0.36204874863707665
+44	0.3868322972163872
+44	0.377266547185381
+44	0.18515955388319538
+44	0.3428666565994219
+44	0.3016880411360726
+44	0.3301881781525116
+44	0.33167241434967887
+44	0.2506333636016607
+44	0.2448223677273963
+44	0.23789893651410046
+44	0.23357556305596805
+44	0.17096465385833562
+44	0.3081368216569758
+44	0.26688022499666614
+44	0.16296474060115063
+44	0.23245058678608932
+44	0.1688852293892632
+44	0.25151710736820315
+44	0.2972686103924004
+44	0.18702034596902647
+44	0.28404753738167515
+44	0.2874651558267844
+44	0.25084144498051014
+44	0.25696693184872826
+44	0.24793595099167753
+44	0.2803209864475393
+44	0.3403654136146932
+44	0.13115309612769505
+44	0.29813457596968046
+44	0.3040328134720477
+44	0.3103418232629314
+44	0.36221641009862027
+44	0.3050153572410707
+44	0.30662854172396853
+44	0.31564828133936457
+44	0.3853366238847844
+44	0.2939916077699927
+44	0.19562714330605427
+44	0.3308590735238194
+44	0.20541113693191893
+44	0.315502649448682
+44	0.31124325235334394
+44	0.29499035137796326
+44	0.22353358474945245
+44	0.12133091588759691
+44	0.3300173746549932
+44	0.3099811501554115
+44	0.33010882146553455
+44	0.25372409511901084
+44	0.3089610079381597
+44	0.3037066014731409
+44	0.14391657433733004
+44	0.24153396503938315
+44	0.3257368607705629
+44	0.24775634031187208
+44	0.2507595317899929
+44	0.2607484988776985
+44	0.2777591035732358
+44	0.35837974385133753
+44	0.2632155617365323
+44	0.2581180298972077
+44	0.31951878337824563
+44	0.16837347878939835
+44	0.3402194713937318
+44	0.31740432567818994
+44	0.15575232069465428
+44	0.30272493967241315
+44	0.36967865231354957
+44	0.34323562374662175
+44	0.2594287772509987
+44	0.318721010105288
+44	0.3107746190644175
+44	0.2078838899836241
+44	0.3944164750278043
+44	0.34505869236880476
+44	0.29217475779180285
+44	0.2800273573842377
+44	0.33957117273450776
+44	0.3806797610777825
+44	0.3190252385544487
+44	0.3643451349205431
+44	0.1753173600285122
+44	0.3073995444092423
+44	0.2893022364677881
+44	0.2728479103738053
+44	0.30232012414196335
+44	0.2792987491863055
+44	0.35513922630718536
+44	0.3267687854703816
+44	0.3443488803295483
+44	0.2667112652287543
+44	0.3468655739840144
+44	0.38439964479989763
+44	0.2757628050892872
+44	0.28706240995068777
+44	0.34496151946091863
+44	0.33064063107443453
+44	0.23379002918665923
+44	0.3385138597928797
+44	0.308932573277822
+44	0.33881501280638554
+44	0.33588916746191577
+44	0.3760615644131266
+44	0.27050755113284636
+44	0.35192144735756997
+44	0.3558357347306987
+44	0.35667426015436937
+44	0.27583985530656563
+44	0.3097706513176945
+44	0.273906478984925
+44	0.3125802751876511
+44	0.40362421959189554
+44	0.35550940074511617
+44	0.2358958363765704
+44	0.32203423458192576
+44	0.3401895644712389
+44	0.27678553262885064
+44	0.21085476038911227
+44	0.3254616764843146
+44	0.3464583652826352
+44	0.2790654926687265
+44	0.19098558653107162
+44	0.24804599400711377
+44	0.2889943173427713
+44	0.33980187275518986
+44	0.3308971675970963
+44	0.3525928246108765
+44	0.3527561632171438
+44	0.35164652218051357
+44	0.3233791036730534
+44	0.2567165891782379
+44	0.31359603835776123
+44	0.26343299759450406
+44	0.28779798960395814
+44	0.28787047241609465
+44	0.275752057169015
+44	0.36999177082749757
+44	0.15367966022441493
+44	0.29334733917176736
+44	0.23878423001079715
+44	0.2706251259508399
+44	0.3127501404473093
+44	0.2467159644227243
+44	0.24886717343868034
+44	0.22586061672119595
+44	0.3096013326689452
+44	0.2946543670579343
+44	0.3325230606544388
+44	0.34748048285543065
+44	0.3174728185682369
+44	0.28807321754473036
+44	0.27894828651928266
+44	0.33692265154339707
+44	0.34476070499222095
+44	0.2931591005237054
+44	0.3245641137125743
+44	0.38830467602307117
+44	0.33823661988486103
+44	0.28425219402746793
+44	0.09361418261221183
+44	0.30235732034720786
+44	0.18622895184680519
+44	0.2944141295741074
+44	0.2862215470544597
+44	0.3709847516583189
+44	0.34918654175904357
+44	0.24893233239840895
+44	0.3489999620816216
+44	0.26151317274677727
+44	0.29781108343621365
+44	0.33086851910783815
+44	0.32991266846069484
+44	0.29809100555499973
+44	0.32452773726801937
+44	0.14353456697701963
+44	0.2066654897252491
+44	0.35075269762878575
+44	0.3223690513283778
+35	0.355681107311671
+35	0.2659217707109207
+35	-0.019094566973099875
+35	0.2139352923590816
+35	0.29433752017819015
+35	0.11000453585311167
+35	0.24962221041496888
+35	0.28257759449659037
+35	0.31864858465803325
+35	0.2783180722357167
+35	0.08716305407902514
+35	0.27285456580992656
+35	0.20985565649243307
+35	0.20156309427639363
+35	0.30297228560375883
+35	0.2532548745101401
+35	0.14522957884239704
+35	0.29564194227253315
+35	0.19394133001655484
+35	0.0021651972612148473
+35	0.23077901643120854
+35	0.32833870589582287
+35	0.2357506329390743
+35	0.2890597914172829
+35	0.23492955658701303
+35	0.2544576664848498
+35	0.04480515965324399
+35	0.237361195154522
+35	0.2943659493573765
+35	0.26904266840020685
+35	0.32605349421863944
+35	0.15627669537658168
+35	0.2655626534951524
+35	0.07466810089947921
+35	0.021775167267366426
+35	0.25796962619957287
+35	0.022310676538692845
+35	0.27973018436193653
+35	0.3117818290432497
+35	0.3153217517365836
+35	0.20273205691689095
+35	0.3120687860835945
+35	0.32198899106908074
+35	0.21854292874501705
+35	0.15308946090177905
+35	0.2865433920434059
+35	0.23483501696794207
+35	0.3540163748203968
+35	0.2694676816339
+35	0.05784989953158701
+35	0.21705329721233332
+35	0.28398821409793645
+35	0.011273430532397245
+35	0.343595649987848
+35	0.2771564379689094
+35	0.3102062370026945
+35	0.29655614803349584
+35	0.11800193866906124
+35	0.04236620633772661
+35	0.20237849294975294
+35	0.20069127129144193
+35	0.2622103972316715
+35	0.027235025158110743
+35	0.07195660961539363
+35	0.08826304394432541
+35	0.2575179605184221
+35	0.20423426763468985
+35	0.34815381497206227
+35	0.3065769574396721
+35	0.24261272535739864
+35	0.29240200499197133
+35	0.32435141097657927
+35	0.26495117831883996
+35	0.11938487413167592
+35	0.3510083295313453
+35	0.276961787109417
+35	0.30689491734177454
+35	0.31101818643381757
+35	0.10627071705569416
+35	0.31627096570501595
+35	0.27580647432753264
+35	0.08323639586356643
+35	0.303543403019393
+35	0.29015667543760804
+35	0.28623725521648474
+35	0.3275458979195667
+35	0.24442769883865129
+35	0.25000683587920364
+35	0.2586347163470989
+35	0.1243900814912062
+35	0.27595249443491887
+35	0.2467917239465574
+35	0.31117958173661153
+35	0.0916134711556194
+35	0.31441568654613566
+35	0.1882559781824197
+35	0.35159671555782046
+35	0.3358442315012207
+35	0.26630093127722015
+35	0.30555020330448973
+35	0.3425775679058296
+35	0.2788216604453484
+35	-0.0023420359800981365
+35	0.23190006072922345
+35	0.3250275539612762
+35	0.3949258905147076
+35	0.26142782313779295
+35	0.250950414646827
+35	0.1965003190987891
+35	0.26605852749040315
+35	0.27730301913514716
+35	0.2899782906884653
+35	0.26684065258169193
+35	0.2240938935246077
+35	0.2027158817898577
+35	0.3154143635021694
+35	0.25181258688857444
+35	0.06271019371760105
+35	0.28059262410031555
+35	0.2616084448843407
+35	0.21795023084839749
+35	0.29200440465285343
+35	0.19352280883286044
+35	0.024386103548767774
+35	0.04705642567159821
+35	0.24754894793938914
+35	0.22589172736058133
+35	0.2830110867641809
+35	0.25269813738108815
+35	0.17886645107114948
+35	0.3285667709146849
+35	0.28295115492614703
+35	0.3052827978976589
+35	0.21409911837751838
+35	0.21016942551169662
+35	0.09031394410780591
+35	0.18177446530639974
+35	0.028369341337036245
+35	-0.0003044149295466696
+35	0.08240567927832294
+35	0.2674957019894185
+35	0.04239183187133258
+35	0.3145117980611312
+35	0.26425585050683975
+35	0.20927264411548635
+35	0.21406334641736854
+35	0.30959544394669625
+35	0.3487571525978533
+35	0.21147691313948355
+35	0.2717754954932169
+35	0.201997899128513
+35	0.34818601348871064
+35	0.2724558293702266
+35	0.008863303973222441
+35	0.17423085088456275
+35	0.32263787166004343
+35	0.2422645619365103
+35	0.2935675835230312
+35	0.3649158915883925
+35	0.2903926327029079
+35	0.15570936383028866
+35	0.2261161026099275
+35	0.3024072766718291
+35	0.21458878395311412
+35	0.019911396175720766
+35	0.28823153485622377
+35	0.06733231875107151
+35	0.3060481762641735
+35	0.011813781134834852
+35	0.29745956180783545
+35	0.1308290681184207
+35	0.18064494699749425
+35	0.29087074594583334
+35	0.19984339589201996
+35	0.3163565028332679
+35	0.25138108690527083
+35	0.3111386553529869
+35	0.3286937249587708
+35	0.27900567758202904
+35	0.10091740126550351
+35	0.26991574919641165
+35	0.25097170837324423
+35	0.27155317256988815
+35	0.33038228160047367
+35	0.2516217345149011
+35	0.3406090269310491
+35	0.27124817105453547
+35	0.38718954061965694
+35	0.2437570880202163
+35	0.24757133681888155
+35	0.010899806872854486
+35	0.19186425504350757
+35	0.2155026799416989
+35	0.22893802894959533
+35	0.2518038399517947
+35	0.09571929513783775
+35	0.2010467106599117
+35	0.05725513311041212
+35	0.3219159110463841
+35	0.26014477846821965
+35	0.36243596228692343
+35	0.2950759641092358
+35	0.2709640493241721
+35	0.2769962276407817
+35	0.33385715453192055
+35	0.09260629008413564
+35	0.2572628803832184
+35	0.2034069303806499
+35	0.02984994205569575
+35	0.24454577364263003
+35	0.31194416629583177
+35	0.25483479889949373
+35	0.13224113112414124
+35	0.3646696915677139
+35	-0.014369177042450818
+35	0.07247049933520464
+35	0.29293603631781256
+35	0.25526983276807597
+35	0.02183969556686816
+35	0.25606502499119
+35	0.3213419762493409
+35	0.25649331343019155
+35	0.2802019938164434
+35	0.27014243756968664
+35	0.3651393768141036
+35	0.177643773710916
+35	0.27764175154987003
+35	0.24704943704436028
+35	0.2529655847462629
+35	0.4171853082087414
+35	0.2862142686461204
+35	0.29440964757367566
+35	0.25916804491120465
+35	0.16411605589126585
+35	0.2577530078514182
+35	0.2761205840428488
+35	0.2994009605078701
+35	0.28362768793586574
+35	0.33939769718449025
+35	0.33206470331062543
+35	0.3101233415707933
+35	0.33540664264476455
+35	0.2403911454462104
+35	0.28720621661334805
+35	0.2976472701871604
+35	0.2690530355836842
+35	0.2767878759890302
+35	0.20921394157326553
+35	0.26928279221237655
+35	-0.020824630790508433
+35	0.2255404959891985
+35	0.29120184916005176
+35	0.25826348547640776
+35	0.2876616822289149
+35	0.27844317770219873
+35	0.19411141228563777
+35	0.3033491824491468
+35	0.3323989337216843
+35	0.26107292275877153
+35	0.30139254148110395
+35	0.20447302243703594
+35	0.34868967754063257
+35	0.3376645266924081
+35	0.2573983573958457
+35	0.18196993941663017
+35	0.3194398751527664
+35	0.03725502995222876
+35	0.3109290970698052
+35	0.24177492250462498
+35	0.3236999027884667
+35	0.3288642099890818
+35	0.11875875081539237
+35	0.2766909152739585
+35	0.28925497416755347
+35	0.03578875279448988
+35	0.19510013219617095
+35	0.2357616737836276
+35	0.2407720840070598
+35	0.21406687254341086
+35	0.2365617782260212
+35	0.29073229570936765
+35	0.273982249748004
+35	0.06569237004952125
+35	0.27789976712548775
+35	0.28923129724454266
+35	0.2558178754507744
+35	0.2403591583681589
+35	0.30530465142251356
+35	0.3429239838285393
+35	0.24263137293154746
+35	0.3397199771367283
+35	0.18643650598014613
+35	0.135797892907839
+35	0.3302877531210997
+35	0.28175331434329604
+35	0.2700124503618883
+35	0.33405801684963116
+35	0.3700930917867664
+35	0.25141551484240693
+35	0.25947210846985064
+35	0.2654865608799841
+35	0.2696508672996097
+35	0.259995660754038
+35	0.259334846056448
+35	0.2814431557517872
+35	0.28436045153946105
+35	0.28797195110482465
+35	0.05121776769451492
+35	0.29755208946990486
+35	0.3427000013612055
+35	0.021174537090417424
+35	0.31083445421348077
+35	0.3367133351219282
+35	0.3585503251692032
+35	0.30805783434905004
+35	0.27773102548930434
+35	0.2610206098270667
+35	0.30349971737813614
+35	0.28886230617561076
+35	0.27287168584394866
+35	0.2586466496170631
+35	0.26607451296260326
+35	0.2648234999326705
+35	0.320913485199973
+35	0.3553903601227713
+35	0.17323813690268816
+35	0.27465221259250433
+35	0.2488790458235738
+35	0.2528496973205886
+35	0.30917813882796497
+35	0.3409316500794371
+35	0.2981008592606208
+35	0.24229869778614357
+35	0.29450455562200295
+35	0.316582531740773
+35	0.32629864874040954
+35	0.1490337904225916
+35	0.2989037714541906
+35	0.21575828035218803
+35	0.27073709396965095
+35	0.1989159289689635
+35	0.2902786214944312
+35	0.26732730448097897
+35	0.32383514025001736
+35	0.2707577900124964
+35	0.2323246595281816
+35	0.2509170415977858
+35	0.2789836045190961
+35	0.23858652564048288
+35	0.3015045192811951
+35	0.3257609003283449
+35	0.3201332114716912
+35	0.34437078093659046
+35	0.09776304882594973
+35	0.2865875060935323
+35	0.31257768342838294
+35	0.14795657133019505
+35	0.2499394453968933
+35	0.2434374466511577
+35	0.2255987642337354
+35	0.265479531426814
+35	0.21738365771199922
+47	0.3348516023685538
+47	0.3519223474992434
+47	0.29651336815864343
+47	0.2026076376576005
+47	0.2564316186124681
+47	0.25156523600826336
+47	0.20253588505583528
+47	0.40119210775007486
+47	0.46520435010188355
+47	0.16590292521511846
+47	0.23446323343286246
+47	0.3264014877789332
+47	0.3440461122544844
+47	0.36816125203606825
+47	0.20880901445179156
+47	0.2926235003248434
+47	0.2481967666279742
+47	0.31341796541375094
+47	0.26823539769362104
+47	0.3619367192961563
+47	0.23538139308496256
+47	0.25166309765140266
+47	0.17693176911026048
+47	0.19590347071899522
+47	0.18967953940127408
+47	0.2680382109304949
+47	0.34324723830684223
+47	0.33507669142036517
+47	0.09303564750045319
+47	0.20201671390754738
+47	0.18828946711117342
+47	0.15002251542544012
+47	0.26084869448741665
+47	0.3447701624561699
+47	0.3334790089603881
+47	0.12474213307928846
+47	0.24222181691565237
+47	0.3062314788091596
+47	0.3051983503905741
+47	0.17232367910230778
+47	0.3762036245594382
+47	0.32650450895118777
+47	0.11954868534652209
+47	0.16053980877278426
+47	0.31751014968717345
+47	0.22552815211371063
+47	0.09205504214572847
+47	0.2537527686808836
+47	0.28338877601851803
+47	0.20057694298923065
+47	0.37336395556849294
+47	0.3836359780737997
+47	0.40438229520677976
+47	0.24194488825490915
+47	0.22014569248963048
+47	0.4137019444547044
+47	0.19263854470977523
+47	0.19294675514467124
+47	0.39791676535600595
+47	0.3569687283544965
+47	0.4043017413123962
+47	0.33654346365751575
+47	0.18385038314843707
+47	0.3074232708484691
+47	0.2730696806062917
+47	0.2082930793927628
+47	0.2822339189172847
+47	0.33893750597155414
+47	0.3020926323357213
+47	0.28969998782022627
+47	0.30895096659316956
+47	0.3512233975285204
+47	0.2917486632020841
+47	0.15931336195099557
+47	0.30336105602512403
+47	0.3243194410829281
+47	0.285217305801867
+47	0.367609541241282
+47	0.20600756501464965
+47	0.27907664324915604
+47	0.25876864099387753
+47	0.23374217211192994
+47	0.2249410390006193
+47	0.34254788659094654
+47	0.3553716496383008
+47	0.37725193533494894
+47	0.28027967186985875
+47	0.2958569727304175
+47	0.1418537363233576
+47	0.26420317276279537
+47	0.2928014233117097
+47	0.38630888095965066
+47	0.4553953496497231
+47	0.3184130016780022
+47	0.36309719001249224
+47	0.2544013179954498
+47	0.21428691653611956
+47	0.3259032404138991
+47	0.26441010099348605
+47	0.3688222977185002
+47	0.30036705673796116
+47	0.22115690392198795
+47	0.21450108818599195
+47	0.4241302374222065
+47	0.36400625930460223
+47	0.3115219371975657
+47	0.19240974427686838
+47	0.294270314913156
+47	0.14963006272432763
+47	0.07840821864137694
+47	0.3822699950179057
+47	0.3153319227868089
+47	0.28585804669089376
+47	0.3035274388790308
+47	0.19236534728812468
+47	0.41787458614965045
+47	0.27803100057208535
+47	0.26207573020138136
+47	0.21504296452213234
+47	0.21153372156097194
+47	0.29785649227462396
+47	0.38517480576746366
+47	0.35538905467804505
+47	0.25935054152245435
+47	0.3342210970153273
+47	0.1575354968982135
+47	0.3038999953487353
+47	0.3203327034108093
+47	0.22614499866629897
+47	0.22793639305902122
+47	0.2623534728189851
+47	0.18193550303102363
+47	0.18239675443873324
+47	0.12575086707890784
+47	0.17730435414453946
+47	0.1736057932319577
+47	0.25618484278715636
+47	0.43613674354001875
+47	0.3270750382255719
+47	0.31822365976153644
+47	0.23655310512319772
+47	0.28322952071720864
+47	0.2403941984539122
+47	0.24792177273535804
+47	0.30776477966105714
+47	0.3545320637984491
+47	0.28633305632730144
+47	0.13115603697416015
+47	0.18113192050170468
+47	0.21095723314762221
+47	0.33353475669788324
+47	0.30535828455214326
+47	0.2577186642483019
+47	0.23653751196589734
+47	0.18365270975599796
+47	0.13876249800690021
+47	0.18940415949613962
+47	0.2824870694784162
+47	0.1533825176488302
+47	0.28703803843645
+47	0.388572423611832
+47	0.23050973208969383
+47	0.2482669900317862
+47	0.18788065809234913
+47	0.1665410172113932
+47	0.19638484263601597
+47	0.42649771892110466
+47	0.14372682891293703
+47	0.1688432589149635
+47	0.21902022239861613
+47	0.3007042929396589
+47	0.19671372737959744
+47	0.23111863717394515
+47	0.24653059441422476
+47	0.22679264847605432
+47	0.363330878578583
+47	0.23234030005064818
+47	0.19021783615724974
+47	0.2530176005503311
+47	0.2008832631602941
+47	0.11291531942731126
+47	0.3332741135080308
+47	0.2793479801243665
+47	0.3833079035146326
+47	0.2929168922737578
+47	0.28542809618360987
+47	0.26079298016618485
+47	0.3417589720435431
+47	0.37323172479369315
+47	0.251840952831138
+47	0.39705584604424204
+47	0.34011222465436
+47	0.05504031418695831
+47	0.3425898742533487
+47	0.2863730479618735
+47	0.3319267762629747
+47	0.14937045864405174
+47	0.33796260071405015
+47	0.259415959756866
+47	0.3386098137688052
+47	0.3540377976552679
+47	0.20316057056658382
+47	0.26360177825995984
+47	0.22590368979538367
+47	0.27754854515229455
+47	0.2815120388321542
+47	0.2549870138199634
+47	0.10722197260353947
+47	0.2829963669736848
+47	0.25042907530370123
+47	0.3755523191281094
+47	0.37601977347241194
+47	0.28930495391750755
+47	0.32535766598169613
+47	0.2853697789210283
+47	0.26235773956511294
+47	0.3944589896675341
+47	0.20729712573431808
+47	0.26098564066163216
+47	0.33051719726453205
+47	0.24369587684321217
+47	0.1973160787998385
+47	0.45774538235012674
+47	0.3484655091642875
+47	0.3271040842264442
+47	0.24112540868081805
+47	0.295038804002707
+47	0.22519120440255985
+47	0.25739280281779525
+47	0.12396022423323301
+47	0.25174751324788147
+47	0.4144266888851145
+47	0.2201600544020857
+47	0.2584717735228463
+47	0.18905121360052832
+47	0.35952665352702046
+47	0.2187791284350617
+47	0.17236479630691803
+47	0.23700454188061057
+47	0.35386192543691614
+47	0.19544138226012747
+47	0.31470253197245224
+47	0.21261464443353545
+47	0.24762107123826324
+47	0.21870139415777728
+47	0.37171733467201534
+47	0.35140077216845056
+47	0.2538534590278777
+47	0.16843890569933895
+47	0.2623126311509619
+47	0.22581810833629867
+47	0.195794957710073
+47	0.3418335878396064
+47	0.3626371506899954
+47	0.2975056239928884
+47	0.20690430243397395
+47	0.3148815277202535
+47	0.2498542822368423
+47	0.35829056416430377
+47	0.3982292309387938
+47	0.3318286087681216
+47	0.30028019131008726
+47	0.16039961118742144
+47	0.28414541194788184
+47	0.2829150837116754
+47	0.2584083630541227
+47	0.22201242701978888
+47	0.33691813618564215
+47	0.1853360784332718
+47	0.3711154555217626
+47	0.29502636413567557
+47	0.38849010623953056
+47	0.3986791772486011
+47	0.34226820624838394
+47	0.19430075649337178
+47	0.32726415660075964
+47	0.3109370991644746
+47	0.18864253386953728
+47	0.24131911299383257
+47	0.2826580402949547
+47	0.19063580810291872
+47	0.2865691887593786
+47	0.2966617947903104
+47	0.3688099788719154
+47	0.25257899571544923
+47	0.3148796209988181
+47	0.3045908365631414
+47	0.28891594783552194
+47	0.2507864237525762
+47	0.3521994173803122
+47	0.29536467083772966
+47	0.4284828371410187
+47	0.4191049179652535
+47	0.39485309683390485
+47	0.265976690101287
+47	0.14934231255779182
+47	0.30110592438362316
+47	0.27927759496539195
+47	0.15617319230338794
+47	0.3726909212870325
+47	0.32211114624817805
+47	0.18832329897497085
+47	0.21065484602552773
+47	0.3237647150870564
+47	0.32328061471540376
+47	0.3161543954182798
+47	0.2363428910517361
+47	0.3126056403894978
+47	0.4794278853273891
+47	0.35946993735337923
+47	0.2610540370547318
+47	0.2259181587343239
+47	0.2572516529295646
+47	0.32050296371175463
+47	0.36104069750804474
+47	0.42100747096129437
+47	0.2869612682961844
+47	0.39789432967074395
+47	0.18133856191996367
+47	0.2948449291022937
+47	0.2549509455742656
+47	0.26684099232777675
+47	0.2183095427241892
+47	0.29417454778744434
+47	0.37696840889082744
+47	0.4165760134727998
+47	0.2753992526075467
+47	0.4604148311917241
+47	0.2509973626698598
+47	0.2462217318079036
+47	0.13433975289387473
+47	0.27532417201696074
+47	0.35217252664766835
+47	0.35684888112251567
+47	0.3094571502810189
+47	0.36667210817212686
+47	0.25957283938641146
+47	0.13797474217264866
+47	0.18730566428894888
+47	0.4055549332604315
+47	0.20950324618494376
+47	0.1946935748388542
+47	0.2627582643913322
+47	0.2251463264958246
+47	0.3278333317308926
+47	0.3038547656482154
+47	0.4090124977789952
+47	0.1881131273057204
+47	0.23726325601652268
+47	0.17207398166318333
+47	0.1669302094044272
+47	0.4448100541279338
+47	0.3370131724306085
+47	0.3849566143262181
+47	0.22238529485992525
+47	0.19553375923645422
+47	0.2834288108962921
+47	0.1942974213867642
+47	0.35875352830765744
+47	0.22322440603525728
+47	0.22702219922042655
+47	0.2544639911549078
+49	0.15356843499783984
+49	0.12623150098377758
+49	0.2343906798765334
+49	0.30239856982145963
+49	0.11989776592123867
+49	0.04699188977848855
+49	0.2512270803010585
+49	0.20053857623371166
+49	0.32277124342178526
+49	0.18014232463706933
+49	0.13329374470013325
+49	0.28653870527274294
+49	0.26371850949088854
+49	0.23162566490587613
+49	0.1433085758202343
+49	0.3254374483319657
+49	0.2830466901286612
+49	0.2424680810699562
+49	0.22356223869165137
+49	0.2543632099101474
+49	0.21342075506089084
+49	0.19550182441841474
+49	0.15184437672323803
+49	0.18144646169966866
+49	0.1875838178797026
+49	0.3020092152535924
+49	0.15422968858094718
+49	0.12493428083430458
+49	0.2064837494470326
+49	0.27413049875690837
+49	0.21674793955364732
+49	0.2322822623617063
+49	0.15973698917447413
+49	0.1490003102584987
+49	0.16580135736074608
+49	0.2223437618170402
+49	0.2354239729925355
+49	0.306833774702245
+49	0.12296357836363589
+49	0.253491212249467
+49	0.21048057377901394
+49	0.13171264232959579
+49	0.2960339401937684
+49	0.2673257056329542
+49	0.29264680136162585
+49	0.3257170972046385
+49	0.14466288547242795
+49	0.20057417413165926
+49	0.1752690086973595
+49	0.17609556304097576
+49	0.17725930102786366
+49	0.33828366249722236
+49	0.30910070288856284
+49	0.22925028612442505
+49	0.23953277381079463
+49	0.30212290340932774
+49	0.22510076514472932
+49	0.18059345332592133
+49	0.2966893859243404
+49	0.1706098270378054
+49	0.25245791153609903
+49	0.20621840380791032
+49	0.238816976111111
+49	0.3258620906143842
+49	0.08855285005938951
+49	0.31659481526626376
+49	0.32635603132938823
+49	0.2785351782455999
+49	0.12831549158761735
+49	0.21072259473274815
+49	0.23457109645533666
+49	0.23656717029617447
+49	0.2784322815489883
+49	0.13813218201090388
+49	0.2144540282039228
+49	0.15182690936347623
+49	0.22944837985631555
+49	0.3235475053812025
+49	0.22690861579864688
+49	0.2068698804421451
+49	0.2261468016564327
+49	0.0671320875203361
+49	0.15813360949440666
+49	0.1600143284311241
+49	0.16223967329364306
+49	0.2455107307405708
+49	0.1281497136648992
+49	0.379324734984708
+49	0.24792454419213183
+49	0.2950396113761844
+49	0.1816666437597885
+49	0.17368653442018916
+49	0.2348901135985823
+49	0.2985757650691855
+49	0.18236105112927445
+49	0.18604696790627176
+49	0.20715275345432907
+49	0.3163345995873679
+49	0.35557911243367396
+49	0.20250275467173934
+49	0.3090696054164314
+49	0.26127119456663783
+49	0.3115525898295857
+49	0.3242408958257054
+49	0.13471361505385746
+49	0.26458051363070195
+49	0.1858263393270174
+49	0.2437376486356671
+49	0.08417808912373946
+49	0.15361628342588293
+49	0.16800175508711376
+49	0.3242285661764571
+49	0.17834323420167095
+49	0.23642679412714332
+49	0.22411967918031625
+49	0.28140760190299935
+49	0.32836321830816084
+49	0.18104327859442415
+49	0.16209232777105154
+49	0.20122950153829386
+49	0.30381701816000867
+49	0.18547889023182892
+49	0.0824677240865066
+49	0.13152795567407466
+49	0.1881781946341429
+49	0.07426521536160678
+49	0.23132039464139995
+49	0.16101539353044658
+49	0.1763451880050172
+49	0.1426076963160945
+49	0.2775623369665286
+49	0.14654390194214267
+49	0.1891322292482995
+49	0.16931699782484438
+49	0.3326445309389925
+49	0.2265068144950161
+49	0.347170296254553
+49	0.22981135626921664
+49	0.2611212554720187
+49	0.31500289763629086
+49	0.18314892920458342
+49	0.2461592551253011
+49	0.07852705395271628
+49	0.19080955459609122
+49	0.1585314347366158
+49	0.08536475682790669
+49	0.3242506354123805
+49	0.2211012527259521
+49	0.1975334623652443
+49	0.2149835285174943
+49	0.11623832260461653
+49	0.32187019025072416
+49	0.22942027923736538
+49	0.30589284032324715
+49	0.28557062740886247
+49	0.30859654387756447
+49	0.2732535642223632
+49	0.23015689596412936
+49	0.17538134225691426
+49	0.2620855032093496
+49	0.19514051678098904
+49	0.18469212493945814
+49	0.1534469160418209
+49	0.2306395297441689
+49	0.17754982740887076
+49	0.24835087077898285
+49	0.197554442508999
+49	0.15702915464051398
+49	0.2713613998421179
+49	0.14192340575292453
+49	0.2602351616856347
+49	0.18901874878478536
+49	0.164013047172889
+49	0.11117416574624031
+49	0.18668348865025816
+49	0.2269212034230739
+49	0.2070959596019698
+49	0.11510729218645521
+49	0.2419599139620594
+49	0.13824860637307484
+49	0.3698171781381985
+49	0.2825927518372786
+49	0.1816792540981322
+49	0.23035620335540488
+49	0.15479710654892123
+49	0.24223243691625834
+49	0.23663756288311144
+49	0.2685582163933614
+49	0.21948437869995444
+49	0.1883087958781436
+49	0.22676524825192465
+49	0.05919695116508444
+49	0.3497829346476078
+49	0.17499720281060907
+49	0.24613953300784247
+49	0.1969408026650682
+49	0.2114713495927806
+49	0.17185325404812005
+49	0.24410106918458746
+49	0.2614534178438185
+49	0.21279750877233353
+49	0.27918188336673383
+49	0.22271258077780315
+49	0.18672642849231041
+49	0.23487946860807263
+49	0.10029360218911199
+49	0.209129091193872
+49	0.16862063883989023
+49	0.1339040107391429
+49	0.2364893178345591
+49	0.20694812568980084
+49	0.2645864020942712
+49	0.13935724199911775
+49	0.19601420459490423
+49	0.30173782898091933
+49	0.28041360515831526
+49	0.23736595851580608
+49	0.27188087767654917
+49	0.21030197188420482
+49	0.3114270214139048
+49	0.17376139156181994
+49	0.24211947829562835
+49	0.29845849707198996
+49	0.26268638548561296
+49	0.22932629132794147
+49	0.2282572274469555
+49	0.3545760161631686
+49	0.27815066453114057
+49	0.08146537404558891
+49	0.10632316329370166
+49	0.1929565131450998
+49	0.17300190269041113
+49	0.15175172620908245
+49	0.22451205272215063
+49	0.18004375943822631
+49	0.27774445182814894
+49	0.16555093170875554
+49	0.19617947249592158
+49	0.22274799881549
+49	0.23860812357753347
+49	0.21744536283273044
+49	0.21927348198422822
+49	0.25563828279108886
+49	0.13503203333427732
+49	0.16162327754865422
+49	0.23292778397551453
+49	0.29960646429685456
+49	0.12246475548562769
+49	0.2786452322701882
+49	0.2156327973081123
+49	0.27396074070950965
+49	0.22692048629956285
+49	0.21837704014771384
+49	0.1932439315445483
+49	0.24454863014977096
+49	0.10354313118825088
+49	0.1897479450964495
+49	0.3009279571166759
+49	0.19584766589954103
+49	0.25482567955941
+49	0.18891753411809412
+49	0.22865345815362387
+49	0.17761477645770035
+49	0.25396156022634864
+49	0.225667507594505
+49	0.11158992078912876
+49	0.3434116076527608
+49	0.18320312470533043
+49	0.22353322431944214
+49	0.13820954015620734
+49	0.160622742623789
+49	0.21864715321566813
+49	0.2840239900529012
+49	0.2507032620019239
+49	0.19037882865644914
+49	0.20432485966386976
+49	0.218474564457654
+49	0.2622230328448926
+49	0.30213016154122435
+49	0.21039707423942203
+49	0.24235206068115314
+49	0.34385074963635354
+49	0.3014969788537147
+49	0.254960110197117
+49	0.21546674671962895
+49	0.25562080927448105
+49	0.23972392569881984
+49	0.2366179130270855
+49	0.3002997026483681
+49	0.20920911714073107
+49	0.11531501427617304
+49	0.21017702926198834
+49	0.1880880748006392
+49	0.20553194085517182
+49	0.2876677954662158
+49	0.24179489529286502
+49	0.2892972778082992
+49	0.24227835377340418
+49	0.23548873761639313
+49	0.27409107604768934
+49	0.3132542558675633
+49	0.19536684559232434
+49	0.2509569766733254
+49	0.10725539456619278
+49	0.09504096245525849
+49	0.360539173768201
+49	0.2614227128560233
+49	0.20239423634150117
+49	0.3474073009350361
+49	0.2690776831561066
+49	0.2236710423791854
+49	0.2968005459549841
+49	0.1903212685955885
+49	0.3041557691281795
+49	0.15747839176761505
+49	0.2922983653592023
+49	0.22717656554523294
+49	0.219100717171459
+49	0.16051130809075004
+49	0.1483342807565577
+49	0.07985791401502958
+49	0.34505934822229206
+49	0.23653976654094508
+49	0.19012700551106684
+49	0.19217913727135988
+49	0.17043490090797067
+49	0.263996355458839
+49	0.22335616175163395
+49	0.19609342844030855
+49	0.22898632297268484
+49	0.0695333431978256
+49	0.2290496923174255
+49	0.059281952962764
+49	0.20341452287308612
+49	0.3476735734442995
+49	0.19613063241099968
+49	0.1809944565590794
+49	0.18580644318635603
+49	0.1884352809631234
+49	0.3247611468829866
+49	0.22386220357966452
+49	0.2163848245894563
+49	0.20984619995882745
+49	0.13790917522210602
+49	0.24236671715447047
+49	0.30028862754047175
+49	0.1736033478715491
+49	0.15304580050860317
+49	0.14532113033764238
+49	0.24049705377186067
+49	0.27338160779474563
+49	0.20307924108353995
+49	0.13360038590801568
+49	0.24761129992819436
+49	0.22375237522754848
+49	0.3625459978874936
+49	0.10928153547932444
+49	0.2805844902257194
+49	0.3096442665838069
+49	0.19097681699166164
+49	0.08583727774512623
+49	0.2065085644988051
+50	0.2812892960208574
+50	0.20773468499485487
+50	0.19794881006258327
+50	0.258179159552894
+50	0.1560813721776305
+50	0.3235656162364647
+50	0.2120558250016107
+50	0.16491797134435052
+50	0.29719277564890406
+50	0.1983153390512105
+50	0.19649632055582086
+50	0.16582370834619023
+50	0.22057235770271813
+50	0.18332986618417776
+50	0.13017300994483874
+50	0.22917119388401988
+50	0.17842518051687123
+50	0.24815337199282134
+50	0.281539517345668
+50	0.2783871826820531
+50	0.19927197057734147
+50	0.2564230003411107
+50	0.23983798878446103
+50	0.20616441310856695
+50	0.20838502325048486
+50	0.20539303044788992
+50	0.2271208077854166
+50	0.29507116666796535
+50	0.16523082255614194
+50	0.19686301788265467
+50	0.21701319346755932
+50	0.2982041399455054
+50	0.34786749126650895
+50	0.1587131458814575
+50	0.18322730534241988
+50	0.2486452533366406
+50	0.2992085549975867
+50	0.20394613983625332
+50	0.21856349697272567
+50	0.25980285308640094
+50	0.14139970605890867
+50	0.22864095261269865
+50	0.19790328176342914
+50	0.3123404602695971
+50	0.18835882922315028
+50	0.14564067104215364
+50	0.20357558710404228
+50	0.2290246534400411
+50	0.2724573024651887
+50	0.3124843259663767
+50	0.23701637773798692
+50	0.35626033517879696
+50	0.16927619299953867
+50	0.26122930039323833
+50	0.21250059169939575
+50	0.1872232932512364
+50	0.2966734062113405
+50	0.15051137341056367
+50	0.21220370517214507
+50	0.20384466719635844
+50	0.2508886553075683
+50	0.22516849288184232
+50	0.21992505251810035
+50	0.22730641440840346
+50	0.16800115513751268
+50	0.2084772008757657
+50	0.2048540532486085
+50	0.2544725019806188
+50	0.2675649573888803
+50	0.16403856581763707
+50	0.2526642479683334
+50	0.21005126523204157
+50	0.20405407571660478
+50	0.2289493614335174
+50	0.2581196099096284
+50	0.22909760749495467
+50	0.17602109692370185
+50	0.2551716928410069
+50	0.1673532113321257
+50	0.3296791979912242
+50	0.17693272552709316
+50	0.1911710192037667
+50	0.2743316511809002
+50	0.25485700471602685
+50	0.3252171491452151
+50	0.32578240765055894
+50	0.30855972402320275
+50	0.28305741678712576
+50	0.15491433082199213
+50	0.17924134093083827
+50	0.27955694450379326
+50	0.25335220449607015
+50	0.21060349799568417
+50	0.23667225739575898
+50	0.24796724271384304
+50	0.17841465281852437
+50	0.20998616971242742
+50	0.17361201045608873
+50	0.2878085514973778
+50	0.2954399191450365
+50	0.25636375485631646
+50	0.1312697589606911
+50	0.18989457049818942
+50	0.24640362322448547
+50	0.19366177971360163
+50	0.3075565046212487
+50	0.34696377104471954
+50	0.24704150822626278
+50	0.20918123160402807
+50	0.28969998767033484
+50	0.3155857843816522
+50	0.16930525874805208
+50	0.23549432319294855
+50	0.2434597022809012
+50	0.17853397480039512
+50	0.2558193486263768
+50	0.21982460501391074
+50	0.25358206832060326
+50	0.19702823705417719
+50	0.1655734793981374
+50	0.16649821337270182
+50	0.23653032249229788
+50	0.20261429533196887
+50	0.2653991278210279
+50	0.20436433552204455
+50	0.18812793500487093
+50	0.23897270471874746
+50	0.15999696302938424
+50	0.1606969342371471
+50	0.22214994172301405
+50	0.2751317751016428
+50	0.22932590339657488
+50	0.19735662807326798
+50	0.18388821286184112
+50	0.10999263403464908
+50	0.27320305964894476
+50	0.3811941439616696
+50	0.19466593483167324
+50	0.22830372974726204
+50	0.2138045605705331
+50	0.2802218602261808
+50	0.2906260521124468
+50	0.2671659633403624
+50	0.19075271418684103
+50	0.1768391386610097
+50	0.28058498652430575
+50	0.2916092408789848
+50	0.25451336695439575
+50	0.29881500098227115
+50	0.20373675442999184
+50	0.08809896865668011
+50	0.2064407011159707
+50	0.1902445259328125
+50	0.2723166453521274
+50	0.2573155526319344
+50	0.15802656415751387
+50	0.24542777024264617
+50	0.24583919600145113
+50	0.13639245709941683
+50	0.2872448302424441
+50	0.22376030375003408
+50	0.162427947019368
+50	0.18707868669313762
+50	0.14469348345234825
+50	0.29837128146673314
+50	0.1818867023337437
+50	0.29982314806768423
+50	0.19749567343606272
+50	0.15522661976974847
+50	0.24872100863151697
+50	0.2268191582418054
+50	0.22234650531102612
+50	0.2436454095434254
+50	0.18821521835946192
+50	0.15951303314595797
+50	0.21935733452301717
+50	0.16434219036288678
+50	0.264739246228475
+50	0.23476311586939655
+50	0.380332138085447
+50	0.1731465942944568
+50	0.22364028878853218
+50	0.3050566832612168
+50	0.18486065751123068
+50	0.33541485103935076
+50	0.2255444906995187
+50	0.25499013776186585
+50	0.21458239934402915
+50	0.2581322880795459
+50	0.22344317752009416
+50	0.19259545813699475
+50	0.2627600985148239
+50	0.21299476154069655
+50	0.2282634648255573
+50	0.12340591858792277
+50	0.23354214926201147
+50	0.2943360131455486
+50	0.18290360558188273
+50	0.16818059177258654
+50	0.2041354529005458
+50	0.29571475736797426
+50	0.3025464423398656
+50	0.13599112146349332
+50	0.17219369014587088
+50	0.34632132756538203
+50	0.12787236985645034
+50	0.2583595634823031
+50	0.3416068503044007
+50	0.24239088344228987
+50	0.24192162982241916
+50	0.20934521553203658
+50	0.2627527840883703
+50	0.1614770699512543
+50	0.24315874036126
+50	0.16513048911301725
+50	0.3088410487833446
+50	0.19414108481051995
+50	0.23499933212105012
+50	0.17881158452741402
+50	0.31714364980158105
+50	0.22953418375183562
+50	0.21967225498585316
+50	0.16499544611862174
+50	0.32004650509697047
+50	0.3174235176289034
+50	0.28121773632551345
+50	0.2054365134218183
+50	0.25084377155413184
+50	0.2020378923016412
+50	0.19858941873352084
+50	0.2687182387269809
+50	0.190208669746561
+50	0.22573466691598135
+50	0.17366575190183223
+50	0.2220824849491256
+50	0.23164954568600205
+50	0.18659546769430158
+50	0.26271739274095895
+50	0.2185763130702863
+50	0.2804419324958712
+50	0.2591289949075892
+50	0.1563594597077273
+50	0.3694949815817701
+50	0.24697444490928505
+50	0.2417709801785135
+50	0.2384931409275034
+50	0.3072391752897628
+50	0.17488402605984732
+50	0.2412729470271303
+50	0.18387077218193168
+50	0.23185384880166873
+50	0.2920789486391401
+50	0.22247196694130214
+50	0.189532980255323
+50	0.27863772057154584
+50	0.21402028555219735
+50	0.17826804137312083
+50	0.28224918051771203
+50	0.23962746610058894
+50	0.3064724569463764
+50	0.2816629248978999
+50	0.2401429141465562
+50	0.19303556552272372
+50	0.22421580796514595
+50	0.21135756472843514
+50	0.3262445242633609
+50	0.3235943009385193
+50	0.23295215217601947
+50	0.23649335145222816
+50	0.1916009673517495
+50	0.2921767021880398
+50	0.20233989009313336
+50	0.170531137186111
+50	0.22216998230202872
+50	0.17866148129262638
+50	0.2825086320165465
+50	0.16567092960432178
+50	0.20293200540361
+50	0.2607296024729447
+50	0.33388156410845293
+50	0.21938960278676076
+50	0.2642746233020772
+50	0.24740072277799802
+50	0.21349728801649115
+50	0.25381956278952494
+50	0.21764254297699145
+50	0.19193013874678144
+50	0.21896277135420922
+50	0.30803051950420496
+50	0.19639194435963855
+50	0.2568683627852837
+50	0.2658769244986924
+50	0.3158745801939579
+50	0.19361913214985368
+50	0.21233537261901567
+50	0.2737415046911244
+50	0.16694701269760806
+50	0.31901939568086407
+50	0.18334115433438808
+50	0.16811159164630185
+50	0.24294140203663991
+50	0.21009405191633124
+50	0.24286944005169633
+50	0.20574891728887829
+50	0.24344988294001105
+50	0.24065222008868764
+50	0.22530329529850812
+50	0.2851796934269989
+50	0.27856400985586194
+50	0.277611122174111
+50	0.09811021950416818
+50	0.13978784202515065
+50	0.21978971602825106
+50	0.3367311009357399
+50	0.2343395344527494
+50	0.27115119813593236
+50	0.2739534110422772
+50	0.15030685317785678
+50	0.30088572606151986
+50	0.3134808293828986
+50	0.2605473207883436
+50	0.31595929053660643
+50	0.2038594387866661
+50	0.2204857803839567
+50	0.19410250016275535
+50	0.1736413133763277
+50	0.27302709827592364
+50	0.2516269031327315
+50	0.1978921777634691
+50	0.2243083937864587
+50	0.20108911616546116
+50	0.24539889957175032
+50	0.37632800524157584
+50	0.21335839728066378
+50	0.2912106640267234
+50	0.2005613675363117
+50	0.28181743103117696
+50	0.23278256616377582
+50	0.2287684154978723
+50	0.19057074246756323
+50	0.1794107461998107
+50	0.20078613713935944
+50	0.2402286782695568
+50	0.23453146049890303
+50	0.2624044095528941
+50	0.239376930240364
+50	0.23810684590860506
+50	0.19584004926245777
+50	0.3130815540072233
+50	0.23044234917139314
+50	0.18720506928854844
+50	0.2458525841537691
+50	0.2168970133917271
+50	0.25089572366072466
+50	0.2797524428545692
+50	0.26549644712602216
+50	0.2484823509707829
+50	0.204350770619732
+50	0.1982394724248776
+50	0.2021636630104217
+50	0.2190947738840282
+50	0.2704769073565234
+22	0.28611841926582504
+22	0.167487527485339
+22	0.26312784720627613
+22	0.16191564559042032
+22	0.26796639668585903
+22	0.4108894181149847
+22	0.3686580607950618
+22	0.12563264250356587
+22	0.31819185353043405
+22	0.23862220711453863
+22	0.22120633825901642
+22	0.37765002918126767
+22	0.28971260824147355
+22	0.2755568788781405
+22	0.3298303338652415
+22	0.20977088092714358
+22	0.21951773077392278
+22	0.19804865325391555
+22	0.1385717694387717
+22	0.2939355201714891
+22	0.26718740958638404
+22	0.19477503975302538
+22	0.17274881508160053
+22	0.33300381866930734
+22	0.20881572688702765
+22	0.3630538306483628
+22	0.34652891696650967
+22	0.20184538793141843
+22	0.31487474611348915
+22	0.21818797229271286
+22	0.3662679090880219
+22	0.2592379133252791
+22	0.38318700113969845
+22	0.19528070800640315
+22	0.21597921507661763
+22	0.35452233407151906
+22	0.1306337608057932
+22	0.369031909445733
+22	0.24623903347204376
+22	0.23742565014609698
+22	0.2533615370692043
+22	0.12625605681319108
+22	0.06808595043999774
+22	0.1652542241229912
+22	0.30350490151396586
+22	0.24701824148346294
+22	0.20533195615736352
+22	0.3220791663878772
+22	0.23112435810368936
+22	0.40399427495991364
+22	0.20874754632823284
+22	0.2863769960513945
+22	0.318046635697007
+22	0.2519482516092857
+22	0.2691847575019064
+22	0.263112844017815
+22	0.22393439593830847
+22	0.3152941905756888
+22	0.20326782827702436
+22	0.202858321671486
+22	0.3070697162691327
+22	0.32013979206822135
+22	0.28469077793827974
+22	0.2569292207659434
+22	0.2606802228639271
+22	0.2918144461436728
+22	0.3574414194807492
+22	0.23951223961630716
+22	0.17759031980535459
+22	0.2601074159058325
+22	0.3158492138809969
+22	0.06691646288192375
+22	0.32253316250537284
+22	0.2770231862079729
+22	0.11459011591957556
+22	0.23727602187157104
+22	0.28120866629456537
+22	0.23490481768963206
+22	0.2098130229821212
+22	0.3922648583979622
+22	0.32761048224210826
+22	0.13903163149542377
+22	0.2061305518408099
+22	0.3124122152075962
+22	0.2606725322866308
+22	0.31644513953445613
+22	0.2746136721694721
+22	0.18916928893985877
+22	0.12555116931489899
+22	0.3146308741694406
+22	0.3033373249948507
+22	0.16730995657668749
+22	0.3701200546584361
+22	0.27733836518023813
+22	0.21725688710366425
+22	0.058912838611086024
+22	0.3530914774380041
+22	0.3106506414484157
+22	0.3746184929236409
+22	0.1801813621365095
+22	0.232845764927315
+22	0.09010495953801283
+22	0.30489532455216345
+22	0.27175148936297805
+22	0.11993622614096483
+22	0.11826636519064343
+22	0.1651921376079006
+22	0.14253042686871742
+22	0.1722177788018911
+22	0.2731028976182583
+22	0.3085370545193968
+22	0.39361309322990534
+22	0.22567505847220237
+22	0.2941976742450981
+22	0.20423855430506038
+22	0.3385761856520718
+22	0.33039441490233085
+22	0.17028883950821885
+22	0.29998018059995285
+22	0.18644051733600506
+22	0.4297251781487922
+22	0.3309113234495055
+22	0.22823720412785506
+22	0.16793947371590007
+22	0.20393928633399816
+22	0.18280567680560258
+22	0.2951698857354437
+22	0.1598876710300469
+22	0.12639454615330362
+22	0.29369702847163687
+22	0.44067540621284695
+22	0.24459479656529404
+22	0.28358660015582215
+22	0.10540942797508637
+22	0.0717269349588497
+22	0.1278613465670268
+22	0.24130776902182394
+22	0.2939292139901712
+22	0.34709967608959613
+22	0.14363849388149272
+22	0.34550795685404806
+22	0.21047567483520105
+22	0.3576573106938018
+22	0.30405401116409053
+22	0.14210996968875036
+22	0.3120337066138052
+22	0.26286188010455425
+22	0.3272128645955192
+22	0.3130138982264145
+22	0.2325745926868959
+22	0.13978619248409663
+22	0.24902874871960773
+22	0.22413240635423765
+22	0.22230549483517142
+22	0.34562717132181375
+22	0.3295876355476658
+22	0.39509972882811983
+22	0.28742183654015785
+22	0.326115374419398
+22	0.31104400769562923
+22	0.17257141494270214
+22	0.07065472081140055
+22	0.30897358250169954
+22	0.31018201471104345
+22	0.12730088123155456
+22	0.27787313696463545
+22	0.43589512202400793
+22	0.1676126898889406
+22	0.2561120805054595
+22	0.3390177066769654
+22	0.2778540026894363
+22	0.30059995668338707
+22	0.21731130415640737
+22	0.27698770286157726
+22	0.31546099246975023
+22	0.2571041218825689
+22	0.26235114791068276
+22	0.40206047863545746
+22	0.29622644177005725
+22	0.19495194219033657
+22	0.2575633898549827
+22	0.35329083080752693
+22	0.1502165589507815
+22	0.36089246990904433
+22	0.2463947781279613
+22	0.25848915030210656
+22	0.3438955285335816
+22	0.30915255833042626
+22	0.36064535507579726
+22	0.1513004477089389
+22	0.23599370433621658
+22	0.18986693355196888
+22	0.26014127267947773
+22	0.28183141620987134
+22	0.10235680250531488
+22	0.17202562716870412
+22	0.26740438393795896
+22	0.2643538811972549
+22	0.42756274114032095
+22	0.3815491269567911
+22	0.2555848035786896
+22	0.18632629759799632
+22	0.196716558145263
+22	0.26318522737923167
+22	0.17039415103325414
+22	0.2933317372398054
+22	0.2239924367611056
+22	0.3007857997873363
+22	0.10508187760772784
+22	0.10329842443782687
+22	0.26678827437364333
+22	0.36142023952615193
+22	0.2875525021004395
+22	0.24048624876959493
+22	0.3288339971540558
+22	0.28884547846325315
+22	0.3633587137171064
+22	0.2306718105154095
+22	0.055611620434213284
+22	0.373269492601017
+22	0.248460043440789
+22	0.19670715868749708
+22	0.13912835490059028
+22	0.22129175809997145
+22	0.22899698436569582
+22	0.29991622753241803
+22	0.28373960521158986
+22	0.2780212250000949
+22	0.3561643052526561
+22	0.2082697082728026
+22	0.3075465230845365
+22	0.26776341539069426
+22	0.2923394628500604
+22	0.15810656637660914
+22	0.3682505761978076
+22	0.3365294385736535
+22	0.3937431071637896
+22	0.3938969418330443
+22	0.2575987892911758
+22	0.22371940171981797
+22	0.18839295597943104
+22	0.24515948683447472
+22	0.1542448008541091
+22	0.32163991396920233
+22	0.3366387557113352
+22	0.36686194985929266
+22	0.2019632459711006
+22	0.12292150195532152
+22	0.1641597022377438
+22	0.32181965434656035
+22	0.3712945170163963
+22	0.3613248346878847
+22	0.3376735927872684
+22	0.2196250897285179
+22	0.36965721004671076
+22	0.1925417211905148
+22	0.23171467769387064
+22	0.17528660436081941
+22	0.08211008280371926
+22	0.28620168578537003
+22	0.19293624304177923
+22	0.27380710399057406
+22	0.2766330718308157
+22	0.39188327407716605
+22	0.24112806670716214
+22	0.3658469650868528
+22	0.30404549439568773
+22	0.41007496857659054
+22	0.32064464570344603
+22	0.25464269539126577
+22	0.1639293467114673
+22	0.2316830896637091
+22	0.1624155646505224
+22	0.30152643077988983
+22	0.35802547333473206
+22	0.38520001079130123
+22	0.17859956322278026
+22	0.27099321922051656
+22	0.29864950475622587
+22	0.3368573736877686
+22	0.24803933817522703
+22	0.43963795136962236
+22	0.24525769608330136
+22	0.3253510531841827
+22	0.15076488040471223
+22	0.301927439114535
+22	0.1404623344787048
+22	0.3832179109058791
+22	0.2739375587131276
+22	0.3086135656547435
+22	0.2303805070311523
+22	0.2305086804289957
+22	0.3816943577070996
+22	0.28002654015305745
+22	0.21794816804757858
+22	0.3262007519364938
+22	0.2931265993316408
+22	0.22184710907693028
+22	0.2475370889050862
+22	0.28073049468158967
+22	0.28301711731191337
+22	0.1815044014132739
+22	0.05897517747472206
+22	0.22543133206306284
+22	0.20667620732843384
+22	0.2540731761249394
+22	0.34226849435331824
+22	0.3818714294174743
+22	0.10462174761085308
+22	0.21975877308945604
+22	0.24602627670187613
+22	0.3181213858649347
+22	0.29697066371146946
+22	0.2673688511196424
+22	0.14655141171196084
+22	0.17515016751372678
+22	0.21685588594264055
+22	0.43009962654985334
+22	0.35259044338675694
+22	0.23497219639821662
+22	0.02884235764047838
+22	0.40192118032409835
+22	0.3120602491427088
+22	0.4165602098895379
+22	0.3427130075408719
+22	0.15664840834981553
+22	0.19206834964279507
+22	0.09983801876552197
+22	0.3882075201669991
+22	0.1029268505166336
+22	0.2045463867827516
+22	0.23155542545617908
+22	0.11736648330164799
+22	0.29488370907376477
+22	0.40260215258868065
+22	0.10164050298078066
+22	0.22085694838555595
+22	0.2485263935409494
+22	0.3243698923108837
+22	0.08296008415217199
+22	0.2423351848035212
+22	0.29151696489899737
+22	0.2805143026977971
+22	0.2934860165354224
+22	0.2768624001973977
+22	0.32484268423807244
+22	0.24736454984171774
+22	0.3782384350478538
+22	0.23556349668705076
+22	0.35413047338263076
+22	0.25862619645258406
+22	0.36420373652146637
+22	0.2978174091966098
+22	0.18733374128904326
+22	0.16178907005384033
+22	0.2640727885484246
+22	0.3654214840256343
+22	0.3419126081857691
+22	0.12707972966150252
+22	0.3446920391958007
+22	0.18035387703565176
+22	0.17610230752267908
+28	0.19335226975798608
+28	0.33473049769405716
+28	0.2904867095608204
+28	0.345431040775908
+28	0.31464534161349095
+28	0.2325191347821745
+28	0.2551246605560427
+28	0.3240676808032849
+28	0.10064178865908768
+28	0.28470060269631875
+28	0.25864558159712897
+28	0.18305327446624328
+28	0.11541115772574853
+28	0.2562162850590619
+28	0.3101447335725297
+28	0.05035228474945392
+28	0.35123060959868996
+28	0.3551157546547861
+28	0.25293221345844674
+28	0.23338144293606825
+28	0.12384636600327685
+28	0.2076037729827724
+28	0.16032936122064237
+28	0.1985917832330015
+28	0.2943695540059882
+28	0.2949410302106017
+28	0.31467982599825334
+28	0.19090420643969438
+28	0.226986026338997
+28	0.2874172007852087
+28	0.3545750113150759
+28	0.33374798061005206
+28	0.3278547804959159
+28	0.3494046797888135
+28	0.3423126748811932
+28	0.3412447481051903
+28	0.12744128292756776
+28	0.13360341315508237
+28	0.3673076959155825
+28	0.07000590902487001
+28	0.38404851687180613
+28	0.21020476703140767
+28	0.33993771246292687
+28	0.18018845366633232
+28	0.055702781177890785
+28	0.21609691698361572
+28	0.10945995198021335
+28	0.08648741350669661
+28	0.4056779609169274
+28	0.318931984691246
+28	0.2685885376967809
+28	0.27590689636574484
+28	0.40349838367692986
+28	0.20799384912301166
+28	0.11743097123599722
+28	0.16450190994587438
+28	0.1898903472074704
+28	0.36807010889653247
+28	0.3263481434627846
+28	0.38948213403436716
+28	0.30853147328670516
+28	0.2635021315214054
+28	0.21760998015911676
+28	0.21663058234396387
+28	0.3279066875918937
+28	0.3131909677216567
+28	0.32100158768909687
+28	0.36553195324760274
+28	0.19161487890907156
+28	0.16286907273582454
+28	0.20320266490784542
+28	0.3001070442572637
+28	0.223667956289406
+28	0.15343269222041048
+28	0.331337265532694
+28	0.2974567445180789
+28	0.2648745816550017
+28	0.11819790912744801
+28	0.2570553340850187
+28	0.4086865527525431
+28	0.2136187406858704
+28	0.18150566862903664
+28	0.19811940637816666
+28	0.2119116125556685
+28	0.22255230367023496
+28	0.3052857932095393
+28	0.21855160452944708
+28	0.30388984747097647
+28	0.34024467055426305
+28	0.3190399573779439
+28	0.263560100330032
+28	0.31086240034148593
+28	0.2215240159296714
+28	0.19515071265755107
+28	0.13056623401242176
+28	0.09682915912703506
+28	0.30655056255539626
+28	0.17617122311434588
+28	0.2612164122262099
+28	0.24535158314997246
+28	0.09431136105261538
+28	0.15871063944018393
+28	0.36799326527064785
+28	0.15175273890862595
+28	0.1869891919233463
+28	0.33801497023307236
+28	0.29316186221447327
+28	0.3046134832180281
+28	0.1489197840327394
+28	0.148466691701812
+28	0.2510899039748137
+28	0.3210436160440593
+28	0.25387379625695383
+28	0.20897442945215494
+28	0.34193200558061526
+28	0.11986607614516713
+28	0.3404127598297422
+28	0.3003686436703764
+28	0.3823714361521171
+28	0.22294804258156817
+28	0.33700363354804336
+28	0.1540978086912313
+28	0.28356499549610653
+28	0.24549098624593016
+28	0.3036167292798378
+28	0.2998352035385352
+28	0.15383801635517624
+28	0.2642888219777548
+28	0.4072294420964684
+28	0.1981010387102529
+28	0.20701528569234798
+28	0.16553474195171577
+28	0.1435416304431175
+28	0.23233628735867376
+28	0.26689347489072085
+28	0.19716802750827436
+28	0.4050215886337541
+28	0.33317737809738257
+28	0.15519832599709701
+28	0.198737409716793
+28	0.2885688495051822
+28	0.12253605400896668
+28	0.12564900872281723
+28	0.3491082162509609
+28	0.35376095408020675
+28	0.31317930756121143
+28	0.30266764147916564
+28	0.3963433572730589
+28	0.2690672569399664
+28	0.13955071326704901
+28	0.2695077785659322
+28	0.1522725794102126
+28	0.27572210377651846
+28	0.15792845830018262
+28	0.32616013298947266
+28	0.2045517461928838
+28	0.34685343510578454
+28	0.1530885375277335
+28	0.4484954181338282
+28	0.34608644494148644
+28	0.3148961426680973
+28	0.1443225541012951
+28	0.282138729066248
+28	0.2476401292071634
+28	0.10715528365048085
+28	0.3498136411513091
+28	0.19141620786129931
+28	0.15848768433385357
+28	0.27515860168631084
+28	0.21016706342395305
+28	0.33358995432627503
+28	0.3456076959333851
+28	0.1873796632294597
+28	0.288679520662697
+28	0.2697836747313806
+28	0.2938212504382195
+28	0.247476457044224
+28	0.2365717285344376
+28	0.2519326161706145
+28	0.3831100360173266
+28	0.12042437495899351
+28	0.2040267512600267
+28	0.3034141227336723
+28	0.17015377163015005
+28	0.14227213748891496
+28	0.3037489148733109
+28	0.43628505714009236
+28	0.16078766993491073
+28	0.44069812936735214
+28	0.20997650937182746
+28	0.28996831805799983
+28	0.306314792005086
+28	0.3598919419924181
+28	0.1528246616374072
+28	0.25067590597813605
+28	0.23629925373649233
+28	0.34889938539157944
+28	0.29768181444153385
+28	0.32090484540585934
+28	0.3312000149316009
+28	0.344889530778707
+28	0.32293786179614975
+28	0.20773591441410685
+28	0.14315337387785357
+28	0.15615507677308624
+28	0.24903610927263975
+28	0.19382427443294403
+28	0.16024055307477228
+28	0.19898015899296664
+28	0.22353096434347464
+28	0.308184767370422
+28	0.15474316990952203
+28	0.38234989851551243
+28	0.22615331975495304
+28	0.15101054641088413
+28	0.23615378042043916
+28	0.15527211340395886
+28	0.34664904667340135
+28	0.17120219806660428
+28	0.3187714504769497
+28	0.3348441011661782
+28	0.13090747757390148
+28	0.2767945331019959
+28	0.13361500356855138
+28	0.15772066628542075
+28	0.40719244398770993
+28	0.2816808159290197
+28	0.2481209691708675
+28	0.2778664430334541
+28	0.1242390315973778
+28	0.3509318125347735
+28	0.14600412854855896
+28	0.3511673550473049
+28	0.37137412450158386
+28	0.3362360278768704
+28	0.28136351307584057
+28	0.13977835928304116
+28	0.15698673331645968
+28	0.2890415376879993
+28	0.30813848920510195
+28	0.3857823954918951
+28	0.37506631953725866
+28	0.2312333178925708
+28	0.29097321336883
+28	0.2410172233364489
+28	0.2526488283770847
+28	0.3170542917979935
+28	0.25791703283195205
+28	0.3116804850467004
+28	0.2289497194547817
+28	0.09308500456782924
+28	0.3898627943415255
+28	0.19273815106761763
+28	0.2659077110324553
+28	0.1422524753383535
+28	0.34621526626738935
+28	0.15880621568747458
+28	0.1368399896338939
+28	0.32567975866863863
+28	0.32226779972547304
+28	0.19455221923976093
+28	0.2935329216053466
+28	0.32809979057003974
+28	0.13282252744954778
+28	0.3601235067049502
+28	0.43291842825567856
+28	0.364414183866539
+28	0.34000972044956096
+28	0.17901325364579315
+28	0.2612285608633211
+28	0.32150465617195795
+28	0.35594885321386593
+28	0.24777863247665594
+28	0.30624233291690045
+28	0.30575839774565594
+28	0.34984269057653167
+28	0.2012329836807544
+28	0.21849509378429047
+28	0.1301467317169573
+28	0.2769423821822105
+28	0.3352329525047634
+28	0.28482659192941717
+28	0.23123742494162514
+28	0.11123561818893629
+28	0.34839695445476465
+28	0.29677549549032695
+28	0.26750320920693527
+28	0.3024530181538285
+28	0.34628531754257114
+28	0.16807841269778145
+28	0.1994298979420483
+28	0.2902162184215615
+28	0.21894269815019962
+28	0.3156589127279625
+28	0.20600585639017444
+28	0.37626148159049766
+28	0.3565712536647587
+28	0.406242810475978
+28	0.2444797288259555
+28	0.3247661346373238
+28	0.1870857861189548
+28	0.2826464914423834
+28	0.3596893137534259
+28	0.2611108382218312
+28	0.28854695979652173
+28	0.24541784697554916
+28	0.366540210538902
+28	0.1822109384892407
+28	0.3692515300933645
+28	0.1224327528086206
+28	0.3386494873021786
+28	0.3186035998727045
+28	0.25601457041733783
+28	0.3356360387849783
+28	0.26371088351198446
+28	0.3533075313758753
+28	0.1725622666980125
+28	0.39652483824319235
+28	0.0962625760208108
+28	0.2117864379807766
+28	0.40483793531297224
+28	0.17603877496897033
+28	0.29894721001718844
+28	0.019571421251051678
+28	0.2838944618202063
+28	0.20694889577223058
+28	0.3426161825494133
+28	0.23526422026757657
+28	0.22125428936259348
+28	0.36575061759823085
+28	0.14396041218737832
+28	0.18744943346302118
+28	0.16495494891420828
+28	0.32820047322309864
+28	0.3716925437017416
+28	0.30642138911431044
+28	0.24322963133827485
+28	0.4103047367603701
+28	0.26066754155910066
+28	0.28066665632481785
+28	0.3319504769812757
+28	0.2792376241115424
+28	0.1886098261904406
+28	0.28776212404224427
+28	0.29954775993690597
+28	0.3783625915201116
+28	0.19613976419121235
+28	0.28219727627755176
+28	0.25073824808388456
+28	0.3297339708432824
+28	0.2437468499339393
+28	0.37850423165750796
+28	0.25232698305272433
+28	0.3210422594682826
+28	0.3120699588228867
+28	0.3066815416565991
+28	0.3280718631700773
+28	0.3891941960139728
+28	0.364244262704249
+28	0.15876906756207002
+28	0.145826014123892
+28	0.30625020144880016
+41	0.22822995789931078
+41	0.31569640037221924
+41	0.15166248594110499
+41	0.3178920439912321
+41	0.33595342505147313
+41	0.3713594263637758
+41	0.21756439896774943
+41	0.19408532088201821
+41	0.18918602727470268
+41	0.17534760303460897
+41	0.13318558885538595
+41	0.12659934029466727
+41	0.22186034755144535
+41	0.3446230446451808
+41	0.28298271563303923
+41	0.16884360932240255
+41	0.3022855426261627
+41	0.2616887710971289
+41	0.06632969751705622
+41	0.3263396119910049
+41	0.09671997781544699
+41	0.3156852893097855
+41	0.3095699575591082
+41	0.20947199688068582
+41	0.17959520179051808
+41	0.13606248305026764
+41	0.22026445830837574
+41	0.3776490699535028
+41	0.3685082255588579
+41	0.2708948096706668
+41	0.14173031345162285
+41	0.3289673825808501
+41	0.21577800982093215
+41	0.38973685120031876
+41	0.16548873305713452
+41	0.1931726184282319
+41	0.21578459348459822
+41	0.2676660635668953
+41	0.3209915212591255
+41	0.28869213698890284
+41	0.14275905955012824
+41	0.2321038448152172
+41	0.26589404109402065
+41	0.1341696455622979
+41	0.20030217828555488
+41	0.25802861848033865
+41	0.24688441618361442
+41	0.29972929701265244
+41	0.13313925438856272
+41	0.25859180304054924
+41	0.162562595268574
+41	0.20846878227084928
+41	0.3711931213571033
+41	0.3759690655298697
+41	0.2668585994064304
+41	0.22759968847172868
+41	0.15573914289097524
+41	0.2734410739855946
+41	0.28544024771859033
+41	0.2899725745394739
+41	0.29167809468809774
+41	0.3857713133924448
+41	0.2247045619973575
+41	0.06274483052653435
+41	0.23899200509785307
+41	0.1639198993216955
+41	0.13709577886492308
+41	0.345755101622272
+41	0.23025653722299486
+41	0.17187469990414425
+41	0.2570029588036106
+41	0.3636591975307291
+41	0.24652953800678637
+41	0.18727517160458163
+41	0.15551266587377077
+41	0.323811958566027
+41	0.20963271698104247
+41	0.2544273581408288
+41	0.13564579640917726
+41	0.16798743991319678
+41	0.17101258828842278
+41	0.30366891858378314
+41	0.32346271352903166
+41	0.17877208989216067
+41	0.3233901340428923
+41	0.2968347177876487
+41	0.2845115729612841
+41	0.08559412463657244
+41	0.1903284381462077
+41	0.152315485125658
+41	0.22995212814010413
+41	0.11418446112254516
+41	0.045663887598604964
+41	0.2466810947822536
+41	0.2790940967197511
+41	0.19706393205417225
+41	0.39085061813562033
+41	0.31687017068388296
+41	0.2003953417193447
+41	0.37787152292744924
+41	0.2448034109434422
+41	0.08309786135372806
+41	0.3100925325551873
+41	0.29298296775354243
+41	0.3351435052066455
+41	0.3597727527179803
+41	0.27621321764713064
+41	0.23314094601214677
+41	0.09880824302332089
+41	0.16841684017213204
+41	0.18340492306894154
+41	0.22849268255976926
+41	0.32263964686904195
+41	0.19654135013721338
+41	0.3607181831218359
+41	0.34344748404281866
+41	0.3341349495445236
+41	0.23581476745713312
+41	0.2672043028319895
+41	0.1640617215318777
+41	0.43554860285021674
+41	0.3199507904843497
+41	0.32504208597815554
+41	0.19310770321640328
+41	0.3413493177781788
+41	0.21386522821317497
+41	0.1746275532171081
+41	0.3670389650845308
+41	0.2851015674776314
+41	0.10544904311787306
+41	0.22692156310221193
+41	0.21573873588380207
+41	0.3139645056713622
+41	0.1615635626575067
+41	0.39289860567673673
+41	0.43096073122297224
+41	0.31831244180916085
+41	0.35909095163284055
+41	0.31200306149367996
+41	0.2285832284140607
+41	0.42113998476049475
+41	0.40182867102717423
+41	0.198287566070158
+41	0.2625394063045762
+41	0.12686974664101047
+41	0.2466168499617456
+41	0.2788663684956426
+41	0.3860276135424996
+41	0.24007406332258266
+41	0.2569858268155676
+41	0.3505732995435767
+41	0.163963271875929
+41	0.27751309798843204
+41	0.23699655966085964
+41	0.19330954488713487
+41	0.1820478329117091
+41	0.24575732499502392
+41	0.28805087400521284
+41	0.35459889429585645
+41	0.3904757829658783
+41	0.2409838338233808
+41	0.15764722411918475
+41	0.29024910355194095
+41	0.18172846058976475
+41	0.28293100056302556
+41	0.39033771329651623
+41	0.2724844262632617
+41	0.1407156534818045
+41	0.16466432078699828
+41	0.299574839625062
+41	0.2744859399858392
+41	0.21191886510318853
+41	0.1490419254320483
+41	0.17722439428401737
+41	0.2167371773282595
+41	0.2277284792822397
+41	0.10750243982725052
+41	0.39422536932896046
+41	0.10524544991362524
+41	0.3149397502789487
+41	0.2807556347047175
+41	0.17511200892151574
+41	0.23782133912406797
+41	0.33679826218107095
+41	0.23751055859434972
+41	0.3407910690839953
+41	0.2550893464987954
+41	0.19282487387604227
+41	0.4414984099824829
+41	0.356323210665123
+41	0.3387368642429418
+41	0.17916780807694266
+41	0.2054278452228087
+41	0.2754694877951447
+41	0.196929510195652
+41	0.1885627161561311
+41	0.15917490266516857
+41	0.13052813029614815
+41	0.35815910676758406
+41	0.09987706516074797
+41	0.08749809986585272
+41	0.12899586385966816
+41	0.18008975809302968
+41	0.30279350364669605
+41	0.192274064216821
+41	0.40430225604531156
+41	0.18553274160740862
+41	0.2425021872190191
+41	0.1470106458054828
+41	0.2675491137594443
+41	0.33358723486313613
+41	0.27067841730115194
+41	0.20087936217162292
+41	0.23719069581143865
+41	0.3504372269847612
+41	0.38883482874499287
+41	0.287285498224195
+41	0.247893524527249
+41	0.1423226425109306
+41	0.2521092374912182
+41	0.3606104305203117
+41	0.24495789806313367
+41	0.15425673568364381
+41	0.36703255712039035
+41	0.2894272542984084
+41	0.145416734249422
+41	0.3357271969588139
+41	0.07797415446414832
+41	0.12483413570283942
+41	0.16375613429750446
+41	0.383560679696462
+41	0.36128425860944197
+41	0.35040876472311266
+41	0.17817385826976115
+41	0.3263001519020626
+41	0.19553473768797902
+41	0.21819292595324236
+41	0.35037394840610886
+41	0.257167710976053
+41	0.14079278427443895
+41	0.14671915830484836
+41	0.15812268158789294
+41	0.19602241808849682
+41	0.19572258886761873
+41	0.31547875748930926
+41	0.3923848217795907
+41	0.29989908554385614
+41	0.3053315250017136
+41	0.22540921361624422
+41	0.20757680661882844
+41	0.13801795436685904
+41	0.21995852728943333
+41	0.2469068135821521
+41	0.3791544402901554
+41	0.3956284416189755
+41	0.26351374939518696
+41	0.17493648988739136
+41	0.10606414829553802
+41	0.2643110394978809
+41	0.18806081437161584
+41	0.36133422430989115
+41	0.41912686910795766
+41	0.34460553947958283
+41	0.3803481676160906
+41	0.13438953301498818
+41	0.32972872898802214
+41	0.20363534140692377
+41	0.17645631769045847
+41	0.3033912101867471
+41	0.3358171534710473
+41	0.1557312641688303
+41	0.2698288494904512
+41	0.30182298122558804
+41	0.37546889540573847
+41	0.38448110619063497
+41	0.2634204929924772
+41	0.13854050472022034
+41	0.16213724325961318
+41	0.34842184247021274
+41	0.3124852271673262
+41	0.12318917353662381
+41	0.24214958336650064
+41	0.19834731832487193
+41	0.2583594382535944
+41	0.29360747089679484
+41	0.25645618939783715
+41	0.19040274599986406
+41	0.3354667166184193
+41	0.26551906998152297
+41	0.2500542421378789
+41	0.16728511745815525
+41	0.3601867957946211
+41	0.3317521440674142
+41	0.150377282152218
+41	0.2759017485977912
+41	0.2808573416106593
+41	0.2802872840651306
+41	0.24190922203771997
+41	0.10900755744220604
+41	0.14921847236528837
+41	0.41215936705253936
+41	0.3248821119210011
+41	0.3591485632460207
+41	0.1040215289087532
+41	0.20832824964835853
+41	0.23577863826141848
+41	0.353966266743974
+41	0.4075979538535067
+41	0.2957054492512406
+41	0.0864891316846192
+41	0.18510619122000455
+41	0.18327153497564638
+41	0.24553569206551468
+41	0.31600160928578785
+41	0.347533046798482
+41	0.19913393508052185
+41	0.2954095361347793
+41	0.358804153802669
+41	0.1391997121696215
+41	0.12251619318408687
+41	0.41843149760690007
+41	0.31299193967537436
+41	0.1824993573334582
+41	0.09588915920307398
+41	0.11051625267248767
+41	0.34496546539367695
+41	0.44333069257434193
+41	0.33961076081619335
+41	0.3636818977001139
+41	0.24535345128355998
+41	0.21511789489807362
+41	0.27770132018952676
+41	0.22212442781190825
+41	0.1905001056985872
+41	0.315796992756534
+41	0.34098988272529057
+41	0.4128258922326642
+41	0.2175286799407439
+41	0.2507731722425762
+41	0.25543895674963635
+41	0.304893934692461
+41	0.4069937873627482
+41	0.22440759147678277
+41	0.36839646227287115
+41	0.32462770826011905
+41	0.3081204449268382
+41	0.416556950248707
+41	0.12192383813551955
+41	0.26510019153384456
+41	0.22536527920979893
+41	0.2297377898356813
+41	0.17533279745801508
+41	0.3283781738580515
+41	0.07773289267997818
+41	0.24676322631900985
+41	0.32333701232835615
+41	0.3277358722401795
+41	0.18311249115595982
+41	0.2457838040065441
+41	0.31981504306820085
+41	0.1300248321239491
+41	0.21588832474826344
+26	0.32648065727176545
+26	0.22266819264076484
+26	0.27288912785393454
+26	0.3091126531836237
+26	0.34109066222883816
+26	0.3102774218953938
+26	0.2389240530602974
+26	0.16129249427007405
+26	0.2433364213051152
+26	0.2042475892578468
+26	0.16098826989660217
+26	0.30226551581351213
+26	0.24709744210344722
+26	0.21659336750996144
+26	0.29173699477015147
+26	0.21566655662680773
+26	0.2941215111208705
+26	0.11042348395048154
+26	0.2754672909804932
+26	0.2953801580626578
+26	0.24932938139906666
+26	0.21155893795769715
+26	0.203760892941546
+26	0.211279877449573
+26	0.2539937099661181
+26	0.17381094886429194
+26	0.20396677767379787
+26	0.2734758702138192
+26	0.224636446187961
+26	0.2253157216480939
+26	0.2281062819705672
+26	0.14496393429177498
+26	0.13923929306317223
+26	0.3044385227766025
+26	0.2912814537832185
+26	0.35417839393346473
+26	0.32985944345228785
+26	0.2739215646029999
+26	0.31787503358106467
+26	0.2589534491527107
+26	0.2443725851247143
+26	0.27604235984199543
+26	0.27927554565655727
+26	0.22049512287146864
+26	0.29914070217640865
+26	0.25351891887847927
+26	0.2737551017673306
+26	0.297771608560281
+26	0.28954207822175715
+26	0.31688531640060413
+26	0.21588541360500582
+26	0.16686658405829985
+26	0.21040466525574064
+26	0.37331320394462025
+26	0.2976631239563831
+26	0.17779505527395448
+26	0.29660251605752785
+26	0.2860058332787115
+26	0.3160930713628361
+26	0.29707837383805047
+26	0.20586591662861306
+26	0.24401991366333828
+26	0.2532132543263582
+26	0.17079588632919498
+26	0.20626594973812248
+26	0.13452200440832263
+26	0.2520239948707072
+26	0.2939005664282693
+26	0.23533425354462711
+26	0.26666337818084995
+26	0.18560202250181454
+26	0.22413352394471453
+26	0.20634540088646336
+26	0.09071376271059554
+26	0.29285828905826594
+26	0.2471465483476878
+26	0.15337004727854656
+26	0.3218081278206777
+26	0.3425258691800861
+26	0.15958899321768386
+26	0.2800784211717147
+26	0.2356114924910728
+26	0.29371763170900655
+26	0.21381623440506597
+26	0.25485780678669767
+26	0.2751795019349265
+26	0.2499487602698535
+26	0.3343456604518655
+26	0.3348203801191422
+26	0.1586818096670051
+26	0.2636571982954939
+26	0.2032929600408384
+26	0.29547197420061294
+26	0.3151009397593283
+26	0.23646057497235992
+26	0.3043186713298811
+26	0.32097685000166
+26	0.3145491872251546
+26	0.29657298957376155
+26	0.26529786647717
+26	0.0980310404021117
+26	0.3484428698689341
+26	0.28872264509745715
+26	0.2828019932187562
+26	0.1963604374940631
+26	0.2154045698855179
+26	0.30648163637767234
+26	0.26571510743168664
+26	0.18910890324896532
+26	0.2566911923445384
+26	0.14199528590934532
+26	0.1860749637756889
+26	0.3138409337137388
+26	0.2866272832339906
+26	0.22865141171620515
+26	0.29653242340932673
+26	0.31582928340452154
+26	0.31794813278154227
+26	0.2946041660616395
+26	0.26498997204045294
+26	0.3799943409719257
+26	0.21128809702588913
+26	0.23317017966462023
+26	0.22380136519733757
+26	0.15068736050192338
+26	0.11774389516084632
+26	0.2634633196228076
+26	0.2729211711200001
+26	0.31929534846158814
+26	0.3002027473676679
+26	0.2791764692974929
+26	0.20305285756756355
+26	0.2073539032564884
+26	0.14603602329164386
+26	0.26495942011841284
+26	0.24552448703087446
+26	0.300674855630666
+26	0.3054527373532473
+26	0.2964333896761757
+26	0.1923202885297147
+26	0.326413446982408
+26	0.2920618325176673
+26	0.2755663724203909
+26	0.22801853377344683
+26	0.23660926540904048
+26	0.18001503719888148
+26	0.35803062286885823
+26	0.34759150332058536
+26	0.3411404687460615
+26	0.26089322610159416
+26	0.17290951980893657
+26	0.07495083283953109
+26	0.24562885559590183
+26	0.33238810061003893
+26	0.15691050227517314
+26	0.22340337061912977
+26	0.34826582933886446
+26	0.11850313099466427
+26	0.21848583858746443
+26	0.29513930402253585
+26	0.22808996049885763
+26	0.1344842581221184
+26	0.29504005491652235
+26	0.1975307841166216
+26	0.24091649871146206
+26	0.24915724596321326
+26	0.08745952625597314
+26	0.22109461228370472
+26	0.2826315449623184
+26	0.13081974161596865
+26	0.2658669975994439
+26	0.1634339037736689
+26	0.23550633533186294
+26	0.27306462203072585
+26	0.23444725378521214
+26	0.17803913707413238
+26	0.22536064594089897
+26	0.2853770813965201
+26	0.19026076638675038
+26	0.3016319525102146
+26	0.2630738722223599
+26	0.28693014749811435
+26	0.24014076057109965
+26	0.24753966934135746
+26	0.3345364334556209
+26	0.22045412323715818
+26	0.21158445818766478
+26	0.17670826760626202
+26	0.17070666965414824
+26	0.20146185255425691
+26	0.2857782588792133
+26	0.21019441424929133
+26	0.2095225653795073
+26	0.09892545435803239
+26	0.1457057972027308
+26	0.13665543318685247
+26	0.17432940404704883
+26	0.2476229688879053
+26	0.2581391119847654
+26	0.16795781225639358
+26	0.3799931083628937
+26	0.34497499177235413
+26	0.15124975873431926
+26	0.2725631071382262
+26	0.1981222539593721
+26	0.23603115921151027
+26	0.29491871543219367
+26	0.223995656766668
+26	0.17661719092667633
+26	0.23603800219546414
+26	0.2936216615334657
+26	0.3411990703889484
+26	0.15613983590134103
+26	0.39756337390140806
+26	0.3372690370226143
+26	0.23316649542239531
+26	0.31905262809318
+26	0.23415150119360098
+26	0.2506074925040997
+26	0.38381995237486793
+26	0.19818482872093196
+26	0.1364322405424849
+26	0.27123835824739756
+26	0.23500099423464937
+26	0.29314042451534944
+26	0.21134125906347553
+26	0.17745006826670404
+26	0.26679457668875156
+26	0.26413182252332085
+26	0.18542481316213225
+26	0.3014992824789851
+26	0.19414857734449434
+26	0.20267272033941583
+26	0.39471750941719586
+26	0.2475902220664688
+26	0.4001958077905306
+26	0.2576619476844617
+26	0.07477440246765231
+26	0.30761954379572604
+26	0.26339989460814534
+26	0.2639862493259489
+26	0.2513259006462742
+26	0.1898078531261566
+26	0.19989829230523934
+26	0.26215392009377786
+26	0.2627944308998176
+26	0.3080022679614191
+26	0.24366561996292607
+26	0.19327992459504076
+26	0.27820456479093497
+26	0.19226764365276014
+26	0.33475943802438346
+26	0.15705179340938918
+26	0.28379982210627797
+26	0.16233136179074817
+26	0.14714122277765312
+26	0.21213736609257675
+26	0.26183236923389136
+26	0.2536417329591514
+26	0.2615378777454539
+26	0.2789623709456238
+26	0.26358474890891
+26	0.30506320149526334
+26	0.17595344931029047
+26	0.2500058197946692
+26	0.3220857993740054
+26	0.27709555783944056
+26	0.3984679319459142
+26	0.1916158156731683
+26	0.2554433712446697
+26	0.2734776152629651
+26	0.2684522895276953
+26	0.3338866423677345
+26	0.2983528120478553
+26	0.3163501541636558
+26	0.22398571376085752
+26	0.32792763123081387
+26	0.22168131412303377
+26	0.31246762802792794
+26	0.27800519808376234
+26	0.29298413945456453
+26	0.26816681355408123
+26	0.3023596503229167
+26	0.14999826544782627
+26	0.2936709594368083
+26	0.30054016461390587
+26	0.2501762247450295
+26	0.31240626526568044
+26	0.31223155633604
+26	0.2348845526256727
+26	0.3025760745240559
+26	0.3707631533104355
+26	0.2939762545557571
+26	0.3391682596153306
+26	0.105368845585493
+26	0.2861479313128773
+26	0.2210644013885029
+26	0.20969021157851633
+26	0.2517827860408101
+26	0.09541452728057132
+26	0.2621307757804556
+26	0.25136886972467987
+26	0.1979247529631467
+26	0.27947942298582196
+26	0.2940067241896968
+26	0.2728526598236662
+26	0.2865758741285174
+26	0.2973115290546571
+26	0.24707246799823296
+26	0.2878909227066788
+26	0.23759442233618414
+26	0.28532685231709515
+26	0.26270501007190705
+26	0.2691383943368696
+26	0.3393393268532207
+26	0.2784413362746226
+26	0.24698425864211432
+26	0.2744358054663478
+26	0.2864624286770876
+26	0.13727620878673202
+26	0.3414414725588289
+26	0.29406178332524485
+26	0.11004789490398294
+26	0.32480172318193584
+26	0.21777975709462555
+26	0.3315788366233662
+26	0.24505343377890806
+26	0.3690866734052142
+26	0.14469146662645602
+26	0.29616529015835025
+26	0.33058675969418116
+26	0.21200513784536262
+26	0.24446549225330685
+26	0.10630189734357832
+26	0.2394738378543164
+26	0.37025690048657933
+26	0.29245055825577404
+26	0.2322188955076863
+26	0.27279257473498975
+26	0.18426150770639427
+26	0.2795014292474441
+26	0.27261498637845405
+26	0.11767510897813425
+26	0.274877029520977
+26	0.3510873861610658
+26	0.22604041637152988
+26	0.18645297074510925
+26	0.16039352709350974
+26	0.26596770546764703
+26	0.25776678275314596
+26	0.27677094216199144
+26	0.132771375518914
+26	0.28912724017167346
+26	0.17243562944633897
+26	0.213204828317089
+26	0.3139623119886088
+26	0.06860134601420688
+26	0.28038656460072725
+26	0.27348264778535997
+26	0.3236190918440646
+26	0.21583000960734663
+26	0.2657930578357702
+30	0.13559657755436674
+30	0.04916105332725071
+30	0.13382584726586053
+30	0.22079208543350246
+30	0.1792318852833977
+30	0.12351538087117815
+30	0.36697622132490315
+30	0.3764021340823387
+30	0.0574435255894609
+30	0.03282508533868659
+30	0.1392381545391137
+30	0.36392399831554806
+30	0.30823915723087614
+30	0.2890522061576961
+30	0.11520531231042601
+30	0.1353805651292466
+30	0.12779597879280824
+30	0.20317635982894902
+30	0.24496726020756418
+30	0.25351455617813434
+30	0.25338646827876726
+30	0.2521491909003311
+30	0.2945934560249258
+30	0.2513684859238915
+30	0.26623913733303517
+30	0.2783364914527853
+30	0.2802596141965148
+30	0.27363712036262694
+30	0.2265560497864996
+30	0.2934357414340945
+30	0.34369509671902637
+30	0.29251191455590464
+30	0.3025192036892092
+30	0.36436271333937587
+30	0.251016383963653
+30	0.1441378787693216
+30	0.1692823882258451
+30	0.2878427248416173
+30	0.2875077069554964
+30	0.29468384150588717
+30	0.28792815254606136
+30	0.30580834462314366
+30	0.17305218121344604
+30	0.23993609394194598
+30	0.2349180402560513
+30	0.10560900641525055
+30	0.2679035086638309
+30	0.1320700772037192
+30	0.2632972558227419
+30	0.34934906818083405
+30	0.343827371745063
+30	0.14585075148988103
+30	0.24658669593130536
+30	0.2645551428814742
+30	0.2975811479653077
+30	0.15591312335955354
+30	0.18477229820814917
+30	0.3816095046076463
+30	0.030792752381337583
+30	0.16386880208013602
+30	0.24064988096953052
+30	0.2192048327735688
+30	0.3617481188258267
+30	0.31131744046444243
+30	0.3112285379889503
+30	0.20960266541696976
+30	0.26128264305272336
+30	0.36130093394128754
+30	0.3219205090649273
+30	0.2556382936438238
+30	0.24937754149506453
+30	0.3538581447526323
+30	0.08239544699299944
+30	0.09457443380852167
+30	0.2473778680971175
+30	0.27166330162353736
+30	0.21908705829951142
+30	0.1552245834160739
+30	0.12685509615310492
+30	0.28906056350444526
+30	0.3187637762879054
+30	0.1519936071386377
+30	0.1292844112194919
+30	0.22686196799484404
+30	0.2647179779445995
+30	0.37899464810798295
+30	0.4004337223164305
+30	0.33290444730389207
+30	0.18344731231573347
+30	0.11074719486588176
+30	0.3189695486210449
+30	0.3000488526421734
+30	0.2891536693643303
+30	0.39127425273706384
+30	0.20887256408349072
+30	0.349398359144504
+30	0.32991369206523974
+30	0.11270673001774
+30	0.10250673837812938
+30	0.17851892035903313
+30	0.15361252786029567
+30	0.2818493406104521
+30	0.23327139708924108
+30	0.2871942913678842
+30	0.3181167027470919
+30	0.10285044723164366
+30	0.136545598943515
+30	0.3369869171674133
+30	0.1502539203919327
+30	0.3274232532249876
+30	0.18426733796704672
+30	0.15477497289095038
+30	0.2831919462487084
+30	0.29828983669936165
+30	0.07466534888000596
+30	0.2943745954089304
+30	0.25673263263972534
+30	0.05025852736990621
+30	0.38207936363769585
+30	0.3125687921268318
+30	0.14153950430764736
+30	0.2270436717042443
+30	0.08801858159392102
+30	0.0899935106866934
+30	0.27144785878394
+30	0.242752687229077
+30	0.22161038998832558
+30	0.2861522184841788
+30	0.27591182421487953
+30	0.3688285069923273
+30	0.39502565262101086
+30	0.28993288567966596
+30	0.16570866176237672
+30	0.22463496607305794
+30	0.32333252096001114
+30	0.30200288882924
+30	0.4042004493832757
+30	0.04264814749731792
+30	0.18430054828004175
+30	0.1938174193421025
+30	0.24514964439299367
+30	0.2876455356022522
+30	0.3122308430861003
+30	0.2699397510844459
+30	0.36923767823289777
+30	0.2935893258478433
+30	0.3267372336097992
+30	0.22897610566283677
+30	0.20082387234642
+30	0.27095270052070025
+30	0.3311269021494414
+30	0.3901339655547814
+30	0.3074861241909827
+30	0.28025624215577427
+30	0.2682872758987125
+30	0.39815129467378824
+30	0.29804236995917477
+30	0.23001540568946738
+30	0.29675701756069667
+30	0.34945196071166507
+30	0.3611535734282843
+30	0.2450599774017786
+30	0.06597061376416212
+30	0.23075250293433022
+30	0.3174722564317895
+30	0.24771026591493922
+30	0.28194514790578695
+30	0.17108482067867484
+30	0.1146883691029887
+30	0.29716717987658525
+30	0.09028500528889553
+30	0.17106026006975183
+30	0.20006065335382464
+30	0.2566655447053284
+30	0.32174180963418486
+30	0.14807300347957392
+30	0.19099066138652118
+30	0.272195330610429
+30	0.27334040354939576
+30	0.3242318986276384
+30	0.1845203297760218
+30	0.27832052462643747
+30	0.30078266424681943
+30	0.2041000310840202
+30	0.2064057537035393
+30	0.24424975964353932
+30	0.29977879632473775
+30	0.35314783843948105
+30	0.3127650821444434
+30	0.18566256247317756
+30	0.3039358960170568
+30	0.28250814051501716
+30	0.07431660241026374
+30	0.08725229355457502
+30	0.12404952192745028
+30	0.22061529150842205
+30	0.18433052908178457
+30	0.2090368972823329
+30	0.30548653710528234
+30	0.2946102147909852
+30	0.3329080646822405
+30	0.31783357729897477
+30	0.03861650348278549
+30	0.19728976828795297
+30	0.19328663814887218
+30	0.21574802743427005
+30	0.3409595270657387
+30	0.37641564968295277
+30	0.049367835155605534
+30	0.07040974465337567
+30	0.16218829770468937
+30	0.27217525367994144
+30	0.21953535325125678
+30	0.16826423451552924
+30	0.2619763286241671
+30	0.35041269093530114
+30	0.35047388897354764
+30	0.380516942193454
+30	0.3251924104123409
+30	0.11892634297272449
+30	0.11407220019084945
+30	0.22923797314011257
+30	0.1414253004573923
+30	0.1895940370780306
+30	0.2997361156693816
+30	0.3102917139751453
+30	0.3549434978006696
+30	0.2234784589802625
+30	0.048330308134704174
+30	0.2518972242465002
+30	0.03598426604522735
+30	0.18713090106769806
+30	0.2411905672873943
+30	0.3544558611610971
+30	0.3447885157179422
+30	0.16148719657832847
+30	0.26448758617953994
+30	0.2552437254914247
+30	0.1689355942976432
+30	0.0756430796021349
+30	0.21545816357516773
+30	0.27056746088571065
+30	0.1971525174724712
+30	0.2587384946931967
+30	0.24649008505710557
+30	0.30148976854579207
+30	0.060749939839909735
+30	0.028039412636903963
+30	0.36409344191030973
+30	0.10195796806087037
+30	0.28907740168147095
+30	0.1832861608564851
+30	0.2265695706237357
+30	0.16904006359704118
+30	0.27601524610175854
+30	0.24309997928251076
+30	0.3480027995044429
+30	0.11307545326292154
+30	0.20465059592866083
+30	0.33148718247961734
+30	0.20273578720432678
+30	0.16612085918105418
+30	0.37572658278233095
+30	0.14273219756428257
+30	0.3185945259973368
+30	0.3010480680479103
+30	0.19337510048426462
+30	0.20747705874589134
+30	0.2981285183921267
+30	0.18815397106968101
+30	0.3099806244050161
+30	0.07963157585544162
+30	0.17305873366559832
+30	0.21965958528339738
+30	0.30851924035401157
+30	0.3040095066231023
+30	0.34322008400156645
+30	0.3266794488540718
+30	0.2479247542070266
+30	0.3698797041273572
+30	0.3087415919678221
+30	0.10005901222638976
+30	0.2186881491720361
+30	0.15994678233723142
+30	0.18061656625758132
+30	0.3447732733467014
+30	0.2882641046399063
+30	0.2878314705017604
+30	0.37825653776772483
+30	0.08389921421381154
+30	0.14797226037120798
+30	0.37674294988057955
+30	0.3714487273939486
+30	0.18711455059141457
+30	0.23020002644582382
+30	0.1048653304881613
+30	0.22906745749322188
+30	0.14212905520347885
+30	0.19112702810262863
+30	0.2802578834837258
+30	0.26114833754288697
+30	0.3546666655970249
+30	0.22745273658719561
+30	0.14115431635574485
+30	0.2909986589544137
+30	0.30674288724557475
+30	0.39270550905274726
+30	0.24815893887312485
+30	0.3308300040410119
+30	0.24225681118748663
+30	0.3016666891644743
+30	0.14336403122893335
+30	0.2128197629693996
+30	0.3566882891050117
+30	0.240887034789627
+30	0.36361041320867693
+30	0.20358988335286407
+30	0.17282090470162176
+30	0.32996846059884305
+30	0.34596179151787027
+30	0.1840511930474743
+30	0.2780655891120059
+30	0.37427281580958516
+30	0.21200369465359362
+30	0.33571498289753465
+30	0.31844911841867124
+30	0.25242101657208416
+30	0.3603121139900714
+30	0.34687248393751446
+30	0.18967565151316146
+30	0.12995058627673037
+30	0.013437345560425341
+30	0.337217193577021
+30	0.3606402338634769
+30	0.330133683709851
+30	0.2751398429477441
+30	0.03651252423409486
+30	0.36819952055947147
+30	0.3003572177939038
+30	0.27038797690128497
+30	0.30817233373876024
+30	0.2523526037786268
+30	0.2578710864775241
+30	0.19999540609443117
+30	0.3056586253270479
+30	0.3259891587894112
+30	0.13073060210823367
+30	0.3964015156988969
+30	0.2747966824174619
+30	0.2592238361695789
+30	0.3240240654988143
+30	0.32599285283608964
+30	0.2466390262686092
+30	0.15888387488037492
+30	0.31419591954470955
+30	0.2910043700113629
+30	0.3286717009756939
+30	0.36793669221592135
+30	0.08070118027653371
+30	0.3563352591394741
+30	0.21752452400900196
+30	0.09421080201095984
+53	0.6843659132920316
+53	0.670700314960229
+53	0.6926788588170535
+53	0.665851218656275
+53	0.6649465851220514
+53	0.6750460577785048
+53	0.666726213990336
+53	0.6816843453174274
+53	0.6746786114839938
+53	0.6166464690400194
+53	0.6102503594383841
+53	0.11636989939122086
+53	0.623835685244621
+53	0.6278332849569714
+53	0.6286802927742846
+53	0.5858283561365573
+53	0.6395524438643022
+53	0.6449556889002349
+53	0.6402940975236581
+53	0.5644000176751326
+53	0.5933782753899137
+53	0.6101237763818687
+53	0.6060036933474137
+53	0.5785875937571511
+53	0.5839979078997064
+53	0.6141992903516283
+53	0.6321378753611125
+53	0.6528968362398646
+53	0.646014992656037
+53	0.6670318237173678
+53	0.6538373650437846
+53	0.6620570588596002
+53	0.6069243628963685
+53	0.5790587792265434
+53	0.6305062356072952
+53	0.666752023338783
+53	0.6725464170587422
+53	0.6535560392622852
+53	0.6420067367715412
+53	0.6461494222087092
+53	0.6268919428537005
+53	0.6714738136018857
+53	0.6504520857842985
+53	0.5579051812011608
+53	0.6040171789104652
+53	0.6076061533384773
+53	0.5943812870789169
+53	0.719071915980997
+53	0.7108531156219684
+53	0.6792419561824609
+53	0.7156885979194285
+53	0.665778979384452
+53	0.699093819668528
+53	0.6546550623774179
+53	0.05155777023184493
+53	0.6478652954540085
+53	0.6625942156334932
+53	0.6806800485671255
+53	0.6543669925382388
+53	0.6556090112984535
+53	0.6535976235838595
+53	0.6382927522827752
+53	0.667188489128768
+53	0.6135742847297087
+53	0.6471424560786485
+53	0.6276680204331139
+53	0.6568569468731715
+53	0.6514796347595329
+53	0.6106614797072067
+53	0.6172400172350537
+53	0.08594413227619811
+53	0.6286501249677696
+53	0.6277328338930286
+53	0.6426589283236298
+53	0.5873156925402556
+53	0.6448575819924728
+53	0.6185614974237371
+53	0.6882241515538426
+53	0.6747983130460723
+53	0.6404517568332319
+53	0.7362374656262783
+53	0.5095694105769685
+53	0.5302085405231477
+53	0.5595705181007925
+53	0.6435446609207842
+53	0.7614902586407865
+53	0.7050059678684506
+53	0.6905931609625975
+53	0.6202954270715536
+53	0.613958700134475
+53	0.6603719876560801
+53	0.6942065713935266
+53	0.7031909372749588
+53	0.6324352644173076
+53	0.6544763461122296
+53	0.6499276568345037
+53	0.6717066717307514
+53	0.66518892640281
+53	0.667155649336138
+53	0.685509735087751
+53	0.68027309665916
+53	0.653773019103984
+53	0.6716644076559353
+53	0.6874660691806254
+53	0.7140312921345826
+53	0.6961820718276175
+53	0.6356393064242276
+53	0.7137611995524261
+53	0.38413221604150055
+53	0.6204653457182179
+53	0.6159818055479281
+53	0.6317635954283349
+53	0.5989472863604608
+53	0.6177613945050919
+53	0.6657527167850877
+53	0.6680093149855831
+53	0.6239489757326802
+53	0.6396373371765438
+53	0.6530132268471077
+53	0.659016010407443
+53	0.6866750012276231
+53	0.6990699695973487
+53	0.5348155040297476
+53	0.5424958363636836
+53	0.5585163445709697
+53	0.5464017611259757
+53	0.6593700672722497
+53	0.5846412089815562
+53	0.6482394233319665
+53	0.6463361005809052
+53	0.7574685851650823
+53	0.5159668217411199
+53	0.5610941613166424
+53	0.5586632937122059
+53	0.6345797203302678
+53	0.6351229001126687
+53	0.7534440641478918
+53	0.6685260776469049
+53	0.647227844247311
+53	0.7512641883177819
+53	0.6992213215053624
+53	0.6916357010376538
+53	0.6780930863425741
+53	0.6791177867645182
+53	0.6477862629072672
+53	0.6921898934844901
+53	0.6644322783088544
+53	0.6815772068599187
+53	0.7012410174511522
+53	0.6334712945285066
+53	0.623329145905249
+53	0.6343183765928896
+53	0.6552749080253853
+53	0.6516258553253476
+53	0.6975226016498385
+53	0.6704880173845161
+53	0.6941222977758721
+53	0.6846500593541388
+53	0.666927430077352
+53	0.6836555075622831
+53	0.6199144895610482
+53	0.46228431861468794
+53	0.6122683909015458
+53	0.5800304636962426
+53	0.627800128953081
+53	0.6238246044567209
+53	0.635229589549587
+53	0.6241230267688014
+53	0.6409905274430089
+53	0.6530744290924138
+53	0.6430260501703303
+53	0.6362948333187913
+53	0.551022798153241
+53	0.586770969512742
+53	0.5946094052308614
+53	0.5855879976833106
+53	0.5895115855956179
+53	0.6745017744657722
+53	0.6806848477636673
+53	0.6872603003188242
+53	0.6745478341664496
+53	0.6999411583132531
+53	0.693002222320838
+53	0.6974575129933906
+53	0.7170847330787474
+53	0.6921780609505112
+53	0.7144711568615898
+53	0.7000589741769521
+53	0.7306603395980374
+53	0.709167316819645
+53	0.7030309898587349
+53	0.6088407394944649
+53	0.5986724244615634
+53	0.5877457419824945
+53	0.59249340813749
+53	0.5965855363553317
+53	0.613167780245427
+53	0.6096808441314889
+53	0.6928952100021799
+53	0.6602418516496693
+53	0.696817990560011
+53	0.6871293466479113
+53	0.629761302432355
+53	0.6399343485709289
+53	0.6031411057348686
+53	0.628722470860352
+53	0.636778328185871
+53	0.6409093598308733
+53	0.6344962383662514
+53	0.618938805348471
+53	0.6850393457579873
+53	0.6213583066246403
+53	0.7275619237964489
+53	0.7080498876748077
+53	0.6833322953358248
+53	0.6958960092312912
+53	0.6936874901428663
+53	0.7003547716758283
+53	0.6949980424041846
+53	0.6818487714137822
+53	0.6871998814971827
+53	0.7123500878944681
+53	0.6967709656446092
+53	0.6988097606795567
+53	0.7079999265236601
+53	0.672626059554346
+53	0.6537494101434332
+53	0.6438323917094304
+53	0.638421577976823
+53	0.709576922139008
+53	0.6651753667210482
+53	0.7093357026275227
+53	0.5920037925055373
+53	0.6858857793806006
+53	0.6632886349322713
+53	0.07655547402143466
+53	0.6604622842246127
+53	0.6172816022144882
+53	0.6491136695445506
+53	0.6622479116167701
+53	0.6563210326389963
+53	0.6662755497489782
+53	0.6562431035006797
+53	0.6703410067559601
+53	0.6402042897471738
+53	0.6648558524811888
+53	0.6371939216783139
+53	0.6233292025868997
+53	0.6237967063537293
+53	0.5860665214675248
+53	0.618138171481863
+53	0.6829673425018968
+53	0.6563393668221101
+53	0.6923019554925137
+53	0.6620283248319256
+53	0.6796981206858763
+53	0.6681105438740773
+53	0.7011830072015965
+53	0.6748276429602628
+53	0.615269906828369
+53	0.6728479185897087
+53	0.6764898214704157
+53	0.6808077787302994
+53	0.6889111608132257
+53	0.6647211553993524
+53	0.6948369891955863
+53	0.63774705836238
+53	0.6913471745786767
+53	0.6983016952559802
+53	0.632038478858326
+53	0.6530922855731426
+53	0.6336497562416116
+53	0.6369546991321673
+53	0.6396675224656798
+53	0.660314524076733
+53	0.6595596996298392
+53	0.587773814560122
+53	0.6217059667146334
+53	0.652777987168298
+53	0.6394595523573425
+53	0.644587668937038
+53	0.7144037380110241
+53	0.685088708900466
+53	0.6818106571594658
+53	0.6393815878909996
+53	0.6740881998004775
+53	0.64630198157054
+53	0.6599795461745653
+53	0.7041187056247874
+53	0.620308962842037
+53	0.6629466030849147
+53	0.6710907842288578
+53	0.6894469787097119
+53	0.6633581172515939
+53	0.6773584426814371
+53	0.6968480839560959
+53	0.663806294296711
+53	0.6443718160001202
+53	0.6148104727053534
+53	0.562238543769344
+53	0.6626262938979277
+53	0.6270751938258934
+53	0.5993285866747886
+53	0.6409595943315113
+53	0.6122680443033702
+53	0.6870753136864883
+53	0.6906347524430693
+53	0.6971040879597591
+53	0.6891883648757534
+53	0.6843086360891001
+53	0.6651718873572138
+53	0.6826496368851902
+53	0.6578998557572127
+53	0.643079125651897
+53	0.670388917306166
+53	0.6863299168906589
+53	0.6898092732595863
+53	0.6558621416016138
+53	0.61564344134684
+53	0.6981241663283759
+53	0.7063081350305866
+53	0.6985215774409538
+53	0.6717243584773548
+53	0.6741942117248675
+53	0.6824987155496137
+53	0.5884960791681174
+53	0.6535532943406738
+53	0.6550579265642157
+53	0.6501804864447047
+53	0.6571716439831797
+53	0.6494224094739728
+53	0.656795184544439
+53	0.6709614576129577
+53	0.6602415134145836
+53	0.7666760435950774
+53	0.7752382123645082
+53	0.7172527855717952
+53	0.7179083680180762
+53	0.6519788390220342
+53	0.6213444566742153
+53	0.604145926609628
+53	0.6330460679028542
+53	0.6237672109043996
+53	0.6473348407175976
+53	0.6522714020172488
+53	0.6817473168981443
+53	0.6623371198152413
+53	0.6511130795372306
+53	0.6545470118563581
+53	-0.06768802401596896
+53	0.6777540590470367
+53	0.6699980846261642
+53	0.6655565759143888
+53	0.6607701015829818
+53	0.5928665376017453
+53	0.7165188642097874
+53	0.6248255402008409
+53	0.628759048695132
+53	0.6269265118129016
+53	0.6287339095058734
+53	0.6490249483400846
+53	0.6427922688007245
+42	0.13297044162255134
+42	0.22884053105851793
+42	0.29497660532268527
+42	0.2441389213529653
+42	0.27413025655560597
+42	0.31546738031351934
+42	0.31058496514530026
+42	0.2146284150224984
+42	0.27463258441217187
+42	0.4082531670968265
+42	0.2493270472692887
+42	0.06190716120911043
+42	0.30482238532504374
+42	0.32332046498618355
+42	0.2772933253574457
+42	0.20797433297005768
+42	0.12026962910540993
+42	0.17729898339347824
+42	0.1764272143637473
+42	0.29041305065096085
+42	0.28458626071064164
+42	0.3497503329686426
+42	0.2808331304558433
+42	0.17458758561567692
+42	0.09163884304059497
+42	0.17935527350155298
+42	0.15041924207169197
+42	0.2541426186776006
+42	0.31728282842841726
+42	0.3868546856461605
+42	0.2816511421694043
+42	0.17801728535484188
+42	0.1600766279510867
+42	0.32823307722448947
+42	0.4243047181504203
+42	0.2721646444634352
+42	0.3126665515438717
+42	0.18708204461222713
+42	0.2517114294730727
+42	0.17448214205366158
+42	0.16981811524295073
+42	0.14645051930373798
+42	0.41272028128538923
+42	0.37195386489661775
+42	0.2697655927307697
+42	0.3955684723145136
+42	0.35995641352883473
+42	0.4481760626062028
+42	0.15367962545832453
+42	0.21443429001626002
+42	0.17975216670837124
+42	0.286677992759233
+42	0.302074984313202
+42	0.2617740383672547
+42	0.283233192993184
+42	0.17109519863127884
+42	0.24044484027362206
+42	0.37465589404416155
+42	0.3222446902140015
+42	0.21791742519085328
+42	0.08198489644687566
+42	0.1295627625382333
+42	0.2611957288251726
+42	0.2402026771469073
+42	0.2522576517961789
+42	0.2454845537804178
+42	0.12578824284800294
+42	0.1428833899979014
+42	0.3351477256345976
+42	0.2511855099150927
+42	0.24189438262292737
+42	0.13838725044452313
+42	0.290451596228602
+42	0.28835167655155153
+42	0.2987558876273675
+42	0.31625378734785226
+42	0.3264730956269911
+42	0.25623465163613546
+42	0.26343307575221797
+42	0.1180409184047895
+42	0.3257039309859315
+42	0.09447409775865515
+42	0.047843989661164786
+42	0.11945136121788545
+42	0.3199775750699157
+42	0.3581927469042299
+42	0.3787547794398795
+42	0.33161801684623815
+42	0.26308926936845245
+42	0.2381892682701511
+42	0.24886301298824756
+42	0.16832220635943307
+42	0.4163935450439573
+42	0.37677898016788836
+42	0.10456624306929564
+42	0.2595522298518037
+42	0.13826711116481646
+42	0.16384988497434716
+42	0.2695744044741137
+42	0.3020425068601268
+42	0.31364250965310736
+42	0.35016206239544007
+42	0.23160776066966876
+42	0.2543558283681679
+42	0.3370851797961805
+42	0.31745486801846595
+42	0.1278397482381301
+42	0.2107164752079108
+42	0.05399062606372894
+42	0.1938526527637241
+42	0.42888370655188496
+42	0.22543949899055774
+42	0.16469997441815695
+42	0.4265810548213245
+42	0.3591929635337713
+42	0.32910872239025957
+42	0.10495808499772807
+42	0.22146712448660028
+42	0.2790990853308245
+42	0.13969130990900352
+42	0.26455714401928904
+42	0.3197860171555231
+42	0.07498995142308232
+42	0.23628587930977704
+42	0.3297067065927781
+42	0.30131685648140266
+42	0.21614160133556107
+42	0.2696620457526268
+42	0.2726033067629803
+42	0.16079433365173526
+42	0.41244955572852315
+42	0.19277118778247818
+42	0.19334850386098204
+42	0.26383618982352736
+42	0.26553119262146097
+42	0.3041119432750138
+42	0.3681955728810107
+42	0.3563317545035562
+42	0.31780722582345494
+42	0.30168258206941023
+42	0.40859617875890597
+42	0.3202631995724868
+42	0.2677896230297515
+42	0.16501994769607378
+42	0.22596796721934234
+42	0.1815318783708669
+42	0.2862176043025645
+42	0.265464150175596
+42	0.2026286741453884
+42	0.24888798678484741
+42	0.20080506590673053
+42	0.3171590384547383
+42	0.1564353497250755
+42	0.32190024880319706
+42	0.14443752059454998
+42	0.1851638559179735
+42	0.2991278137754127
+42	0.27736092215487596
+42	0.3308767620828261
+42	0.12431128085220564
+42	0.28992354936573916
+42	0.2226150426096398
+42	0.30530897483650826
+42	0.22909818754657765
+42	0.29135202291965867
+42	0.2276632365160676
+42	0.19179628197547915
+42	0.30637846185064
+42	0.14694267919945922
+42	0.2818609302650568
+42	0.27751475938638137
+42	0.24524771662811984
+42	0.1632460703961561
+42	0.2678151901058054
+42	0.18591622295107468
+42	0.2869692847755483
+42	0.1968986314951194
+42	0.3211980137725994
+42	0.4147268653813236
+42	0.3258407240913792
+42	0.19025662816233174
+42	0.2831321151468732
+42	0.30580950056066547
+42	0.1935876464945885
+42	0.2567821358228041
+42	0.25074661694934003
+42	0.3677878635256093
+42	0.33583566288559363
+42	0.3460499885601523
+42	0.3227636018528428
+42	0.2426765772739665
+42	0.30448604203132895
+42	0.14123401512971648
+42	0.1398866453402284
+42	0.3463776222864078
+42	0.21880492385634967
+42	0.31074511959814444
+42	0.37302610345776077
+42	0.25441058045614817
+42	0.40917850628807373
+42	0.3436843231179533
+42	0.21039968620609434
+42	0.2820575062302106
+42	0.2857400747408175
+42	0.2240720225199722
+42	0.3762570867260243
+42	0.12178209359066629
+42	0.25318673349028004
+42	0.21710491600950435
+42	0.08969235410573947
+42	0.3422916563708627
+42	0.24948841804032781
+42	0.2981811186996301
+42	0.11252551350680819
+42	0.2085941209872235
+42	0.3795781508234715
+42	0.2258004955381494
+42	0.17081526310060174
+42	0.1695688193385924
+42	0.1164492982249643
+42	0.20457191162769775
+42	0.28766625908222454
+42	0.2689616237849957
+42	0.26427134426860593
+42	0.3207087468941736
+42	0.2712089738528373
+42	0.3698647146393895
+42	0.33729602630543964
+42	0.22403211227839084
+42	0.3121753837379933
+42	0.25486496149429216
+42	0.2187233643215878
+42	0.3801408649965943
+42	0.3385324441289332
+42	0.30938499861539065
+42	0.16770578201538353
+42	0.30825525692198347
+42	0.35755602793700014
+42	0.23214951739632061
+42	0.23509093201820086
+42	0.32158282713837644
+42	0.30336321288188767
+42	0.13103119243023673
+42	0.13399429991167258
+42	0.25341348029812333
+42	0.2617331526831307
+42	0.2509342426397983
+42	0.30711942611831095
+42	0.2223533577577322
+42	0.3472717816167187
+42	0.2854467891077006
+42	0.30601637770304146
+42	0.2445037843980727
+42	0.28151681932224176
+42	0.3081093143130619
+42	0.18754220598081234
+42	0.12154773975075009
+42	0.25031956656505494
+42	0.28562721005601743
+42	0.16299290790812718
+42	0.28453936794718754
+42	0.14392700982503434
+42	0.19818206957982254
+42	0.33468005288752306
+42	0.22789923257953795
+42	0.3000666081504022
+42	0.1756790412676303
+42	0.2067884625352549
+42	0.3023816114506043
+42	0.14566686037109797
+42	0.25038634815012
+42	0.2559513066586083
+42	0.2683141804362857
+42	0.12715388282000412
+42	0.15175447680819237
+42	0.205765793626032
+42	0.24190727957533406
+42	0.19774206703990416
+42	0.19914198194493843
+42	0.28705145813167415
+42	0.28378238894210506
+42	0.32151322864030946
+42	0.1930714044856029
+42	0.4482111662175079
+42	0.3262194998013266
+42	0.35395923866224227
+42	0.2277090333714133
+42	0.3024383233048674
+42	0.2708483816438317
+42	0.2453509638027151
+42	0.3470823799361768
+42	0.1538614089795122
+42	0.2803635117222011
+42	0.43041716938398905
+42	0.3313183127390842
+42	0.23853684062397273
+42	0.2986263110187488
+42	0.2113478422486397
+42	0.2927546062225398
+42	0.2857907244881094
+42	0.16868354454895107
+42	0.24393865847233248
+42	0.20971919525637123
+42	0.34790136699026714
+42	0.22903140091609925
+42	0.18314516926022512
+42	0.2985403184881531
+42	0.34325321987767243
+42	0.3703351920356902
+42	0.16495291238429818
+42	0.2744920752082862
+42	0.39723311556239244
+42	0.3708470643289866
+42	0.17885863578329786
+42	0.2241019015742405
+42	0.0778413071835237
+42	0.26370745262091444
+42	0.23748872755087752
+42	0.2587402770494755
+42	0.2710440450741832
+42	0.24493368601246904
+42	0.2862666663685323
+42	0.19297694934012807
+42	0.35595488475824816
+42	0.19541699229184223
+42	0.27770741859265957
+42	0.2529939941789346
+42	0.23131174941695717
+42	0.25900506001469237
+42	0.33239866266790236
+42	0.3739887253499491
+42	0.1386520272290297
+42	0.19002030463228095
+42	0.35558868264808274
+42	0.3909867181039006
+42	0.3671897133783728
+42	0.32714699612854453
+42	0.21483119475887877
+42	0.11101395509066998
+42	0.15402802872452773
+42	0.3517433059409072
+42	0.09865627722954017
+42	0.3004771523010809
+42	0.2666876524292616
+42	0.17240780089771873
+42	0.3007652335182386
+42	0.2783913272359643
+42	0.2937656171640572
+42	0.17060716928338918
+42	0.24012038895786827
+42	0.2541268160014588
+42	0.2914960551134255
+42	0.1914404641553811
+42	0.3420483766029299
+42	0.19161463793016156
+42	0.35947880477226846
+42	0.32590365292908263
+42	0.24149440475104278
+42	0.2563133687412727
+42	0.3385473763599305
+42	0.35743135198476056
+42	0.25947437050876143
+24	0.19790553689768478
+24	0.22710811785916638
+24	0.2831273799389847
+24	0.21768690780962435
+24	0.27036730802197745
+24	0.143590365299517
+24	0.18294037856101222
+24	0.1783198749237604
+24	0.15674393674027787
+24	0.2582612819030768
+24	0.14727150232568184
+24	0.31814618639138886
+24	0.14967045513811827
+24	0.24801086329591995
+24	0.25885234003506746
+24	0.21232480902835915
+24	0.16517216699364065
+24	0.18554568474204466
+24	0.1598339757099598
+24	0.20331834521180123
+24	0.17897862612624316
+24	0.278577116714342
+24	0.1429963197703243
+24	0.12213543123128281
+24	0.1017324474265239
+24	0.1308610201530273
+24	0.1821769971216753
+24	0.1972339366624553
+24	0.19740659530165688
+24	0.24986336201033715
+24	0.15190695979945926
+24	0.1724014415531246
+24	0.10358513600980995
+24	0.07763957156812229
+24	0.24813551872451234
+24	0.27982370821680647
+24	0.22916825974695587
+24	0.31165991680365673
+24	0.2855595752387192
+24	0.24374725836179922
+24	0.19444021229873196
+24	0.12956696443389554
+24	0.22564269415176758
+24	0.13347298431100682
+24	0.25103488988522776
+24	0.1994134370224856
+24	0.17036755487843536
+24	0.2637123845966683
+24	0.19474582982842406
+24	0.10822086339102806
+24	0.33139487471825446
+24	0.3260347663539263
+24	0.2395373469751279
+24	0.18066711419388307
+24	0.15011401078798106
+24	0.06085855982611361
+24	0.2740503662256725
+24	0.16497959904529824
+24	0.1557267825383838
+24	0.1794003224318102
+24	0.19464521331310378
+24	0.10746110557194019
+24	0.21982976959738443
+24	0.17899863190020893
+24	0.1674976920401691
+24	0.1361407388934812
+24	0.1528964600457554
+24	0.24073645033341817
+24	0.21031562207853088
+24	0.300690852526878
+24	0.2674495319877774
+24	0.20209003084587865
+24	0.29639456385306123
+24	0.23044835565337585
+24	0.13348495503155772
+24	0.2817086519967083
+24	0.08383157823383504
+24	0.29755817279469177
+24	0.3473700612179135
+24	0.22356881435348475
+24	0.2738196162046613
+24	0.27224938838431645
+24	0.12966139576234487
+24	0.1743417198397487
+24	0.2107107355783217
+24	0.1543592586893307
+24	0.03475276855466731
+24	0.06964595524251203
+24	0.1404184949297129
+24	0.16205549471342223
+24	0.1977002055344568
+24	0.1319312155968245
+24	0.22332303533976
+24	0.051641313140702874
+24	0.15936352109395727
+24	0.22411380725014227
+24	0.15374498115673582
+24	0.14658063251747713
+24	0.21311610762075384
+24	0.24013068719624023
+24	0.3153501453438446
+24	0.2743267690686412
+24	0.13412443229939097
+24	0.09469674839036354
+24	-0.0008026463123723161
+24	0.20051208583539445
+24	0.37950548861040234
+24	0.3953801882460549
+24	0.12463347788629495
+24	0.11529283785904973
+24	0.17870332268945036
+24	0.17113482766595028
+24	0.3636874214002569
+24	0.32036967535645516
+24	0.346560664261649
+24	0.27209973335415844
+24	0.15856286744788872
+24	0.2072281716012997
+24	0.09391771546387198
+24	0.1767783939892196
+24	0.1709285659735161
+24	0.265428786130952
+24	0.26180127129429087
+24	0.0804291160017483
+24	0.019086930615344246
+24	0.1691801428806647
+24	0.3365645882288077
+24	0.18613018257669234
+24	0.23497833262333512
+24	0.1470197485980157
+24	0.27175744728515894
+24	0.3004000535433247
+24	0.23173758381416587
+24	0.19658388309924624
+24	0.29406884872540273
+24	0.1535962589703202
+24	0.13721042267902778
+24	0.21932471346887925
+24	0.0744704582875836
+24	0.06069995200207256
+24	0.1949476071270506
+24	0.27134615089359554
+24	0.28277453372961897
+24	0.28745357627016255
+24	0.29561695539319344
+24	0.06486494118178614
+24	0.15351713761094823
+24	0.08454337854419323
+24	0.12585503375149584
+24	0.13083318616841416
+24	0.1460791982310937
+24	0.28406351996676377
+24	0.2740369890350601
+24	0.1694502088308146
+24	0.19201677250582158
+24	0.25478156136126545
+24	0.15467593443345182
+24	0.18201796488216165
+24	0.08542574983667961
+24	0.1098681703140521
+24	0.24883923709982914
+24	0.15435935909269868
+24	0.1402682583286043
+24	0.17015682814510155
+24	0.15309577086805926
+24	0.25924934772872316
+24	0.1984452312413463
+24	0.10478889753170559
+24	0.2717653292503921
+24	0.2809065570015751
+24	0.3346232087491217
+24	0.1348981001142936
+24	0.2238128408816988
+24	0.26020574632255944
+24	0.18991738024402166
+24	0.0762738003264113
+24	0.12017140041004391
+24	0.062460175074459556
+24	0.214645793763688
+24	0.11327473030974505
+24	0.12671643973799382
+24	0.3177275269684542
+24	0.3384193473663254
+24	0.26462982434978677
+24	0.19505330500642676
+24	0.19467799214424833
+24	0.17618423738433037
+24	0.2270461779672993
+24	0.42522923994614
+24	0.3481752095523971
+24	0.18280334727015984
+24	0.18808615016173005
+24	0.17046475131337574
+24	0.1231478614171666
+24	0.13954207787446146
+24	0.2666784856105947
+24	0.12950785458594619
+24	0.1695868178247034
+24	0.23355940988523655
+24	0.17678342699135027
+24	0.2161707759758454
+24	0.3430671301828069
+24	0.26042760464093395
+24	0.2141010318346544
+24	0.1347995089466797
+24	0.2052740711928698
+24	0.18784578106007796
+24	0.13666570116494764
+24	0.13220198687432042
+24	0.12520639464311684
+24	0.12445855819609349
+24	0.23506790850037024
+24	0.3298291866486825
+24	0.3567787799633996
+24	0.18907055926572758
+24	0.3122185052282716
+24	0.15812805025932886
+24	0.25629084322164664
+24	0.3253140206833454
+24	0.243773433074451
+24	0.15946897290186102
+24	0.24180713394682954
+24	0.2391005409001054
+24	0.3134464230133931
+24	0.09118348968674822
+24	0.20960732751901331
+24	0.246413742067776
+24	0.1755156293556726
+24	0.11695781978312311
+24	0.09812033772168058
+24	0.13738549343302067
+24	0.33896450925921134
+24	0.3128133946196963
+24	0.19626055641212345
+24	0.1871176016211831
+24	0.22704225226582633
+24	0.2795215768188443
+24	0.04222009253793321
+24	0.2872944538732025
+24	0.25231535052099413
+24	0.1795221846213304
+24	0.3598640682462977
+24	0.16041462684381608
+24	0.07104839338667983
+24	0.29584931961133637
+24	0.2745219160605802
+24	0.30131943867679245
+24	0.24711176122985282
+24	0.3099234984813589
+24	0.07641702867054065
+24	0.046616247252729066
+24	0.15650752483154676
+24	0.20435457793018194
+24	0.1315317195828127
+24	0.2563307627271625
+24	0.3518049424359911
+24	0.21068971709356055
+24	0.27267322752741646
+24	0.15904277733885722
+24	0.060037431579857026
+24	0.17835252511467092
+24	0.3541719862170675
+24	0.19240186079371493
+24	0.19826748084379392
+24	0.27640930916154477
+24	0.19683334723542562
+24	0.21960747406909195
+24	0.254064765220687
+24	0.08036017899404158
+24	0.13505515854501007
+24	0.26736759044802316
+24	0.14512437906581974
+24	0.2367691259585742
+24	0.09501408658821882
+24	0.031838911255741
+24	0.27987936549866893
+24	0.21505549416194367
+24	0.16535214620391775
+24	0.16895356276699802
+24	0.10068659391240721
+24	0.2544536222322728
+24	0.37905198932092965
+24	0.36458646650927695
+24	0.18635280438370577
+24	0.18242550419142772
+24	0.20221367335460044
+24	0.15888904241703067
+24	0.18885856704765916
+24	0.31996979014315147
+24	0.20985027347030782
+24	0.2692637195887928
+24	0.266666731479606
+24	0.11421094769794367
+24	0.08532939431987357
+24	0.26115204532667385
+24	0.28008396111120776
+24	0.297923437058102
+24	0.3387646825075406
+24	0.27317264047478856
+24	0.2717431838135809
+24	0.195536460459092
+24	0.2480047518739607
+24	0.09861303512616916
+24	0.2545547263338116
+24	0.27751880067075574
+24	0.17950767512386148
+24	0.14309360799564727
+24	0.16805503360072419
+24	0.2463850103193961
+24	0.1707040750547897
+24	0.2500780109052853
+24	0.3011003288791075
+24	0.15138605494450988
+24	0.1536032512740231
+24	0.30717424623181483
+24	0.13522174925006844
+24	0.09301292636501513
+24	0.30531282048697905
+24	0.1521719023191452
+24	0.10305393318198186
+24	0.1559238680322331
+24	0.16919209362939264
+24	0.18997307645449682
+24	0.12804752565748506
+24	0.17438009206613994
+24	0.1805186927008004
+24	0.1323143434919826
+24	0.2779407775636691
+24	0.10144400793412071
+24	0.21475880584334206
+24	0.14606579236273134
+24	0.1884446671097144
+24	0.13917987082915778
+24	0.24844676687836068
+24	0.42123207953911657
+24	0.18711501953990128
+24	0.20509417797301704
+24	0.049945092060653895
+24	0.27813337353139295
+24	0.36387241772098833
+24	0.1340211952966878
+24	0.0827905974957253
+24	0.17286725099797293
+24	0.11493405455372409
+24	0.342471987623805
+24	0.2986955445740717
+24	0.19431437057695522
+24	0.15589385168195286
+24	0.12586460474593186
+24	0.07916139856469634
+24	0.2407008631486092
+24	0.24216871719435012
+24	0.19980193686034936
+24	0.3511503054674501
+24	0.2944237995100867
+24	0.163940170946309
+24	0.08922198895993404
+24	0.2673014358108566
+24	0.12871012881170585
+24	0.12436573433077032
+24	0.19569361010375178
+24	0.26757800161923245
+48	0.3551675893476568
+48	0.3029839426639329
+48	0.2691616723769636
+48	0.1206207496644454
+48	0.012552239608334848
+48	0.32559820703421627
+48	0.38658068089439623
+48	0.27924432200080734
+48	0.07324450962652737
+48	0.1196318290196782
+48	0.23287467665698908
+48	0.2822216828864572
+48	0.303721016904814
+48	0.07015163290305716
+48	0.37746786788543196
+48	0.3900805962741682
+48	0.28460059312753627
+48	0.22525352563087564
+48	0.2324280763809819
+48	0.3753830494018469
+48	0.305648532301218
+48	0.2951826834385632
+48	0.1972370781504936
+48	0.30385142730691833
+48	0.3015014598432605
+48	0.3503062849228447
+48	0.37878250388663354
+48	0.3011404320264295
+48	0.33438488284948303
+48	0.3714115150506672
+48	0.29570383514736254
+48	0.3202851502438718
+48	0.33518830200434885
+48	0.12290864887338578
+48	0.11123465027366145
+48	0.16044065599140994
+48	0.26683022089490893
+48	0.3276994055780216
+48	0.1188397952727262
+48	0.13353933341711596
+48	0.10306131092373856
+48	0.2685019899453477
+48	0.23438856270336753
+48	0.3134210908001407
+48	0.268138709598159
+48	0.3315368791929473
+48	0.29437489209191214
+48	0.09877408762644943
+48	0.2210425120857767
+48	0.3417255558757113
+48	0.44800368818191755
+48	0.10922895389109953
+48	0.06460299240570631
+48	0.3019664619968205
+48	0.4085704861590551
+48	0.32488856076547884
+48	0.26367767484099786
+48	0.11459645668153874
+48	0.20159979495303215
+48	0.38130083313817087
+48	0.2246694533058003
+48	0.40006270680395495
+48	0.3209164922662687
+48	0.36366050970274943
+48	0.08910793481325206
+48	0.08013597295258618
+48	0.40929663590554527
+48	0.32306618898959627
+48	0.04296512427831905
+48	0.3457926939700018
+48	0.25527449667450774
+48	0.24239122983463626
+48	0.24497930272144777
+48	0.36734665422666013
+48	0.2995918499931306
+48	0.32916670531529973
+48	0.30913729063526635
+48	0.09082509905747674
+48	0.15775291309319306
+48	0.30101208488562126
+48	0.4517951098510396
+48	0.0986653293132975
+48	0.08816738510698048
+48	0.21293105493923503
+48	0.20117764743585406
+48	0.18040936501590968
+48	0.3438588487122324
+48	0.4243293228505781
+48	0.253738277849286
+48	0.2901243870179684
+48	0.3447880134933692
+48	0.33067893970571244
+48	0.3313696373670865
+48	0.3163745475695047
+48	0.34380002645649255
+48	0.10349827451337927
+48	0.3662550988168423
+48	0.4063949356725796
+48	0.3690814443528347
+48	0.37911978888396447
+48	0.3998800655177146
+48	0.29135571485451656
+48	0.3194863565692299
+48	0.11495630268809529
+48	0.1451522647353847
+48	0.39373244312610767
+48	0.4172129309017197
+48	0.42556473615625656
+48	0.2023738712452383
+48	0.2926146286420459
+48	0.3128594918286925
+48	0.22441916841647913
+48	0.21589424697875184
+48	0.3344985336757542
+48	0.22951019476896456
+48	0.39634592373539734
+48	0.38131689680117953
+48	0.08159211781809257
+48	0.11082451328671881
+48	0.12836750670023173
+48	0.15083350464109582
+48	0.16063000394134938
+48	0.25872920322168086
+48	0.17715354202832825
+48	0.09216220267412116
+48	0.3067864966817196
+48	0.3464050606354432
+48	0.09201117098022833
+48	0.0880493842928479
+48	0.2233514014070444
+48	0.30352271325694963
+48	0.060372608455139906
+48	0.3357056378259479
+48	0.3012744054645768
+48	0.3609594466021884
+48	0.3122088557254297
+48	0.37251416080266236
+48	0.17698222695812113
+48	0.03364468340629478
+48	0.3779571024164658
+48	0.3827177211010319
+48	0.14377113288122315
+48	0.16114501629748038
+48	0.2388509044016457
+48	0.2347860615031928
+48	0.3028506016038527
+48	0.42101467340062204
+48	0.26974611352359934
+48	0.09323259164290024
+48	0.20538663303618807
+48	0.3327214284641184
+48	0.3729863283238458
+48	0.35176111726425957
+48	0.30107373136677545
+48	0.05745659297233838
+48	0.3060990688143276
+48	0.26917619180975805
+48	0.2855106227519919
+48	0.26931808166474314
+48	0.2364877554304346
+48	0.10918578709913011
+48	0.2607512485156109
+48	0.30393578914306135
+48	0.22025456605526347
+48	0.11459590161950015
+48	0.17819392851270116
+48	0.3953152236327759
+48	0.10058901364412431
+48	0.2145380630372501
+48	0.3162234766368334
+48	0.3726039771782065
+48	0.3311286401363222
+48	0.2550330062779568
+48	0.2969727160950758
+48	0.10716506131360012
+48	0.31759766509425685
+48	0.37802062502536043
+48	0.2789507976181642
+48	0.36243632646191065
+48	0.05841635586296305
+48	0.4111205353145853
+48	0.28223360744530096
+48	0.29818769906659676
+48	0.41051475398542375
+48	0.23001261910970186
+48	0.3156090056684118
+48	0.350463651155245
+48	0.4382539035109758
+48	0.2583319259546643
+48	0.3277551096888999
+48	0.1159733844482558
+48	0.23064467891355708
+48	0.182862026469426
+48	0.3294006569251962
+48	0.38285468874736267
+48	0.3172203314572131
+48	0.3584384624703026
+48	0.21770978409556252
+48	0.3968728048298897
+48	0.09881606835110456
+48	0.1250387606415887
+48	0.264128971722677
+48	0.3043658155246808
+48	0.26999286986421017
+48	0.26146138319100076
+48	0.3812998020857394
+48	0.33306741286218183
+48	0.2938034139566092
+48	0.11778915046877264
+48	0.20577246822952228
+48	0.2833992619313439
+48	0.3589300122400213
+48	0.42132651005544125
+48	0.10524311692590656
+48	0.14632892429046526
+48	0.34702590704951575
+48	0.40302082851139664
+48	0.4036189086754585
+48	0.45769762570835243
+48	0.34690853723787923
+48	0.33694538698283705
+48	0.3051054156934929
+48	0.11792209247826003
+48	0.41479954920478523
+48	0.3814502296322183
+48	0.3052100307356337
+48	0.3709693909895762
+48	0.11017259812148356
+48	0.26958797673825563
+48	0.4052506325781916
+48	0.4001884126812448
+48	0.1206397389622727
+48	0.1956180471140636
+48	0.3773850796282823
+48	0.2541403282857185
+48	0.11162269270006023
+48	0.13871365567135605
+48	-0.003381142816973241
+48	0.17260792108644965
+48	0.31929858556004165
+48	0.33384643181600737
+48	0.3743359973452494
+48	0.381773919284412
+48	0.0730299245107845
+48	0.22653064788610186
+48	0.29774414002967126
+48	0.39424501529953254
+48	0.394123000961944
+48	0.2288826480078343
+48	0.3407773008789615
+48	0.3611622482752198
+48	0.2279758812276352
+48	0.38408181294794863
+48	0.3952752690275577
+48	0.11916009673437547
+48	0.2075518406500319
+48	0.37186632511283985
+48	0.2903224408096983
+48	0.4287597961289081
+48	0.2155614368920194
+48	0.4023916038857773
+48	0.3677496028587203
+48	0.3842801956625593
+48	0.41190094820330003
+48	0.25053820111991243
+48	0.17042835452135385
+48	0.2901880837379948
+48	0.23014950771760914
+48	0.37982484355289853
+48	0.3229165937944346
+48	0.3113722241872444
+48	0.018292416026866563
+48	0.2568119438701664
+48	0.27035803311727075
+48	0.3295936819082532
+48	0.4118447875498257
+48	0.22818924341197003
+48	0.2526194804418207
+48	0.2619798104387617
+48	0.2903636303465669
+48	0.3648699819992016
+48	0.3812934446402758
+48	0.3714173430289321
+48	0.2925849157147705
+48	0.2791036777070334
+48	0.1118747183451188
+48	0.3363326970129055
+48	0.3531028395754862
+48	0.3745473399171792
+48	0.09726066590360619
+48	0.1302524248617692
+48	0.2444207840792473
+48	0.37114014146472324
+48	0.4155342712321063
+48	0.09541129393087755
+48	0.04959857828836236
+48	0.15597584203567655
+48	0.38016440914906907
+48	0.21192206382333445
+48	0.3415553151444974
+48	0.3391624455856367
+48	0.05933841297508696
+48	0.38613096503060823
+48	0.1965469348220211
+48	0.28189893641237707
+48	0.3657865303612813
+48	0.45649521977674656
+48	0.40348356645640066
+48	0.08783585084207264
+48	0.15725435651551112
+48	0.20381634390756406
+48	0.2487645173733094
+48	0.42856057120551266
+48	0.31708536960863903
+48	0.30221572050824147
+48	0.3739806292033797
+48	0.3995210463370675
+48	0.2900109718069549
+48	0.20496899451977654
+48	0.3041321221561581
+48	0.2826348038272992
+48	0.2457130850700033
+48	0.40462121420573716
+48	0.338964819867775
+48	0.2352015410051038
+48	0.119671337113974
+48	0.4057654590226315
+48	0.33162582039037347
+48	0.36800801282872364
+48	0.430151290901478
+48	0.27095908632799964
+48	0.2512756294420702
+48	0.388335689831204
+48	0.14739792939592142
+48	0.47332344250024977
+48	0.44287099841905275
+48	0.3354252497568977
+48	0.4535285112178097
+48	0.38968209731859166
+48	0.3123392408053267
+48	0.37487979873156746
+48	0.3489623343326257
+48	0.3594027884494982
+48	0.055350449089219385
+48	0.387485154930159
+48	0.37209113972305813
+48	0.1653442363153301
+48	0.3247774534652951
+48	0.3409757495903718
+48	0.11833854448791185
+48	0.3633412872303644
+48	0.35989314965332575
+48	0.18681704776203456
+48	0.2752672764245704
+48	0.345049551886198
+48	0.18689076927675113
+48	0.3171670364269706
+48	0.24993450280137797
+48	0.35115316046546846
+48	0.33908037083592685
+48	0.24912945718917787
+48	0.402658020888856
+45	0.3124983169402127
+45	0.33116875206500856
+45	0.2505059659029082
+45	0.23908424235008405
+45	0.23150046654835985
+45	0.3690828650635876
+45	0.2672522578452901
+45	0.28266974409419626
+45	0.32351023282100394
+45	0.2507789169802386
+45	0.26400405362899027
+45	0.3416554562767774
+45	0.28205107954164776
+45	0.2768053599315089
+45	0.1680936163312445
+45	0.16957231259976444
+45	0.17934463200395923
+45	0.11290859799957205
+45	0.28514096473653316
+45	0.24778422567334418
+45	0.3248972822355931
+45	0.28992719979174614
+45	0.22266250610310465
+45	0.2842277997924959
+45	0.20601606125135902
+45	0.3598999496289073
+45	0.28455889065063256
+45	0.213726740063389
+45	0.1752801286108505
+45	0.2835964528456392
+45	0.20938715525551715
+45	0.1626422670535399
+45	0.29896317396739175
+45	0.3204592151586491
+45	0.228547148252908
+45	0.2868651138298503
+45	0.17239153763688986
+45	0.2755450573021767
+45	0.22224968383310278
+45	0.30344269114178146
+45	0.3093948825870862
+45	0.3158976157099567
+45	0.003304267487999917
+45	0.25800933695584316
+45	0.11034422785973776
+45	0.2990529756707605
+45	0.2218243436560208
+45	0.3173665238627233
+45	0.24957344655865893
+45	0.36911637941359493
+45	0.33735232219191263
+45	0.29830809376546064
+45	0.2104461034838414
+45	0.27921739062409046
+45	0.3464289030225082
+45	0.16295360219479035
+45	0.12397398226243038
+45	0.13602267634182982
+45	0.16522077076609204
+45	0.312547482131316
+45	0.13137725769708888
+45	0.2673601512971812
+45	0.28763903631123827
+45	0.38906096034080995
+45	0.36400436752243914
+45	0.17738271685793888
+45	0.2504179161569889
+45	0.15482437308595862
+45	0.2253107521516874
+45	0.23604353136432066
+45	0.08270751916129206
+45	0.1085790424811283
+45	0.3555903925748332
+45	0.31333141004004333
+45	0.28712492727744093
+45	0.17789602844926133
+45	0.2268242349678045
+45	0.3100236306767119
+45	0.38093686701231816
+45	0.32170605672550373
+45	0.3569746789012745
+45	0.22872566452402426
+45	0.24592870155555946
+45	0.22060354791415637
+45	0.2885872381571404
+45	0.3985795242129321
+45	0.19195908488392613
+45	0.18377752818147186
+45	0.2905239356491232
+45	0.21556529506365493
+45	0.3318147045694093
+45	0.038441432351721774
+45	0.2281571586854437
+45	0.37142364269726014
+45	0.24790934752138302
+45	0.2898135140972893
+45	0.3001690120825347
+45	0.36556791410991546
+45	0.27169088470418
+45	0.15388815275307252
+45	0.3130531939648414
+45	0.31980204207316654
+45	0.23283227514336094
+45	0.27118817044743626
+45	0.36747205649924314
+45	0.307772861904412
+45	0.2958329026090127
+45	0.29199327105227946
+45	0.2127652014775416
+45	0.24663632821634326
+45	0.12925723947935688
+45	0.25107265982594207
+45	0.27126002617190503
+45	0.3149475016302158
+45	0.16401850572673618
+45	0.3049305068219805
+45	-0.05425744908847504
+45	0.1767245364500823
+45	0.33215192499208557
+45	0.23123276024412937
+45	0.3449866910322812
+45	0.23716528487109984
+45	0.28529046827783205
+45	0.3085749303577661
+45	0.1312105994261713
+45	0.2731138009832046
+45	0.2040914859076373
+45	0.3512070701863584
+45	0.1306891024498381
+45	0.29421557768662476
+45	0.11843930645360808
+45	0.3273816198964007
+45	0.2746408092976431
+45	0.2321710306011338
+45	0.3332670764109456
+45	0.18592561904224572
+45	0.2521091918779046
+45	0.2852173916410787
+45	0.3460231024420837
+45	0.2880549831331247
+45	0.3287923689796415
+45	0.17735270857281685
+45	0.26163414101486543
+45	0.2669200236191398
+45	0.2871319873874225
+45	0.34945665997439535
+45	0.2880106783412256
+45	0.29630212121462407
+45	0.2943289268377174
+45	0.1948468123913131
+45	0.3179904423182695
+45	0.3593394598005488
+45	0.30998023736837016
+45	0.2283260637315052
+45	0.3038748267313915
+45	0.27194753841390196
+45	0.28227368864835506
+45	0.351683325255807
+45	0.23892991516827547
+45	0.21238383385871756
+45	0.15936347639477402
+45	0.2542485938246705
+45	0.3418170139482488
+45	0.18642144745719177
+45	0.29373172139973786
+45	0.32235271143597727
+45	0.1497808435296539
+45	0.1725611579479046
+45	0.28408476592626003
+45	0.13232235939431677
+45	0.2844313725116561
+45	0.26768010828251254
+45	0.2619131410844523
+45	0.2582511250775779
+45	0.22203163427519984
+45	0.2238733401589703
+45	0.32416183706617946
+45	0.303536921738626
+45	0.1623813926162908
+45	0.2985309510557688
+45	0.304168679804778
+45	0.2892070105301445
+45	0.2997225118704924
+45	0.2715909806380545
+45	0.301408524084552
+45	0.30315340240732014
+45	0.42544899032248784
+45	0.2774349279993822
+45	0.4176441726012256
+45	0.18355892903487803
+45	0.21224917036191707
+45	0.26577084385143457
+45	0.32981623615772143
+45	0.13060022315834208
+45	0.29055888541894814
+45	0.22523450295880185
+45	0.26772378856258866
+45	0.27097141570653527
+45	0.3592034732824547
+45	0.22382417981000743
+45	0.3523679536165535
+45	0.12667751186340973
+45	0.31216937618543306
+45	0.3347468570303935
+45	0.2917148250470128
+45	0.24526812632820852
+45	0.27361728155182774
+45	0.23583864446871075
+45	0.17184907096701138
+45	0.31922586290380806
+45	0.2691044468868288
+45	0.38570988540889717
+45	0.24445210544752216
+45	0.37041340430384806
+45	0.1914918946167576
+45	0.27045525389217207
+45	0.2723333937844612
+45	0.30671693005542305
+45	0.18494876931720708
+45	0.30806752420231953
+45	0.2983097006865208
+45	0.3330056819777362
+45	0.2671546053212572
+45	0.26346897721416046
+45	0.39576012279702233
+45	0.27868720017866716
+45	0.3511355097793164
+45	0.30234269046573065
+45	0.19390261000196143
+45	0.3504867373785553
+45	0.16935257438158638
+45	0.28629221184312087
+45	0.19203644523810387
+45	0.3096782466798112
+45	0.1883967309154943
+45	0.3033614021497964
+45	0.3314573829210318
+45	0.28650720126325807
+45	0.3219917167142385
+45	0.1770469051189398
+45	0.27247889944869075
+45	0.30610685898876655
+45	0.18348339002775169
+45	0.30168953003659815
+45	0.2751732394601797
+45	0.29529139484829003
+45	0.14763909857634178
+45	0.24698221715371527
+45	0.2698374052721342
+45	0.18263039730206423
+45	0.20869507808701016
+45	0.2983528849704588
+45	0.27583917978949984
+45	0.1624039629705889
+45	0.3353166469459483
+45	0.35398969287139703
+45	0.3573139519352138
+45	0.36605981750978467
+45	0.30629646912066777
+45	0.26951477433247867
+45	0.2901807702781627
+45	0.33075306944795485
+45	0.27301098139429286
+45	0.17643189094562686
+45	0.35300193526897256
+45	0.1525446161121612
+45	0.37968260559321104
+45	0.3935425335598787
+45	0.37134106511769926
+45	0.25438964749270526
+45	0.14693416876059745
+45	0.25714839694205455
+45	0.3842574821878314
+45	0.2215537036604381
+45	0.13446590356023672
+45	0.2131269096077401
+45	0.3685514586765904
+45	0.2303195886420406
+45	-0.03795661043088061
+45	0.33970539501556374
+45	0.16822848514719987
+45	0.2123406336295905
+45	0.21411457322483476
+45	0.1648447197100161
+45	0.27754696387413386
+45	0.259921629951526
+45	0.3450641584453181
+45	0.3620443073991871
+45	0.39782744998915015
+45	0.28872265683452086
+45	0.3413099422876647
+45	0.08895880478675093
+45	0.13041939980386133
+45	0.21858279558743512
+45	0.20125210040148278
+45	0.2985494056828693
+45	0.14659480024188595
+45	0.2009468671219388
+45	0.3096408319304985
+45	0.14054409390545686
+45	0.29052411086634294
+45	0.2828973385314684
+45	0.3026404854071716
+45	0.2912358121247724
+45	0.2773186464530342
+45	0.3282132136860264
+45	0.32430774442149274
+45	0.35848764693479446
+45	0.3152033425021248
+45	0.18129300673540721
+45	0.30396326208511176
+45	0.18133070763282236
+45	0.16831907329912119
+45	0.31549242889674134
+45	0.19060404124715621
+45	0.35682036391843996
+45	0.2920972583226804
+45	0.28712011333289894
+45	0.14149808669586292
+45	0.3181888461913371
+45	0.36472892921803024
+45	0.37973996889342565
+45	0.27540096016782595
+45	0.32376185671377805
+45	0.30332378437275404
+45	0.2461171942603896
+45	0.11566304679158444
+45	0.19565531916658782
+45	0.23054900746524035
+45	0.2978985694293955
+45	0.32922537904517346
+45	0.25437014936293434
+45	0.2521485224863052
+45	0.32930672839609026
+45	0.41544577274958255
+45	0.2943210301276344
+45	0.1412497963689245
+45	0.2805331580287191
+45	0.21739918154712298
+45	0.30174809848351836
+45	0.3809099451684133
+45	0.33091030247087183
+45	0.28979775752794934
+45	0.32341946052372367
+45	0.2555861189973346
+45	0.3918744739377754
+45	0.34736003804310084
+45	0.30990772982342796
+45	0.25349325082283486
+45	0.2992783389891617
+45	0.17374233353892327
+45	0.22525246775632057
+45	0.3104574229357429
+45	0.3473081668292879
+45	0.3434668521283889
+45	0.24773314961304338
+45	0.1918164940736658
+45	0.31946527502602595
+45	0.2134468828637457
+45	0.262696936412497
+45	0.21513437267995564
+45	0.2973943087147385
+36	0.24427146730778732
+36	0.31204342680974995
+36	0.24570332728511304
+36	0.34038557689166643
+36	0.2688184924735642
+36	0.2603973712222202
+36	0.30771090085032204
+36	0.22310515739032552
+36	0.307773315041014
+36	0.18595253904568315
+36	0.22248131298023419
+36	0.23477808001015626
+36	0.22237835367017747
+36	0.11447003281594137
+36	0.21826795282253192
+36	0.27630370815643507
+36	0.23298293528280206
+36	0.2225833407344554
+36	0.2536178296630963
+36	0.2670044827197302
+36	0.20050425002516936
+36	0.1379708083656261
+36	0.08218598918423203
+36	0.2414151756520649
+36	0.3042727236317815
+36	0.35323572337004494
+36	0.1670817136270995
+36	0.28733915171561464
+36	0.2386035269138472
+36	0.3276864767389458
+36	0.20582624241999106
+36	0.20206401514550346
+36	0.21311834236998048
+36	0.2292085507393673
+36	0.13203726240963665
+36	0.21225256802766093
+36	0.20217908899571096
+36	0.27557463341914895
+36	0.3254378561280572
+36	0.2364010326948404
+36	0.22762847414447152
+36	0.23106390098754626
+36	0.08675804667562387
+36	0.15823779328778756
+36	0.2505979709301272
+36	0.17953422061755503
+36	0.23118284867819675
+36	0.18285756209110746
+36	0.3011678558237383
+36	0.23351754495725838
+36	0.1677022447699643
+36	0.2681972012325979
+36	0.29834479410915143
+36	0.25217651971703553
+36	0.3079566860538634
+36	0.20588654805042844
+36	0.25911558838693655
+36	0.29469432846301286
+36	0.22213005189758842
+36	0.19328184468991447
+36	0.33173774370135056
+36	0.30331141945240303
+36	0.20911302637503418
+36	0.29741725460099866
+36	0.12005642091999164
+36	0.2069457259429041
+36	0.316690772341566
+36	0.27152737152436446
+36	0.3382386431921839
+36	0.1931009918026606
+36	0.27823261922380593
+36	0.26656365664628023
+36	0.2636469511711614
+36	0.3187058379629633
+36	0.2655022467439439
+36	0.2651373119640723
+36	0.24466147315422318
+36	0.3173323941679964
+36	0.3423790519481916
+36	0.30794279313805856
+36	0.22844572228226212
+36	0.1942780151424823
+36	0.1920624369321219
+36	0.3082831380111679
+36	0.31102465063439144
+36	0.21876055935152205
+36	0.2512272421505301
+36	0.2684793127177926
+36	0.2196562441318272
+36	0.32941608875725503
+36	0.30745741594231163
+36	0.24040706668925815
+36	0.2949631749423152
+36	0.24031922203492195
+36	0.23809318769501764
+36	0.3223782648989957
+36	0.21172090068948402
+36	0.18601141479084726
+36	0.3463065452352794
+36	0.40138892180088553
+36	0.2625667297835832
+36	0.2885074542357118
+36	0.21597667902577136
+36	0.33787297305180336
+36	0.3422627949658
+36	0.2890365399846574
+36	0.3774830923820299
+36	0.25391698159751847
+36	0.16240973087520208
+36	0.3235189322122219
+36	0.19574365568241986
+36	0.3235706744307778
+36	0.31724848668204403
+36	0.24009252845587425
+36	0.2828917152381169
+36	0.30282852802670596
+36	0.23771037395348715
+36	0.2786082371248654
+36	0.302348180335183
+36	0.3149054007863396
+36	0.2892773369642084
+36	0.07538920077523126
+36	0.17274767647117695
+36	0.15757900445997067
+36	0.19498513655840066
+36	0.28293968415632426
+36	0.33719807933950025
+36	0.37260774148103076
+36	0.1736998372462386
+36	0.28081854846704474
+36	0.2577416403468778
+36	0.20665784975455032
+36	0.2532544276336852
+36	0.2605898477486986
+36	0.22897663577590713
+36	0.23936648258981008
+36	0.23392570113869457
+36	0.2898690898069418
+36	0.34873822728817633
+36	0.3024323533706175
+36	0.2837221872834981
+36	0.20166667424400006
+36	0.3075760596480369
+36	0.28594637920045524
+36	0.24802397615988114
+36	0.37101819239438755
+36	0.34753677996001037
+36	0.30339646776569285
+36	0.2312532101660195
+36	0.2845938108376081
+36	0.31430155937650783
+36	0.2807483912322857
+36	0.2603258863165526
+36	0.3621141176184937
+36	0.3274508844876463
+36	0.25945817625850115
+36	0.31478869283466726
+36	0.31110298400484077
+36	0.24419289513268552
+36	0.4093777475309508
+36	0.36141795596932735
+36	0.1891478840952936
+36	0.15881488016318082
+36	0.32955545920444523
+36	0.2788990833883014
+36	0.31602677678184865
+36	0.18433626663807806
+36	0.23157353863842317
+36	0.3551043859298729
+36	0.33942827216801374
+36	0.2487284056610558
+36	0.38836894547944145
+36	0.10936741061200957
+36	0.09839369010908268
+36	0.19973414400739867
+36	0.2949362456018372
+36	0.2883814352139955
+36	0.25611469943677523
+36	0.15981284488579903
+36	0.2599096130711949
+36	0.12723327885600305
+36	0.31455814130672255
+36	0.2672137780252093
+36	0.3412774462326104
+36	0.13012470399323667
+36	0.26527513375640366
+36	0.22448782937138168
+36	0.15540301333693107
+36	0.23013880575720175
+36	0.2624740540448403
+36	0.2732388642740673
+36	0.2945952726342992
+36	0.16463675089739008
+36	0.33618466055484925
+36	0.25937816539120506
+36	0.23188630711853497
+36	0.17046125697542908
+36	0.2599511006677394
+36	0.20448860639250713
+36	0.08339716084552319
+36	0.23826472686229905
+36	0.32459421468464583
+36	0.1771178558276174
+36	0.24099062981575187
+36	0.252690168538217
+36	0.260365929903469
+36	0.34484202747428355
+36	0.26651024691517666
+36	0.2922719708457139
+36	0.2758282139097068
+36	0.350104291829071
+36	0.16802923838987804
+36	0.20304195531363203
+36	0.2905396374996647
+36	0.2271837140577333
+36	0.28637471802264725
+36	0.2441100618104127
+36	0.306597644188263
+36	0.19897906678110694
+36	0.35966096234913547
+36	0.25953056904210425
+36	0.27863497003969345
+36	0.1946273949805612
+36	0.1797885382767864
+36	0.3178109006858161
+36	0.307814399877964
+36	0.2610667850690462
+36	0.2622522145545033
+36	0.21546511457623926
+36	0.203912979843987
+36	0.11955307914712562
+36	0.38360519573283525
+36	0.32499332226597016
+36	0.3061203159212279
+36	0.0771724475751712
+36	0.1829182959568614
+36	0.17890687956927306
+36	0.24825092680767183
+36	0.3735629205865073
+36	0.19119929837440422
+36	0.23470257624143925
+36	0.24331481136772995
+36	0.2034555684098294
+36	0.24845346496805598
+36	0.20978061744458065
+36	0.2891971479571476
+36	0.3660682127880132
+36	0.2970625122958659
+36	0.3331729579975633
+36	0.19298093042971956
+36	0.2828960255128723
+36	0.3005083317640981
+36	0.3154491644992025
+36	0.29737021330398955
+36	0.21719431784907064
+36	0.35865765193348725
+36	0.17437791253281457
+36	0.25839167562142756
+36	0.18961010336975903
+36	0.22205707728121177
+36	0.24547334487582284
+36	0.2992612152977638
+36	0.261662487864983
+36	0.22605290050378468
+36	0.26518380961350324
+36	0.20886162144848924
+36	0.23876137978608147
+36	0.31585936463258707
+36	0.29733854087891176
+36	0.20554086716698555
+36	0.31751167405453634
+36	0.15321201161343917
+36	0.2120356308581129
+36	0.23385658513714586
+36	0.26885242009855087
+36	0.23212254454502207
+36	0.22960005423305846
+36	0.21901575658034803
+36	0.31050816338133586
+36	0.3391388379045855
+36	0.16258133984015494
+36	0.4025834253566042
+36	0.20376695323319052
+36	0.19480508458382137
+36	0.2622691983779372
+36	0.20873034566973314
+36	0.21910208713731139
+36	0.2399657106451429
+36	0.2267786324002338
+36	0.30996384191618226
+36	0.24414915443786403
+36	0.15349318163776846
+36	0.23536431080653886
+36	0.3359914131075278
+36	0.21090758031613543
+36	0.05823896860110463
+36	0.18436865382703088
+36	0.2100088489648645
+36	0.36476390339370995
+36	0.3194045214521137
+36	0.3522334163987418
+36	0.1752110679160632
+36	0.18105920664045
+36	0.16848691728417475
+36	0.16534791291050197
+36	0.2713214856130816
+36	0.0911751090679717
+36	0.1670959362643785
+36	0.32261246188346593
+36	0.2734289781561431
+36	0.21213818188580746
+36	0.04215819440285626
+36	0.23519308363854474
+36	0.3615843456381741
+36	0.33332100774984513
+36	0.16718521778904288
+36	0.17624878979642114
+36	0.16781186435955422
+36	0.1657523848231246
+36	0.2906417938672173
+36	0.15868011727494233
+36	0.3032954131165106
+36	0.2960568626583758
+36	0.17720041459249591
+36	0.09111909688687084
+36	0.2561746407466182
+36	0.2886218440343664
+36	0.3400643725855228
+36	0.3241086871129594
+36	0.31317743130991726
+36	0.27518319549414166
+36	0.23470545889252878
+36	0.2805141433020553
+36	0.3695614318700892
+36	0.31568613246712307
+36	0.29878758884343193
+36	0.25943066075580395
+36	0.06211024944042182
+36	0.318595370010759
+36	0.15745562320725898
+36	0.2511765297577194
+36	0.24681299264437193
+36	0.23121615382820385
+36	0.19584065430896436
+36	0.3054071981780634
+36	0.2830812503580395
+36	0.24573151513312325
+36	0.04450957954023866
+36	0.15367008639889648
+36	0.2620826841708024
+36	0.22931929591081043
+36	0.19174892744140254
+36	0.30864539850382616
+36	0.3261992960078575
+36	0.3507692710813035
+36	0.3743399475469092
+36	0.303109846165951
+36	0.2119006195698333
+36	0.2996619600132085
+36	0.3107609084269637
+36	0.26910984916426556
+36	0.2184253409660522
+51	0.13061336421495415
+51	0.35918323041257727
+51	0.35302728780765225
+51	0.16519402103046138
+51	0.12400558892016462
+51	0.2419486767381491
+51	0.32398007118242717
+51	0.3378443174307483
+51	0.22585938769703603
+51	0.2926167248573044
+51	0.1980237949415752
+51	0.19443159572722082
+51	0.17510207230211217
+51	0.23010737040591825
+51	0.24277425550126192
+51	0.19817024560657123
+51	0.3021160696260172
+51	0.28463477918221863
+51	0.16373761474270093
+51	0.29320012913470184
+51	0.27734319711680977
+51	0.2014428817938745
+51	0.24875870102527808
+51	0.1309513438502099
+51	0.36778027319773626
+51	0.36076720664244055
+51	0.2673575775975403
+51	0.1655583329991059
+51	0.2438368875738747
+51	0.33115621764532105
+51	0.29760062069980303
+51	0.2164390994415728
+51	0.1935098588257783
+51	0.21028512363332436
+51	0.2705042967767912
+51	0.1341772258739392
+51	0.21025035879703693
+51	0.30734684288009134
+51	0.17322478112242615
+51	0.29682805566959763
+51	0.33271615922042225
+51	0.17684186903458282
+51	0.19404127797563545
+51	0.27772900700403724
+51	0.329538226875035
+51	0.20937818624421578
+51	0.16887647136501305
+51	0.18011652455081087
+51	0.22013286208674837
+51	0.27827213101073606
+51	0.2626160455441365
+51	0.21259982424337537
+51	0.1960451235305594
+51	0.13344396816818505
+51	0.22255615232554427
+51	0.31891870548761075
+51	0.15015005719097357
+51	0.2860255012684819
+51	0.1540357537325655
+51	0.21091307682671048
+51	0.19784104984810436
+51	0.17135824456658125
+51	0.17193874486534175
+51	0.25214103990132297
+51	0.3654407132015835
+51	0.22124989358104402
+51	0.17451616595766775
+51	0.27598017039808015
+51	0.2876275764933418
+51	0.3091833719812608
+51	0.21227782222786445
+51	0.2119639236080944
+51	0.2511305142488564
+51	0.1686612166045915
+51	0.25849315510552145
+51	0.20202650310297945
+51	0.14971794346208145
+51	0.1533810357325523
+51	0.16486778701373775
+51	0.298491464642392
+51	0.20804063117768096
+51	0.11636426496848931
+51	0.13358240346016856
+51	0.1856103349262507
+51	0.1869461807073336
+51	0.3247483265438945
+51	0.25072105499949215
+51	0.17865379262719663
+51	0.15803270272514808
+51	0.15088699314476517
+51	0.19906154135000548
+51	0.16849506626068234
+51	0.1690755918808376
+51	0.3521436235766633
+51	0.30347063092600834
+51	0.2648806717835466
+51	0.42411637881869224
+51	0.2276490287067868
+51	0.17210660187794494
+51	0.33341349378052937
+51	0.3390587747888679
+51	0.2449864931327802
+51	0.30966229909841647
+51	0.30643328500128225
+51	0.34197939953136963
+51	0.16241247926092775
+51	0.40324969990063586
+51	0.31618068359653273
+51	0.12689862478683028
+51	0.3456899853487656
+51	0.14776203504018265
+51	0.19939152264709692
+51	0.22037715094192165
+51	0.15744324427816728
+51	0.25931935292122477
+51	0.20565633947301315
+51	0.31517335395468354
+51	0.1851068413085114
+51	0.2359740489426926
+51	0.20484926887613897
+51	0.160509504307968
+51	0.3375489180012562
+51	0.22705799155070597
+51	0.17463612521717095
+51	0.24657303010621265
+51	0.16779905547300045
+51	0.26525758996399873
+51	0.3655343504894428
+51	0.09663375740222893
+51	0.1710665107261253
+51	0.35763421662199274
+51	0.3186263309644919
+51	0.18658555833193197
+51	0.2855188373084495
+51	0.1878300244456726
+51	0.025994298537171574
+51	0.14596599973007945
+51	0.25707683003993154
+51	0.26112157711038847
+51	0.38907762678826757
+51	0.1717793267844647
+51	0.22469177955530062
+51	0.15372651596656753
+51	0.21341984579967924
+51	0.19677081458962256
+51	0.3900291378906112
+51	0.32394934759245164
+51	0.170884159287156
+51	0.35929560865383714
+51	0.1712757307451685
+51	0.13755107010840692
+51	0.2134813846233662
+51	0.18430222065836907
+51	0.251456280735534
+51	0.19408237009546367
+51	0.33749697328751616
+51	0.19226984516000353
+51	0.456401155751528
+51	0.24657332479093913
+51	0.22537498522576485
+51	0.20549581582590096
+51	0.19622401169769021
+51	0.19191716861153965
+51	0.12642865923622684
+51	0.2654585117498909
+51	0.1720443712198741
+51	0.2526526499383589
+51	0.12256299527206468
+51	0.35053920506737907
+51	0.14306422264868127
+51	0.25807638622122947
+51	0.3237682012141121
+51	0.19935074338482747
+51	0.36047724789200264
+51	0.22417467014470047
+51	0.12517582727262463
+51	0.14503575720615147
+51	0.16850468067372218
+51	0.28839140504181693
+51	0.15856677607402098
+51	0.3227949656550466
+51	0.1877589759504039
+51	0.1429738517363382
+51	0.20846751502431654
+51	0.3791958953084136
+51	0.2379954502163637
+51	0.1494425075202709
+51	0.24239247080637955
+51	0.21430091255238057
+51	0.23012599268632233
+51	0.2178508279635958
+51	0.33756475756348225
+51	0.33865276986871
+51	0.20010550352800785
+51	0.19196004418783227
+51	0.22527164648650957
+51	0.14648237046149376
+51	0.22453238934830697
+51	0.27734345222941126
+51	0.21054904457124732
+51	0.30140981897543206
+51	0.2421323594538578
+51	0.27960696276204605
+51	0.18986284178955393
+51	0.1636324928664745
+51	0.1646477066336602
+51	0.1563212003280619
+51	0.16300088706503618
+51	0.2861681624425813
+51	0.217825656664612
+51	0.23085067828717312
+51	0.4000237490848359
+51	0.2601850245399157
+51	0.25190241449839235
+51	0.1971962305950358
+51	0.29055318216980425
+51	0.26958796743752805
+51	0.3421331918719655
+51	0.3744729277101542
+51	0.3785029777795428
+51	0.25735714579248814
+51	0.2716280817516917
+51	0.1903913313895022
+51	0.16110858601383266
+51	0.3651028902660645
+51	0.13732153628401442
+51	0.25885160164850773
+51	0.2079980959480303
+51	0.28425828066330794
+51	0.28916408750493916
+51	0.2664941487014969
+51	0.206482947914437
+51	0.2179997354037833
+51	0.2818222590542537
+51	0.2698392726256812
+51	0.33353045914266777
+51	0.24973384433652418
+51	0.2847814444947426
+51	0.18945084313296265
+51	0.29920238803788984
+51	0.17667519492135367
+51	0.2842589252374111
+51	0.25887176741272555
+51	0.2647134455286389
+51	0.36855220636066494
+51	0.1824946639688409
+51	0.42456731824460137
+51	0.22335512225081786
+51	0.16261708582912884
+51	0.23439981480585706
+51	0.1591983057342957
+51	0.27817746000913446
+51	0.21735770625878342
+51	0.10738654403008387
+51	0.1257844275298454
+51	0.2964452711916938
+51	0.21127830596627212
+51	0.13100582082621914
+51	0.3646868667849123
+51	0.20554137773725448
+51	0.17694141159605062
+51	0.17319101776342272
+51	0.21078365464264628
+51	0.30245145517925587
+51	0.19511928986601684
+51	0.19085418619207475
+51	0.24325590838117164
+51	0.35201092111479926
+51	0.2500410587222918
+51	0.24003941294023218
+51	0.2776487056359243
+51	0.35175055543276007
+51	0.3895434976746261
+51	0.13565168855008203
+51	0.3085619752153536
+51	0.21420346033792892
+51	0.16483225025593082
+51	0.22697178010396715
+51	0.11934592669838648
+51	0.16110993829531958
+51	0.25650106741322243
+51	0.2602524538894335
+51	0.3061900476441776
+51	0.22558012498512003
+51	0.20079558983432982
+51	0.34718379639131924
+51	0.2260828476644629
+51	0.305540190284696
+51	0.20719840391530314
+51	0.3687635274677751
+51	0.4003104972407289
+51	0.1619813910420108
+51	0.21408668483001336
+51	0.2346165335035678
+51	0.1718170228650185
+51	0.24127762861872065
+51	0.2744822934791397
+51	0.19835503541067168
+51	0.4156755698267807
+51	0.31341251416766436
+51	0.2663381837060711
+51	0.19745726756286447
+51	0.2758940471677057
+51	0.17294375502022777
+51	0.33272799379895707
+51	0.17481303683105423
+51	0.2615694459090224
+51	0.33193656395716997
+51	0.2028449900118089
+51	0.40600189610073506
+51	0.39298027030269295
+51	0.1677880836001466
+51	0.20255631380793485
+51	0.22174990432428177
+51	0.1699647489165158
+51	0.1487727178587182
+51	0.19341116471173214
+51	0.2514640388843921
+51	0.2025495620678479
+51	0.25061795249575797
+51	0.3313237392262237
+51	0.16959510309385167
+51	0.1818430039620051
+51	0.14852868325452862
+51	0.2677207971095776
+51	0.3841866639451124
+51	0.18854755411420715
+51	0.2282015526916539
+51	0.1482915460667038
+51	0.24498249507608078
+51	0.11220488436900149
+51	0.2516096713159781
+51	0.2452388733363624
+51	0.3101915589334934
+51	0.25206120886332906
+51	0.29187068519160964
+51	0.2506762678357936
+51	0.18747177595215037
+51	0.1716732450668308
+51	0.14455381132164372
+51	0.20705765513773539
+51	0.20476140876771898
+51	0.30234166798825457
+51	0.18764753219910982
+51	0.20064493553090182
+51	0.37887252283368783
+51	0.19813901980033818
+51	0.11327303679697205
+51	0.42655437271764135
+51	0.12343875516625796
+51	0.3586599789432232
+51	0.2555146635260567
+51	0.20199774412034316
+51	0.21017565917849312
+51	0.1307990964008561
+51	0.1957461690310881
+51	0.21300968826161346
+51	0.3162561613731308
+51	0.22631500347395275
+51	0.3635265411576577
+51	0.3162584210263268
+51	0.1205643265207087
+31	0.2550444097089856
+31	0.3188244852211945
+31	0.3805821131722711
+31	0.3418994268610245
+31	0.3143928713713301
+31	0.2567251120874877
+31	0.19628166158183688
+31	0.27452269591243167
+31	0.27030943837087784
+31	0.25133698024127393
+31	0.2678037909892383
+31	0.36067016224343185
+31	0.27669115663306226
+31	0.22923997675203064
+31	0.3115505213650266
+31	0.20664008053874
+31	0.21211427718643777
+31	0.1629283266351534
+31	0.26904468836386375
+31	0.24026237604243864
+31	0.09521484352889976
+31	0.13861349069681567
+31	0.1897534580918344
+31	0.28013925444445387
+31	0.30404533948963763
+31	0.2723899593141609
+31	0.30326613264746316
+31	0.2905797420641941
+31	0.2656530359448959
+31	0.32895053700055205
+31	0.22719378105124277
+31	0.2634464091337656
+31	0.2816393387332522
+31	0.2610171443430018
+31	0.13974407727504742
+31	0.13732839274527636
+31	0.296233493638788
+31	0.3092101205214578
+31	0.21778504719924
+31	0.27704669832382395
+31	0.24715480031482676
+31	0.31790496058221235
+31	0.2872706490358668
+31	0.28197601580294995
+31	0.25136997048459625
+31	0.28290248794866174
+31	0.25288231143815443
+31	0.2577879131275597
+31	0.38355796826043237
+31	0.32476332820091924
+31	0.3409891271623124
+31	0.3004012383215717
+31	0.11569432612897987
+31	0.2485443249577618
+31	0.20672085294618928
+31	0.2747292852146759
+31	0.08069122483645678
+31	0.27369974798767405
+31	0.24664844978538997
+31	0.28526142958217987
+31	0.1879636556016878
+31	0.304767838896056
+31	0.27572218520207614
+31	0.2745662395600429
+31	0.27408683259503835
+31	0.19583702756306454
+31	0.16266873387696057
+31	0.0826975285882784
+31	0.16059942588600404
+31	0.2459697194573387
+31	0.32562568217920884
+31	0.25285873824660793
+31	0.09392776954391477
+31	0.21745051780010763
+31	0.3066703867964422
+31	0.292593406205459
+31	0.16388565174946024
+31	0.20521484633354856
+31	0.3402170107960361
+31	0.3624276632573831
+31	0.18415667014936504
+31	0.2561044272891926
+31	0.24158820655580882
+31	0.14601317870455774
+31	0.14130154448426657
+31	0.10455848313042641
+31	0.1789096651135518
+31	0.3171930964987843
+31	0.28843026216491235
+31	0.3814483374317062
+31	0.3066205359868528
+31	0.32244490507809154
+31	0.3308889534237532
+31	0.2742505317639283
+31	0.04374076086545226
+31	0.2682968769153256
+31	0.33166169502542425
+31	0.3253314892021729
+31	0.06825406261307965
+31	0.35737861034902696
+31	0.2800835387005666
+31	0.3322865374141319
+31	0.25370918509436374
+31	0.40709025588407
+31	0.35300755658569827
+31	0.29140399914672477
+31	0.1223543165803427
+31	0.21086624279209024
+31	0.16545334982421817
+31	0.13492876487630817
+31	0.2874773862744031
+31	0.3211897634252505
+31	0.08867319166767508
+31	0.1358477032624857
+31	0.31942474407563176
+31	0.309469837051999
+31	0.14509685379297219
+31	0.2461324366749645
+31	0.26961354840673846
+31	0.2521069729773201
+31	0.35367928941617766
+31	0.31132974878505254
+31	0.07247410263003434
+31	0.2969839814332437
+31	0.16778108591785207
+31	0.18483542198280284
+31	0.1840896295669773
+31	0.259728274116778
+31	0.20973454613031234
+31	0.2568202029432276
+31	0.23581490378009592
+31	0.22919674139666063
+31	0.258776041383513
+31	0.060024200453325884
+31	0.18260477578062118
+31	0.23108273844487412
+31	0.20892703913287478
+31	0.22692368737241247
+31	0.30333851348416774
+31	0.16652651169518018
+31	0.3469876144528928
+31	0.22224510035096548
+31	0.32436810552723744
+31	0.3320784770187387
+31	0.19643347471123618
+31	0.15973242389002246
+31	0.18440510830473172
+31	0.2594582636888921
+31	0.26168113877486043
+31	0.2719599692528015
+31	0.241200576778624
+31	0.15128446413841337
+31	0.24420490227425257
+31	0.23469874060790719
+31	0.26545411873505836
+31	0.3375861196540876
+31	0.3593075433780126
+31	0.2046315077910745
+31	0.3817023253456606
+31	0.3426179167215389
+31	0.10942854261385473
+31	0.0427708342126069
+31	0.25781684517822145
+31	0.2286085164509009
+31	0.2223238088949201
+31	0.2947692927609096
+31	0.294259822724407
+31	0.07110348399060415
+31	0.2511076676516869
+31	0.28551689345681286
+31	0.12817184236393514
+31	0.26859722052176493
+31	0.3270892790094914
+31	0.24196856847163445
+31	0.25100462693840947
+31	0.2862540720535198
+31	0.23219246224695075
+31	0.28396655759429584
+31	0.22636364793197994
+31	0.3391628908116432
+31	0.10870356204294647
+31	0.1347593300346443
+31	0.21837076879331518
+31	0.18448943000942772
+31	0.32815514920186567
+31	0.1219632893889705
+31	0.14317432051795068
+31	0.29211964825078957
+31	0.37661886776741516
+31	0.2425740660062464
+31	0.26229017241383634
+31	0.28858325641257
+31	0.15018836848097997
+31	0.1717060866173876
+31	0.12587470019026425
+31	0.23447175122312422
+31	0.13763346377873198
+31	0.19689224458035312
+31	0.30156355762706627
+31	0.31792464402493276
+31	0.2640589428372296
+31	0.3361410051471858
+31	0.3033360058947222
+31	0.1454335646203313
+31	0.28652939172553016
+31	0.219009989707044
+31	0.3146688897830863
+31	0.3106274715641879
+31	0.28649823941455493
+31	0.17611124787657145
+31	0.27892940616090317
+31	0.20946821794677278
+31	0.14729832350798663
+31	0.30166103948703793
+31	0.2841453292633666
+31	0.18318665534504439
+31	0.33983121362597085
+31	0.3001686069932142
+31	0.1362347530772385
+31	0.2674418750847339
+31	0.28854943705607766
+31	0.2574585021070115
+31	0.27952776515806305
+31	0.1484028195063901
+31	0.21089670837774346
+31	0.08645835334076174
+31	0.08718719582933769
+31	0.21844259540151514
+31	0.0785874906348336
+31	0.21629172801684446
+31	0.3218211991306418
+31	0.32865084955866813
+31	0.40318030404975347
+31	0.2446037833398507
+31	0.2609076066193949
+31	0.18935804081419358
+31	0.2850722263238325
+31	0.22678502098162423
+31	0.21010454890805885
+31	0.16399566846746014
+31	0.31650962337813027
+31	0.27030273915575803
+31	0.29825032056992384
+31	0.2593458388285031
+31	0.24805145479233612
+31	0.16968662862926362
+31	0.19818626553172236
+31	0.2008692203046271
+31	0.09693701033667515
+31	0.22983748482622193
+31	0.19938782013046677
+31	0.2754062841465843
+31	0.2754516394417725
+31	0.26120084506077634
+31	0.3596290512094134
+31	0.2952548958916933
+31	0.24322421228261432
+31	0.1314632874567837
+31	0.13669244721418736
+31	0.13279818181273617
+31	0.2951480792529798
+31	0.2734081130620251
+31	0.2855244198007207
+31	0.10168761325989885
+31	0.270203784362888
+31	0.2004245827783512
+31	0.298441701742697
+31	0.13335942371661125
+31	0.27915769194653617
+31	0.33238504361039034
+31	0.2478173507087044
+31	0.1776497554126517
+31	0.34439208279946915
+31	0.23515229958827655
+31	0.22043131705818886
+31	0.30246353937061615
+31	0.25789862581883455
+31	0.2615570182976649
+31	0.13436233154564114
+31	0.16090242520480721
+31	0.2891983338830433
+31	0.06402763985077714
+31	0.35116176928155696
+31	0.29769747668182434
+31	0.1890969182673824
+31	0.294844817816421
+31	0.2980212669252452
+31	0.31253608799849475
+31	0.25562850441819174
+31	0.3261200047191898
+31	0.22269371542347563
+31	0.22351212114950725
+31	0.08220516639988204
+31	0.07172465192442547
+31	0.144407909182474
+31	0.09785025509218989
+31	0.23627953823909406
+31	0.26936062503116764
+31	0.32578724163807354
+31	0.1825589498013152
+31	0.08604415433710726
+31	0.1257687728417292
+31	0.25772590344434226
+31	0.18915234870817438
+31	0.2720297173197165
+31	0.16941561222627374
+31	0.10865328475257303
+31	0.17390429681830633
+31	0.31088120083796555
+31	0.2625407286090724
+31	0.29101766018868763
+31	0.3154701468474979
+31	0.17818025916506414
+31	0.11845983072714335
+31	0.28943227584037673
+31	0.14825801408189127
+31	0.26231313845131715
+31	0.2752976057202677
+31	0.2990610507466465
+31	0.33041693841366004
+31	0.14940512351095128
+31	0.29023278918720374
+31	0.2530342681684745
+31	0.32201548030913224
+31	0.16583261908671293
+31	0.31995744595853454
+31	0.19692599303785835
+31	0.36092129634381215
+31	0.24389796551036202
+31	0.12298495550557098
+31	0.2166459580878088
+31	0.15150236405671794
+31	0.2080948573420151
+31	0.13864376044157434
+31	0.28731436839441277
+31	0.09741934238844788
+31	0.3045547921849566
+31	0.3628597079315927
+31	0.20042214342538864
+31	0.21667287167589455
+31	0.22671353162300034
+31	0.28371421201342095
+31	0.2890545905751138
+31	0.1510780788676603
+31	0.25601564608265287
+31	0.25034161523878296
+31	0.2244874777355168
+31	0.27066835775446724
+31	0.1274085843989306
+31	0.10529006935901655
+31	0.12272205306303796
+31	0.24835256451157192
+31	0.31206267723066894
+31	0.37682501280044045
+31	0.22436297581891895
+31	0.26913945836566777
+31	0.29358520079998673
+31	0.2867776015093181
+31	0.23427436928028433
+31	0.21537748003752677
+31	0.1303615985756346
+31	0.33413874506857316
+18	0.18655674161209318
+18	0.31712774880817424
+18	0.25485143595422866
+18	0.2929265008210875
+18	0.262205159088819
+18	0.14650563736362016
+18	0.2187664587445839
+18	0.1582941600598791
+18	0.1993881580996296
+18	0.21260881146065838
+18	0.13887643897191726
+18	0.24847910138013898
+18	0.26976287374717595
+18	0.1604357912044477
+18	0.25402938797845337
+18	0.25871256577469887
+18	0.14620162901973363
+18	0.2618097292609052
+18	0.21680723312475658
+18	0.17408166679710932
+18	0.18092568438816825
+18	0.1246664616022484
+18	0.14641582242477166
+18	0.04465898495767775
+18	0.04980309050094995
+18	0.15537123383720333
+18	0.21823329556399176
+18	0.2617146028736916
+18	0.26983513848507423
+18	0.18879633095214293
+18	0.21438886188983947
+18	0.19300680086470576
+18	0.1716305728831042
+18	0.11786304215296221
+18	0.24505803187607988
+18	0.13274404894491054
+18	0.09274905302039545
+18	0.2283169868504471
+18	0.28437957886030985
+18	0.25168166568225286
+18	0.2870007859227798
+18	0.13244827637847364
+18	0.05751608005790465
+18	0.15706570302407807
+18	0.19505666662335738
+18	0.07490468075503887
+18	0.2195798645459943
+18	0.22145577055859048
+18	0.21539314680892235
+18	0.3057113503574621
+18	0.24240803936455457
+18	0.10940795346289714
+18	0.20936851233755496
+18	0.05815215962664946
+18	0.260787347302907
+18	0.22698142737184623
+18	0.18794785283312432
+18	0.1845492868860719
+18	0.14630405536627727
+18	0.31080838747145234
+18	0.2717386710819765
+18	0.19540435912072265
+18	0.25376522739995977
+18	0.23730399305018812
+18	0.20878810539231366
+18	0.1625968208885195
+18	0.20807924362450317
+18	0.24889580543114198
+18	0.24852978816498575
+18	0.18031711189595706
+18	0.20097921613202058
+18	0.21099504887273923
+18	0.1993371204380732
+18	0.051565718335174274
+18	0.24380848383553755
+18	0.058244593152699094
+18	0.030530365855954214
+18	0.267129619085531
+18	0.30818594954805917
+18	0.20543582449548445
+18	0.256808620656918
+18	0.0359654663060308
+18	0.03648883224031952
+18	0.18358662504616652
+18	0.2687753237717476
+18	0.2392429460662549
+18	0.09007508777196199
+18	0.17788708630510977
+18	0.2635227733500592
+18	0.2869696082438501
+18	0.14643076158091545
+18	0.2692260762052722
+18	0.07360384279239289
+18	0.2311250813955464
+18	0.2627830748635335
+18	0.2537630452941378
+18	0.2593075779921723
+18	0.2658727874180251
+18	0.23263299462719386
+18	0.32703778955407886
+18	0.38698547782884674
+18	0.22747097234374636
+18	0.1466090015214553
+18	0.22293783456035074
+18	0.19822728226734435
+18	0.16419372884153338
+18	0.2779694636788223
+18	0.2186123784793021
+18	0.13801558408126594
+18	0.14213023305230008
+18	0.17151846049519825
+18	0.26359334954351715
+18	0.19704222919677436
+18	0.11455398454120493
+18	0.22445335245888468
+18	0.16188106428047516
+18	0.22078291844331105
+18	0.2614702629441646
+18	0.2650946328364195
+18	0.26886099874256447
+18	0.1932482143789709
+18	0.23349363651972602
+18	0.1801152957302404
+18	0.18724372781511708
+18	0.004684328023559752
+18	0.28174426170585115
+18	0.07295888490688482
+18	0.30937088952067726
+18	0.2916180998113596
+18	0.2991560367700988
+18	0.380598828049574
+18	0.21743358349655995
+18	0.2823131407705047
+18	0.18278589692306746
+18	0.2539866550129982
+18	0.20070394504430772
+18	0.053544571405530046
+18	0.18121710012505626
+18	0.16470955747597585
+18	0.30209925260103576
+18	0.18335059723269187
+18	0.1328272045356128
+18	0.18899891220323328
+18	0.273419904723869
+18	0.24000765830583198
+18	0.2811648113297161
+18	0.27224939771907436
+18	0.27646879972084076
+18	0.239706117295359
+18	0.05922221446350727
+18	0.3057123048528723
+18	0.21279333734959915
+18	0.2168504366614695
+18	0.25539757454422213
+18	0.10171241072514835
+18	0.23535149199052274
+18	0.20935951547525217
+18	0.23621821690922223
+18	0.11538333841104328
+18	0.21817234785278367
+18	0.23058502617788199
+18	0.09534183244233783
+18	0.11579621240619249
+18	0.1277756641447192
+18	0.1688642184336117
+18	0.2268005546243205
+18	0.23827541194378887
+18	0.21054754052161392
+18	0.1929473714160662
+18	0.27492012908920027
+18	0.23238261042202918
+18	0.23626888167418272
+18	-0.02411394058845351
+18	0.17816712351986572
+18	0.009118359692457747
+18	0.23529640416470834
+18	-0.016055012682273117
+18	0.17590206289471622
+18	0.24353357793988986
+18	0.2664833033341769
+18	0.1846509820486012
+18	0.26044816147991656
+18	0.17316963157162324
+18	0.2429874631675845
+18	0.17375250451161
+18	0.20258007923039573
+18	0.2669119380721185
+18	0.2139429615641464
+18	0.20594241414033698
+18	0.21766907115268863
+18	0.13846226998978914
+18	0.20574065041394146
+18	0.2557550587876404
+18	0.08231049281173772
+18	0.20780688516036472
+18	0.19843350902953577
+18	0.17543109790978031
+18	0.21834927266355658
+18	0.27585369385496716
+18	0.24116490997643886
+18	0.16008571501925214
+18	0.1758091840260834
+18	0.1836047058838793
+18	0.17440605965410108
+18	0.05076986386526622
+18	0.21636019003814164
+18	0.18528828013278714
+18	0.13721145622019504
+18	0.18044744197333046
+18	0.2762893981276428
+18	0.24224851529850294
+18	0.1892792078054275
+18	-0.0015233764473862937
+18	0.07769003208504034
+18	0.21346959036854452
+18	0.06882760701613459
+18	0.28987364122992015
+18	0.19720620783391585
+18	0.053332625468060904
+18	0.21422865156998297
+18	0.318790937446362
+18	0.1840284341919134
+18	0.30467874266197076
+18	0.25802830429762713
+18	0.24535481634996623
+18	0.18249183866862673
+18	0.3788623864298507
+18	0.2612825529683933
+18	0.10572717815391766
+18	0.23892576223071596
+18	0.08426378505991383
+18	0.21223657024031342
+18	0.2705712039228194
+18	-0.015403036864229627
+18	0.14481701200896469
+18	0.1878652182262456
+18	0.25829081911232576
+18	0.28984162859427737
+18	0.17125328148757726
+18	0.2743859070073547
+18	0.2584613451823222
+18	0.2342456414688126
+18	0.19695103305744446
+18	0.20477136644127802
+18	0.21052729191848593
+18	0.2710191274497894
+18	0.1033227270651668
+18	0.2800768858743681
+18	0.24210007966248492
+18	0.288261509873924
+18	0.28361755152624374
+18	0.22725679619445158
+18	0.18659313395689586
+18	0.01915471549312322
+18	0.25922587918898404
+18	0.1745873727324579
+18	0.34551886225014117
+18	0.29891743656000686
+18	0.038675962161913525
+18	0.324324492886653
+18	0.18389063633232222
+18	0.1896144973943626
+18	0.16519952864046047
+18	0.1461285317144388
+18	0.17660116802195114
+18	0.20772514869427772
+18	0.07355735471395161
+18	0.2990026011369333
+18	0.20102776042100684
+18	0.18518900910790245
+18	0.14635098007068742
+18	0.18214272256802785
+18	0.25106023642309744
+18	0.2376290558250893
+18	0.2351146790264321
+18	0.23403063167691576
+18	0.26390122760011736
+18	0.1904175592584473
+18	0.25501902536994214
+18	0.018464326681043346
+18	0.007355552624983917
+18	0.2313075619658195
+18	0.2031025716479774
+18	0.23680001915800958
+18	0.23697294896333387
+18	0.07567904584607205
+18	0.23636805274990763
+18	0.09655595749693731
+18	0.14268971290924157
+18	0.23036933699462087
+18	0.29714970014129555
+18	0.07159366477404161
+18	0.26763107150546456
+18	0.2159025624034843
+18	0.21305574194164456
+18	0.31123172439914004
+18	0.16725770530355547
+18	0.1821430749387412
+18	0.16031841728442353
+18	0.2595525191320325
+18	0.2197504214480002
+18	0.2856669963515088
+18	0.24610195190328654
+18	0.06190552921743131
+18	-0.016251718745873847
+18	0.1584399338536664
+18	0.27231792580585185
+18	0.2781672265885572
+18	0.278495355002617
+18	0.289634306743421
+18	0.23076244684456348
+18	0.21330205581688766
+18	0.02268610855825825
+18	0.22098602425091668
+18	0.2348852381698174
+18	0.2787118002419559
+18	0.30634197878003455
+18	0.20918238898708985
+18	0.03307574000195855
+18	0.23719274395591647
+18	0.34527092256613456
+18	0.20529238594906252
+18	0.23133815964140234
+18	0.07967354558584341
+18	0.22915459581492317
+18	0.1669589793958181
+18	0.24581127602794772
+18	0.18695806576910834
+18	0.2576015489099506
+18	0.0515265266845579
+18	0.2523051190734382
+18	0.1889116771310302
+18	0.24132511309726343
+18	0.2239923904169262
+18	0.313882123459607
+18	0.2564883481644929
+18	0.36170443838453137
+18	0.05535284093607344
+18	0.2011890887323603
+18	0.2799240395357682
+18	0.24608654924272017
+18	0.16818504552944127
+18	0.16153822241002755
+18	0.07660669433419309
+18	0.11194445889705432
+18	0.17652325538219035
+18	0.21733964512411483
+18	0.10319383996760494
+18	0.2066175052836636
+18	0.251950789366206
+18	0.02615241967561528
+18	0.31051968315933515
+18	0.21117012942873606
+18	0.21529491772020243
+18	0.21782967243823675
+18	0.29705620863853516
+18	0.10753849989257472
+18	0.2308329494260472
+18	0.23297335089483986
+18	0.21347062546815312
+18	0.06303608840161509
+18	0.273388366837516
+39	0.23523106469445873
+39	0.34939181516402923
+39	0.12452741224700932
+39	0.10311311250447643
+39	0.30049307995118
+39	0.14023877234184692
+39	0.2971119393669564
+39	0.28734721856798034
+39	0.3038619436133352
+39	0.1944037197448446
+39	0.2709283941124235
+39	0.2824921912551894
+39	0.2911314784398581
+39	0.30764710253989813
+39	0.011879613528302867
+39	0.27943478305983266
+39	0.3132098377859289
+39	0.21501232789403354
+39	0.03897770574257667
+39	0.2199703909325234
+39	0.3185634430200429
+39	0.2785540360123663
+39	0.34194424280404034
+39	0.2256251014383882
+39	0.26208884179546055
+39	0.32349030108589477
+39	0.27436371756334343
+39	0.29041793671094385
+39	0.28428009565634543
+39	0.2486145048752668
+39	0.14810391358103558
+39	0.35841848004553384
+39	0.2058895777387516
+39	0.3017616022410194
+39	0.28919495628663866
+39	0.3186256016765926
+39	0.2921785327352844
+39	0.28986775621343863
+39	0.09861045405754044
+39	0.32872099276365213
+39	0.32582260052569434
+39	0.3515045233419393
+39	0.3296095566194677
+39	0.33624844131447323
+39	0.28510535920818686
+39	0.2904453132527574
+39	0.15963124005948745
+39	0.2356195376106545
+39	0.03709246835566258
+39	0.25890949228022786
+39	0.3363655822490239
+39	0.21876949082965494
+39	0.2622511799048556
+39	0.3135644620910114
+39	0.2541583780878962
+39	0.2895254636385613
+39	0.2911908078350007
+39	0.29931370744779523
+39	0.30485359944393736
+39	0.1351389525326643
+39	0.203634413809052
+39	0.2736655150412606
+39	0.3589766901015125
+39	0.029234026069476227
+39	0.2513150932804503
+39	0.2914351230274828
+39	0.3017142530115999
+39	0.25591485096349237
+39	0.32645711939703104
+39	0.28678476521289875
+39	0.2095447499705701
+39	0.2629173570305238
+39	0.22354095929845028
+39	0.2965148997298133
+39	0.16380749718688287
+39	0.23057175836519658
+39	0.20787664590040236
+39	0.058311277881670204
+39	0.23414109397722715
+39	0.3150550724937557
+39	0.3307039767605542
+39	0.18243539956144714
+39	0.21692992361409216
+39	0.044598627242957316
+39	0.2950415918977661
+39	0.41094156399176995
+39	0.2734142316553373
+39	0.3140763568881898
+39	0.07811896641111724
+39	0.11091951168969642
+39	0.2653951689141346
+39	0.2578004862269655
+39	0.2031020588809513
+39	0.37668213360129443
+39	0.03343201145797168
+39	0.35778113307530723
+39	0.34213971065109955
+39	0.11693522301977088
+39	0.17664063552149548
+39	0.3300386406075427
+39	0.34911971753653204
+39	0.24484372048969982
+39	0.32563641515109615
+39	0.3362426911636755
+39	0.3357660641002966
+39	0.285003253678421
+39	0.35785328993171617
+39	0.15569009816883783
+39	0.21495972607235447
+39	0.2566726178983054
+39	0.2427643074521305
+39	0.05864197674715082
+39	0.27684141806474816
+39	0.12313346882151074
+39	0.0027529388974050404
+39	0.16310402026521814
+39	0.26931564356933585
+39	0.18527078024437005
+39	0.37409620535878657
+39	0.06165702413340497
+39	0.39716360300539977
+39	0.149019749692554
+39	0.17796490596907116
+39	0.24834764459848507
+39	0.21771791143715097
+39	0.20700176015070734
+39	0.3355625207007856
+39	0.29350781257135117
+39	0.25638634755216516
+39	0.18608664846149411
+39	0.11421849751731582
+39	0.25978880678525895
+39	0.10523677910353756
+39	0.26487539914416447
+39	0.3040720704257962
+39	0.05537244544394001
+39	0.410470943529475
+39	0.29287276909807514
+39	0.3091627956191476
+39	0.3683544579160538
+39	0.1471862019890666
+39	0.38209946357647145
+39	0.09887070964110008
+39	0.24283158594341928
+39	0.27033365816853433
+39	0.2151224700080166
+39	0.250923319975553
+39	0.38587651747357554
+39	0.28564745883962067
+39	0.18555901394059976
+39	0.22174593012872687
+39	0.27839297804727176
+39	0.35549332991618804
+39	0.2943132730980878
+39	0.33845870361293134
+39	0.3339371172360671
+39	0.3322929896525517
+39	0.28639095400300274
+39	0.3019509546583716
+39	0.2638973876269947
+39	0.25647305098267564
+39	0.1488921260554296
+39	0.221166235161731
+39	0.08930747796846525
+39	0.23137138713421634
+39	0.2807453266856055
+39	0.3521384502427298
+39	0.25551324676620885
+39	0.2807622841676836
+39	0.24433132412128045
+39	0.2873359607851418
+39	0.18015640881816258
+39	0.13651793277980767
+39	0.2382664345865216
+39	0.09314417766468272
+39	0.239351920145919
+39	0.2903096450723458
+39	0.13133323817042622
+39	0.25022661638902366
+39	0.3594601995004828
+39	0.1875050590121582
+39	0.12978515998635712
+39	0.2848163694043271
+39	0.14897748693357013
+39	0.22213082882875188
+39	0.381797340898288
+39	0.1501125586040786
+39	0.26529233029186094
+39	0.12813600186314525
+39	0.29573455453225406
+39	0.3560662333256874
+39	0.2976120622878016
+39	0.3092280330785864
+39	0.15483816473715264
+39	0.25744950417503
+39	0.13654630909183543
+39	0.188430416307758
+39	0.20471107626586887
+39	0.22256768650159509
+39	0.1760425758304806
+39	0.22583266974603358
+39	0.16058299581306681
+39	0.19710094774400758
+39	0.20659029856331496
+39	0.16633483616186145
+39	0.22311875637273595
+39	0.30737113365414215
+39	0.25276255742273823
+39	0.04597798408646391
+39	0.12239358192531774
+39	0.32803726839141
+39	0.2676142873419129
+39	0.268763216826183
+39	0.2594699087776131
+39	0.30373005547043563
+39	0.2333670070249423
+39	0.25912558946060904
+39	0.07809388162898366
+39	0.3862111431978294
+39	0.3663831907385867
+39	0.28524530060599235
+39	0.24792619241677394
+39	0.31136022243469846
+39	0.2795175470388763
+39	0.2438088896499906
+39	0.3772480230114366
+39	0.29867736814634077
+39	0.24098474247928622
+39	0.23774232122801464
+39	0.33140595938091066
+39	0.32916298427833873
+39	0.032771778812337164
+39	0.34465808508193263
+39	0.3562610681517559
+39	0.25436944769120345
+39	0.28414722851376856
+39	0.24922600806919878
+39	0.2960136852364939
+39	0.011795562463223008
+39	0.2805466904668475
+39	0.09531178832447455
+39	0.2756663027909097
+39	0.2973686933499795
+39	0.28954062946399783
+39	0.268923320120367
+39	0.22596300679038578
+39	0.16110912375124847
+39	0.30750694676066415
+39	0.2735342503092344
+39	0.252351067618672
+39	0.3083465574498771
+39	0.35793312771311026
+39	0.16081610777215355
+39	0.3098725146031527
+39	0.30944967492933145
+39	0.29356740681240534
+39	0.3234050153053475
+39	0.2838595443477834
+39	0.2828710072379323
+39	0.28890350567518835
+39	0.32767405746539435
+39	0.28490207469692047
+39	0.24438085847407176
+39	0.1849825225729701
+39	0.2594376738615204
+39	0.28006383071380964
+39	0.32963164856400834
+39	0.28240139010852316
+39	0.20414831968220526
+39	0.13489255678709391
+39	0.24875661727247358
+39	0.24877743212082518
+39	0.28464027291964095
+39	0.3131410840984017
+39	0.26265532240871803
+39	0.3122137506338315
+39	0.24224662235518496
+39	0.32453249608205825
+39	0.1796480788252938
+39	0.3947080209666824
+39	0.2720304801429465
+39	0.2852415895144268
+39	0.36316954452342315
+39	0.266302528044127
+39	0.08646216709848821
+39	0.07500264889309848
+39	0.26477666618150525
+39	0.3358146978617398
+39	0.20815587798479077
+39	0.32301808540793464
+39	0.0968856350017516
+39	0.28131777621728743
+39	0.12700788460869122
+39	0.2604945978475822
+39	0.2758980948263502
+39	0.33400540213232083
+39	0.26983511579425745
+39	0.22157343406153288
+39	0.2630951653104667
+39	0.26773030800112074
+39	0.242659766161192
+39	0.3012612478822837
+39	0.2700726083770859
+39	0.117463914983738
+39	0.32190186003802235
+39	0.22069236698742226
+39	0.3703309555132205
+39	0.17521873198416377
+39	0.27157638305929727
+39	0.12792660575132997
+39	0.22555406864870908
+39	0.3631910005211331
+39	0.2884028712019001
+39	0.14813515094738205
+39	0.3065996331477647
+39	0.2563076860867764
+39	0.28154801224100134
+39	0.24442134481259106
+39	0.23510479406395263
+39	0.3206682057202476
+39	0.20857820032257277
+39	0.012223103769570217
+39	0.3947513347337751
+39	0.3326452593546224
+39	0.23229981838627498
+39	0.3199662200355225
+39	0.27458008023976105
+39	0.27968290053967476
+39	0.1386234648876683
+39	0.34918809745812224
+39	0.21762039328572114
+39	0.1969673530810968
+39	0.2752518329074538
+39	0.298076419098624
+39	0.2862746326857818
+39	0.26296352077438623
+39	0.4238235903111659
+39	0.29539854961841494
+39	0.23056664739832308
+39	0.3068761475888808
+39	0.2670108564354867
+39	0.3148970687535129
+39	0.2507725296035645
+39	0.32871077292637363
+39	0.3185709246641773
+39	0.07321966965460526
+39	0.28442002406184175
+39	0.28348526151561276
+39	0.36931515749765775
+39	0.2793854197592311
+39	0.30603638174022846
+39	0.20855700456394438
+39	0.12772509459481882
+39	0.2736196702705094
+39	0.30719602455833644
+39	0.1421168910598522
+39	0.2969123096158922
+39	0.15857216049864897
+39	0.2515889418070062
+39	0.11431660397333969
+39	0.23868129842596403
+39	0.2916743702636588
+37	0.19052845989076878
+37	0.15980514587580974
+37	0.047034763476271405
+37	0.3517762216538552
+37	0.22202358440300674
+37	0.3247664670142522
+37	0.3307937196871773
+37	0.2687496120979557
+37	0.2683894703971923
+37	0.18376629958427673
+37	0.053665166291772384
+37	0.3547171584612233
+37	0.3864610715453984
+37	0.29482683015956784
+37	0.24325775284075382
+37	0.26810622544619894
+37	0.2146781421062827
+37	0.27248078418933713
+37	0.2624092519420571
+37	0.17284625666768252
+37	0.19286882474681769
+37	0.07776112667499366
+37	0.2984495811037665
+37	0.24435722308936372
+37	0.11159522114114319
+37	0.195603245135086
+37	0.3105400063709478
+37	0.3153210997011478
+37	0.2609579588589899
+37	0.24834972122309892
+37	0.3416784525011463
+37	0.3555002454570951
+37	0.3225539264737441
+37	0.3392087981492529
+37	0.2502947235415083
+37	0.17706787611065697
+37	0.28455502355386497
+37	0.2588998987891471
+37	0.3074215043527889
+37	0.3403419781012537
+37	0.22154661708431445
+37	0.2997394394292471
+37	0.17076340723000885
+37	0.23041708605546066
+37	0.33935984950175213
+37	0.23447740147896143
+37	0.26481140735552167
+37	0.2720721054811981
+37	0.1499051068649816
+37	0.08467068070336142
+37	0.33662557943832516
+37	0.325990706204882
+37	0.17749295790861747
+37	0.1999780771735648
+37	0.07419960373837846
+37	0.20252698261926977
+37	0.33452758589067394
+37	0.19596539289173792
+37	0.29028284412296973
+37	0.31749829548621267
+37	0.3215085092944606
+37	0.3060761926283935
+37	0.3172726970486921
+37	0.22242723963043193
+37	0.3310839308713287
+37	0.28554832046453754
+37	0.1468623024326337
+37	0.1729244725547929
+37	0.06796663443683965
+37	0.33046308553847253
+37	0.3626132139663605
+37	0.29063018271955404
+37	0.2639693107977946
+37	0.03867343112801904
+37	0.25265803410166615
+37	0.21531307077257564
+37	0.2173222733499032
+37	0.2599300377670121
+37	0.2753715225334864
+37	0.3630198783681536
+37	0.22345953351646847
+37	0.0858253413492836
+37	0.22483014397112266
+37	0.2934688032676427
+37	0.27354508520156173
+37	0.21338499720197335
+37	0.20238456738008798
+37	0.2283793754284707
+37	0.2884228378286262
+37	0.3440208583014325
+37	0.30992775975514886
+37	0.33707634243848
+37	0.37757509395677036
+37	0.2792473593016244
+37	0.16187453322416387
+37	0.11355076219264015
+37	0.2563915579431062
+37	0.3147235941513392
+37	0.307168730797966
+37	0.23836525235868913
+37	0.35678991704575436
+37	0.3011557946360509
+37	0.3396364468288513
+37	0.2054390779962785
+37	0.2828237939850711
+37	0.31395114835724836
+37	0.2686477339852715
+37	0.08030675295435243
+37	0.22055267863605674
+37	0.3387167149746347
+37	0.18741452190723581
+37	0.3393161947563964
+37	0.3122748186515624
+37	0.3441118263641859
+37	0.2759428099033218
+37	0.2502072007215937
+37	0.24470727701982722
+37	0.27030702888156727
+37	0.2592979324714965
+37	0.35934603371697593
+37	0.202360311362859
+37	0.2588219907618176
+37	0.23236625702498473
+37	0.3063920271960947
+37	0.24908487324560916
+37	0.21537358540070123
+37	0.2170443585548227
+37	0.31148261467830624
+37	0.13143694201487918
+37	0.09793040652390861
+37	0.07082385400594697
+37	0.1299733854213965
+37	0.20262576744655023
+37	0.2960220371006537
+37	0.3876284046107635
+37	0.12638141214447637
+37	0.37925974794687856
+37	0.28257024444238277
+37	0.30613840901593364
+37	0.33125607724890277
+37	0.30915020296621115
+37	0.22501399138480974
+37	0.34131722403321396
+37	0.17430777980807646
+37	0.23759131554340226
+37	0.08662176972796817
+37	0.1477289798268612
+37	0.2917798693114181
+37	0.3258909501067239
+37	0.2918709483308942
+37	0.10499516185228117
+37	0.1946132536147473
+37	0.09075400017890697
+37	0.28406774494921777
+37	0.37083420798862826
+37	0.31645632346854424
+37	0.3580774069908192
+37	0.3366287045384244
+37	0.2522507485207991
+37	0.17264246909151
+37	0.14816171162345654
+37	0.15503024979413096
+37	0.11474265919198924
+37	0.2739625709182879
+37	0.28026507985185206
+37	0.2183216168184088
+37	0.3467757399300854
+37	0.11278043219543012
+37	0.2583768413389307
+37	0.11535131327420314
+37	0.2957616124963744
+37	0.2733052990427905
+37	0.32490270205843935
+37	0.2531094075792038
+37	0.15243891139900512
+37	0.2833214167241828
+37	0.07906899830515887
+37	0.2475147322772006
+37	0.38183490524769387
+37	0.2718064239648717
+37	0.29699339336676944
+37	0.09693170348496156
+37	0.3297526814221767
+37	0.1457013812145921
+37	0.2197353082727338
+37	0.28489389126134823
+37	0.06228161887845388
+37	0.3514690452814975
+37	0.2876009888454981
+37	0.32329641098582534
+37	0.07276071431976161
+37	0.13031616547369082
+37	0.2028880043583038
+37	0.3264658632074946
+37	0.3042892616349248
+37	0.2407470984101747
+37	0.04270061557814673
+37	0.1567451655476877
+37	0.05257554693926335
+37	0.3225990050080469
+37	0.30826689404775914
+37	0.2202921486404358
+37	0.26323281089863027
+37	0.2238184735737638
+37	0.21302828402892585
+37	0.28452698595933157
+37	0.31795155410207276
+37	0.27102308064134223
+37	0.3470651879733085
+37	0.3099703546208238
+37	0.36226329825226783
+37	0.288790349472771
+37	0.3453696749862316
+37	0.14508380988239894
+37	0.3618914649420724
+37	0.2769608816424219
+37	0.06381606778415577
+37	0.283986162736005
+37	0.24455213821211327
+37	0.17508358527144408
+37	0.1672046351584075
+37	0.3316907902670862
+37	0.35638974158688397
+37	0.3672894695964316
+37	0.387992844968286
+37	0.22938095315521925
+37	0.34905890215956514
+37	0.3696215458981533
+37	0.26065668779186985
+37	0.36721556933672095
+37	0.31196811874915353
+37	0.2981213830403505
+37	0.24431113627670573
+37	0.22185252798091865
+37	0.3139571078932199
+37	0.33046827505073006
+37	0.0749060862367171
+37	0.2649390292760711
+37	0.32291122460027477
+37	0.32063787012296624
+37	0.28045207110809167
+37	0.29996203303270425
+37	0.31513912406347794
+37	0.34769925230248855
+37	0.36946822366442156
+37	0.35588006211418377
+37	0.3410739563436681
+37	0.19695179619720105
+37	0.2506741532894934
+37	0.2120546154464797
+37	0.31091517992743073
+37	0.30509767666906285
+37	0.305471573955577
+37	0.06861080092583519
+37	0.21316951842682333
+37	0.3553150264513984
+37	0.357887520262299
+37	0.28376786553520306
+37	0.10015223675612116
+37	0.2205266253048579
+37	0.1886148203488433
+37	0.1386773333264193
+37	0.34375389923384797
+37	0.36750082987065563
+37	0.3226787878338401
+37	0.3275326406337184
+37	0.11922214802529789
+37	0.2772796510891782
+37	0.2563362293086256
+37	0.22137570014591249
+37	0.3313232776407857
+37	0.30439043074895783
+37	0.0934209827117221
+37	0.06573206192618422
+37	0.11739123631041379
+37	0.2573206245810513
+37	0.28258686727429877
+37	0.3045435864021827
+37	0.1815874315838285
+37	0.3345619282346745
+37	0.11532004223387052
+37	0.23788458290928394
+37	0.20091175023805732
+37	0.11963468378047581
+37	0.3185339140726753
+37	0.31214224887961256
+37	0.23411187467291403
+37	0.3410541443167619
+37	0.32860127445125786
+37	0.1857018497434479
+37	0.12064202705314377
+37	0.2453916974337248
+37	0.31619911041242604
+37	0.24227606693426001
+37	0.32381110667250307
+37	0.3057839091358238
+37	0.31578716699569753
+37	0.041863794241597044
+37	0.2983644696593723
+37	0.19695997088422196
+37	0.41579215080946413
+37	0.2194942961963832
+37	0.27693639535892817
+37	0.18151725195003443
+37	0.26861510782439624
+37	0.1052050264564497
+37	0.34626164961308387
+37	0.10951140591869463
+37	0.2823952802783056
+37	0.1484958110012541
+37	0.26681058252277406
+37	-0.0008046612888060755
+37	0.15105422588620568
+37	0.3025910894940709
+37	0.19870996011798242
+37	0.15041260142174198
+37	0.20300874303395333
+37	0.3104319797851954
+37	0.22842979831394317
+37	0.30678032848537395
+37	0.23875395989757753
+37	0.1779551610550029
+37	0.11815842180729376
+37	0.30820125576342344
+37	0.2534713621120601
+37	0.20970609523553693
+37	0.38542665722532465
+37	0.0786822291595343
+37	0.14329535399940166
+37	0.17569399168168745
+37	0.3069352224421539
+37	0.3463707656389418
+37	0.37847191926242546
+37	0.3017066714654718
+37	0.34152170444841606
+37	0.23761274386527584
+37	0.2677208321435662
+37	0.1424071871806851
+37	0.08242306618149069
+37	0.33970698978911323
+37	0.30503118799663315
+37	0.2769993744102221
+37	0.26008798275256567
+37	0.34071995805362293
+37	0.2985050635570559
+37	0.09793515751596331
+37	0.2844431915766646
+37	0.24653315229074357
+37	0.2116907848864522
+37	0.08711658341908718
+37	0.3254217382985338
+37	0.3464281129017124
+37	0.15063546773625594
+37	0.4013256158386049
+37	0.17001938534436983
+37	0.31223315274441854
+37	0.2722667053653717
+37	0.380919305953451
+37	0.18649897355349118
+37	0.3153297525164536
+37	0.30559585624170615
+37	0.12965937057544855
+23	0.15048780762122527
+23	0.2784763875868352
+23	0.3514827165624139
+23	0.23429609336676252
+23	0.2621607704321238
+23	0.254015216242522
+23	0.1476552307733328
+23	0.13774363826221314
+23	0.13672803060974062
+23	0.20647808351082256
+23	0.23697125846862765
+23	0.2632012839699373
+23	0.24972254923687146
+23	0.28259169510965393
+23	0.20938069108534937
+23	0.15114524250289388
+23	0.12615615052778456
+23	0.23498242844239361
+23	0.23976117630229082
+23	0.198707547763308
+23	0.25884876568516585
+23	0.28039341798867207
+23	0.20523010069036854
+23	0.0920826437928238
+23	0.1042089787319408
+23	0.13291711360345126
+23	0.2229881663287687
+23	0.1443689760083709
+23	0.24359438601947084
+23	0.1513966442529261
+23	0.21418375721508576
+23	0.1413139019658984
+23	0.156024802424137
+23	0.148885708221995
+23	0.21149539600019043
+23	0.18798804155344478
+23	0.24820840839296462
+23	0.20351660674791652
+23	0.1534166578068108
+23	0.35709807962843615
+23	0.15328064660419838
+23	0.27839850470642497
+23	0.2668467307456152
+23	0.2761117850132174
+23	0.08613928814133599
+23	0.19584038484734706
+23	0.2059063838962955
+23	0.26490117067046987
+23	0.16972831123874632
+23	0.2406948098607957
+23	0.3655657195106817
+23	0.23539526755796067
+23	0.3364882716951593
+23	0.3019255941514473
+23	0.13802871757619994
+23	0.11192420904593323
+23	0.1383278637090876
+23	0.15712872860970353
+23	0.27339022495428517
+23	0.26064992150759286
+23	0.1934921110886216
+23	0.17888738768890466
+23	0.13462366005367238
+23	0.17896794940590763
+23	0.23900443917050446
+23	0.156609601687993
+23	0.17556395593469473
+23	0.17749524404305883
+23	0.30207307786821525
+23	0.24823105055838857
+23	0.09760518164015387
+23	0.33390700066907564
+23	0.1424359912498532
+23	0.16265593286923963
+23	0.1701261513833614
+23	0.24396974062709195
+23	0.3210951688974127
+23	0.22446694675125872
+23	0.26975660422695813
+23	0.21696414397987607
+23	0.18545587178324313
+23	0.054034778224601406
+23	0.07450956634379338
+23	0.15563557055475574
+23	0.19946972824730433
+23	0.24666272902184624
+23	0.30808117222390247
+23	0.3521319578838552
+23	0.16405691457139907
+23	0.27901984517474737
+23	0.16781608541972404
+23	0.13857247013245375
+23	0.2858348116638087
+23	0.2487251903130982
+23	0.243011493158557
+23	0.21793281118360489
+23	0.22573636412091028
+23	0.2262874586620676
+23	0.164227767165594
+23	0.09572810225144394
+23	0.13358470131388236
+23	0.19427749444208117
+23	0.23649329995230256
+23	0.12993658819712017
+23	0.17843382451669348
+23	0.09926554967545612
+23	0.2946281785143714
+23	0.20435447386400182
+23	0.16160479389013185
+23	0.2662885261886648
+23	0.18092076967424936
+23	0.10116913222422694
+23	0.17248986413293213
+23	0.15536154567469937
+23	0.14803455411139965
+23	0.21267930299684915
+23	0.05470535615558111
+23	0.2927469696381926
+23	0.25636286587535473
+23	0.2615495051625526
+23	0.10546900449122001
+23	0.2310685793955795
+23	0.27046853506222523
+23	0.0546994133386377
+23	0.20675572732411984
+23	0.21651705595815193
+23	0.25324344855308717
+23	0.2542937493622423
+23	0.21678070586827877
+23	0.2763476335351363
+23	0.2793060648709878
+23	0.1965986537911921
+23	0.14539173652600648
+23	0.17197951047047963
+23	0.24704462174070105
+23	0.25041029475301835
+23	0.2947194343675825
+23	0.17260633030581263
+23	0.2547183679860561
+23	0.20911082655585697
+23	0.1446490328638905
+23	0.2665742402432002
+23	0.29843120857491445
+23	0.2793432690326718
+23	0.24243034431786298
+23	0.2171853208377953
+23	0.18555002946351154
+23	0.27133378352326704
+23	0.22063843088784524
+23	0.21213232169608612
+23	0.2648848886300383
+23	0.1905446633464009
+23	0.184141576345108
+23	0.19844305182163163
+23	0.2234655148157388
+23	0.1876254439780617
+23	0.17718676081304308
+23	0.20533797808965695
+23	0.2579059957459745
+23	0.23975839623719203
+23	0.36275250360368483
+23	0.20997560788042163
+23	0.2801434139994211
+23	0.3387909525555339
+23	0.14089482311563478
+23	0.17915675168164222
+23	0.20995358465918518
+23	0.2478243462588325
+23	0.25915123310100013
+23	0.28658937321790096
+23	0.26378232955332015
+23	0.16739119080382822
+23	0.29172572701703475
+23	0.1467358348029523
+23	0.18475156839614174
+23	0.15261875932217156
+23	0.22543867478524546
+23	0.2777890303985595
+23	0.26254293983635013
+23	0.3017879172080453
+23	0.18005909627249303
+23	0.2222066279279492
+23	0.2632162844761449
+23	0.24078795932603006
+23	0.22728280469389975
+23	0.23691109517473694
+23	0.20496673405990018
+23	0.21939732841895046
+23	0.14611328006231478
+23	0.3415404272509269
+23	0.21913746872120607
+23	0.24846523637930837
+23	0.06738957083801747
+23	0.29514620693625476
+23	0.10584761925911372
+23	0.10524281808956089
+23	0.22693836777473606
+23	0.2009002101207049
+23	0.19713524192168164
+23	0.2617201115491236
+23	0.16910313436068303
+23	0.24543823962691008
+23	0.20604935465925667
+23	0.2650615990659885
+23	0.14206007536042162
+23	0.21850719657423778
+23	0.20894289065849062
+23	0.23334045522666494
+23	0.1356557360429512
+23	0.13956028978680307
+23	0.2431541436361089
+23	0.24563255006870957
+23	0.33294615385366455
+23	0.1263685782344583
+23	0.17343779490720215
+23	0.23202879999213608
+23	0.24565721080153718
+23	0.12178778788464131
+23	0.2788122994541936
+23	0.18667081989224837
+23	0.21440498354118975
+23	0.2645191739217844
+23	0.18996711270523453
+23	0.24700401104729622
+23	0.3034452449865425
+23	0.16010386192261034
+23	0.2583568376561395
+23	0.2797882848389623
+23	0.20992878729754466
+23	0.09628405086653394
+23	0.17405382236172526
+23	0.15156790640290488
+23	0.1591578330315048
+23	0.18818598500294378
+23	0.2814707450019546
+23	0.16574396253545265
+23	0.13684847026362892
+23	0.11627898302216452
+23	0.1781337190032968
+23	0.22282048083860592
+23	0.12013729716749103
+23	0.21093806380335442
+23	0.34053734864929325
+23	0.15685993678436347
+23	0.20797988572244433
+23	0.20522679270757602
+23	0.17439767880443416
+23	0.20112212521422043
+23	0.26436028999378364
+23	0.18303343498606547
+23	0.1529939150111218
+23	0.33584275221499255
+23	0.2661359192338301
+23	0.18396466914484125
+23	0.30259571802468493
+23	0.15774721979822773
+23	0.21805116209110062
+23	0.2829611525524469
+23	0.29847050159074173
+23	0.198837129012167
+23	0.28164139444755193
+23	0.19459133635718542
+23	0.21465174326252562
+23	0.1844133373990116
+23	0.19383093453181827
+23	0.24638893197152306
+23	0.18799044320147043
+23	0.1890422232248861
+23	0.24375865497347793
+23	0.2094850673151969
+23	0.09481696113453306
+23	0.15374459367686133
+23	0.28436269183555324
+23	0.3332379534623764
+23	0.12841415106355553
+23	0.278563890203365
+23	0.22577271221372217
+23	0.212357392405989
+23	0.1155614986885939
+23	0.2017584315846029
+23	0.253330978255989
+23	0.33796534511319765
+23	0.3006082611292065
+23	0.15030079471910637
+23	0.11241051250115203
+23	0.2651689097618914
+23	0.19539795404781904
+23	0.19165088070812178
+23	0.2970168902643199
+23	0.27968008893121593
+23	0.2922306582656777
+23	0.20935103761581447
+23	0.19481493511576398
+23	0.14823496360064364
+23	0.16070721394454135
+23	0.1654562377119444
+23	0.2434189783098981
+23	0.25470093251502374
+23	0.2536502678974918
+23	0.22588347963682312
+23	0.22654131667499325
+23	0.25620541712070977
+23	0.09384890803282471
+23	0.24209469837205375
+23	0.14927744124168937
+23	0.3202529445029965
+23	0.26213189863838504
+23	0.21037414516656006
+23	0.12682006029782747
+23	0.20172001577494325
+23	0.2459717608507693
+23	0.221261581831187
+23	0.18079686000512574
+23	0.2053489837568122
+23	0.18262229475205308
+23	0.23514198323572044
+23	0.26660347090008274
+23	0.34177031593876334
+23	0.2541955468894756
+23	0.1856353968683921
+23	0.2441652000746851
+23	0.1360297049194301
+23	0.2238804939190172
+23	0.30046022108778503
+23	0.22746081590528255
+23	0.16073935813146686
+23	0.1553874279372821
+23	0.17516815489316578
+23	0.25507001988696093
+23	0.2547696111191129
+23	0.1584406761009342
+23	0.20486263459873985
+23	0.2758458270483662
+23	0.14515803897929241
+23	0.25538174201089414
+23	0.3050698404752621
+23	0.25898891368908195
+23	0.19130950605258584
+23	0.26432460391890417
+23	0.1834571970588198
+23	0.1854175762764853
+23	0.28726099830032586
+23	0.2652629768621752
+23	0.21943144035304352
+23	0.26605731196824445
+23	0.22648157229473992
+23	0.3981134631978425
+23	0.34020806160669287
+23	0.1979564558864009
+23	0.3501780409894424
+23	0.23105138280664667
+23	0.234946985222951
+23	0.23175145211889855
+23	0.25468777780048624
+23	0.19944760406880727
+23	0.22528071837850303
+23	0.2073714620503671
+23	0.14728303441801474
+23	0.28127813612080327
+23	0.1694378023857021
+23	0.2484967958437017
+23	0.11428667916892704
Index: src/com/util/draw_oriline.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/draw_oriline.py b/src/com/util/draw_oriline.py
new file mode 100644
--- /dev/null	(date 1624340298000)
+++ b/src/com/util/draw_oriline.py	(date 1624340298000)
@@ -0,0 +1,39 @@
+# matplotlib中有很多可用的模块，我们使用pyplot模块
+from matplotlib import pyplot as plt
+# y = [0.3056671509276266, 0.29301946059517237, 0.33010695485965064, 0.29282299882691837, 0.293851967415084, 0.29345687997082004, 0.28800967659639276, 0.2729322952420815, 0.28154919750016666, 0.2619130630855975, 0.25322872886191244, 0.26964402393154474, 0.2834618736220443, 0.2724042411731637, 0.2787851503361826, 0.28356204052334244, 0.27542799354895303, 0.2715127707823463, 0.3013009040252022, 0.23547162342330683, 0.2528824236081994, 0.247206665251566, 0.24413469239421512, 0.2574798970118813, 0.24626387331796729, 0.24711732598750488, 0.24330974629391794, 0.2364792817312738, 0.23904266176016434, 0.24053992590178613, 0.25087836676317715, 0.24242231055446292, 0.2377722914452138, 0.23428166722473892, 0.23696353740018347, 0.24626892189616742, 0.21957904651113178, 0.24056077878112378, 0.24118249830992325, 0.2386405898824982, 0.23437994232644205, 0.23993553804314655, 0.232001099249591, 0.2385319516710613, 0.23201652551474777, 0.2296159662630247, 0.24575202005065006, 0.228259753273881, 0.24441290808760602, 0.234859065193197, 0.22498073461263077, 0.22612432001725488, 0.22101927321890127, 0.24471399868312088, 0.25753757519566495, 0.2357635520722555, 0.2346673189945843, 0.2236114348406377, 0.2295828555589137, 0.23819124439488287, 0.2427181653354479, 0.23134077664302743]
+y = [0.518883950036505, 0.22099129677466725, 0.23339358328477197, 0.16321416004844333, 0.22765648008688635, 0.12626873669417008, 0.10061323683222999, 0.1118608840295802, 0.14410756528377533, 0.06025991171760404, 0.09474259687830573, 0.0624044744864754, 0.07556426006814708, 0.06406946601751058, 0.06019029823010382, 0.043422013845132744, 0.06723578784452833, 0.05312044622943453, 0.036462158693567566, 0.07331404713508875, 0.04992739718569362, 0.05961339503688657, 0.05880868511841349, 0.05426795995267837, 0.04043417662868033, 0.04830686889750802, 0.08755936684167903, 0.04080098646733424, 0.054693828984771084]
+
+    # [17.17352564179379,10.429812444292981,2.2684924200825067,1.8833681234846944,1.3010058415972667, 1.0054526348476824,1.774010920006296,1.1624174215223477,0.8795011795085409,0.8804893260416777,0.9668381499207538,1.0186926897453226,1.2489867424187453,1.7588398965156598,3.662090181980444,1.913831648943217,2.947908490896225,3.191486165251421,3.399735023793967,3.8526736692242,2.0305367617503456,9.429632979890574,3.269230315218801,4.600765455028285,5.851516409088736,6.645087022172368,7.768487942607506,14.077916155042855,4.759564465802649,6.737976531619611]
+# y = [0.1769242749913879,0.17086356489554697,0.15613284804250882,0.16311684477588403,0.15747196729416432,0.15110910457113516,
+#      0.15099196184588515,0.14732225595609003,0.14584347411342288,0.1504912329432757,0.14856380029864932,0.1462206476084564,
+# 0.15936455422121545,0.1523332199000794,0.1451936922967434,0.14277758044393166,0.14431680414987647,0.1485642952763516,0.14378249710020813,
+# 0.1411788750277913,0.1454246858863727,0.14299778332528862,0.1434996260896973,0.14304679421627003,0.15234173882914626,0.1429228452236756,
+# 0.14428764678861783,0.13918464096344035,0.14868795175267302,0.1501741200361563,0.14308213312988696,0.1409261500381905,0.15020002116975578,
+# 0.14033224190706792,0.14476955017965773,0.14859254868782085,0.13994632094450618,0.13701126821663068,0.14086873197685118,0.13511908329699351,
+# 0.13613303653571918,0.13975786255753558,0.1338772449804389,0.13578432976551677,0.141379711744578,0.13252018554055173,0.13971926482475322,
+#      0.13824520405867827,0.132685590211464,0.12990016571205595,0.13468411451448564,0.13374444113477416,0.13372599414509276,0.13522296285499696,
+# 0.13425611445437308,0.1387976084066474,0.12937271206275278,0.13685424366722937,0.13799043793393218,0.13565961773628774,0.13348220580297968,
+#      0.13384535196034805,0.14048345986267793,0.13684888653781102,0.13314238174454027,0.13004027193655138,0.14820916545779808,0.14078020353032195,
+#      0.13038599523513214,0.1318445178153722,0.1277335300717665,0.13380451289855916,0.13473493217126184,0.12994345828242923,0.13119456512124641]
+# y = [0.18708745487358258, 0.1865022422178932, 0.16815709322690964, 0.16957692575195563,0.16562755049570746,0.16381269110285718,0.17335779543804086,
+#      0.15844928699990976,0.15714720571818558,0.16282607226268106,0.15373247894256012,0.15767525,41181834,0.15888055835081183,0.15387496886693913,
+# 0.1534555332492227,0.15175964407946751,0.1533665891898715,0.1549288225562676,0.1501708811391955,0.14817049321920975,0.1521355895244557,0.14769609434449155,
+# 0.1511421925995661,0.1421916799052902,0.15492675647787427,0.1570738824489324,0.14722584544316583,0.14234746879209642,0.1488260016169237]
+x = list(range(0, len(y)))
+#生成图表
+l1=plt.plot(x,y,'g--',label='loss')
+
+plt.plot(x, y)
+plt.xlabel('epoch')
+plt.ylabel('loss')
+plt.title('AE Loss')
+#设置纵坐标刻度
+plt.legend()
+
+# plt.yticks([0, 25, 50, 75, 90])
+#设置填充选项：参数分别对应横坐标，纵坐标，纵坐标填充起始值，填充颜色（可以有更多选项）
+plt.plot(x,y,'go-')
+
+# plt.(x, y, 10, color = 'green')
+#显示图表
+plt.show()
Index: src/com/util/draw_scatter.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/draw_scatter.py b/src/com/util/draw_scatter.py
new file mode 100644
--- /dev/null	(date 1624180169000)
+++ b/src/com/util/draw_scatter.py	(date 1624180169000)
@@ -0,0 +1,55 @@
+import json
+# import os
+
+import matplotlib.pyplot as plt
+import numpy as np
+import pandas as pd
+import seaborn as sns
+# % matplotlib inline
+
+sns.set_style("whitegrid")
+sns.set_context("paper")
+# 设置风格、尺度
+
+# import warnings
+# warnings.filterwarnings('ignore')
+# 不发出警告
+import os.path
+path = 'alice_ae_user_correlation'
+
+if not os.path.isfile(path+f'.tsv'):
+    # print ("File exist")
+    Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "../../../"))
+
+    brain2txt = json.load(open(Proj_dir +'/'+path+ f'.json', 'r'))
+    df = pd.DataFrame(columns=['user', 'correlation'])
+    for k, v in brain2txt.items():
+        # 插入数据
+        # df['user'] = k
+        print(k, np.mean(v))
+        for i in range(len(v)):
+            df = df.append({"user": k, "correlation": v[i]}, ignore_index=True)
+            # df[f'{i}'] = v[i]
+    df.sort_values(by="user", ascending=False)
+    df.to_csv(path+f'.tsv', index=False, sep='\t')
+else:
+    df = pd.read_csv(path+f'.tsv', sep='\t', header=0)
+    df.columns = ['user', 'correlation']
+    df.sort_values(by="user", ascending=False)
+
+    # df = pd.DataFrame(columns=['user', 'correlation'])
+
+
+sns.stripplot(x="user",          # x → 设置分组统计字段
+              y="correlation",   # y → 数据分布统计字段
+              # 这里xy数据对调，将会使得散点图横向分布
+              data= df,        # data → 对应数据
+              jitter = True,    # jitter → 当点数据重合较多时，用该参数做一些调整，也可以设置间距如：jitter = 0.1
+              size = 5, edgecolor = 'w',linewidth=1,marker = 'o'  # 设置点的大小、描边颜色或宽度、点样式
+              )
+plt.show()
+# plt.savefig("")
+
+sns.catplot(x="user", y="correlation",data=df, kind="box")
+plt.savefig(path+f'.png')
+plt.show()
Index: src/com/util/alice_cae_user_correlation.tsv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/alice_cae_user_correlation.tsv b/src/com/util/alice_cae_user_correlation.tsv
new file mode 100644
--- /dev/null	(date 1616247294000)
+++ b/src/com/util/alice_cae_user_correlation.tsv	(date 1616247294000)
@@ -0,0 +1,8327 @@
+user	correlation
+36	-0.01954521291242569
+36	0.0029631128482928296
+36	0.010280743978196913
+36	0.006840585499758286
+36	0.006177902097259845
+36	-0.0019353962504244078
+36	0.017098937498401735
+36	-0.021354269893308932
+36	0.004746745729894907
+36	-0.020497459142425355
+36	-0.009577851014287698
+36	-0.013774712682159128
+36	-0.0076932145072556735
+36	0.008118518199059479
+36	0.016727881678127873
+36	0.023268679014816943
+36	0.005493446202816799
+36	-0.016454615782761257
+36	-0.022657563846450898
+36	-0.01013179843893424
+36	-0.015769592255767788
+36	-0.005530819029416747
+36	0.03163250249628255
+36	0.006165729278628622
+36	-0.011995321803220237
+36	-0.00029944699526879845
+36	0.007197042515129379
+36	-0.002003063735056496
+36	-0.03160399742957807
+36	0.003724238411871665
+36	-0.007924646153838543
+36	-0.004410926959722177
+36	0.008054623749584267
+36	-0.003091067550294301
+36	-0.03859767023290117
+36	0.03450379055939161
+36	-0.00655918568469313
+36	0.039089196138691495
+36	-0.017287202557333903
+36	0.0017566371376588148
+36	-0.003708495102314467
+36	0.015560578283382955
+36	0.008811070284087773
+36	0.014141394670004222
+36	-0.008808829770838501
+36	-0.002287764755590949
+36	0.035373064561889586
+36	-0.00960276595858587
+36	-0.006900429021070757
+36	-0.02161380116087978
+36	-0.0076266140902809835
+36	0.011922739543786224
+36	-0.007100504250962599
+36	0.008797815254896988
+36	-0.013816238850902114
+36	-0.02628204963865978
+36	0.014093366950880728
+36	0.014801052830985505
+36	0.016476219837199255
+36	-0.0014370337451964728
+36	0.02439425091607292
+36	0.03298460432935644
+36	0.024576523891111854
+36	-0.0014457760763552454
+36	-0.003066388673157125
+36	0.008150149218284686
+36	-0.0025000639708450388
+36	0.012691226793187791
+36	9.873674571278303e-05
+36	0.0033813528344374543
+36	0.03152448364050676
+36	0.01239190324844754
+36	-0.007188368159538028
+36	0.03791580038161756
+36	0.004213544557274784
+36	0.01758998774867815
+36	-0.0039968651152913
+36	0.008176357558123057
+36	0.013181730308801782
+36	-0.015082534928685394
+36	-0.00806225862160956
+36	0.01359479521217317
+36	-0.015165998643218728
+36	0.009387416511172947
+36	0.0023736717234482184
+36	-0.03267140134522636
+36	0.017511000199174565
+36	-0.019809597983403163
+36	-0.0004199781555681587
+36	0.008862574519860868
+36	-0.009773759078502853
+36	0.01687781672096798
+36	0.00274649175520373
+36	0.0175372607014541
+36	0.031241625978608606
+36	0.008409659641182631
+36	-0.008240945076818638
+36	0.019463656186214054
+36	0.006265342279750583
+36	0.030722748128289304
+36	0.027532698705954043
+36	0.013224042182658945
+36	-0.004027479516369186
+36	0.00615142457036908
+36	-0.008207533273566622
+36	-0.02272007343056984
+36	0.017355856330343478
+36	0.03143212606718321
+36	0.000542119459195038
+36	0.006252187076082523
+36	0.006102117475838879
+36	-0.0037560116913005533
+36	0.04754524735658298
+36	0.04177893245396331
+36	0.011213289939295861
+36	0.002067767229639752
+36	0.010218654068882524
+36	0.005961130230488273
+36	0.014290001175176897
+36	0.02075756200401912
+36	0.0202087982539854
+36	0.028464138319008184
+36	-0.017107449161746745
+36	-0.020254167485232264
+36	-0.011718657259115988
+36	0.027684836457601614
+36	-0.03192111831293914
+36	0.012545447239540068
+36	-0.017226890521771152
+36	0.010416780163425591
+36	0.01838253307754991
+36	-0.008451822474986681
+36	-0.01306681128530737
+36	0.017770187554481277
+36	-0.0011358168948847646
+36	-0.005850538860819608
+36	-0.0031930711293675132
+36	0.03240997198337554
+36	-0.0011342747549620811
+36	0.0173097344127464
+36	0.019044587866423147
+36	0.03266599484464579
+36	0.0020690210227871718
+36	-0.015396391458127115
+36	0.0013576008939340585
+36	-0.0019914168347946524
+36	-0.0006237336855551628
+36	0.011647378426143124
+36	0.019564590646266384
+36	0.020991286305362077
+36	0.005937523962526006
+36	0.040538903093384676
+36	-0.006697782474421654
+36	-0.017630722445914654
+36	0.000625231693834471
+36	-0.017270275475632275
+36	0.001442418640913189
+36	0.008020984379545496
+36	0.03257444779178081
+36	0.007256539657992014
+36	-0.014681189977959743
+36	0.008759846528248398
+36	0.009133678416530323
+36	0.033660621230771244
+36	-0.018795850279738676
+36	-0.018636800415611738
+36	-0.024605794692345632
+36	-0.00048353834085954864
+36	-0.013062565262673022
+36	-0.008800157954897367
+36	-0.009758470391374735
+36	0.005373695769661157
+36	-0.0006258258867388385
+36	-0.0018122644345853626
+36	0.0013668822437430278
+36	0.01386086536736983
+36	-0.0057950467571682065
+36	-0.0007220469572575823
+36	0.0010656211293648887
+36	0.010400903000187532
+36	-0.02897780675502956
+36	-0.04076981062815597
+36	-0.00014077702219846537
+36	0.0017613982651858366
+36	0.001676615210848647
+36	-0.009374076030895951
+36	0.0027771743223735956
+36	0.00875834869381008
+36	0.0030446359732257994
+36	0.018680036584822923
+36	0.042931582763319154
+36	-0.03619798380399615
+36	-0.002298421026299877
+36	0.010078547352667874
+36	-0.02994006934824641
+36	0.004810796246558115
+36	-0.011822704641665448
+36	0.01698164166043109
+36	0.014411100187188462
+36	0.010851351809740289
+36	0.024788294398586385
+36	0.03432590224955538
+36	0.017322205076055624
+36	-0.017903890792173884
+36	-0.013367100575670634
+36	-0.05499967041570849
+36	0.009642843943989277
+36	-0.024662440877365157
+36	-0.00900649609072213
+36	-0.0010985339124370433
+36	-0.029090274975419272
+36	-0.027642519090149417
+36	0.0025486693215085584
+36	-0.011414382830231945
+36	0.01438513898413622
+36	-0.0002751369335391207
+36	0.01470446688006127
+36	-0.015281532911489851
+36	0.020262155972968196
+36	0.008955555305484964
+36	-0.002573865040645883
+36	0.020301375876028028
+36	0.02654617172988597
+36	0.016501271498005707
+36	0.0030356706383588023
+36	0.016462959499385487
+36	-0.004394157969375519
+36	0.00046500471486718485
+36	0.014225414135998215
+36	0.0038381966485395466
+36	-0.00897145764032931
+36	-0.015271187201570063
+36	0.008443213557054328
+36	0.01395503303931763
+36	0.0171795144369576
+36	-0.0331830653576184
+36	0.007304278664598648
+36	0.027253212498858714
+36	0.021109187800319326
+36	0.030154327025868004
+36	0.005377559677017625
+36	-0.008892121775573537
+36	-0.010380089579068275
+36	0.006371220772680764
+36	-0.007084654333276425
+36	0.02018244471487293
+36	0.02868966691144983
+36	0.02093591649772812
+36	0.02008948432426875
+36	0.0005540102579824947
+36	0.020976466328987246
+36	0.01725387038056914
+36	0.01138871274259541
+36	0.0015669602387436419
+36	0.023566313236434433
+36	0.021675502520793553
+36	0.015913417320431125
+36	-0.0008081819718010583
+36	0.0022902742365065475
+36	0.007381733311897473
+36	0.024623842673149574
+36	0.040836440899873094
+36	0.0034454297669705533
+36	-0.016051882263640314
+36	-0.0018359939450507527
+36	-0.01912425959870412
+36	0.012902210804731449
+36	0.013453399363296066
+36	0.005455729196938473
+36	0.027519428199951273
+36	0.011239127919600038
+36	0.016218383697548917
+36	-0.001527844581276059
+36	0.0026825294269984053
+36	-0.0042894847624805246
+36	-0.02140434132526659
+36	0.01690119330305199
+36	0.004126602540519641
+36	0.005146399713997409
+36	-0.028430629930838898
+36	-0.034808770079558134
+36	0.008659767915168145
+36	-0.018182211636787265
+36	0.00811469472724156
+36	-0.013509977334049019
+36	0.012291947435576257
+36	-0.0038649158585422083
+36	-0.009144770075079404
+36	-0.050354805097706776
+36	0.004855033492721218
+36	0.0330721889129586
+36	-0.04013308333144608
+36	0.020125960667912796
+36	0.00211122220244402
+36	0.0075462997874572455
+36	-0.002761134704141604
+36	0.001421601002088116
+36	-0.0037526518604941335
+36	0.021545380762562724
+36	0.012069061606554155
+36	0.01730219895283047
+36	-0.005445706350620376
+36	-0.0019494367982324842
+36	0.008394357640224712
+36	0.0038810898228054664
+36	0.002961247346486511
+36	-0.009809489845007638
+36	0.00433281915957945
+36	0.019006563166270283
+36	0.009969472655513682
+36	0.020052758739330784
+36	-0.0008088499454517127
+36	-0.0018800001224761138
+36	0.010524596391936916
+36	-0.0013165206670137744
+36	-0.001623684730729187
+36	0.002491045136421094
+36	-0.02231647295820523
+36	0.012217340269923301
+36	0.009644354595541147
+36	-0.00563533119743144
+36	0.020406237008461805
+36	-0.018071386069090267
+36	0.020607599474299285
+36	-0.009040429968691116
+36	-0.004058354672845824
+36	0.0007758137894103587
+36	0.005218531037283641
+36	0.010455757089019066
+36	0.019929558718604783
+36	-0.02286128812140078
+36	-0.009277401406949156
+36	-0.017896614154895532
+36	0.02815583119937006
+36	0.013071696746345582
+36	0.035610484862012924
+36	0.035091803903821786
+36	0.025212708047677456
+36	0.004658390757971009
+36	-0.011654520862079545
+36	-0.00745968809437442
+36	0.0015161445237900123
+36	-0.01095389193858356
+36	0.0021617748686273814
+36	0.009339512484171536
+36	0.050244635433255205
+36	0.012054422321851043
+36	0.025257387152740625
+36	0.004463011565942775
+36	0.014284564925693277
+36	0.020321979422347914
+36	-0.012360017683972062
+36	-0.023318423001239076
+36	-0.017267031074898926
+36	-0.014322581227251609
+36	-0.03351952077747237
+36	-0.006065479597299538
+36	0.0154793938879841
+36	-0.017919342552562705
+36	-0.041073847525574136
+36	0.01715523314722648
+36	0.011509612912454307
+35	-0.014006894834645438
+35	0.0019427385920882754
+35	0.012459811100493495
+35	0.015450551584987513
+35	0.0041427547285631085
+35	0.004484972588935652
+35	0.028055316962785005
+35	-0.01631501073170531
+35	0.00645921050768283
+35	-0.007595006470907905
+35	-0.010367553102433496
+35	-0.004946242333866605
+35	-0.0060107852080194596
+35	0.015382902889261791
+35	0.020974704450217967
+35	0.02637339074627683
+35	0.014745271480388903
+35	-0.008436761993763316
+35	-0.018913161874828607
+35	-0.00018401459367562833
+35	-0.005309078624378553
+35	-0.0042463384170405355
+35	0.033495146255921864
+35	0.010158435848349662
+35	-0.006499675628618514
+35	0.008950513240095971
+35	0.011671942091971352
+35	0.007734299829801756
+35	-0.01793155700483447
+35	0.005549709988692689
+35	-0.004691529855248336
+35	-0.0022758502228306123
+35	0.013079074338013778
+35	-0.004375771591793113
+35	-0.031183123611808382
+35	0.03819666179621334
+35	-0.004192118305703199
+35	0.04117380172082618
+35	-0.009217196006224702
+35	0.00500543065159003
+35	-0.0032289418494542165
+35	0.0181234353507118
+35	0.011829863150735063
+35	0.017137929159749283
+35	-0.005740399324730821
+35	0.0021701220605090566
+35	0.03915661869338557
+35	-0.005018699619194396
+35	-0.0056706469501516706
+35	-0.008537120339906085
+35	-0.0023525116417042868
+35	0.016530285781616014
+35	-0.0003865207584554826
+35	0.020557743883168625
+35	-0.00524456967804517
+35	-0.018178058006685094
+35	0.009364662888946104
+35	0.023437769826669758
+35	0.010504096791810733
+35	0.002265560731542861
+35	0.029674268811532328
+35	0.03074347635075669
+35	0.030505596474243394
+35	0.005520538334805046
+35	-0.0008263377091513595
+35	0.007925173429184126
+35	0.007150918492500927
+35	0.012086190225319137
+35	0.00653440285268604
+35	-0.000554826079113259
+35	0.0353188501254928
+35	0.008597412918323248
+35	-0.0001294157212841259
+35	0.034891094374254854
+35	0.010924708719956381
+35	0.01755145256362391
+35	0.006715474525668529
+35	0.006037804069227653
+35	0.023665512439509068
+35	-0.00724748743080748
+35	0.0003059477401490165
+35	0.023967771800841704
+35	-0.012639389802244385
+35	0.005444796485380767
+35	0.004462104926941695
+35	-0.01941245039393083
+35	0.024249126342379135
+35	-0.021087644207091725
+35	0.013363015679906677
+35	0.01029742451638233
+35	-0.003922484104885419
+35	0.021118038428603388
+35	0.0027115072004037606
+35	0.02041679910571673
+35	0.03279269780399284
+35	0.013098375825996265
+35	-0.002178325457025216
+35	0.01327041905691244
+35	0.00813948094592759
+35	0.028595817928226835
+35	0.02750254197680422
+35	0.017409394785101357
+35	0.006604666807295251
+35	0.015640751022133074
+35	-0.0030167556391799194
+35	-0.014268605417804088
+35	0.02788118308291829
+35	0.031637022151138436
+35	0.009842899662347372
+35	0.013356632108997027
+35	0.00894871332331697
+35	0.0011568661281059467
+35	0.045753488709468514
+35	0.04233516760982203
+35	0.017500995829781152
+35	0.005296476400267093
+35	0.016179528440952072
+35	0.016406049158041988
+35	0.02160726820404294
+35	0.03233809737791127
+35	0.017779911604281412
+35	0.031710043229386045
+35	-0.009110451095014193
+35	-0.011894835847010172
+35	-0.008288620717123676
+35	0.036348252626943356
+35	-0.03504489919981598
+35	0.013709961119181314
+35	-0.01563562006342505
+35	0.020194354900151652
+35	0.020995058316906654
+35	-0.003552487454355298
+35	-0.006423904100578048
+35	0.021409005406857872
+35	0.00761814702601151
+35	0.007239464962091251
+35	0.004526805513331476
+35	0.0438622090415843
+35	-0.0027697966892545173
+35	0.014834214064720354
+35	0.0204472756559299
+35	0.03343643972029732
+35	0.007515395563551267
+35	-0.0063799554079554755
+35	0.00754084967471857
+35	0.006460264093300291
+35	0.003941736321341878
+35	0.017426281010804553
+35	0.027341096767459515
+35	0.020000870388457655
+35	0.004877132122299819
+35	0.040063767954982885
+35	0.006679857071227811
+35	-0.01227495877389064
+35	0.009068428374051217
+35	-0.011794503049494818
+35	0.007921473301068198
+35	0.0137684662236217
+35	0.02691686819487574
+35	0.008834638852120009
+35	-0.012643131591811555
+35	0.01414717602953692
+35	0.014462032485886013
+35	0.03234959782988002
+35	-0.018951987796432552
+35	-0.01690227573403262
+35	-0.02220482137744893
+35	0.010879826507051217
+35	-0.005974506714708332
+35	-0.00797073074006907
+35	-0.003412281972505455
+35	0.008748264531139879
+35	0.006334794448844372
+35	-0.0002479430203747222
+35	0.00020208455813871935
+35	0.016771257752051332
+35	0.005244814608735865
+35	0.00031443314376740605
+35	0.0028438651679257403
+35	0.012479549224010717
+35	-0.018126274332983677
+35	-0.029549710406367852
+35	0.007841652219488376
+35	-0.0010944419425607038
+35	0.00912970988471804
+35	-0.0011690122494933122
+35	0.0040765786050249555
+35	0.011316058724795689
+35	0.0019002346458774763
+35	0.030477751821578195
+35	0.04670693779169464
+35	-0.027692534592983466
+35	0.01113198663768929
+35	0.0175781770611519
+35	-0.019291448059661646
+35	0.00970887619563947
+35	-0.009178971409518004
+35	0.018328131994606946
+35	0.0295388065115752
+35	0.016206271249774022
+35	0.025150007979946976
+35	0.037381876124314255
+35	0.026392115428876727
+35	-0.011810113817059827
+35	-0.008427552232236209
+35	-0.050028399783344425
+35	0.013467691548025526
+35	-0.020240589683073375
+35	-0.008010995892802873
+35	0.013748138399523187
+35	-0.029396718269925303
+35	-0.019146236893079323
+35	0.008529952533470499
+35	-0.006323580132392179
+35	0.012828641225356107
+35	0.00494540240153156
+35	0.019271830594117707
+35	-0.008857714939343736
+35	0.029267720849845184
+35	0.01493085039361467
+35	0.004594068955374033
+35	0.013064475435427087
+35	0.026885409247120642
+35	0.01901690697508293
+35	0.009354109470365107
+35	0.026440497735605594
+35	-0.0002620467866355987
+35	0.013319844843269622
+35	0.025430657131795185
+35	0.011282571670163541
+35	-0.00919177159168875
+35	-0.008628244077139396
+35	0.016129675829501967
+35	0.018259196741617797
+35	0.02091649594438479
+35	-0.03650011077439805
+35	0.01016240451763875
+35	0.03123121974426255
+35	0.030602078610074794
+35	0.03220885231123301
+35	0.014760179944357816
+35	-0.004303477314646049
+35	-0.002444052628090818
+35	0.008082017217319852
+35	0.0028864428827451074
+35	0.018454823700713368
+35	0.03654695973154001
+35	0.03228960816919648
+35	0.0215733857092292
+35	0.0009095841938904506
+35	0.02388358000646236
+35	0.02233505834178082
+35	0.023887823442544222
+35	0.011877315750153456
+35	0.03757091800804623
+35	0.03280992886219343
+35	0.02045422704119257
+35	0.0095487850525291
+35	0.012103282329932968
+35	0.008678471075809307
+35	0.03500775596193579
+35	0.042893142807605464
+35	0.009929195448632067
+35	-0.007400138355361543
+35	0.010160265439477505
+35	-0.009698875567093113
+35	0.020325116756950482
+35	0.022598348369099346
+35	0.01554390208015398
+35	0.036916061441990784
+35	0.019335926912772448
+35	0.02780413709530869
+35	0.0009533109396183918
+35	0.014314555615701826
+35	0.003251155426218166
+35	-0.012314128783883254
+35	0.02500466944845323
+35	0.014506256275457433
+35	0.014830057888273507
+35	-0.025542780711342673
+35	-0.026362435785435404
+35	0.01652278191155099
+35	-0.004202207812578551
+35	0.01128702111879883
+35	-0.007522856577748832
+35	0.014138672195222997
+35	-0.0012736321413682348
+35	-0.009156377647152084
+35	-0.031823157506427724
+35	0.004888150457631947
+35	0.03143278904121611
+35	-0.029111011721376964
+35	0.0242186838283733
+35	0.0026032405772611093
+35	0.017809716014512877
+35	0.013467511855682318
+35	0.009515284109137866
+35	0.010253358153088213
+35	0.03472866977759946
+35	0.013628005511464225
+35	0.02300992638669698
+35	0.008069973497746555
+35	0.0022473688975445136
+35	0.00951842628663916
+35	0.015161355379597879
+35	0.0014427548468072626
+35	-0.0012861671378544795
+35	0.009412935515211033
+35	0.017179130844475803
+35	0.012803702921699217
+35	0.024749525933084632
+35	0.0013830704049476918
+35	-0.0008246436993982077
+35	0.024710679229803422
+35	0.006921843263942494
+35	0.004558750202987402
+35	0.011164727111766814
+35	-0.01621169985852524
+35	0.016662399447169143
+35	0.017645843143987684
+35	-0.0016162160209553223
+35	0.024616103876308512
+35	-0.009732220121742102
+35	0.02090706661422222
+35	0.0018183504161951212
+35	0.008460311797485907
+35	0.006956217120811339
+35	0.0010780995110673728
+35	0.017009483471079657
+35	0.03222708798451116
+35	-0.0047201700827825275
+35	-0.0012090198403142162
+35	-0.002433590465176305
+35	0.030962602267201735
+35	0.015811665039438146
+35	0.040133322905639916
+35	0.040520470046576156
+35	0.02820079555787754
+35	0.0072205520521165375
+35	-0.013574770930345452
+35	-0.0010682015080542885
+35	0.0022117272065003556
+35	-9.676931142902674e-05
+35	0.010178069018677575
+35	0.023316507815327788
+35	0.056553537983872394
+35	0.01410124586553054
+35	0.02928829939404254
+35	0.004334272734253258
+35	0.01595238366586292
+35	0.0250543999215584
+35	-0.011745531157169758
+35	-0.015077888120560066
+35	-0.006375099735124856
+35	-0.007439965541525373
+35	-0.024627139358253565
+35	-0.008871243906933772
+35	0.020013563109802096
+35	-0.008631835907964205
+35	-0.030091980774566218
+35	0.023333360425225963
+35	0.013654810656747465
+44	-0.023611759814641413
+44	-0.0024812620503659767
+44	0.015287422138234476
+44	0.008200993225509325
+44	0.005757235878322369
+44	0.00010260150737089622
+44	0.019929075694631922
+44	-0.023090945362497985
+44	0.003434777911278656
+44	-0.016694751424403756
+44	-0.010875053152992488
+44	-0.009672862371872535
+44	-0.004732548827869199
+44	0.008828902601235292
+44	0.012121842234031717
+44	0.02041385338697309
+44	0.010364182712402543
+44	-0.02447668138419267
+44	-0.028380922698637984
+44	-0.00615300055366364
+44	-0.01646594785810602
+44	-0.00825192452240184
+44	0.021906240990358063
+44	0.003765828056233748
+44	-0.013415327448510043
+44	0.0061051529483469
+44	0.005128335202867284
+44	-0.0038552359926005485
+44	-0.029604300737056364
+44	0.001942354348673197
+44	-0.008590027092941209
+44	0.00019138931688729007
+44	0.010490572056828037
+44	-0.006378423106897932
+44	-0.03831300583589124
+44	0.021747386143499955
+44	-0.0033524879352872738
+44	0.031956298755023
+44	-0.01790384909434394
+44	-0.0023361884901600123
+44	-0.013476234367372414
+44	0.004827720380051095
+44	0.003637932464809532
+44	0.0005026666713808866
+44	-0.015305475406223071
+44	7.063759419076373e-05
+44	0.027848096515959465
+44	-0.004981321669739826
+44	-0.014948594241714337
+44	-0.01679797735002404
+44	-0.006270662940146339
+44	-0.00017505315358531893
+44	-0.01246517292886928
+44	0.0071470744575849255
+44	-0.012076815551627786
+44	-0.02921341593827042
+44	0.002905639807556073
+44	0.011822483468861571
+44	0.005860837382268839
+44	-0.005343650957479235
+44	0.01051235997321379
+44	0.022870855491649224
+44	0.012623588022279827
+44	-0.0033326295331693747
+44	-0.0017147702904337983
+44	0.009576757354870236
+44	0.0022589826007619112
+44	0.017183742492588177
+44	0.003334520083965405
+44	-0.0007002614100160327
+44	0.03226779884178095
+44	0.007901045543907564
+44	0.0009650654885575171
+44	0.028343976173980847
+44	0.0038821593540493407
+44	0.016216844134166065
+44	-0.02120022889658061
+44	0.0036597855729128084
+44	0.010387833926984637
+44	-0.01647389978328952
+44	-0.0036489296338600447
+44	0.015176200842057822
+44	-0.01340553780612412
+44	-0.0018685347091112244
+44	-0.008952267970052335
+44	-0.04253026990272401
+44	0.007076687827482585
+44	-0.02761324213930592
+44	-0.004232951823514568
+44	0.003730812606504072
+44	-0.011522062932767852
+44	0.001152864645905981
+44	-0.011789590813563625
+44	-0.0018052675176499105
+44	0.01991215401719904
+44	0.01723458790175657
+44	-0.003976836522674216
+44	0.012178120103438828
+44	0.00452080932108522
+44	0.02806185110327853
+44	0.02468667721752302
+44	0.01106255338826476
+44	-0.016206814385721937
+44	0.006747439431034117
+44	-0.011163830687169802
+44	-0.022825650392770427
+44	0.016802292787029525
+44	0.03376361368995088
+44	0.00240034812578016
+44	-0.0009606967152848099
+44	-0.008458554732697639
+44	-0.012297569759936944
+44	0.03168289685491466
+44	0.040546752869952025
+44	0.01279610961279582
+44	0.0045992676229564345
+44	0.00644746363989627
+44	0.011910138133071024
+44	0.005714633760098711
+44	0.028912492080674028
+44	0.013008990956156942
+44	0.014810769427493958
+44	-0.02638117127700743
+44	-0.018810371755037043
+44	-0.020748273252954526
+44	0.022549009013945458
+44	-0.04187903406914498
+44	0.004603996000106518
+44	-0.02815525683093223
+44	0.004115564305345027
+44	0.009213126938817049
+44	-0.01092275132512381
+44	-0.010467392930230933
+44	0.009779836944280479
+44	-0.006149476770589698
+44	-0.007959420496006842
+44	-0.012737543541267259
+44	0.03486957747821786
+44	-0.003038138637391324
+44	0.00822693782794898
+44	0.010605619629018955
+44	0.020987894720488252
+44	-0.005329091421706469
+44	-0.021385788882630284
+44	-0.009305434667177257
+44	-0.0023418186365816033
+44	-0.006167080647127593
+44	0.017594484959297357
+44	0.024544548049462184
+44	0.007330840969927597
+44	0.0028753988217833757
+44	0.028698050727056577
+44	-0.004159303922806523
+44	-0.017897576766942157
+44	-0.0038881893395923016
+44	-0.013293555047278041
+44	-0.004564447557555838
+44	0.0009965081228763548
+44	0.019623843385180778
+44	-0.007782050511478611
+44	-0.011207031277552537
+44	0.004441486310602401
+44	-1.467744683197583e-05
+44	0.02869626729946162
+44	-0.02416076959247471
+44	-0.023866533490298956
+44	-0.028466386872498303
+44	-0.0025849057841303234
+44	-0.013404092928584405
+44	-0.016302516280780083
+44	-0.017928200791292984
+44	-0.0016652244440439068
+44	-0.00031237217624025963
+44	-0.012036051333773142
+44	-0.009344592316544387
+44	0.004440393245295835
+44	0.0010660783700651869
+44	-0.00657595119612066
+44	-0.006793160475202519
+44	-0.004628579758048939
+44	-0.02948523870742399
+44	-0.04110721619954769
+44	0.005047996065708897
+44	-0.004587436802716498
+44	-0.0029898464204724615
+44	0.004008750789009089
+44	0.0014258643433130022
+44	0.0028883556346362455
+44	-0.001220970795150675
+44	0.02555516263094267
+44	0.035936778884720605
+44	-0.03699148606384301
+44	0.004923485446908828
+44	0.014026901216155031
+44	-0.01563336097379412
+44	0.0045642823901205064
+44	-0.00900755704221869
+44	0.009118870444512622
+44	0.015801580580791286
+44	0.01986269728393693
+44	0.01796442368177031
+44	0.025686696414037265
+44	0.018830163395839445
+44	-0.01811989611430378
+44	-0.01739675584568484
+44	-0.0605284813630031
+44	0.0004314840667655989
+44	-0.019515343356572058
+44	-0.01093873761294496
+44	0.0035083649305770303
+44	-0.032406867015200125
+44	-0.02984493778678364
+44	-0.005271176388103221
+44	-0.01171786856445126
+44	0.002441443045213097
+44	-0.007690744644324887
+44	0.008585889614021272
+44	-0.014593136800455484
+44	0.01101194375137137
+44	0.015027633121459782
+44	-0.0019935955429886947
+44	0.011345548085067976
+44	0.022898412964612275
+44	0.012856557808416061
+44	0.002137668382595194
+44	0.013350659575745924
+44	-0.0014039045826431847
+44	-0.0014448677999378818
+44	0.010868443810160597
+44	-0.009704329385890591
+44	-0.0073805968291011485
+44	-0.016469841260326308
+44	0.011443894947827828
+44	0.021378305999109094
+44	0.020059367662938844
+44	-0.04481739190993147
+44	0.007141372236803743
+44	0.024923045926322513
+44	0.01997105655976788
+44	0.023667085350691303
+44	0.003840343597370442
+44	-0.008693325984928313
+44	-0.011811995296904241
+44	-0.001911711057416865
+44	-0.0005879266047599074
+44	0.019686568634167893
+44	0.022849426087420098
+44	0.034247288386625364
+44	0.009693747002817905
+44	-0.00394882124020241
+44	0.013709144567081619
+44	0.01236739179529862
+44	0.00900873327669846
+44	0.0074070623883368695
+44	0.024474828790194306
+44	0.025690929710322098
+44	0.007673166217872805
+44	0.008801309707681794
+44	-0.007135077388165406
+44	0.00010771661078130727
+44	0.025522902599707475
+44	0.03595714956501517
+44	0.005240867208698431
+44	-0.008146006938164066
+44	0.0040005251625981515
+44	-0.017166331233776307
+44	0.015982981601625132
+44	0.007699165028472012
+44	0.004113976078774759
+44	0.02630409256214789
+44	0.013144527218636199
+44	0.011383101439130204
+44	-0.003243836278496144
+44	0.010030254023296454
+44	0.001093874793000968
+44	-0.005529894413316013
+44	0.02391438101556233
+44	0.014634406644628553
+44	0.007515914901794191
+44	-0.0329145103720531
+44	-0.04228693497294785
+44	0.006131276771934618
+44	-0.016758329335377443
+44	0.006665889176357867
+44	-0.023176465594408283
+44	0.010878744178372864
+44	-0.012131471546626919
+44	-0.021064100053315535
+44	-0.04457452422378405
+44	-0.0014135967544777752
+44	0.03548196846841652
+44	-0.04225671878559364
+44	0.013636440227553014
+44	-0.001971834429987449
+44	0.007990775931509188
+44	-0.000994321119990047
+44	-0.0037904614552603686
+44	0.002070423286221924
+44	0.020815283670515564
+44	0.010014845952232754
+44	0.006145873378225286
+44	-0.0012243805008832446
+44	0.0025383580365007383
+44	0.004318659663788089
+44	0.005124485790501712
+44	-0.003276181463329344
+44	-0.009781583599932284
+44	0.0034254216325645855
+44	0.020767821167437774
+44	0.004871762385580944
+44	0.013827675004711128
+44	-0.0013320802246271862
+44	-0.0072742029725670265
+44	0.022288116557745406
+44	0.001880533775865079
+44	0.007927237092762237
+44	0.005799423478163901
+44	-0.017763874015783596
+44	0.01323114476162222
+44	0.012626488534362277
+44	-0.0032432777906781667
+44	0.007924477065704687
+44	-0.029014807086143526
+44	0.015143680645852507
+44	-0.00566870638709381
+44	0.0017516135121883407
+44	0.002179438660605156
+44	-0.00279476897540004
+44	0.010582840679249906
+44	0.029572281396426158
+44	-0.010132584215638007
+44	-0.007210193263058268
+44	-0.011439953853025155
+44	0.013669429483254074
+44	0.0018034134068113817
+44	0.03452287516373988
+44	0.036180250305439234
+44	0.016974592269570845
+44	0.0018748109814046496
+44	-0.010363547465765895
+44	-0.0018172640036857434
+44	-0.0033054506914099286
+44	-0.003432759680083285
+44	0.002225077927621737
+44	0.020086749019146123
+44	0.045357265746104075
+44	0.007067836847219824
+44	0.01388678662984507
+44	-0.008293810029010324
+44	0.00793322004907408
+44	0.014766595509791597
+44	-0.02053034807274441
+44	-0.024221958480235454
+44	-0.00900270174276592
+44	-0.022187114473420498
+44	-0.03750137351671756
+44	-0.012685832064512901
+44	0.007349240078952807
+44	-0.018414892567678504
+44	-0.03991359066319926
+44	0.008757497238360732
+44	0.002507881115459822
+47	-0.01317211086662448
+47	0.014969176822026559
+47	0.026918966205281402
+47	0.02087885155055801
+47	0.012479757567463483
+47	0.009416138572678328
+47	0.03071641048451856
+47	-0.00941997156240228
+47	0.009537434958272443
+47	-0.005652928703989082
+47	-0.007418476398112706
+47	0.009835662043665098
+47	0.0059982550921927795
+47	0.026208130650528363
+47	0.02508316835651888
+47	0.029678817864220216
+47	0.011845686173538867
+47	-0.004968985577008833
+47	-0.017837742916531375
+47	0.009735040948851413
+47	0.0042027743392467265
+47	0.00323636834157786
+47	0.03809321909634755
+47	0.017509936690074644
+47	0.008873477525121486
+47	0.015186376840298972
+47	0.025123534480684762
+47	0.014594639387583713
+47	-0.019634158192529772
+47	0.013359224171533166
+47	-0.004368450958842738
+47	-0.0026598117731683533
+47	0.013671309981461292
+47	0.0036615863794751645
+47	-0.028454571459877245
+47	0.04510738950701912
+47	-0.0021913005595572553
+47	0.04064973296925031
+47	0.005813772858024596
+47	0.006760614423725834
+47	-0.0020428686026965153
+47	0.02322088781123093
+47	0.01838520819602966
+47	0.012644881603543762
+47	-0.000323179620360104
+47	0.013335865983173871
+47	0.04433603884693265
+47	-0.0005444634576969352
+47	-0.0005537356347135661
+47	-0.011059237803834627
+47	0.008645710258728427
+47	0.01843998288629187
+47	0.004289586666358313
+47	0.0159037380643252
+47	-0.001032925519734224
+47	-0.013738723033775387
+47	0.017275888067088404
+47	0.026356586815753286
+47	0.02539294271730355
+47	0.009661828335894464
+47	0.025850386209607803
+47	0.03530542177581524
+47	0.030792622388393167
+47	0.007100127714782106
+47	0.0018068197845115977
+47	0.016497405511850773
+47	0.011048914680280974
+47	0.019603367631228663
+47	0.007804582184026463
+47	0.0067862504539183055
+47	0.03228903577660583
+47	0.017240943476749974
+47	0.01743766244525692
+47	0.040466242207860686
+47	0.011262394943200995
+47	0.023120672679969305
+47	-0.001575845698763895
+47	0.014878752319026474
+47	0.040559292639952234
+47	-0.003864110035928509
+47	0.011028563177554586
+47	0.028673500431067978
+47	-0.004259677237999655
+47	0.010073386214528475
+47	0.012985266892943615
+47	-0.02831144150487748
+47	0.015511365755862247
+47	-0.012168483178637494
+47	0.01113143280573236
+47	0.02687997862441275
+47	0.004197415465511538
+47	0.021720855516250418
+47	0.011028014106111856
+47	0.020637507358913357
+47	0.03429981145336266
+47	0.02845402456783919
+47	0.008343181661779876
+47	0.028960184968879296
+47	0.019217063152728052
+47	0.03698176596673001
+47	0.040923176870636305
+47	0.018974111306070112
+47	0.0038197789776455594
+47	0.01580242070169945
+47	0.007720311543913582
+47	-0.012114523530871946
+47	0.026200317500471117
+47	0.03977679232885158
+47	0.018563239876331218
+47	0.030102763395106927
+47	0.009338261086480506
+47	0.016995813869260627
+47	0.05046907444518069
+47	0.053824846108663955
+47	0.026192374845769147
+47	0.016865802287809463
+47	0.021773878441016924
+47	0.011934500924628241
+47	0.025019040284322037
+47	0.04371006651272671
+47	0.02494920457652311
+47	0.024872842744948852
+47	-0.0053817104856059405
+47	-0.007089459955283422
+47	-0.0025353265196941016
+47	0.03570935287441069
+47	-0.013031484524966476
+47	0.022042002606501458
+47	-0.006486524081661486
+47	0.023768402349704558
+47	0.01906946472005406
+47	0.0007899919849650499
+47	0.0013275249527732835
+47	0.01912533022051908
+47	0.011485207619643611
+47	0.007636217188608353
+47	0.001804072143930281
+47	0.046649896284118635
+47	0.006507857515789631
+47	0.02049500211426162
+47	0.02498482866565893
+47	0.03748994709842479
+47	0.005025701959611826
+47	-0.0029839800726640317
+47	0.015176341485911547
+47	0.007061178988365819
+47	0.009490785810187996
+47	0.02288117671310471
+47	0.031875668360794945
+47	0.032433482580559905
+47	0.01419446350685288
+47	0.04838659858629823
+47	0.01236566209325067
+47	-0.0071324610127151584
+47	0.0046573047085771355
+47	0.0025884323797571813
+47	0.009928035169585379
+47	0.012938521676259293
+47	0.040353111302361314
+47	0.011186613964786388
+47	-0.00506714289875881
+47	0.010591930985370056
+47	0.014851005896441978
+47	0.03354557064860818
+47	-0.014026266325896618
+47	-0.0033985645591251006
+47	-0.01111741802391215
+47	0.01632360077650997
+47	-0.0020269937719560763
+47	0.004636625991600875
+47	0.002633172989853163
+47	0.008738608871295366
+47	0.015272479328137738
+47	0.009656940404033126
+47	0.0023640743585911636
+47	0.021266053130589966
+47	0.010671329700881438
+47	0.008548936320975541
+47	0.006336349748628723
+47	0.02259128246770049
+47	-0.014319892964885915
+47	-0.024960579547478306
+47	0.001266270778654226
+47	0.00988477135035927
+47	0.005607103061265296
+47	0.0036848737672454126
+47	0.012444657543190314
+47	0.007305767000350077
+47	0.009759136451262418
+47	0.04203038877711923
+47	0.05099882860135718
+47	-0.02272144038558066
+47	0.007367352152874557
+47	0.017875884761540145
+47	-0.010918895755741098
+47	0.0085396993327341
+47	0.004959149159227681
+47	0.02281930069255213
+47	0.03633184140329675
+47	0.023640383219914116
+47	0.03909491992081263
+47	0.04404497150776097
+47	0.03548410586708947
+47	-0.008568812286909483
+47	0.0016481346797917993
+47	-0.04690361282359261
+47	0.015537672558440775
+47	-0.019556307761841425
+47	-0.00021635629391732173
+47	0.007357161060761339
+47	-0.025451364382417588
+47	-0.015037222592081156
+47	0.009560920532488432
+47	-0.00026994686675148354
+47	0.008465326967892744
+47	0.011646721873643564
+47	0.024238311163927023
+47	-0.0004445532140143243
+47	0.02931025232583118
+47	0.01910492010869162
+47	0.002009463296721461
+47	0.018485098737086068
+47	0.02769975628818946
+47	0.02135185500944068
+47	0.01992128877657728
+47	0.0275144802200931
+47	0.008057743358152443
+47	0.010023172080668347
+47	0.031568517998247385
+47	0.014423999159233267
+47	0.003292911994961514
+47	-0.005697479980157467
+47	0.026318736089403293
+47	0.03174795198245451
+47	0.03336265092660267
+47	-0.030717724680415115
+47	0.014691866853251424
+47	0.03336806998842363
+47	0.040021833213776496
+47	0.0320192256052734
+47	0.023366037328287192
+47	-0.0060027259435676585
+47	0.008065415468812181
+47	0.00431568786514477
+47	0.002923731709164037
+47	0.01318276636955053
+47	0.030860550001095017
+47	0.03968785333654207
+47	0.02778368704453294
+47	0.017330178833225896
+47	0.02952983195859505
+47	0.022906093371814727
+47	0.023638861959096102
+47	0.021464507339300463
+47	0.03738189581107694
+47	0.03274183970415629
+47	0.02389626028223519
+47	0.018386150489253444
+47	0.01897660718425863
+47	0.01558636565381322
+47	0.035110583322236016
+47	0.04418609926159313
+47	0.00921055467085601
+47	-0.00806531364913878
+47	0.014402889517066876
+47	-0.01265301927382776
+47	0.01676206416891033
+47	0.025301677030693238
+47	0.017604097088913407
+47	0.044311213504053724
+47	0.019459850583229805
+47	0.024906766483379635
+47	0.006044109376822505
+47	0.016416746020148264
+47	0.003329541728524936
+47	-0.005983617294470543
+47	0.027607485158399992
+47	0.014717676659866332
+47	0.016887255532213014
+47	-0.023188468841085972
+47	-0.019342520887929662
+47	0.016706085321041966
+47	-0.011693410468421662
+47	0.02727562044052747
+47	-0.004992385695446466
+47	0.028350246111276126
+47	0.0006567548674554453
+47	-0.00801875508875974
+47	-0.02365768971030461
+47	0.019745856922452426
+47	0.04211862405526955
+47	-0.02623212856043643
+47	0.031076349590223287
+47	0.007839740285823148
+47	0.015144770325574479
+47	0.00975436360768431
+47	0.013559653915105782
+47	0.012088671043236745
+47	0.03028224164696037
+47	0.023346066482731895
+47	0.026710034548060133
+47	0.012164597344254863
+47	0.016492768973075198
+47	0.01812041269931428
+47	0.02885324619195448
+47	0.008145761760931161
+47	-0.0011457956521647335
+47	0.006249732442934422
+47	0.02269951046734854
+47	0.019087353526936347
+47	0.028094938353399174
+47	0.002925287635550367
+47	0.006014604608069512
+47	0.026749493010947943
+47	0.004118200645824766
+47	0.016882093591861002
+47	0.01818115648505439
+47	-0.014496132062420744
+47	0.0223760358058163
+47	0.014356878049795284
+47	0.00094330795884165
+47	0.027108082608286014
+47	-0.013330517348451178
+47	0.026202117996199613
+47	0.01248642703280085
+47	0.017012537449148844
+47	0.02161689024155355
+47	0.00841820690582183
+47	0.01842194206196841
+47	0.03723659656124209
+47	-0.002739263993642112
+47	0.009762198174227289
+47	0.01204549547994815
+47	0.027744454691401285
+47	0.024403656686104117
+47	0.055790546899611174
+47	0.046902193140674
+47	0.03446881486436424
+47	0.015945782646803627
+47	-0.009790313369332585
+47	0.005970345128989467
+47	0.009376780965665013
+47	0.00021552680220558233
+47	0.012997569735585628
+47	0.02615162324246855
+47	0.05134242221244494
+47	0.020075021934475402
+47	0.02969821069881856
+47	0.010024823129303004
+47	0.020760171245127353
+47	0.029775395708989103
+47	-0.006628012938592416
+47	-0.009639983087340633
+47	-0.0035129775079733015
+47	-0.012928771659156874
+47	-0.030281220688847952
+47	-0.003222043447619687
+47	0.0160098617840008
+47	0.004371004605116923
+47	-0.021472815533786688
+47	0.030311668104421704
+47	0.013704069452215925
+45	-0.030580770214380156
+45	-0.017604786784364175
+45	-0.008091142066795187
+45	-0.0084647003390559
+45	-0.015943723542356767
+45	-0.016677130015087097
+45	0.0026164449391753416
+45	-0.039626700887393
+45	-0.017990140722851114
+45	-0.036020314467015584
+45	-0.04319822194298296
+45	-0.01971606769138343
+45	-0.02535126889336223
+45	-0.006117987925627684
+45	0.0007626064224963633
+45	0.009414006494492764
+45	-0.0030974333695682173
+45	-0.029329684284099704
+45	-0.04186506250294774
+45	-0.017690228902438265
+45	-0.02330433859565454
+45	-0.019598213914879533
+45	0.007033208976111671
+45	0.0036899594508329704
+45	-0.02069260566853918
+45	-0.01707360318453992
+45	-0.0020568169016973122
+45	-0.006064528248529936
+45	-0.03580315939138722
+45	-0.009505026394126748
+45	-0.031117697823840395
+45	-0.026534670614747253
+45	-0.009079171209737962
+45	-0.017864897932527903
+45	-0.05269963327336094
+45	0.018760105420969484
+45	-0.02289335556150814
+45	0.02029982034955944
+45	-0.02891524715856453
+45	-0.018171514406908715
+45	-0.023864601810054228
+45	-0.003586886978744554
+45	-0.006106494762379694
+45	-0.0006585195750136719
+45	-0.02663159781421511
+45	-0.022674652277381642
+45	0.01293261493493219
+45	-0.02291531249821583
+45	-0.018999668037454183
+45	-0.02401726212990446
+45	-0.017942873109890286
+45	-0.004510559074305257
+45	-0.02274232172028157
+45	-0.0018342375267641257
+45	-0.023248901468816963
+45	-0.036650647675179275
+45	-0.010961150507900228
+45	-0.0018060948431641052
+45	0.002412905350745789
+45	-0.020073311799025446
+45	0.0019741314497282243
+45	0.01974935886969069
+45	0.013125518201013228
+45	-0.02565152643545244
+45	-0.020639340029541136
+45	-0.006342580190949134
+45	-0.01428299366013145
+45	-0.001992399917338736
+45	-0.024608121993586626
+45	-0.021710974238701636
+45	0.007539091431650898
+45	-0.007886192328632899
+45	-0.015921598552289494
+45	0.014054835812250968
+45	-0.019012534706656953
+45	-0.0044139836735902745
+45	-0.002771429330674063
+45	-0.01627696994859767
+45	0.0025000821239331626
+45	-0.032485801589646514
+45	-0.022263647112911383
+45	0.003056172909571808
+45	-0.032431709759300265
+45	-0.015456241635412104
+45	-0.01165758064071697
+45	-0.027796028458165263
+45	0.014518084355564573
+45	-0.035250991054617015
+45	-0.018746222404335565
+45	-0.012156914897054083
+45	-0.029903592691665117
+45	0.0056936203230854
+45	-0.017232912318987173
+45	-0.002234909757158683
+45	0.00762958801420025
+45	-0.00801441752042069
+45	-0.012666759271055754
+45	0.006575334606727869
+45	-0.008754602247256075
+45	0.0057192245701513265
+45	0.011922032696055325
+45	0.0004936327999397788
+45	-0.014908992577986653
+45	0.0017082975009117612
+45	-0.026777820221600118
+45	-0.02750420078543926
+45	0.002942604298708624
+45	0.017869548094518576
+45	-0.020346477860116858
+45	-0.01075670077920856
+45	-0.016574419117412264
+45	-0.01699581165612487
+45	0.02278141193067203
+45	0.021096874703856943
+45	-0.007812312499857354
+45	-0.014228537805349587
+45	-0.0021326716059095648
+45	-0.006805120259425845
+45	0.006992728353270054
+45	0.005584714315434035
+45	-0.0011227982162769173
+45	0.009706917479652567
+45	-0.026779374962228018
+45	-0.03386875040105272
+45	-0.023447198604394193
+45	0.012943848359621162
+45	-0.05967050113047771
+45	-0.003300987768182382
+45	-0.025037808306984967
+45	-0.0018493166006126086
+45	0.0064861718595839776
+45	-0.02002721118075335
+45	-0.02148130830098058
+45	-0.004357940741278021
+45	-0.013934968628417714
+45	-0.02169066970682229
+45	-0.019157441111227445
+45	0.018356553642158314
+45	-0.016738814218430986
+45	0.0014844498575528203
+45	0.0036956288266858355
+45	0.02381910662929149
+45	-0.01493754423246772
+45	-0.03153053482533082
+45	-0.016718419219445873
+45	-0.014845761620495218
+45	-0.017485479212193476
+45	-0.015785974115168105
+45	0.0026087006025441914
+45	0.010179627959675693
+45	-0.01665925595939643
+45	0.024949650773205743
+45	-0.016002822955974
+45	-0.02775224145667779
+45	-0.020002648463314895
+45	-0.03582214790375285
+45	-0.02592725157795455
+45	-0.008323598893351226
+45	0.010907650177939675
+45	-0.01365390936792846
+45	-0.036208489970778655
+45	0.0006829414411529922
+45	-0.004825930076767037
+45	0.0061513679468787
+45	-0.04111695955882555
+45	-0.036631979231629926
+45	-0.04573063706022728
+45	-0.013059721212000405
+45	-0.019521370715284213
+45	-0.03101480561340843
+45	-0.02286619778604608
+45	-0.01074438246405127
+45	-0.009798438938737062
+45	-0.01260306173193704
+45	-0.023480041601930766
+45	-0.0014844301611793974
+45	-0.017810568335220642
+45	-0.013120137406706546
+45	-0.012778127304698687
+45	0.005168423381248151
+45	-0.046043065308384874
+45	-0.04064444268004297
+45	-0.014706299779548637
+45	-0.014788643683341032
+45	-0.0024412779532233158
+45	-0.022799194662055662
+45	-0.016669822921062952
+45	-0.01463055706298586
+45	-0.014270049689499114
+45	0.0005238383584282542
+45	0.017513209581245026
+45	-0.05524490404082234
+45	-0.012882674885393684
+45	-0.017261590851522353
+45	-0.04365878067105465
+45	-0.012582230275943487
+45	-0.026077262897986113
+45	-0.002481112161443104
+45	0.014973309276560655
+45	0.00670279885929848
+45	0.019637581689963934
+45	0.015062860033542316
+45	0.011513234034708516
+45	-0.03574652125321906
+45	-0.03182752046278988
+45	-0.06492080109055721
+45	-0.007450017561159371
+45	-0.0381771374130611
+45	-0.025238486399816535
+45	-0.017534827523044052
+45	-0.04760596100699697
+45	-0.038887643471607454
+45	-0.012456830576971707
+45	-0.027300622755259178
+45	-0.009653998563342545
+45	-0.018511219293463575
+45	-0.0036770919209182518
+45	-0.028166297360628707
+45	0.0014060241639226418
+45	-0.00014986327362369285
+45	-0.01462820515625476
+45	-0.008316849997156638
+45	0.004916681642369502
+45	-0.007836344287747016
+45	-0.0047033817367692
+45	0.004032815381659565
+45	-0.026623379456645026
+45	-0.018024923573722033
+45	0.002731398580201724
+45	-0.00645419774820866
+45	-0.02354972120818247
+45	-0.03371188214034306
+45	-0.0038407643735200937
+45	-0.004042802543041173
+45	0.013154512704151489
+45	-0.04508785658520129
+45	-0.010743152445083273
+45	0.009064633741045833
+45	0.016730162205927667
+45	0.008145156425289608
+45	-0.007552728527517287
+45	-0.026037371821034033
+45	-0.018995982533106172
+45	-0.009509718773925407
+45	-0.022386729384318467
+45	-0.003648649152841503
+45	0.005696610909642221
+45	0.01125618611900548
+45	0.011258671773706989
+45	-0.01404867287295622
+45	-0.0031648326922280646
+45	0.0014053514806103744
+45	-0.007110629207912092
+45	-0.013549662606294631
+45	0.00889633114379596
+45	0.010547273156604458
+45	-0.002449479330006514
+45	-0.01109582215230535
+45	-0.0063857611440954615
+45	-0.011787917935604512
+45	0.005784081850774873
+45	0.028590009861132398
+45	-0.010320145419720737
+45	-0.030907510848996848
+45	-0.012805945017279823
+45	-0.034209644571019146
+45	-0.006802591904194588
+45	-0.002398888888463087
+45	-0.0028837232693333216
+45	0.012925282827430658
+45	-0.004381337020784877
+45	-0.00937539293509756
+45	-0.01829052378480246
+45	-0.016047058166093593
+45	-0.01832013204611872
+45	-0.03382353295030198
+45	0.000573615129195285
+45	-0.014049552652453183
+45	-0.011367600355115625
+45	-0.03679198993921076
+45	-0.05136780480640769
+45	-0.0068623454532668465
+45	-0.03050852516667585
+45	-0.010167114430689832
+45	-0.029359963095586358
+45	-0.005464215700352387
+45	-0.019431994454485273
+45	-0.025998473987745598
+45	-0.04758326468970946
+45	-0.008439261070154466
+45	0.015803543973716572
+45	-0.04571766460381254
+45	0.013705952594544022
+45	-0.02479651438507639
+45	-0.014872089317336941
+45	-0.019656913844624216
+45	-0.016919889429088602
+45	-0.015847721102248715
+45	0.01362129964694095
+45	-0.002501953099945789
+45	0.001046192331649155
+45	-0.011720064343632278
+45	-0.013468404908664095
+45	-0.01531670481865637
+45	0.008895202590485403
+45	-0.008919062100749256
+45	-0.026855416196592576
+45	-0.006553442236892847
+45	-0.003616115695711459
+45	-0.00403620194914151
+45	-0.0011267004647028574
+45	-0.03355939341333051
+45	-0.02478093073693023
+45	0.002448919684323695
+45	-0.012012944241494655
+45	-0.022693340914362366
+45	-0.009983493417797506
+45	-0.03931594365906621
+45	-4.463720903409816e-05
+45	-0.012217129956578613
+45	-0.029643639574394486
+45	0.0010722695994104718
+45	-0.02740293017431277
+45	-0.0009532626011835077
+45	-0.019665015767442843
+45	-0.01458269367953994
+45	-0.012197013501874167
+45	-0.01677642460549075
+45	-0.011933721067329851
+45	0.001467109752011094
+45	-0.032929488632788224
+45	-0.024353848994100112
+45	-0.028689264190047175
+45	0.007585226926861006
+45	0.0017924945800340153
+45	0.013391859534592383
+45	0.021804569670673186
+45	-0.0009374190159504644
+45	-0.009766909518859458
+45	-0.032797416424065085
+45	-0.02568151874274991
+45	-0.011594681998537705
+45	-0.02714142728346569
+45	-0.012534902679106773
+45	-0.008377797919358726
+45	0.03555085744079045
+45	-0.011952078487766037
+45	0.012704839028571656
+45	-0.01725723574612725
+45	-0.005472627275195156
+45	0.010516049871598264
+45	-0.024036129258339232
+45	-0.03708601363271452
+45	-0.03685446027941815
+45	-0.026155365719400976
+45	-0.04382974552432557
+45	-0.022277239935499016
+45	-0.0035359746092438666
+45	-0.024213696623520516
+45	-0.05085495516981274
+45	0.006203441594713314
+45	-0.011938833708452815
+22	-0.01712889798039886
+22	0.005648162973235864
+22	0.019002068136781763
+22	0.015588391768057867
+22	0.011986102582260131
+22	0.007425329437274761
+22	0.022049821393735947
+22	-0.019622695486278964
+22	0.007378211870809032
+22	-0.00495270992511479
+22	-0.011931269209767226
+22	-0.0041819776461457445
+22	-0.0007542106831477995
+22	0.016075592363033336
+22	0.02048653263276704
+22	0.026993778652521283
+22	0.01056066777891965
+22	-0.013639482234344398
+22	-0.022662171950953866
+22	0.0006902711191704288
+22	-0.00991171036042662
+22	0.00045915108234001304
+22	0.02690335520799285
+22	0.011958401028797498
+22	-0.002043881030641669
+22	0.01040332048484821
+22	0.01625722026611104
+22	0.004591498372539053
+22	-0.026354525400348255
+22	0.009177391658889537
+22	-0.004796079605789014
+22	-0.00016490282637289397
+22	0.016006809304891765
+22	0.002645058056025111
+22	-0.028796969395407088
+22	0.04004717301270453
+22	-0.001961978173160156
+22	0.042765866285648414
+22	-0.007209302406976347
+22	0.004520398055040963
+22	-1.657188004786513e-05
+22	0.016812101888384015
+22	0.014818386280755378
+22	0.013090862985111298
+22	-0.004672475760140961
+22	0.003432615251733044
+22	0.040149822221516425
+22	-0.004720443072463462
+22	-0.007780477759078638
+22	-0.01527644963857818
+22	0.009895896686478774
+22	0.013860068942271216
+22	-0.004986009423644527
+22	0.018099679935427587
+22	-0.002887915076323056
+22	-0.019806834972151324
+22	0.01600019947689962
+22	0.02196291476924339
+22	0.01522660437213291
+22	0.006072209829309663
+22	0.021402748289905352
+22	0.026337969363180815
+22	0.02490205922767563
+22	0.0018188576174474188
+22	-0.0022214427939700903
+22	0.007739257169714683
+22	0.006048170680611922
+22	0.016189246979686777
+22	0.004322488482006301
+22	0.0025242240952657396
+22	0.038380067417744544
+22	0.013976429784012513
+22	0.005533230124829785
+22	0.036757312601087756
+22	0.014237606877124127
+22	0.023835417660289727
+22	0.004097891105631216
+22	0.00975048486620543
+22	0.02481911443047733
+22	-0.007949200168408367
+22	0.007610768662538762
+22	0.02071282778064728
+22	-0.015459351463520366
+22	0.00912041432029857
+22	0.0034433669628861573
+22	-0.030050319672912006
+22	0.014229406744859292
+22	-0.02240742663726685
+22	0.004974299643423143
+22	0.014517897366799301
+22	0.0006708550858950064
+22	0.01938193906266463
+22	0.0013340303271285935
+22	0.012562861913476905
+22	0.028583981855102785
+22	0.018636217026678312
+22	0.0009529306329648024
+22	0.02253655804706371
+22	0.013752558596601345
+22	0.035456330698718896
+22	0.031391397765536344
+22	0.017596619976102422
+22	-0.005361616380193385
+22	0.013562341388720485
+22	0.0017209615059230157
+22	-0.01993129740083081
+22	0.026188242807137628
+22	0.035781514638394865
+22	0.009979337136216161
+22	0.017056201137880686
+22	0.0018944561976552865
+22	0.0038067890172329374
+22	0.044712790508693395
+22	0.04733419943337335
+22	0.018256281302962876
+22	0.012713352411410306
+22	0.014950643677078327
+22	0.012569980878483022
+22	0.022354414311039763
+22	0.027296397287390712
+22	0.021262309446871935
+22	0.020880314561365364
+22	-0.008850410496752455
+22	-0.010189019933181104
+22	-0.00959037763061475
+22	0.03573529488839546
+22	-0.02801431129068847
+22	0.015406535541684733
+22	-0.014931474153829345
+22	0.01573455158323458
+22	0.018243698115580534
+22	-0.008261133807166528
+22	-0.0033035590823678033
+22	0.019341724999956834
+22	0.0019111813434466453
+22	-0.0036636229926603377
+22	0.0008243767860806428
+22	0.04174219794632632
+22	0.001997757701675474
+22	0.02052894905654927
+22	0.02414685927186974
+22	0.031283603031756715
+22	-0.002424100894683712
+22	-0.015125589793237052
+22	0.0007421095385810574
+22	0.007021446452098671
+22	0.0026888874340275084
+22	0.01724617463843193
+22	0.026277350235349398
+22	0.013790373212558993
+22	0.0009883539409072082
+22	0.037455525964563474
+22	0.0038441675456407755
+22	-0.013683231432880437
+22	0.003738979668299599
+22	-0.00453066800087284
+22	0.007485945394572476
+22	0.010361437137874059
+22	0.028218246030084968
+22	0.007867899909923702
+22	-0.011011399048653224
+22	0.01075540933565212
+22	0.014011581738145628
+22	0.031125538775682336
+22	-0.01859758421001634
+22	-0.01401309544532862
+22	-0.018311838517201622
+22	0.00971959342117395
+22	-0.009519666426690478
+22	-0.004842265789740521
+22	-0.006273352890894837
+22	0.005433286357543745
+22	0.008960045272685204
+22	-0.0015151191225032737
+22	0.003422730747051551
+22	0.018175036447625376
+22	0.004633439625114748
+22	0.0021748868403622104
+22	0.00920571099417243
+22	0.005087213117946113
+22	-0.022981052902806814
+22	-0.027962052413218526
+22	0.003912779405571626
+22	0.001820956684588673
+22	0.006677689422354368
+22	-0.0020612039508872116
+22	0.00730228485745158
+22	0.007905704878822419
+22	0.008247659477312685
+22	0.02981255775944063
+22	0.04673068933875247
+22	-0.029739478623930542
+22	0.003952273431206712
+22	0.008812768218804331
+22	-0.01872514209345986
+22	0.008526071556148289
+22	-0.004216733747197985
+22	0.018554109858215047
+22	0.03222717386539363
+22	0.021217477934266125
+22	0.031182374707716985
+22	0.03717455852475197
+22	0.03188564363694468
+22	-0.010094529025805005
+22	-0.0064441027781372935
+22	-0.05057260282793021
+22	0.011330455221037046
+22	-0.016733222871992914
+22	-0.0053466628998895425
+22	0.011116235743968838
+22	-0.029643651986191132
+22	-0.019419694751852568
+22	0.0052861859803455995
+22	-0.003773924190962149
+22	0.011680142960513399
+22	0.003396509382552541
+22	0.020126294840096894
+22	-0.008270669976080088
+22	0.02534997502551895
+22	0.017225866237890533
+22	0.002202800553515311
+22	0.020108321873934527
+22	0.02869936807384381
+22	0.019727067856909877
+22	0.01094011211437895
+22	0.026618116047327237
+22	0.002583253149880364
+22	0.01017155720593381
+22	0.02232600175070702
+22	0.0032849443780420093
+22	-0.004062972286839456
+22	-0.013757143048749223
+22	0.016069935024347726
+22	0.023009549002692944
+22	0.024048978503669893
+22	-0.026576561628072273
+22	0.012692872302178602
+22	0.029695511315185597
+22	0.027192081284194286
+22	0.027834258182600134
+22	0.015632918601963825
+22	-0.00538183734868277
+22	-0.005312754768160291
+22	0.006331507134464322
+22	-0.0014309145979717272
+22	0.01561224297430745
+22	0.030917640766526484
+22	0.031074710337358636
+22	0.015109200001622039
+22	0.009083710729285955
+22	0.024351773117118787
+22	0.021684761463646136
+22	0.020546194814792824
+22	0.011539696718607342
+22	0.03242417174667592
+22	0.03126249323722687
+22	0.01255214812529993
+22	0.004045378604117234
+22	0.0071779204586831236
+22	0.007740119068088018
+22	0.032671163418940156
+22	0.040334281620186416
+22	0.003619898688103555
+22	-0.013906666997831522
+22	0.00883254888232154
+22	-0.017764528455940492
+22	0.011752229969494824
+22	0.019823997655224013
+22	0.010666898225877469
+22	0.03471966303851933
+22	0.019624042473713167
+22	0.021547883918258723
+22	-2.7203921210893172e-05
+22	0.015785729939456643
+22	0.002793433753167282
+22	-0.006116520138374743
+22	0.029796867084736806
+22	0.016336617514747135
+22	0.012475996336116782
+22	-0.02480322746006889
+22	-0.03229584176954019
+22	0.010013547910237921
+22	-0.016514655877775702
+22	0.013700440301411852
+22	-0.007325559390530336
+22	0.022624363284892476
+22	-0.00034840564975350825
+22	-0.005104959079737176
+22	-0.03102875437133804
+22	0.004640924525340481
+22	0.03395001157718419
+22	-0.03498780277975242
+22	0.022657611687607097
+22	-0.0010610697612470734
+22	0.007669311273048439
+22	0.0021504829017124174
+22	0.007856598023002509
+22	0.0068276554363025654
+22	0.026409015536187373
+22	0.018748971774781024
+22	0.018908125581367504
+22	0.001605578003763427
+22	0.005175584392977491
+22	0.011694166967324341
+22	0.015586294244613904
+22	0.005476964928669061
+22	-0.004105432861083141
+22	0.008714756797987411
+22	0.01928312013608158
+22	0.014525080966164327
+22	0.024923443197937174
+22	-0.001758068078837456
+22	0.0007645725522232199
+22	0.0231462753801197
+22	0.006039540713926334
+22	0.00774122982828512
+22	0.01060634095165277
+22	-0.014469567177229
+22	0.01762087426096011
+22	0.00789089778684448
+22	-0.0024517933292346836
+22	0.01361233213084273
+22	-0.012916774467417028
+22	0.023180615610344145
+22	-0.0015132973030411525
+22	0.013491503945055742
+22	0.009550099253807828
+22	8.191317889233096e-05
+22	0.015590085803478019
+22	0.02919008410954661
+22	-0.01548060347396902
+22	-5.6860763718783155e-05
+22	-0.003385172709382624
+22	0.026373214073328925
+22	0.01480261931957001
+22	0.042275557706021566
+22	0.04370381464452526
+22	0.03040797723613026
+22	0.01278443703203262
+22	-0.010529615925033394
+22	0.0029285588458149553
+22	-0.0018669568506541156
+22	-0.005131405468334044
+22	0.007497751284189989
+22	0.01972828791797555
+22	0.05411397568636499
+22	0.013524203514224765
+22	0.02928599863666313
+22	0.005703849213079208
+22	0.016279788841765765
+22	0.030651135713375167
+22	-0.014164461304704633
+22	-0.017950966194758958
+22	-0.007823233980636831
+22	-0.012740649626250242
+22	-0.030638294929047377
+22	-0.0037427984192062416
+22	0.018631457252588426
+22	-0.011070839438407875
+22	-0.029521241022691012
+22	0.018020468719818845
+22	0.004316175045595927
+41	-0.017400927854820187
+41	0.0013849085172555657
+41	0.01642647389588563
+41	0.013388158787020895
+41	0.006820194819745906
+41	0.002924038975670623
+41	0.024667667436508847
+41	-0.01850854049273807
+41	0.007692148688630019
+41	-0.01255346823323629
+41	-0.010714790236318068
+41	-0.005417243222668699
+41	-0.007238856556188868
+41	0.012989117483256138
+41	0.020544543325674895
+41	0.026074382418072257
+41	0.02161252293494307
+41	-0.018099101618120575
+41	-0.016492049995959712
+41	-0.003730409398646419
+41	-0.013192651716277084
+41	-0.005086921326312914
+41	0.026666820434538867
+41	0.009808713119710865
+41	-0.0016107844796948293
+41	0.007551368887378344
+41	0.017292112650496957
+41	0.003402079412472928
+41	-0.025745456794866076
+41	0.005766227641711544
+41	-0.0034888162578389737
+41	0.0005591158350829547
+41	0.017941328027874272
+41	-0.0006853294952157219
+41	-0.02487617545136751
+41	0.03711021695644142
+41	-0.0023285576710100624
+41	0.04146703606343277
+41	-0.01354949925085906
+41	0.0026409959717274205
+41	-0.004508585193383925
+41	0.01370093519472029
+41	0.009276494626426506
+41	0.010354413090704593
+41	-0.0008663579641803208
+41	-0.000262700120261469
+41	0.03639609018647128
+41	-0.0049732826112139335
+41	-0.010296862536779456
+41	-0.006562838524549163
+41	0.0017784884723294435
+41	0.01900809917853566
+41	-0.01249739269201265
+41	0.01678770968950495
+41	-0.008139842374023263
+41	-0.02376103336194312
+41	0.016040291335038082
+41	0.022307359391759412
+41	0.010469940945077482
+41	0.0019675038671802436
+41	0.021903349935775432
+41	0.02914352307060587
+41	0.022171111251722452
+41	9.778143595287581e-05
+41	-0.0023235214991565016
+41	0.006257523753335008
+41	0.005222157264746717
+41	0.01617353661507729
+41	0.004165421732091498
+41	0.002533863035220445
+41	0.03695899664828677
+41	0.011603315750951084
+41	0.003856335345252056
+41	0.034053445304025584
+41	0.004063778614228047
+41	0.019365076408749186
+41	0.015353819776145123
+41	0.004234833494928802
+41	0.017439602878154624
+41	-0.005099085859943718
+41	0.009088255242399841
+41	0.023493672369561017
+41	-0.006088457602233338
+41	0.004836375481603679
+41	-0.0027879503818233403
+41	-0.01835935173959261
+41	0.014636768962166933
+41	-0.020214975732040303
+41	0.008219416415262623
+41	0.01187499489350976
+41	-0.0038639574102479327
+41	0.011995110944223479
+41	0.0019289215448254466
+41	0.013025357025229662
+41	0.024586105762120777
+41	0.016383209975201762
+41	-0.002213697022702522
+41	0.01811584091649889
+41	0.009278169348993105
+41	0.03489215191845089
+41	0.026207965193623506
+41	0.018610694260497204
+41	-0.003192267960838773
+41	0.017045784070084127
+41	0.0003146902383261233
+41	-0.021080278667556445
+41	0.027257239529282124
+41	0.029021290316098205
+41	0.00994082413291933
+41	0.01718520703130185
+41	0.004097114002254381
+41	-0.0019481126748207153
+41	0.04608934748310612
+41	0.049309965687627216
+41	0.015581237117842742
+41	0.0012162246193193006
+41	0.016543221974346097
+41	0.012341174362225602
+41	0.017371158278426765
+41	0.02744088481060454
+41	0.012659655303623134
+41	0.023959947178695012
+41	-0.00529786537705212
+41	-0.012051694853820509
+41	-0.006801032760130025
+41	0.036155237467909516
+41	-0.029073162371595997
+41	0.016771177642892356
+41	-0.012928469297210001
+41	0.01089171453455479
+41	0.016648145859871333
+41	-0.008689171310739086
+41	-0.010914177169152696
+41	0.019351236816970593
+41	0.0008439212042898395
+41	-0.0019528477550748526
+41	-0.0008720351891848677
+41	0.0430372374861276
+41	0.0008154643500025079
+41	0.02423048974043069
+41	0.024711584372441874
+41	0.03450002293043066
+41	0.001497522160125823
+41	-0.012642186928909668
+41	-0.003564624245216677
+41	0.00666067293710977
+41	-0.0042691155124331154
+41	0.016087691695390795
+41	0.025814911355739333
+41	0.015931198365639002
+41	0.00461272150416444
+41	0.03569780363120933
+41	0.008934138482145536
+41	-0.00834728546187253
+41	0.004070229710735527
+41	-0.009049173070032725
+41	0.0036716546880383003
+41	0.010683150755448248
+41	0.024507150432818106
+41	0.005708888726802425
+41	-0.009321949402089816
+41	0.009814422229660802
+41	0.012861397347524842
+41	0.029813607159316278
+41	-0.018399090350172315
+41	-0.01922306619271363
+41	-0.022760488431845975
+41	0.005596062759357972
+41	-0.010964058860856425
+41	-0.0010781251202280526
+41	-0.002601237745265576
+41	0.00677802125288088
+41	0.008411913261279455
+41	-0.004880548329914706
+41	0.0035190142244143235
+41	0.012279687834476206
+41	0.006291403588696116
+41	-0.0005414270442411417
+41	0.0010164247939555774
+41	0.006691581996343816
+41	-0.026246092515109894
+41	-0.03315173592843163
+41	0.003645209672612301
+41	0.00025160994163593434
+41	0.011207800822862504
+41	-0.0012538346969572652
+41	0.004283477523567305
+41	0.011635373615565015
+41	0.005406896133158519
+41	0.030248786820203526
+41	0.046125076488394846
+41	-0.02873414345602797
+41	0.006226824961865369
+41	0.013952206478601
+41	-0.023151453973290374
+41	0.010127938448667972
+41	-0.009678638618151958
+41	0.014878948300965329
+41	0.029432249465505097
+41	0.022369007605924505
+41	0.026746912756688477
+41	0.0386578262820858
+41	0.027963769028500337
+41	-0.014143618857646574
+41	-0.005632140992723263
+41	-0.04723659950990612
+41	0.014974399333845576
+41	-0.01765148519494764
+41	-0.006925331748100511
+41	0.008647402679183337
+41	-0.027159053250406667
+41	-0.022103691489539053
+41	0.004973797392653459
+41	-0.010757045517833432
+41	0.008043596441156188
+41	0.0009119358518904679
+41	0.022628600189864102
+41	-0.012119110804261476
+41	0.03057253374631032
+41	0.020932795972913112
+41	0.002017492766056047
+41	0.022655486819487407
+41	0.0330578034679431
+41	0.020648464856820346
+41	0.009230296943174258
+41	0.027173464464627095
+41	0.004875962108414191
+41	0.005519194525180191
+41	0.021983025917895284
+41	0.003426202131109145
+41	-0.0015776017369664617
+41	-0.014720966911522318
+41	0.014031243151337911
+41	0.023079642524176262
+41	0.019940125011669592
+41	-0.03384142163308904
+41	0.011920170084943149
+41	0.02880302439041423
+41	0.025710465308091304
+41	0.028480942545988097
+41	0.00929609653708498
+41	-0.007654645911160428
+41	-0.0012650298415711964
+41	0.005925499383076118
+41	-0.0005177341756056205
+41	0.01980617895749193
+41	0.02696339005260281
+41	0.03379129041593187
+41	0.017325279061985693
+41	0.004355145859361761
+41	0.019896665135641763
+41	0.020235397698639444
+41	0.014860351149491538
+41	0.011603825903792086
+41	0.02628293258722766
+41	0.028808177858263603
+41	0.015262718344787499
+41	0.012913418844246509
+41	0.009758096822126977
+41	0.008673606806783703
+41	0.03165555459113156
+41	0.04333338111085191
+41	0.0036840252889220482
+41	-0.013334295296959054
+41	0.006401292637759331
+41	-0.01262775391170654
+41	0.013565420053705018
+41	0.016698111085558964
+41	0.013366794690354204
+41	0.03158561491158319
+41	0.01507792088804238
+41	0.017852352873468633
+41	-0.00420880081970892
+41	0.012626851205257089
+41	0.007918305580280616
+41	-0.0031402077640410456
+41	0.030493012111962675
+41	0.017918980813109876
+41	0.011560073574239629
+41	-0.028077838971049356
+41	-0.03680312010257818
+41	0.010082360333490106
+41	-0.016381406176997005
+41	0.011286407554973206
+41	-0.008870493445915211
+41	0.01650446011556042
+41	-0.004501194998249253
+41	-0.009873767917699797
+41	-0.03661488261425564
+41	0.003581067428009141
+41	0.02930456620484328
+41	-0.03281928217738684
+41	0.025162297767817938
+41	-0.0005740986316768506
+41	0.011440939065996929
+41	0.005941300164528436
+41	0.010379523433139094
+41	0.007163210015705352
+41	0.026649421426100675
+41	0.022737446477642156
+41	0.019456340218641708
+41	0.0023149452009341293
+41	0.001623556813234354
+41	0.007080204058491567
+41	0.013904599729615776
+41	0.0008984868537652819
+41	-0.005491574722860141
+41	0.011185332498912069
+41	0.01564818686545545
+41	0.016999262546869967
+41	0.022832552879733202
+41	0.003414672464638272
+41	-0.0011933311656786075
+41	0.020951893639635927
+41	0.007814306725114005
+41	0.005601512711337981
+41	0.005861540737430341
+41	-0.00947227972827876
+41	0.02317611202196338
+41	0.009074042826206018
+41	-0.0013376284583929358
+41	0.01832496522301199
+41	-0.012973368730470664
+41	0.015004822736925848
+41	-0.0026416016854697508
+41	0.012496563251474026
+41	0.008716299460476442
+41	0.0033500564993599884
+41	0.012677371908911557
+41	0.032430488837058194
+41	-0.01205517408867182
+41	-0.0016589200166341992
+41	-0.0077378640710206075
+41	0.02851404826309936
+41	0.013436390126051407
+41	0.037648642653673535
+41	0.04749342399893948
+41	0.025575964843576025
+41	0.011137580500603048
+41	-0.011623384109139745
+41	-0.0011926616010772978
+41	0.0004801764331590482
+41	-0.0001056200634237826
+41	0.005729931806943546
+41	0.020274046390617594
+41	0.05909898407142453
+41	0.01121608678163718
+41	0.025694234546978514
+41	0.0020878187083711087
+41	0.01641485677533808
+41	0.02708353976232397
+41	-0.006274301007263827
+41	-0.01987939388507442
+41	-0.005955360080211114
+41	-0.015155426128055809
+41	-0.03549780645740285
+41	-0.013782508678338924
+41	0.013455279326188643
+41	-0.01609289388157192
+41	-0.03321557279422233
+41	0.013218012294395077
+41	0.0053333451783566434
+48	-0.029682771412228574
+48	-0.009196439323437843
+48	0.0033085045108092615
+48	0.005144178750031738
+48	-0.004753804211523951
+48	-0.010885268990694114
+48	0.015307440294231709
+48	-0.029216901969086967
+48	-0.00533076936773493
+48	-0.026367916855606535
+48	-0.021471064146710996
+48	-0.01433846005140182
+48	-0.013733382245478001
+48	0.0014036385329421353
+48	0.003820282957001677
+48	0.013052892871136382
+48	0.00610409193777009
+48	-0.028916333998177047
+48	-0.027272869317388305
+48	-0.008798338945639554
+48	-0.017995832608610943
+48	-0.015399884389789053
+48	0.01867812819503063
+48	-0.006484298041080141
+48	-0.01996739021892154
+48	-0.007307422447954148
+48	0.004904155128581123
+48	-0.010613332925585852
+48	-0.0317538918922171
+48	-0.004070661186811128
+48	-0.01743099982075509
+48	-0.01299418858646541
+48	0.0004922430739387659
+48	-0.011404607468334375
+48	-0.04300252098580688
+48	0.02531515982314933
+48	-0.01776311224341511
+48	0.031210134166375685
+48	-0.02209336053793654
+48	-0.011717702088950482
+48	-0.016652799527619385
+48	0.0028957619439779533
+48	-0.005501843123537475
+48	-0.000500893799049043
+48	-0.01667234588516805
+48	-0.011377918686674544
+48	0.025899083125581868
+48	-0.019851615480935066
+48	-0.015441159184104552
+48	-0.02024897731545676
+48	-0.014137047721757199
+48	0.004173817351473842
+48	-0.015844127466749878
+48	0.006478969925447924
+48	-0.022779712333779262
+48	-0.03333351604097695
+48	-0.00332243637877141
+48	0.00913111521096404
+48	0.006244487171045793
+48	-0.008387948418694434
+48	0.008814847685194452
+48	0.01812836102983159
+48	0.013377868779570113
+48	-0.014894495707006003
+48	-0.006884426913777448
+48	0.0030311285791050253
+48	-0.008345164640415771
+48	0.0015232485563980342
+48	-0.008274169628412119
+48	-0.01270831078742534
+48	0.02151327584074779
+48	-0.004476828158441035
+48	-0.013970349372497602
+48	0.023269707073111517
+48	0.0011676059230302737
+48	0.009173980758069982
+48	-0.008063975490414708
+48	-0.006705661457695076
+48	0.006183604175376633
+48	-0.021093118033669287
+48	-0.009620874375198865
+48	0.010726443941413564
+48	-0.02315278294034772
+48	-0.009965046400969206
+48	-0.011589004069363695
+48	-0.04187615101520788
+48	0.003141877396734785
+48	-0.035858545329846774
+48	-0.00827471811410598
+48	0.001490658316453653
+48	-0.02273122619311775
+48	-0.00025588732804338266
+48	-0.01466940556828175
+48	0.006789930159425953
+48	0.015277516106273233
+48	0.004388379412294661
+48	-0.016306363226884755
+48	0.005581977369379181
+48	-0.00350114002549869
+48	0.020737535998303712
+48	0.01616537302319649
+48	0.0015337234311863861
+48	-0.01963485049762596
+48	0.0026511187235681677
+48	-0.013403306600807
+48	-0.028338974916306367
+48	0.011968759182535475
+48	0.029816737834007758
+48	-0.004225038843861024
+48	-0.0021004141572321666
+48	-0.014267498640809602
+48	-0.008082049747440655
+48	0.026988468498991048
+48	0.030514420513869184
+48	0.006350706009981914
+48	-0.008344513197117261
+48	-0.001555028303150396
+48	0.00305360363162126
+48	-0.00033428080954463473
+48	0.014131831617088923
+48	0.00580223055101502
+48	0.007503842475301546
+48	-0.022534214189837445
+48	-0.02709474202422878
+48	-0.02762135887689868
+48	0.025268086474286713
+48	-0.045088650652659226
+48	0.0031625106185331495
+48	-0.028201513200970002
+48	-0.00035798896720693835
+48	0.010500020754335268
+48	-0.018423213794991938
+48	-0.02632110049057349
+48	0.004653454735120723
+48	-0.011450266544279462
+48	-0.007428138671395304
+48	-0.009361690985315004
+48	0.022934570778353952
+48	-0.012877916230068148
+48	0.006439555210022992
+48	0.007034919289716389
+48	0.014888642542098122
+48	-0.0030039558533859353
+48	-0.023569714474604826
+48	-0.010944692237299943
+48	-0.0046188520896950705
+48	-0.007418686400555847
+48	0.007432328716438783
+48	0.012204844307989552
+48	0.012313971611727925
+48	-0.0008833895333940653
+48	0.029376073547592123
+48	-0.015605289170257039
+48	-0.026169735789115547
+48	-0.008266213198605364
+48	-0.017024450690976533
+48	-0.005892010967626163
+48	-0.0005975762385062519
+48	0.013371504821613214
+48	-0.011843579886149412
+48	-0.01919926513930553
+48	0.0021841472321231935
+48	-0.003416068907063557
+48	0.023136186953820942
+48	-0.03461696577383383
+48	-0.029435774424141185
+48	-0.034159617603781736
+48	-0.00998245394358249
+48	-0.021272118927201593
+48	-0.01841406216648617
+48	-0.01883734444081039
+48	-0.007564684754836893
+48	-0.004902355459989407
+48	-0.013295003919854128
+48	-0.01282048404558374
+48	0.0017145497730688233
+48	-0.011140236434054096
+48	-0.004704679347112671
+48	-0.012565334759759655
+48	-0.0034682861337429005
+48	-0.03656996345882061
+48	-0.04576361173031977
+48	-0.006054264846219528
+48	-0.014376199459903625
+48	-0.015389685031854313
+48	-0.010611125609796693
+48	-0.009645663578579771
+48	0.0005571279665637847
+48	-0.012499411190437544
+48	0.01746191528365569
+48	0.030721561834078506
+48	-0.04582241900705668
+48	-0.0026184205899636077
+48	0.0024802270616521922
+48	-0.03162554290689206
+48	-0.006173805112879319
+48	-0.02162662805958057
+48	-0.001508477029221147
+48	0.011757712835726061
+48	0.01038294600773016
+48	0.015669938350037927
+48	0.022354325736095092
+48	0.013151408915748699
+48	-0.025426627368793312
+48	-0.019583889646393942
+48	-0.064444380385118
+48	0.0004300938673760511
+48	-0.03260765421920622
+48	-0.024122391994988092
+48	-0.0001620105199105536
+48	-0.04268014295277715
+48	-0.03572642186874935
+48	-0.006792165228521173
+48	-0.021386305696439848
+48	-0.0024253281406190824
+48	-0.011668027028200568
+48	0.0067017736522647225
+48	-0.024748030461709047
+48	0.009704622219576775
+48	0.003458309619559909
+48	-0.008091884382192388
+48	0.005666587398676118
+48	0.01749091127903671
+48	0.006682937065060972
+48	-0.0020429195508062568
+48	0.009977300218782034
+48	-0.012878738934164012
+48	-0.0015464102950910738
+48	0.00925121444696113
+48	-0.01112347132764117
+48	-0.01522255879262062
+48	-0.019635666595048732
+48	0.0043367897300558775
+48	0.014090073155590379
+48	0.0021467948934741888
+48	-0.05012806498510585
+48	-0.00375214325649518
+48	0.018401189018173055
+48	0.017772441318561313
+48	0.02741612735326409
+48	0.0006229201959502093
+48	-0.0188086939374746
+48	-0.01650276219773775
+48	-0.005396474675936137
+48	-0.013836764934339559
+48	-0.0008919012277511467
+48	0.012366844066765014
+48	0.01721775622051367
+48	0.008017773235081854
+48	-0.013542396762282772
+48	0.0017136066054939231
+48	0.005550781987015216
+48	0.005613506410462674
+48	-0.0013457036693898376
+48	0.019854309009989735
+48	0.02096334565965434
+48	0.00909277433316138
+48	-0.0009251870378009338
+48	-0.00935985424263134
+48	0.0005645303934958978
+48	0.02610993259652967
+48	0.033760756239783245
+48	-0.002128132271242957
+48	-0.025329669349467884
+48	-0.003706888741036551
+48	-0.021652229407249084
+48	0.0016167376764956336
+48	0.010390092592277012
+48	-0.005111601716230957
+48	0.02455160546233812
+48	0.007498928395011758
+48	0.010832294419643005
+48	-0.01291079927694978
+48	0.0019099928564425405
+48	-0.009276551557233283
+48	-0.024296561805445555
+48	0.01727629068211077
+48	0.0022335229875494423
+48	-4.8785004131162536e-05
+48	-0.03642490381057775
+48	-0.042530310386715973
+48	-0.0039984735949732
+48	-0.019711805048408245
+48	-0.00423778835074619
+48	-0.021730004702152115
+48	-0.0011883944130337092
+48	-0.021469090560645852
+48	-0.021572408886217066
+48	-0.05337510950648101
+48	-0.008129103083692019
+48	0.030265021229948723
+48	-0.04861453415889515
+48	0.012279274063769663
+48	-0.011035788490831932
+48	0.00047128595620004644
+48	-0.004286815136626312
+48	-0.005939313492129834
+48	-0.002576820646290294
+48	0.012673558344104776
+48	0.0016133311617967919
+48	0.006343217703201367
+48	-0.009433225286389705
+48	-0.008511278147591561
+48	-0.006115246726558941
+48	0.0017608065041336517
+48	-0.011368044152806137
+48	-0.018958985238563642
+48	-0.004716572153728242
+48	0.003042717143084589
+48	0.004686923926748811
+48	0.006004152088106734
+48	-0.010171887890466294
+48	-0.013187425677588986
+48	0.008325283854082845
+48	-0.0027986141962121147
+48	-0.002075470051766622
+48	-0.004758624438112786
+48	-0.026062938535480557
+48	0.0006458020706701854
+48	0.00571584348249018
+48	-0.013810656742354108
+48	0.00604052286483657
+48	-0.02489050564945438
+48	0.010811376728583922
+48	-0.00825078408369757
+48	2.7404857985889963e-05
+48	-0.001789393979906988
+48	-0.009084555836898621
+48	0.006298216867850032
+48	0.02092335946686879
+48	-0.024198297556570506
+48	-0.0109695451408793
+48	-0.020408363313219238
+48	0.022518300327033676
+48	0.0014854281154190632
+48	0.03214584411738076
+48	0.029126987075547874
+48	0.019045570859518912
+48	-0.0042118535245777265
+48	-0.025192841737247212
+48	-0.015446702564887727
+48	-0.010310574670679784
+48	-0.01865058797402318
+48	-0.0020129083887012633
+48	0.0077688208981256425
+48	0.04003062584503013
+48	-7.319580694297036e-05
+48	0.009092994660729695
+48	-0.010173509540994136
+48	0.0014253026383680238
+48	0.009742006099074827
+48	-0.024580479947912758
+48	-0.030471508894308413
+48	-0.01787468479820524
+48	-0.02546094686442267
+48	-0.04220304470714251
+48	-0.025230532431268524
+48	0.004865123266576709
+48	-0.025594597578004735
+48	-0.046021629277276835
+48	0.009522620020343021
+48	0.002755144417390128
+37	-0.021700686301856717
+37	0.0008835651025588507
+37	0.012201069079247345
+37	0.011169990393373207
+37	0.004356785087924445
+37	0.004699532017976163
+37	0.023311596664309833
+37	-0.019135148552567448
+37	0.007688816827410001
+37	-0.011975717438036146
+37	-0.007148092803209704
+37	-0.011484765168506699
+37	-0.008070130912716331
+37	0.020186170935780068
+37	0.009895799602985597
+37	0.016928515877098645
+37	0.005779209953111624
+37	-0.01512480387403007
+37	-0.017698571365125305
+37	-0.004034049356503556
+37	-0.010593932266637913
+37	0.0004402085440285366
+37	0.028304359347504773
+37	0.006097834484142673
+37	-0.014828086004466843
+37	0.005385441297050172
+37	0.013148785068426965
+37	-0.0013266795708449268
+37	-0.027441883314599323
+37	0.0039445461630530695
+37	-0.004788293885898388
+37	-0.003287586772333845
+37	0.01287504106522023
+37	-0.005456281435383933
+37	-0.029437010172244437
+37	0.03199719717034888
+37	-0.012877371909213115
+37	0.0440580297690752
+37	-0.012435902051078222
+37	0.0026612777015629814
+37	-0.007418521041504961
+37	0.006559138303626689
+37	0.0069416802381464075
+37	0.005651950583720711
+37	-0.007549024657849789
+37	0.00034353951890655164
+37	0.026421279604167538
+37	-0.01238308761789853
+37	-0.007880838688101204
+37	-0.022714685386250013
+37	-0.002294684833597693
+37	0.011052940826455216
+37	-0.012661543222992337
+37	0.009859075082280414
+37	-0.016415996703281185
+37	-0.02646288615462853
+37	0.007890729827912807
+37	0.016698550306808526
+37	0.011168780386028592
+37	0.0017985897100691196
+37	0.018307162628713326
+37	0.027450114866982622
+37	0.023068890496493417
+37	-0.0063767402889814894
+37	2.7400857666766792e-05
+37	0.006400560582862039
+37	0.0016313776607366917
+37	0.011251172285839528
+37	-0.0007325088959353013
+37	0.0004451936590303819
+37	0.029255695231868453
+37	0.009560284717689068
+37	-0.0005341798920688326
+37	0.029099372687902855
+37	0.0069250415170409255
+37	0.01657955223204198
+37	-0.006098616561763497
+37	0.005981247076831876
+37	0.006625053457185604
+37	-0.015727681377837786
+37	-0.0016279642760843299
+37	0.016126572599155283
+37	-0.015018030950483596
+37	-0.0021626388603661626
+37	0.006199700783448412
+37	-0.03592889416333034
+37	0.0026271512314267917
+37	-0.032659241767693095
+37	0.0008135719682914339
+37	0.0058719577078112884
+37	-0.011329587275637062
+37	0.00516551302529517
+37	-0.0051678484798461785
+37	0.006311026018810991
+37	0.02746122696301188
+37	0.01603980264090008
+37	-0.007242127180875904
+37	0.014854110256063202
+37	0.010744876519857166
+37	0.025733164571888966
+37	0.02529029617873426
+37	0.007773434587926667
+37	-0.010470629729433772
+37	0.006169049932947859
+37	-0.009555403394370469
+37	-0.02356101858272062
+37	0.017387239803372073
+37	0.026635326693908407
+37	0.002853511850602695
+37	0.004937322033140289
+37	-0.007148857339642307
+37	-0.00653000909720542
+37	0.032875890424332255
+37	0.040015167339665834
+37	0.015312214353243609
+37	0.005131676410965817
+37	0.010363515569904235
+37	0.011635947713517968
+37	0.00425537832982613
+37	0.017710824078952348
+37	0.011662842835889696
+37	0.018609998182865628
+37	-0.02465045788649805
+37	-0.023827557913572422
+37	-0.020246903530581676
+37	0.023392501350209205
+37	-0.03451880044022001
+37	0.00785274535792083
+37	-0.025607255363865728
+37	0.006852333860083275
+37	0.00523330888469242
+37	-0.011379951432118842
+37	-0.008269487880583756
+37	0.013670778875142935
+37	-0.005440513318309347
+37	-0.003996449059389636
+37	-0.0023953538123629645
+37	0.029978782301921553
+37	-0.0025357615080578975
+37	0.0057366709500664345
+37	0.014493184434614384
+37	0.025644001446830187
+37	-0.0010146640593231978
+37	-0.017662399886729113
+37	-0.00024135258636929341
+37	0.004109282578277712
+37	-0.004507293943109187
+37	0.013313638740808672
+37	0.023257819936229527
+37	0.015623372766793122
+37	0.002106958416381562
+37	0.035111960372440194
+37	-0.0037917308963887853
+37	-0.018409946740209383
+37	-0.00036951891648679633
+37	-0.01934008539506688
+37	-0.0018225553427186497
+37	0.00502485097055767
+37	0.023620340273969507
+37	-0.006726896260713557
+37	-0.01580181925586298
+37	0.0027096978711802265
+37	0.0007710055176764712
+37	0.03187727355139309
+37	-0.02555478249581823
+37	-0.020898930481293664
+37	-0.02307785375243224
+37	-0.0014496586334630628
+37	-0.010426051504486765
+37	-0.007976221206555818
+37	-0.011733869246490293
+37	0.0065379238553412
+37	0.004819422551670888
+37	-0.012843570699088402
+37	-0.0027798566123017447
+37	0.0066779678300325695
+37	-0.006657361532030288
+37	0.00037908577544952906
+37	3.77401757670114e-05
+37	0.0019151178783696162
+37	-0.02646738716526197
+37	-0.03672796705869714
+37	0.0024021689048302074
+37	-0.0013545909085882807
+37	0.0049118651376614895
+37	0.0006880297676924974
+37	0.0057571723603144255
+37	0.009153983199065255
+37	0.0024391623706653876
+37	0.024071688263818634
+37	0.031051101565983837
+37	-0.035192851098856594
+37	0.0018220103695276036
+37	0.012289562377799615
+37	-0.018303976530567135
+37	0.007612746738051783
+37	-0.00893054703393623
+37	0.010749160660216493
+37	0.019044385521735138
+37	0.011942337122683366
+37	0.021918238819717353
+37	0.03282366101298598
+37	0.021094232061229342
+37	-0.01416255217594935
+37	-0.009309493773355708
+37	-0.051327278985502274
+37	0.002772334298068853
+37	-0.021660633034081292
+37	-0.009030925696964193
+37	0.0036197597070067073
+37	-0.02969665076550636
+37	-0.02328473171191958
+37	0.0020404598535410314
+37	-0.01132473053083278
+37	0.01012787447378333
+37	-0.0033596759786444475
+37	0.011989654512673458
+37	-0.018380802708449582
+37	0.019762426883407843
+37	0.008558529454057889
+37	-0.0010149035213380799
+37	0.018398253179485798
+37	0.024509962379189097
+37	0.012723705011023234
+37	0.0009397018764974683
+37	0.015701376279608728
+37	-0.00639766869240358
+37	0.004033304507326818
+37	0.014284564481143987
+37	-0.005076692903654366
+37	-0.005128726460478421
+37	-0.015291147376611035
+37	0.007461292306426122
+37	0.018175401515159034
+37	0.016425852243301484
+37	-0.0342791613852163
+37	0.011593780986090523
+37	0.023528562476320177
+37	0.023159082146013005
+37	0.023711983466971433
+37	0.008213449148258325
+37	-0.012312288842323204
+37	-0.01022876671744225
+37	0.004171272268654377
+37	-0.0028012731787373808
+37	0.010122204192293661
+37	0.02632234353039853
+37	0.030360560513299304
+37	0.010527816657194163
+37	-0.003434724646703915
+37	0.00812884842055881
+37	0.013055760837367496
+37	0.014823789939026647
+37	0.005766336793759842
+37	0.021389967570680977
+37	0.02562139063236224
+37	0.01824241154452553
+37	0.004512632883126038
+37	-0.0030606171825183787
+37	0.002052014083906753
+37	0.02491917197724369
+37	0.041444993828630074
+37	0.0028917440553412567
+37	-0.01053692302779459
+37	0.0016133631773855234
+37	-0.02051675448473936
+37	0.0047389251075282855
+37	0.014905673742132624
+37	0.001420067282460276
+37	0.026494575441422585
+37	0.015925637074209967
+37	0.02096131236307195
+37	-0.0030081435981957104
+37	0.005080903505714742
+37	-0.0013572834069146
+37	-0.011491781978002658
+37	0.024297348654834378
+37	0.009236180819667383
+37	0.009865028024901483
+37	-0.02399328593214656
+37	-0.04053023308505873
+37	0.0026605223449700345
+37	-0.020574638382972042
+37	0.0067536991528619585
+37	-0.013093481275670272
+37	0.010900786721177098
+37	-0.005564459005584609
+37	-0.01260869755534528
+37	-0.042655206676656725
+37	0.0004444184417903243
+37	0.03196449166899256
+37	-0.041099129178753836
+37	0.01412490721349494
+37	-0.0027010772297981277
+37	0.008687712250798391
+37	-0.0030987809038753337
+37	-0.0011493217224359301
+37	0.002596918810034405
+37	0.023140987427978845
+37	0.012924795328241468
+37	0.012924924156096548
+37	-0.002587252709575065
+37	0.0013256904826825045
+37	0.005390878718839129
+37	0.0075249568624142695
+37	-0.0017179597707155608
+37	-0.008017493626110875
+37	-0.0006041001395142826
+37	0.019922819663783328
+37	0.011051881435339604
+37	0.02289129640990209
+37	0.0008120716432624101
+37	-0.006390882656851691
+37	0.02150092108935157
+37	0.004955732080421598
+37	0.0064829605368261975
+37	0.0008430774507574864
+37	-0.022426271992598227
+37	0.00781259430902402
+37	0.006404872292096681
+37	-0.005200518773246286
+37	0.0029610011521240334
+37	-0.018445661577891643
+37	0.0186206416797004
+37	-0.0010689295724154238
+37	0.004333754288070117
+37	0.0009919788449906106
+37	-0.0034653328584150628
+37	0.006598051680111668
+37	0.02690805351076918
+37	-0.014404322308249479
+37	-0.0074154633986515065
+37	-0.008610713843794691
+37	0.019195498962616117
+37	0.008462436703363989
+37	0.029584446485379848
+37	0.03416972506803032
+37	0.021659442713176828
+37	0.004223948067049819
+37	-0.012591614357735186
+37	-0.0010670288490928683
+37	0.0017233439478497186
+37	-0.007005340002477434
+37	0.006126384468421725
+37	0.016727085402556303
+37	0.04716760707292605
+37	0.008293943419415395
+37	0.018494719120717033
+37	-0.004113857925355006
+37	0.010333286826526077
+37	0.017099088744301737
+37	-0.015613558597884455
+37	-0.02219211245654716
+37	-0.007678502871177528
+37	-0.016781302330560254
+37	-0.03866467519854794
+37	-0.009906473541452987
+37	0.009011257582660723
+37	-0.018417085312634588
+37	-0.04180791631043969
+37	0.011712956091506273
+37	0.006832576692089828
+39	-0.015333972149530018
+39	-0.0006701854942324904
+39	0.012940856947203656
+39	0.016090438528799607
+39	0.0036110823942920693
+39	0.0045871867056220105
+39	0.027447113946317072
+39	-0.015055078137796864
+39	0.0050684545257799534
+39	-0.017736626257247954
+39	-0.012265015849138451
+39	-0.001894473802266429
+39	-0.005308379287682844
+39	0.01564670025507895
+39	0.014565610997118077
+39	0.019154950075933135
+39	0.005519318006399237
+39	-0.01587103404151998
+39	-0.023146320574737252
+39	-0.0010679906474186762
+39	-0.006026639618036878
+39	-0.0007053869093733489
+39	0.029370650242506874
+39	0.004685184155988028
+39	-0.014198982094866633
+39	0.0034372672360746853
+39	0.016620949442013987
+39	0.004999759947551525
+39	-0.02672658472027769
+39	0.008314708563183329
+39	-0.010200206933900214
+39	-0.00594473183991553
+39	0.007010291045952978
+39	0.0025480223605736686
+39	-0.03011844505395333
+39	0.037426229875501094
+39	-0.0063065122885707465
+39	0.039921120147630725
+39	-0.010281878336971374
+39	-0.0013654557207397108
+39	-0.009272479250140797
+39	0.01357323986015614
+39	0.008723781369015148
+39	0.009266177407511796
+39	-0.008118410093460383
+39	0.0024833943176008214
+39	0.030015435486345263
+39	-0.014208875802770247
+39	-0.005417268491487046
+39	-0.020939655705932928
+39	-0.0033314616917264816
+39	0.007828705988013069
+39	-0.004132672363780206
+39	0.01541998954019993
+39	-0.011820441658291157
+39	-0.021714781873525373
+39	0.0010764431093500959
+39	0.01703925040981606
+39	0.013237269484229531
+39	0.003990577490053076
+39	0.02009425119922582
+39	0.0274915649027869
+39	0.028154541110054856
+39	-0.0021290268497628846
+39	0.006741518197675352
+39	0.02026303142302582
+39	0.007211751036594861
+39	0.0181861231585804
+39	0.0005175229576329652
+39	0.0035057943569096
+39	0.023533929980960697
+39	0.0038228091490727333
+39	-0.00041938012744393633
+39	0.02977236587647648
+39	0.00515488271908158
+39	0.020402685113065644
+39	-0.0006754781305024724
+39	0.005792096649001257
+39	0.016996359648913453
+39	-0.012866443256630035
+39	0.0009850426468940724
+39	0.020104545186195744
+39	-0.013998718535809446
+39	0.002654587494001334
+39	0.0027999224153219962
+39	-0.0333216419330147
+39	0.00451085502576703
+39	-0.026314613712393
+39	0.0017566748190399573
+39	0.012303512013078492
+39	-0.013241917006025608
+39	0.015206740073552636
+39	-0.00891114495617786
+39	0.013662619408638483
+39	0.02684758163867239
+39	0.01929246602357634
+39	-0.0005624701703681336
+39	0.02166307623192994
+39	0.008818669897489431
+39	0.02045110136097133
+39	0.02689646053187581
+39	0.012377426410078652
+39	-0.0039526714465303965
+39	0.01506941047458964
+39	-0.003539912866080764
+39	-0.018499980740525723
+39	0.023843936308950445
+39	0.03583219819196009
+39	0.004224554266319111
+39	0.008132236440704875
+39	-0.0014917652457994263
+39	0.0020171020659416738
+39	0.03657647930808848
+39	0.042491076914800543
+39	0.01927420206599656
+39	0.006316747767075973
+39	0.016701949105155562
+39	0.015837011052327588
+39	0.014260471200627293
+39	0.025984143679264594
+39	0.009908667258307288
+39	0.019736320548448063
+39	-0.01754394000235971
+39	-0.01841784193810304
+39	-0.010435246669588293
+39	0.029825946224261077
+39	-0.03912809784029298
+39	0.006788240137221626
+39	-0.018918707557462566
+39	0.013122995258175115
+39	0.009254759539812349
+39	-0.008886267295652664
+39	-0.005545749841414572
+39	0.016435795593389018
+39	5.082308305588247e-05
+39	0.002491715444225629
+39	-0.002935893640648865
+39	0.03316954017177882
+39	0.005069840577010713
+39	0.006216999090891865
+39	0.012198231508430097
+39	0.03000766463700803
+39	0.0028805385157233644
+39	-0.013918749630871325
+39	0.0024593996608630268
+39	0.002813252837590243
+39	0.007725086042151214
+39	0.006513386558255667
+39	0.017613407277358127
+39	0.025675893913916614
+39	0.011753901960714267
+39	0.03974373375045318
+39	0.00032898229522555143
+39	-0.01174769314499159
+39	-0.0010515455550747215
+39	-0.016128895985992462
+39	-0.000533485524272441
+39	0.007045929656828291
+39	0.02009597281682935
+39	0.0027821814737063453
+39	-0.015114256159217802
+39	0.0068401718252790455
+39	0.003168820060705616
+39	0.034427842663076476
+39	-0.024198781176285426
+39	-0.01995580177462421
+39	-0.026043742432394067
+39	0.005652757765992685
+39	-0.006168336733019864
+39	-0.007512378082804507
+39	-0.00325450619081162
+39	0.003064007883447298
+39	0.005961512624298256
+39	-0.00826293372731063
+39	-0.009468186998680668
+39	0.010023271654332038
+39	0.001600770951151693
+39	-0.005572403212019207
+39	-0.0023322274426302394
+39	0.01240714998503874
+39	-0.023464993327577753
+39	-0.03294110624979506
+39	0.0016544154798966977
+39	0.004267115807632241
+39	0.0031590089446670733
+39	0.0032567601611971347
+39	0.00305317028658023
+39	0.00644470090032255
+39	-0.001915425826875756
+39	0.022758354064874423
+39	0.03335198730661877
+39	-0.032169966894465905
+39	0.0017018460199685335
+39	0.01606145898469188
+39	-0.014815577103552502
+39	0.006582752071717297
+39	-0.0035344710952925113
+39	0.015164175217578641
+39	0.025643079704789195
+39	0.019437313335527576
+39	0.03236153653445198
+39	0.04102511268151434
+39	0.02602562801410382
+39	-0.011989167792224007
+39	-0.007172254288093859
+39	-0.054187707359824935
+39	0.007664835932378285
+39	-0.020987340900232382
+39	-0.008658915845731956
+39	0.002354645350068604
+39	-0.02857916179305758
+39	-0.0194674888355343
+39	0.0018014748772664565
+39	-0.00974653345285782
+39	0.011868372526781731
+39	0.001725408433633087
+39	0.014692348121893625
+39	-0.014639902430712282
+39	0.02211928713447693
+39	0.008303917338315188
+39	-0.0026817008815467197
+39	0.013283077443744093
+39	0.023190432157282885
+39	0.009724914890830733
+39	0.0088744438273431
+39	0.018762198813757118
+39	-0.008709454350345635
+39	0.004338456202491758
+39	0.02036414149239038
+39	0.0062608796102690475
+39	-0.010869932233091578
+39	-0.010471852865512875
+39	0.012555626174960206
+39	0.022614146275664694
+39	0.017986382871932483
+39	-0.03789552711849624
+39	0.010244677796449863
+39	0.03023196852317781
+39	0.03878073697706301
+39	0.025617421852840827
+39	0.0163491361825412
+39	-0.00994709816241762
+39	-0.012223845858208111
+39	0.0027461468613341755
+39	-0.002622234285444095
+39	0.007547911525388178
+39	0.02314667580168081
+39	0.029753771897943364
+39	0.01792411706007609
+39	-0.003202797936784104
+39	0.01018522374659721
+39	0.01509589216188333
+39	0.015636188363180877
+39	0.009062087495255406
+39	0.03119507271112328
+39	0.026062109241229633
+39	0.012738591481909894
+39	0.008427862870496813
+39	0.00551632039860883
+39	0.007096379623547503
+39	0.024045030200105354
+39	0.03992624798079727
+39	0.008766561674796641
+39	-0.011728758637276746
+39	0.0019535031611004087
+39	-0.018659192231498856
+39	0.009566343063308983
+39	0.02158317770291227
+39	0.002995453002077842
+39	0.03516385224234083
+39	0.010837840150322993
+39	0.022687314237941805
+39	-0.0018264847881318714
+39	0.004589359521668068
+39	-0.007738104730021324
+39	-0.01888694140713596
+39	0.01795394482642976
+39	0.002882472103057711
+39	0.009396988338748477
+39	-0.034262163577139695
+39	-0.037928717021693405
+39	0.0010917639655509757
+39	-0.014061730577523173
+39	0.008685726848741287
+39	-0.012889352277436684
+39	0.014532108502164146
+39	-0.010430594125921875
+39	-0.014952722963906127
+39	-0.03434727385670388
+39	0.006047215163411252
+39	0.03613681584213073
+39	-0.03500723530405043
+39	0.021406176385900953
+39	-0.0024583651340020513
+39	0.006952483004724276
+39	-0.00015520504754714531
+39	-0.0006115523888762515
+39	0.004023828551891776
+39	0.02294146118373563
+39	0.009572754393622025
+39	0.018251575292287204
+39	0.0021736862322545045
+39	0.0030908031976215724
+39	0.00879539743435922
+39	0.015515282232027201
+39	-0.0009748872887469808
+39	-0.008051641361647663
+39	-0.0029106703498495796
+39	0.018848456891164357
+39	0.012605619930686205
+39	0.020897911438021076
+39	0.0009746199042618049
+39	-0.004715555188354264
+39	0.025925677577402002
+39	-0.00468278398491019
+39	0.004504327956745527
+39	0.0025932600047894275
+39	-0.02607004631413711
+39	0.00619927527830092
+39	0.00559948140876099
+39	-0.005569156522093805
+39	0.012775884659355488
+39	-0.019957834884364884
+39	0.021701691489830335
+39	-0.00022111653451155217
+39	9.033685446305849e-05
+39	0.004649056096842319
+39	0.0006686602641052415
+39	0.010801486944036333
+39	0.02381317353423737
+39	-0.011908735995213656
+39	-0.0025554066687993398
+39	-0.010266522440597932
+39	0.023500656848322234
+39	0.01162503808739889
+39	0.03248278945977519
+39	0.03575719167062274
+39	0.025157169626553483
+39	0.007948109687210428
+39	-0.018126299864065512
+39	0.0012059994026302776
+39	0.00500797342283935
+39	-0.010255987358949666
+39	0.001771181241218521
+39	0.015444793992952156
+39	0.04459292495158767
+39	0.0056717877790212045
+39	0.021654674179328513
+39	-0.00038877634087135265
+39	0.013532682558043707
+39	0.021971687380392874
+39	-0.008947323862099035
+39	-0.017868001232935665
+39	-0.012001558993109203
+39	-0.015061723351393903
+39	-0.03513135284101912
+39	-0.009434553686493406
+39	0.009521928445423334
+39	-0.007167969834626037
+39	-0.04088261576532652
+39	0.016521145391890285
+39	0.005864810664477262
+18	-0.02067137000036953
+18	-0.008477810612954578
+18	0.0035638433314700724
+18	0.009358574338403211
+18	-0.007328692427553306
+18	-0.0025579632297808713
+18	0.0141707672084685
+18	-0.02510791854748178
+18	-0.0010848296542765058
+18	-0.019197878430208863
+18	-0.019138731230785563
+18	-0.00942855749154136
+18	-0.01732929850116564
+18	0.00185396908324533
+18	0.007605843103487363
+18	0.013415250363127537
+18	0.009092531925739179
+18	-0.029733813997777102
+18	-0.02893884967041079
+18	-0.0158697583107219
+18	-0.021541309871923767
+18	-0.013848683743667345
+18	0.017135145480716533
+18	-0.01042923830994895
+18	-0.016890262659183725
+18	-0.004256930645002687
+18	0.0025747643552650064
+18	-0.007747556648716515
+18	-0.03348930677438696
+18	-0.00502064723919023
+18	-0.01584485810369
+18	-0.01030491748353953
+18	0.0056527926760468975
+18	-0.012631638677548277
+18	-0.037567010122668165
+18	0.01586560355868166
+18	-0.014450029976088923
+18	0.03242431583380566
+18	-0.023967014179416376
+18	-0.01033799874394967
+18	-0.008632907084973385
+18	-0.00141644563202478
+18	-0.005180115113300312
+18	0.0023076729086161326
+18	-0.012745851877799263
+18	-0.006502147787231131
+18	0.0244108865706156
+18	-0.02122690867182839
+18	-0.016962726860752567
+18	-0.015513966498161893
+18	-0.0110493837978308
+18	0.005557725973067132
+18	-0.01783334558610299
+18	0.012764764398425624
+18	-0.021431173071987636
+18	-0.03447457268792596
+18	-0.0011514278972740845
+18	0.010595763788747185
+18	-0.0025629503956086284
+18	-0.0047357256260866076
+18	0.010833597641884456
+18	0.01374619892674871
+18	0.018629743271765743
+18	-0.011692674807871308
+18	-0.005265699792418158
+18	-0.0036153852604505978
+18	-0.008961133912470436
+18	0.008290588028736879
+18	-0.00670090529067053
+18	-0.009322520140255463
+18	0.020973871474719696
+18	0.002061585604625899
+18	-0.011876124224971075
+18	0.0185666188691576
+18	0.0025516703145446575
+18	0.010603665390081889
+18	0.0003984070076184278
+18	-0.0043678802956597425
+18	0.003099066935980219
+18	-0.02734225667375303
+18	-0.008620341174899172
+18	0.010680330855649603
+18	-0.02209659170613499
+18	-0.004955742961189207
+18	-0.010684629490270948
+18	-0.02386675574619226
+18	0.00833260172462418
+18	-0.03189422587091576
+18	-0.002990410645973469
+18	-0.005512249025169299
+18	-0.015416607742783415
+18	-0.0011316183521975281
+18	-0.01006054599136966
+18	0.0027920674702172723
+18	0.017002878597716178
+18	-0.0024089486450309524
+18	-0.015934201035799237
+18	0.0037563195849578223
+18	-0.0020205286319124756
+18	0.020196274848649103
+18	0.014576980764485731
+18	0.0014869081030116813
+18	-0.011895365635244903
+18	0.002578738488292507
+18	-0.016912862591578794
+18	-0.023934487697302675
+18	0.013902264986056503
+18	0.021941510807056887
+18	-0.0041685565632583925
+18	0.0001228831812350316
+18	-0.008304575363675544
+18	-0.015224268925240796
+18	0.028578416526861387
+18	0.02779323063295491
+18	0.005618633188788443
+18	-0.002467779795860701
+18	0.005503461820535002
+18	0.00477238957509543
+18	0.006287233424301829
+18	0.014104789255298091
+18	0.0043368483996173044
+18	0.008785337074183944
+18	-0.022309774727298372
+18	-0.027720253601312896
+18	-0.027231351228151603
+18	0.021067069032976685
+18	-0.052242920493173646
+18	0.0048343610077073865
+18	-0.03152246615336474
+18	0.0015703898834800948
+18	0.009267309317248597
+18	-0.018334456367710045
+18	-0.01636228992145619
+18	0.007385448655982624
+18	-0.004192044817130837
+18	-0.009264937219264448
+18	-0.0054885145773781235
+18	0.024352804332585284
+18	-0.005331246640953124
+18	0.009623069181627072
+18	0.003636397880259034
+18	0.01642863840012522
+18	-0.009545110948601774
+18	-0.02590638444113605
+18	-0.012747041570921352
+18	-0.003539897597073833
+18	-0.006739709468397661
+18	0.00659172355774366
+18	0.012847915663151776
+18	0.0018853119990067614
+18	-0.007186903477546084
+18	0.02379196419052122
+18	-0.00900892050940328
+18	-0.02716855267079413
+18	-0.003762732402263556
+18	-0.025721530367654007
+18	-0.002591097051216367
+18	0.0046119094108190645
+18	0.015639623661823858
+18	-0.005819806458922905
+18	-0.018159366370572888
+18	0.006024579208443976
+18	-0.003958197857469646
+18	0.02220106348987968
+18	-0.027401199446829408
+18	-0.028117037846340377
+18	-0.04083179532413396
+18	-0.006986932769227858
+18	-0.021708678699162227
+18	-0.01301440856845854
+18	-0.019850255686090165
+18	-0.009032778166999584
+18	-0.003315920205998321
+18	-0.017488423755752557
+18	-0.0035916613113367323
+18	-0.0012345301012932455
+18	-0.008033863828392872
+18	-0.013015891989498932
+18	-0.013164362846295928
+18	-0.008430774003281865
+18	-0.03233228338333846
+18	-0.04040006958605443
+18	-0.00039165329231615907
+18	-0.009263862142183145
+18	-0.0019015206780814808
+18	-0.008757788966175158
+18	-0.009403034946318688
+18	0.004321009719082992
+18	-0.009965910860256248
+18	0.017133569636930766
+18	0.030837209851504524
+18	-0.04238661102797332
+18	-0.0038589670567895007
+18	0.0015513496266581928
+18	-0.027803768982617418
+18	-0.00022853668555790913
+18	-0.015572678446744953
+18	0.005751190210616577
+18	0.017475341492341392
+18	0.012076401596639414
+18	0.013012221596199431
+18	0.02775776923226659
+18	0.011010394847837337
+18	-0.024435053364458448
+18	-0.021087338152881486
+18	-0.05787294910484225
+18	0.0008077008465316831
+18	-0.028086649155665912
+18	-0.018212668531235744
+18	0.004973643377021341
+18	-0.03513754254754935
+18	-0.032838277233480706
+18	-0.007787961406145328
+18	-0.01723834311215475
+18	0.0015271968661753317
+18	-0.009616355292432818
+18	0.005814799154633611
+18	-0.023905335929635355
+18	0.014190912626727755
+18	0.007141335308258286
+18	-0.006564944304536134
+18	0.008363523373456746
+18	0.023173035651397396
+18	0.006509238485336864
+18	-0.004889863053878375
+18	0.00968161775696826
+18	-0.005934854700177775
+18	0.003519725279063654
+18	0.01104184680577888
+18	-0.0026374578283256604
+18	-0.016278425632342965
+18	-0.018379142942294417
+18	-0.000136180905257321
+18	0.007774572365734328
+18	0.010701809986655058
+18	-0.04234878253709115
+18	0.0040208817140683
+18	0.021539579068295327
+18	0.016902913394429696
+18	0.022513360323490782
+18	0.004300703064582988
+18	-0.018283049029644356
+18	-0.019539064144105087
+18	-0.0014622374570524782
+18	-0.004898335606846194
+18	0.006225032610576633
+18	0.022167469553708175
+18	0.020521650028603188
+18	0.009608715164444944
+18	-0.010874549728738503
+18	0.00912826644122276
+18	0.010533278940874203
+18	0.005228220801791049
+18	-0.0008747588208182618
+18	0.01813752518757194
+18	0.014806815243327616
+18	0.005112577199591055
+18	0.00039955908140382255
+18	-0.0051525540238061395
+18	-0.008542343303946645
+18	0.023251332899355066
+18	0.0288467758864885
+18	-0.0005830912890780152
+18	-0.019875269134875573
+18	-0.005397995320264189
+18	-0.029819250888724714
+18	0.0064391771839069235
+18	0.0007831978236863299
+18	-0.0012296116287162026
+18	0.024557151436017194
+18	0.010277440983239036
+18	0.013267603410844939
+18	-0.01234704556584903
+18	-0.00047566835450294295
+18	-0.011859246667055554
+18	-0.022681079018817347
+18	0.013767805806581815
+18	0.00035059829758790384
+18	8.247168276601737e-05
+18	-0.03606984612247655
+18	-0.0437641356619116
+18	0.0009686977068920687
+18	-0.019005316063654576
+18	-0.004657298264405035
+18	-0.02208938576341112
+18	0.0003509469152922658
+18	-0.015561158394747063
+18	-0.017010170921829035
+18	-0.043777274117799685
+18	-0.01163812338956269
+18	0.0213996223864715
+18	-0.04476465366700855
+18	0.012052525945440583
+18	-0.008533502346314049
+18	0.0012209290918260504
+18	-0.006963396538846149
+18	-0.0031011105199592547
+18	-0.0016305667891396754
+18	0.017154544280630915
+18	0.00393910429164724
+18	0.005446885712247984
+18	-0.004837914442562753
+18	-0.010805741560983744
+18	-0.0032934909306177626
+18	0.0041911197477909005
+18	-0.009812836657216889
+18	-0.014248493262373525
+18	-0.0030442217756338607
+18	0.008659744707389732
+18	0.0024943681361908436
+18	0.01293692509842811
+18	-0.006564050866934166
+18	-0.014312159681774347
+18	0.017141965610656285
+18	-0.002111104881847889
+18	-0.007854767440087224
+18	-0.008452546098745956
+18	-0.020898256202650314
+18	0.004382777991939219
+18	0.004682276899021976
+18	-0.008066748050562076
+18	-0.001116435588081217
+18	-0.02081125589842935
+18	0.011246230138319374
+18	-0.01168846971319446
+18	-0.002687141458768789
+18	-0.0067681285226225026
+18	-0.009237278214329476
+18	0.005430735077900857
+18	0.016013737816877118
+18	-0.021356213016783594
+18	-0.013874211990847539
+18	-0.01792972091448703
+18	0.026336522852353134
+18	-0.001958960470039351
+18	0.025402917751520895
+18	0.030687046522538102
+18	0.016500381324728412
+18	-0.005225177938714278
+18	-0.02281192059973174
+18	-0.010598110729582255
+18	-0.008199536021441436
+18	-0.011562767236266695
+18	-0.000645184811138333
+18	0.010540367388351641
+18	0.04599892604571466
+18	0.0037428752139948085
+18	0.013841509234398789
+18	-0.005453171939430575
+18	0.0046581157149731545
+18	0.012771841180241203
+18	-0.026650885469354464
+18	-0.030664765444458217
+18	-0.014894290909855593
+18	-0.019750725044839563
+18	-0.041435406366516415
+18	-0.019493374710720292
+18	0.010670729182419438
+18	-0.021462279590927547
+18	-0.05077535434517789
+18	0.004776870778539139
+18	0.0021115165007170433
+43	0.0158670119504296
+43	0.01609022115249794
+43	0.03847404947179304
+43	0.058213916847280875
+43	0.020605230911150043
+43	0.02210471717627393
+43	0.0493783109838836
+43	0.011024389551866982
+43	0.027503912391939205
+43	-0.012066005378834182
+43	-0.00239081800795518
+43	0.028624978884004258
+43	0.0079191552583598
+43	0.031041710662022354
+43	0.042478696013415335
+43	0.04837308153272291
+43	0.03590931047031877
+43	0.03448658435632435
+43	0.021932676269651986
+43	0.014862385851218005
+43	-0.004535725710828504
+43	0.00516962387543806
+43	0.06769084066524643
+43	0.04187037178725366
+43	0.022222942283171048
+43	0.027137259872126437
+43	0.040323115420517405
+43	0.02153392090263352
+43	-0.006785561562715266
+43	0.04013531550994924
+43	0.03376279655395848
+43	0.02365063837071622
+43	0.029734302824397853
+43	0.029146477498689944
+43	-0.010381163375026313
+43	0.07574399963177836
+43	0.048469109343114054
+43	0.0604534335830142
+43	0.023004040081997704
+43	0.025210858528429882
+43	0.0031415202899197536
+43	0.04673514219240545
+43	0.0498376079527294
+43	0.05008575045893133
+43	0.029017639014257923
+43	-0.0021596474581875333
+43	0.07869932003841752
+43	0.01900990670948017
+43	0.030236339307699662
+43	-0.0012005196439617066
+43	0.03478019647881909
+43	0.047760420073355105
+43	0.013332578607340235
+43	0.04902670851409895
+43	0.022949255722039902
+43	0.006333352454791968
+43	0.039493802365851864
+43	0.06145760140847766
+43	0.06591911073933154
+43	0.03200265250476647
+43	0.06199360498366617
+43	0.05410424255572448
+43	0.05353802574288378
+43	0.03178921980895148
+43	0.02283816652163232
+43	0.03370061106814033
+43	0.0171122591018462
+43	0.023219375912502085
+43	0.021363713978662793
+43	0.021193627527947786
+43	0.04772938350268722
+43	0.03137867378091983
+43	0.01807658493141596
+43	0.0686834645832252
+43	0.026681095238775446
+43	0.03625653926567887
+43	0.026895527852437436
+43	0.010303181869826938
+43	0.0513771930192667
+43	0.01584499744290024
+43	0.010554598007486616
+43	0.03351384495528244
+43	0.004119456349148789
+43	0.036762822922620696
+43	0.004768886103190605
+43	0.0004302191540195534
+43	0.0721040142612787
+43	0.02062134388721833
+43	0.02915641417243271
+43	0.026131570314900977
+43	0.017438544458136553
+43	0.06644217317312869
+43	0.02927722225764912
+43	0.05037246612769172
+43	0.05411552016261351
+43	0.03058199187663572
+43	0.017304283864113524
+43	0.02871810893783872
+43	0.037260793927536166
+43	0.0550846898693894
+43	0.04304623679039791
+43	0.027839498086009464
+43	0.04494389730840856
+43	0.05882227541339856
+43	0.030446351892282928
+43	0.033976841164459023
+43	0.04648509434654338
+43	0.051105382073837885
+43	0.020739162040927614
+43	0.04867444034280808
+43	0.04074070234959735
+43	0.03309728510767863
+43	0.06599498496051297
+43	0.05625342969051637
+43	0.028269336728388605
+43	0.003887643207368088
+43	0.038676460296198596
+43	0.0346860145317564
+43	0.06534918281360512
+43	0.05657220801736823
+43	0.030322701607403624
+43	0.04828187838065648
+43	0.026859489504356755
+43	0.012987116213501354
+43	0.01965191671552419
+43	0.05672871979017194
+43	-0.010756893500808058
+43	0.031042274739728575
+43	0.022002090747863547
+43	0.04729319031470666
+43	0.05450177176245498
+43	0.02794743016545348
+43	0.025174682849313557
+43	0.0377876886072629
+43	0.024183270102823822
+43	0.027546517366751278
+43	0.02253874854410035
+43	0.04723152636925183
+43	0.013860865869896677
+43	0.03752519553543027
+43	0.04654494153115249
+43	0.06801952699284484
+43	0.011647958979987414
+43	0.02484450729987666
+43	0.03403978841129382
+43	0.03016225223346762
+43	0.042307216961724764
+43	0.02896431434851382
+43	0.0403839454598515
+43	0.05082504649141838
+43	0.042326747499836316
+43	0.06704469318506054
+43	0.029253949040733744
+43	0.015674228626232693
+43	0.024125265023040878
+43	0.006864997883944147
+43	0.03174092307140632
+43	0.030019209423230143
+43	0.04238177111070142
+43	0.042282160156337185
+43	0.01337263863693142
+43	0.04417028842211368
+43	0.05118115998799863
+43	0.05455665346848977
+43	0.0020732485136146454
+43	0.007479248030343576
+43	0.009096997757396622
+43	0.041607921223195954
+43	0.009668135128760785
+43	0.008621139010657801
+43	0.03794858872920976
+43	0.038549812553164746
+43	0.02824059070892181
+43	0.0522578244140897
+43	0.006512686344741047
+43	0.044344539213108186
+43	0.03786737992176931
+43	0.023221805573846437
+43	0.02504784508144244
+43	0.04957426487282735
+43	-0.0014503766226744736
+43	0.01298585225375912
+43	0.025443572128267453
+43	0.038321532329979306
+43	0.027622098602673367
+43	0.011570669770834157
+43	0.01495313255833747
+43	0.03289353205296417
+43	0.016176554094037263
+43	0.036519719573148555
+43	0.07596333358056326
+43	0.00015413336471024476
+43	0.022166070284551618
+43	0.014199763677403908
+43	-0.012347318782555053
+43	0.031192041411476155
+43	0.012828412953625818
+43	0.054998750572874705
+43	0.05457700502759992
+43	0.029000496866460158
+43	0.05560266004243621
+43	0.0535202929319593
+43	0.046406386415327225
+43	0.017924900606860184
+43	0.010344195836973255
+43	-0.019163470346423683
+43	0.05758929403088145
+43	0.002653349157303319
+43	0.017550822859704655
+43	0.018052349446582485
+43	0.006392306790279062
+43	0.016065388597139085
+43	0.040019334419449666
+43	0.025004145492682456
+43	0.031264975578937634
+43	0.03971742034938086
+43	0.0398484851622973
+43	0.01011033724201814
+43	0.05882390889006217
+43	0.04259476728330296
+43	0.013761054502680562
+43	0.020458231910091527
+43	0.04432242609899748
+43	0.03288691987555079
+43	0.038586723206007714
+43	0.04522028795669828
+43	0.004086441739316586
+43	0.02719078762941486
+43	0.039956342685048774
+43	0.04447701999915259
+43	-0.014845118091794736
+43	0.0174055759710966
+43	0.0330371485556531
+43	0.023416218943516424
+43	0.04057895817968169
+43	0.0021999679345760716
+43	0.03538816533488212
+43	0.05331154671514231
+43	0.0443385482387009
+43	0.039176928113186356
+43	0.034058858829250076
+43	0.009074970764543253
+43	0.022243273796006883
+43	0.04375287044678454
+43	0.006257527911626384
+43	0.022768868042967703
+43	0.03852027204824841
+43	0.025635610244383978
+43	0.04175627701349644
+43	0.01908912240254863
+43	0.03386648403012719
+43	0.04343823708047251
+43	0.05213342130906232
+43	0.03143454799527438
+43	0.04780542509095844
+43	0.0538206758532993
+43	0.0458514940498801
+43	0.023749008887194424
+43	0.05453694365009579
+43	0.032823756835303856
+43	0.04655174015258437
+43	0.05856458962605012
+43	0.04001598398142167
+43	0.016277271910328954
+43	0.03930794689653232
+43	0.010420528646748523
+43	0.04415335577707044
+43	0.0357868042314503
+43	0.06403772453092386
+43	0.0372092348319737
+43	0.044611988832606586
+43	0.04131550629455553
+43	0.009566697590661553
+43	0.02735886158723502
+43	0.014064007165220192
+43	0.0005018545662592498
+43	0.03292464197983107
+43	0.02387254002849244
+43	0.026730040210903992
+43	0.019899679768342164
+43	-0.003672810488984349
+43	0.03540291219128741
+43	0.014087558809436136
+43	0.011840531757551183
+43	0.03261421284259427
+43	0.029300098228923807
+43	0.03569124575482073
+43	0.025772045234134584
+43	0.01331678517094558
+43	0.05876091502114742
+43	0.052813003647726425
+43	0.0029601982581654728
+43	0.04940592784004223
+43	0.02397282887804482
+43	0.036854203231127904
+43	0.04095133055628475
+43	0.03604643229981111
+43	0.03583759696828999
+43	0.05536794260131736
+43	0.02433418829134074
+43	0.04915331109787481
+43	0.023586666352140826
+43	0.031189460003835885
+43	0.04512291043994603
+43	0.04300982031025321
+43	0.04461937340395485
+43	0.020661207147362266
+43	0.03903660974963114
+43	0.03630271493464143
+43	0.04360168361683153
+43	0.03543611494889965
+43	0.019213938490307645
+43	0.026782470486719286
+43	0.03237169788206416
+43	0.01956106395573783
+43	0.02844478828002221
+43	0.012641833672371308
+43	0.016269181174919586
+43	0.023226270338469537
+43	0.02617333823155664
+43	0.013432098705749669
+43	0.048810349425449505
+43	0.00786115318988195
+43	0.03833970224710042
+43	0.01962707913900275
+43	0.02863705646501402
+43	0.043883927333726536
+43	0.036338728226567404
+43	0.04732303248733258
+43	0.04113909490586962
+43	0.007948865171195186
+43	0.01715663415323964
+43	0.007914187671150803
+43	0.054591669614953424
+43	0.03870493826216169
+43	0.06378804456673458
+43	0.04325875981008334
+43	0.05053361646973228
+43	0.035725075273904366
+43	-0.001581598194359531
+43	0.01729176996444498
+43	0.01879113381095544
+43	0.003907237722281449
+43	0.026848557039604353
+43	0.029852333852637795
+43	0.06332423058124192
+43	0.031391875440360234
+43	0.0607815256355871
+43	0.036835353768831486
+43	0.04556525057435903
+43	0.07058841106849566
+43	0.01220901763693301
+43	0.014629772548199792
+43	0.015891381889601635
+43	0.02474586173223264
+43	0.011636807668808206
+43	0.023018028193711643
+43	0.039870883459978884
+43	0.019227335011465906
+43	0.013061967998956607
+43	0.05445460113757096
+43	0.04383502622180531
+50	-0.03273760291603277
+50	-0.0015050969422289572
+50	0.010451297322720259
+50	0.010145271632880655
+50	0.0019936963201694275
+50	-0.004446029037882283
+50	0.01837022427235379
+50	-0.026227887001834867
+50	-0.0017025385088950064
+50	-0.022302404276466244
+50	-0.01648329202859545
+50	-0.013169646788730624
+50	-0.009265108402375858
+50	0.0011986219993269356
+50	0.010875540652984558
+50	0.02145768996719734
+50	0.005947361413528661
+50	-0.025942739642626184
+50	-0.030530490066800853
+50	-0.012615140091366238
+50	-0.014979661449345285
+50	-0.01007227203523423
+50	0.018639868036140005
+50	-0.009229284374417446
+50	-0.01729972586479008
+50	-0.0008453581827218757
+50	0.002976946660222347
+50	-0.004770128105403111
+50	-0.035912709262874355
+50	-0.0015657391077158874
+50	-0.013641884908879893
+50	-0.007850806381509213
+50	0.0017471654353262511
+50	-0.009992940641713778
+50	-0.03681337439680531
+50	0.027930754488611393
+50	-0.010873350053522296
+50	0.034361032439766265
+50	-0.020380861555418746
+50	-0.0048932764858783395
+50	-0.016865960907258223
+50	0.003939941333504537
+50	0.0017530872859498757
+50	-0.004847024763419451
+50	-0.020106132394642984
+50	-0.003340802445436185
+50	0.026498578506706012
+50	-0.013065431636939172
+50	-0.01712212139558077
+50	-0.021759665231563946
+50	-0.009206584975587339
+50	0.001135654052539328
+50	-0.01201966031229473
+50	0.0062504795266205785
+50	-0.01663627277959978
+50	-0.02835514027128589
+50	-0.0028475331181520083
+50	0.01433567066429674
+50	0.009987434085144515
+50	-0.009367517374670477
+50	0.009891525314090696
+50	0.024609180980532726
+50	0.01643984307568782
+50	-0.00688196415180582
+50	-0.00906976296604082
+50	0.003758779499013551
+50	-0.003197880132021827
+50	0.013449466740272236
+50	-0.0015656654842037775
+50	-0.007123853123695347
+50	0.02047922086947579
+50	0.0005497531229836009
+50	-0.0075129534306767436
+50	0.030454672771537107
+50	0.003745437761139788
+50	0.011755638225601855
+50	-0.008135233476090848
+50	0.0026808643273714123
+50	0.010070055122541752
+50	-0.019715333604327204
+50	-0.005089994789397793
+50	0.014408944308784854
+50	-0.017927537672715557
+50	-0.0006461940372225163
+50	-0.008601743841393636
+50	-0.04267045408366033
+50	0.005213988991592728
+50	-0.025029341026588915
+50	-0.005338943782398297
+50	0.009061755532386327
+50	-0.017582118524506363
+50	-0.0039062792232819
+50	-0.011402361184425664
+50	0.00847013054564533
+50	0.015122447017603081
+50	0.012291315854605824
+50	-0.010203296291050086
+50	0.013913625339656264
+50	-0.002642245116832375
+50	0.022896767028304493
+50	0.020624965188541188
+50	0.004624877386130358
+50	-0.012491036175743684
+50	0.00671573700834508
+50	-0.014584324828367398
+50	-0.02464926163642223
+50	0.01459529360008016
+50	0.025764283317283584
+50	-0.002741683817618696
+50	0.005138155798136769
+50	-0.006790803899937695
+50	-0.004801978434610821
+50	0.0347225276419338
+50	0.0365405541583899
+50	0.009313689200373853
+50	-0.004945565576147544
+50	-0.0017568765702995427
+50	0.003714129909782255
+50	0.006321277398202147
+50	0.02274793867407266
+50	0.007370368080369427
+50	0.010196827719152762
+50	-0.028617070546612545
+50	-0.03202123478313893
+50	-0.020864075100804066
+50	0.022365440776409985
+50	-0.03461094002322872
+50	0.0050046290561099
+50	-0.022607256018270173
+50	0.001547397702849246
+50	0.0064256158031658715
+50	-0.016833057797954434
+50	-0.016421421824487904
+50	0.00601978290980313
+50	-0.0060695407621798566
+50	-0.012439036141295885
+50	-0.011422181128008167
+50	0.0343701120151581
+50	-0.0015866330162893705
+50	0.011146279688804798
+50	0.011055268024687403
+50	0.020749172605485228
+50	1.726011183345345e-05
+50	-0.02234403174862335
+50	-0.007269737965674369
+50	-0.003751207734828172
+50	-0.009117850869980466
+50	0.012171821407257801
+50	0.022308325141529473
+50	0.007622227356465667
+50	0.0006738817625910254
+50	0.028070070902083737
+50	-0.00823239027147002
+50	-0.020613942319693237
+50	-0.00896056593494141
+50	-0.01944953304097762
+50	-0.006079351340942487
+50	0.003319213515728012
+50	0.01590222667484009
+50	-0.004148420756256173
+50	-0.014259241267714561
+50	-0.0017824887253873646
+50	0.0011198158588918911
+50	0.02990219204666043
+50	-0.027787820534200973
+50	-0.03090861137636185
+50	-0.028192968406238233
+50	-0.006914925732995602
+50	-0.016553720732204413
+50	-0.01812037680658125
+50	-0.014233408973035258
+50	-0.004267143386488535
+50	-0.004657007183410003
+50	-0.016234191806907015
+50	-0.012093096333156982
+50	0.00210918155445169
+50	-0.0034323656559113267
+50	-0.010136204948250778
+50	-0.011837163463239335
+50	-0.005871470660709351
+50	-0.0359323986467612
+50	-0.042699610567081936
+50	-0.0025674318110859014
+50	-0.006205722391325593
+50	-0.008838913158840271
+50	-0.008630930862449853
+50	-0.003972051989340392
+50	-0.0018292834413025621
+50	-0.004557431961873255
+50	0.020252993665285497
+50	0.03627974920531089
+50	-0.04108348180571998
+50	0.0024518344602636835
+50	0.0054711396702702905
+50	-0.0290150617231842
+50	0.00034320082854719753
+50	-0.015198558253379334
+50	0.006163182357622283
+50	0.012066502582517657
+50	0.01490119357727849
+50	0.020487596103510308
+50	0.03192805379526769
+50	0.018187026196098716
+50	-0.025340889264561735
+50	-0.01921202676016972
+50	-0.06199702208425559
+50	0.0043268092518474865
+50	-0.021907788027613444
+50	-0.016505837971813497
+50	-0.0023687700731125517
+50	-0.039563800585922466
+50	-0.032155667330659145
+50	-0.003920494124111824
+50	-0.015264986988593231
+50	0.004045675204082126
+50	-0.006285610520123119
+50	0.00994557442304892
+50	-0.014659219727821962
+50	0.014360890841988962
+50	0.010337660162283359
+50	-0.007542273624447411
+50	0.016313884943197524
+50	0.02042387172662545
+50	0.009572617997973877
+50	-0.004082726146936223
+50	0.012646123361358404
+50	-0.005025951429164779
+50	-0.0023493479745136164
+50	0.01164390003305819
+50	-0.009309670995902585
+50	-0.00742152271245698
+50	-0.02339196140251754
+50	0.007481955038492366
+50	0.0146724866768679
+50	0.010716902565631129
+50	-0.040835139736242296
+50	0.0034054052875836845
+50	0.023449066318512655
+50	0.02675933608351668
+50	0.02246662937555754
+50	0.00033963785172500454
+50	-0.010834781204133158
+50	-0.019255291590391754
+50	-0.010809462395003253
+50	-0.0027699294858950425
+50	0.010183047067458928
+50	0.01759689052740659
+50	0.024247503469559787
+50	0.011766626722756558
+50	-0.006300652712741536
+50	0.015883158862726912
+50	0.006393811639304541
+50	0.003859556023605448
+50	0.003445988715602256
+50	0.018800666017163903
+50	0.018220282613898926
+50	0.006919280591369487
+50	0.002796202985611476
+50	-0.007859030650210036
+50	0.0009677638555779136
+50	0.020536336723868454
+50	0.038848047298690194
+50	0.0027877675510923836
+50	-0.012680839632650215
+50	-0.003439301827177883
+50	-0.02451504031043728
+50	0.009804461978574461
+50	0.007529749756409464
+50	-0.0009955072149447324
+50	0.021232415382578793
+50	0.006018504177450666
+50	0.008559764376544909
+50	-0.011477630084744683
+50	0.006209693939195627
+50	-0.004242553609882501
+50	-0.01776907161878906
+50	0.016333758951455914
+50	0.005457064554845397
+50	0.002425730560047039
+50	-0.04203583145733242
+50	-0.04464517816461604
+50	-0.002535036403931934
+50	-0.021753774874567165
+50	-0.0019962192283408298
+50	-0.01946000327888354
+50	0.004850384453566266
+50	-0.016441031376677843
+50	-0.017798806757078536
+50	-0.05191278716456264
+50	-0.0013524646580212682
+50	0.028749932672727675
+50	-0.04348023910182224
+50	0.0157775751693599
+50	-0.005016221931162894
+50	-0.0009926885893288624
+50	-0.00280923290295532
+50	-0.0032225587047919665
+50	-0.002073343532635816
+50	0.011690356388057639
+50	0.010763274952887147
+50	0.012337651136540997
+50	-0.0034622673353141664
+50	-0.0022264543769540115
+50	0.0015749693201088065
+50	0.001335460077014972
+50	-0.006823717266090286
+50	-0.01660184037200845
+50	0.000727203517323034
+50	0.01507593378980832
+50	0.004127653139075295
+50	0.008579898965402658
+50	-0.0052336690655439295
+50	-0.004059032855115993
+50	0.01584065586714937
+50	-0.004722501160916742
+50	0.0036145279039986196
+50	-0.003876540889223268
+50	-0.02575440704128912
+50	0.009008135377298668
+50	0.0034316139690311527
+50	-0.01422423957616933
+50	0.005839582440147066
+50	-0.030379620491793644
+50	0.011035612961304243
+50	-0.00747300406099058
+50	-0.003474919754612426
+50	-0.001255290529802649
+50	-0.0042498134901972255
+50	0.00515875619526664
+50	0.0248848461889821
+50	-0.017171416018005946
+50	-0.010003963409591183
+50	-0.018817525843390987
+50	0.020113390778119588
+50	0.002592766361877607
+50	0.03138702875964908
+50	0.03317079980403038
+50	0.021523715636997377
+50	0.0009705815325290125
+50	-0.017881273242109655
+50	-0.00751357830652774
+50	-0.004018920563442246
+50	-0.011108564220035082
+50	-0.0037434127056394694
+50	0.011444305394884346
+50	0.04102813776610837
+50	0.001924341377733721
+50	0.013878338314369583
+50	-0.00787209484658429
+50	0.005988799836724241
+50	0.016794907229884706
+50	-0.016344765637818955
+50	-0.027264653368964744
+50	-0.012224530067960317
+50	-0.023158255454422433
+50	-0.042996267246005124
+50	-0.010974288177246478
+50	0.004714732618291156
+50	-0.023856232019506284
+50	-0.050902957334421996
+50	0.006624497628552361
+50	-0.004614687498107023
+53	-0.040836375261081394
+53	-0.0015300041436323386
+53	0.012405296487826255
+53	-0.003236637169893273
+53	0.004953257155966925
+53	-0.006320027321146496
+53	0.008376414244648285
+53	-0.01219837669557475
+53	-0.0026805502134974535
+53	-0.017725558474290526
+53	0.005867839027011129
+53	0.005117153650144187
+53	-0.009812899272391911
+53	-0.0008502083126306194
+53	-0.001657970848260823
+53	0.0007605898213038791
+53	-0.005210113581995195
+53	-0.01321173900282128
+53	-0.022753109824130726
+53	-0.03760734537621184
+53	-0.03712130166383977
+53	-0.009066508650982926
+53	0.020426923314012083
+53	-0.012700289316518799
+53	-0.011416889190900335
+53	0.010023034525809382
+53	0.002760525360205897
+53	0.0073091057692478995
+53	-0.02863448151166339
+53	-0.0001813842254175114
+53	-0.026302755270029423
+53	-0.02861800557651945
+53	-0.005961561562410992
+53	-0.008986607895717372
+53	-0.03108804769413783
+53	0.012912753747560278
+53	-0.01806472663429218
+53	0.0023244705831623495
+53	-0.008404077919044742
+53	-0.005077410818697558
+53	-0.01818550428816373
+53	0.00505168796256916
+53	-0.008241794398143348
+53	-0.027769452191209704
+53	-0.007782800798715185
+53	0.00034722225430009054
+53	0.02706207196553215
+53	-0.026213039433875075
+53	-0.029854904866544265
+53	-0.01910118276167036
+53	-0.017949848348066517
+53	0.022786366267023375
+53	-0.01847859420093175
+53	0.014204691611438648
+53	-0.023397814315728436
+53	-0.029190688325737457
+53	0.01123208947697497
+53	0.03303233230572113
+53	0.03208967211875541
+53	0.004153105380417352
+53	0.000433606178577161
+53	0.01979384784209289
+53	0.02120238905199212
+53	-0.005906227235462224
+53	-0.014136004049168193
+53	-0.009757191995146323
+53	-0.023169094934464837
+53	0.0018959292407181862
+53	-0.023555236637894245
+53	-0.022131489689370946
+53	0.008915369094452659
+53	0.01055500378900596
+53	0.0011241678544916102
+53	0.009492948323642737
+53	-0.0017302649793283814
+53	-0.0017677467129700657
+53	0.016731069917688465
+53	0.015344168774231214
+53	-0.0027868393725547537
+53	-0.011866984884274054
+53	-0.004592706815515191
+53	0.015781812167195066
+53	-0.0036065653620383263
+53	-0.008994578699560303
+53	0.002595263074486807
+53	-0.019464876498867512
+53	0.007138245225572926
+53	-0.020325730158104224
+53	0.012174851377918081
+53	-0.0020379451717747192
+53	-0.011474936035627452
+53	-0.017406650260021403
+53	-0.006336803254672612
+53	0.006459032546894722
+53	0.04224134863227088
+53	0.01083564039125016
+53	-0.003620501404132459
+53	0.007286103690222002
+53	0.005199052972792578
+53	0.016095058309063975
+53	0.010630506544990724
+53	0.0031581346382240786
+53	0.013994571542608785
+53	0.004219824527961297
+53	0.0115675790007646
+53	-0.010493377112341181
+53	0.017188587742797155
+53	0.002863602789672322
+53	-0.014580305724723392
+53	0.015590254467107064
+53	-0.016214970306182443
+53	0.014494221978365807
+53	0.007172503529093816
+53	0.02529201149772103
+53	0.02594781687598171
+53	-0.015117383537278413
+53	-0.02432062630370059
+53	-0.02635573973150763
+53	0.016163159741554835
+53	0.014789314244874655
+53	0.007571848403696593
+53	0.037680702735144296
+53	-0.007077288150698571
+53	-0.0200133040660269
+53	-0.005719380690224955
+53	0.028950741064936426
+53	0.0014726997306956334
+53	0.005606298979417385
+53	-0.017784504970276695
+53	-0.0069251927237901885
+53	-0.0032995625412654997
+53	-0.027433569188314563
+53	-0.022055801298948085
+53	-0.002688517814359503
+53	-0.006671183327124917
+53	-0.00754787144574372
+53	-0.01364827301439143
+53	0.007494403035572668
+53	0.0013923106767413202
+53	-0.011236683359668813
+53	-0.004276169777370784
+53	-0.008787089937915873
+53	-0.02895084662404444
+53	-0.020864526426119377
+53	0.00663999227081615
+53	-0.0012457049057560976
+53	-0.021144545742809273
+53	-0.00849226596776109
+53	0.014776860077305503
+53	0.010155885431592142
+53	-0.004824323963166232
+53	0.01666303729873883
+53	-0.004708638410842022
+53	-0.0011313924142001036
+53	0.011318859833939987
+53	-0.02256772114863966
+53	-0.020503833718448185
+53	-0.005508527822035623
+53	0.029496286611922103
+53	0.027452946661342396
+53	-0.014608754452315437
+53	-0.01679707735961988
+53	0.003439204248736927
+53	0.018985448013647512
+53	-0.01504157250201419
+53	-0.020771242214315196
+53	-0.017484210280666827
+53	-0.005913231569812844
+53	-0.021258459365785926
+53	-0.017385973829410123
+53	-0.028641122096698043
+53	-0.023647326854469547
+53	-0.018548537072740245
+53	-0.028695835789678926
+53	-0.009316426636967542
+53	0.005194275604313932
+53	-0.007369582772219542
+53	0.002387950974681768
+53	-0.0032760370729734115
+53	0.015296089607253326
+53	-0.03090024283150725
+53	-0.04589361329879683
+53	-0.029622333039978216
+53	-0.003445313485940275
+53	-0.028344256013025097
+53	-0.019634371305080587
+53	-0.0018113224121200483
+53	-0.004033413613980509
+53	-0.008311927001586792
+53	0.022071668477575575
+53	0.017649294854929956
+53	-0.033633682789490416
+53	-0.013249765736319275
+53	-0.009978013488152606
+53	-0.06284388570086182
+53	-0.0160963227857471
+53	-0.007860352999402118
+53	-0.016289986077830613
+53	0.01605014197056969
+53	-0.016369350866445816
+53	0.010655045351978898
+53	0.010904286534327215
+53	0.017968551917262255
+53	-0.03176252460416351
+53	-0.020985021519519472
+53	-0.045618035514181955
+53	8.492621671222975e-05
+53	-0.026615190698649094
+53	-0.010248758727455887
+53	-0.008306548790482317
+53	-0.02899152621452171
+53	-0.028789891730273742
+53	-0.029416526389473743
+53	-0.024328381831589568
+53	-0.014761696862532966
+53	-0.010436869711408146
+53	0.01873744517020595
+53	-0.02176423950268068
+53	0.004702430573121151
+53	-0.0025578593103050304
+53	-0.010926606406052088
+53	0.02567186481272089
+53	0.022433969654317702
+53	0.01816793787558055
+53	-0.01710477979697234
+53	0.014344339543939303
+53	-0.026618821666489916
+53	-0.004099946033777073
+53	0.011872300008556654
+53	0.0025780010467919877
+53	-0.03239534656174761
+53	-0.030700064415745028
+53	0.019907026925761743
+53	0.017703261255325464
+53	-0.00040806007430936933
+53	-0.022706559173004178
+53	0.0020807216382422123
+53	-0.00029494195022335086
+53	-0.0066808491767911616
+53	0.00860357263195183
+53	0.0017854408018468848
+53	-0.030385540256898543
+53	-0.017429344342516074
+53	-0.009693265065264352
+53	-0.021627377845138337
+53	-0.004778667433168979
+53	-0.0016607438533016916
+53	-0.01051387833911047
+53	0.006760755972122552
+53	-0.001080622245769578
+53	-0.005260720862925152
+53	0.002968321138498366
+53	0.004826633184367573
+53	0.00890502371187572
+53	-0.005089345943869519
+53	0.01571183959657488
+53	0.005031741757390122
+53	0.0067397845205813605
+53	0.001976457465418181
+53	0.017908308674012375
+53	0.016905773587189053
+53	0.023638903427336315
+53	-0.027121906625676297
+53	-0.03529396174133158
+53	-0.003260600409681398
+53	-0.016310885485953372
+53	-0.009886212119690931
+53	0.016555566709058396
+53	-0.0026611067259201568
+53	0.0008502571512454484
+53	0.009357265553996613
+53	-0.004960364433198322
+53	-0.03354920470227878
+53	-0.0056543728011153125
+53	-0.018077465999641645
+53	-0.02123696586373509
+53	0.01543507946264599
+53	0.008769764517707243
+53	-0.02273474762631087
+53	-0.04134924050205964
+53	-0.04051741541821741
+53	-0.012884221034992796
+53	-0.014716849524056379
+53	-0.009830559706899545
+53	-0.003944466469012778
+53	0.012243468685211974
+53	-0.006556840723574542
+53	-0.01817440719904512
+53	-0.02477185880368527
+53	-0.005907283227136221
+53	0.021380582811302336
+53	-0.027619691229357646
+53	0.01123456081441606
+53	0.0031697869224458206
+53	-0.004359976544402329
+53	-0.004885267225827509
+53	0.014074333605326813
+53	-0.009563524008095832
+53	-0.019367723030477155
+53	0.004200246446223167
+53	0.0016774801955705058
+53	-0.008295896039558548
+53	0.001398653267544951
+53	0.008349567964384606
+53	-0.007377110433181735
+53	0.00044847696983984993
+53	-0.019474031136992052
+53	-0.015581571864441562
+53	0.005470647814378456
+53	0.027025579430117852
+53	0.024188904793023627
+53	0.0009491048499378765
+53	0.0020902964129463487
+53	0.009382665695752308
+53	-0.010532027835628961
+53	0.00445485773488481
+53	-0.01006533997724054
+53	-0.02605055499093542
+53	-0.011365024575397462
+53	-0.00938862188987143
+53	-0.0008124199623996521
+53	0.02157541696005937
+53	-0.02751835003441057
+53	-0.010866396801386664
+53	-0.004329144100630185
+53	0.006974528025070473
+53	0.0008199711590168065
+53	-0.017836943300886542
+53	0.0006375499820638903
+53	0.010733713010315398
+53	-0.014669108269694468
+53	-0.011086506094301512
+53	-0.013669037331163762
+53	0.019513223589560858
+53	0.0329830762478433
+53	0.03161660043400376
+53	0.0157782585731556
+53	0.024185519178653785
+53	-0.021711015005187188
+53	-0.04209515491824736
+53	-0.00889223340140912
+53	-0.029997360503739082
+53	-0.0390539207274139
+53	-0.01930654156104548
+53	-0.01634444809799814
+53	0.036808728660781546
+53	0.008353481172134188
+53	0.006990753151859635
+53	-0.0006035849253376318
+53	0.0169401393490327
+53	0.021276154178777342
+53	-0.020242207680426432
+53	-0.006293348670721486
+53	-0.009958876745209361
+53	-0.011623478103608002
+53	-0.02525198554333783
+53	-0.017521594920773778
+53	0.004555208954101266
+53	-0.006956627853541596
+53	-0.024877413357403816
+53	-0.005900344503167923
+53	-0.018609659467148685
+30	0.00018267043086111383
+30	0.01795000293103381
+30	0.03148474363991746
+30	0.029421345155973583
+30	0.02328828965090186
+30	0.016456262775715404
+30	0.042150838571764146
+30	0.0006461659719373397
+30	0.023789972305838077
+30	0.0005716747496881594
+30	0.004543343149568435
+30	0.005576912943727311
+30	0.007350551287623628
+30	0.024144462962658805
+30	0.03355008752339015
+30	0.03824378111010287
+30	0.02325978868507122
+30	0.0022034020857820465
+30	-0.0029572567167367937
+30	0.012470846047009264
+30	0.005905496660394298
+30	0.00628560984545638
+30	0.04888902069328452
+30	0.010134483147222964
+30	0.005147719794551506
+30	0.01844481224935251
+30	0.023174982473740096
+30	0.015598050696788032
+30	-0.012953508780989175
+30	0.021115558333184046
+30	0.011706374128530823
+30	0.01560100976173988
+30	0.022991176903139465
+30	0.013904007103706211
+30	-0.013856961734524446
+30	0.05379885142654714
+30	0.012512612928762065
+30	0.05452916523477438
+30	-0.0025429003757657634
+30	0.015165238171298445
+30	0.004978279862125606
+30	0.02987776518801434
+30	0.023823733509215985
+30	0.02385552348430977
+30	0.008274541596726933
+30	0.015494148412767516
+30	0.05473840790837009
+30	0.0033518677162855124
+30	0.003653510945436332
+30	-0.0040147196275619815
+30	0.013683783032641549
+30	0.02673407898715574
+30	0.016140518085264233
+30	0.02646988935733597
+30	0.010532861588176868
+30	-0.005141418067216351
+30	0.02589747560067842
+30	0.035768121381345254
+30	0.026500266723325516
+30	0.018870968239334318
+30	0.04252077810704121
+30	0.04665223566845558
+30	0.0398142383664649
+30	0.01948940305143789
+30	0.012758451336967548
+30	0.028922692022988743
+30	0.021919567212341146
+30	0.028938572336960115
+30	0.02458681386196051
+30	0.018576287457391226
+30	0.04818873406940677
+30	0.018625396325714052
+30	0.012879571325664401
+30	0.05272058096469273
+30	0.021931018652202927
+30	0.035168965763873815
+30	0.015522601549979335
+30	0.02082481945582356
+30	0.03312853526912564
+30	0.007445358215237786
+30	0.017025044130911608
+30	0.033517967837131936
+30	0.0071435099420029255
+30	0.024441538648345446
+30	0.02253847965933792
+30	-0.009937704188118316
+30	0.031566575856559594
+30	-0.007017091315280713
+30	0.018546753546625674
+30	0.02812686835375789
+30	0.011785286553329312
+30	0.025658825571602623
+30	0.0181991680328825
+30	0.035175012294553144
+30	0.044037976813633015
+30	0.03071906646808165
+30	0.006718903588771679
+30	0.03584898745920304
+30	0.025067043076045264
+30	0.04744274119517075
+30	0.04275493030716244
+30	0.029360699763827065
+30	0.012366253309964693
+30	0.026607689097493333
+30	0.013746394792650798
+30	-0.004915899700210338
+30	0.03531419240080703
+30	0.0428271696022181
+30	0.02316525351549174
+30	0.026282466803913305
+30	0.0186820498471224
+30	0.011220124715198738
+30	0.061942094178193845
+30	0.06027386630419494
+30	0.032843149827603765
+30	0.01868661517356627
+30	0.03140100306652799
+30	0.023730684607638625
+30	0.031297717252297304
+30	0.046746756656252164
+30	0.031586893803628106
+30	0.040706878214453755
+30	0.00598803874405884
+30	-0.0014726865711024836
+30	0.004724762693800177
+30	0.05006496799221372
+30	-0.019302641442291664
+30	0.022456024143423698
+30	-0.00417881074305979
+30	0.02668699246987335
+30	0.03828819552935825
+30	0.011624459830518609
+30	0.004834895775739353
+30	0.03517123502230664
+30	0.020092614021597253
+30	0.014307483324577777
+30	0.015769529927894058
+30	0.053700041125379336
+30	0.013623724764576125
+30	0.03686008023108085
+30	0.03382516658490569
+30	0.054220888116871
+30	0.026995819883664042
+30	0.004480603304202074
+30	0.019395240617574968
+30	0.015192745342538764
+30	0.019529011489367903
+30	0.031027171697680662
+30	0.03992834479877756
+30	0.0386058065834778
+30	0.026864163653899376
+30	0.05505746627353008
+30	0.015789919800769322
+30	0.005295412845306703
+30	0.01545604868253104
+30	0.005950744790050235
+30	0.024025080076543713
+30	0.023783905265482123
+30	0.03812993297775132
+30	0.022138292051960558
+30	0.0074752418999938135
+30	0.01734017923200087
+30	0.0248566028518455
+30	0.04982595829672415
+30	-0.00162995907157822
+30	0.0015454986542833603
+30	-0.007992348385659698
+30	0.021413316922521516
+30	0.007750691030850071
+30	0.012666596111276398
+30	0.011655382034310992
+30	0.021302112020482742
+30	0.02085172708797403
+30	0.00521433111371771
+30	0.011565185981892484
+30	0.025910670022680937
+30	0.017251807150317315
+30	0.014483162919490351
+30	0.013921460786476195
+30	0.027787815046157224
+30	-0.011104248017604632
+30	-0.022311520673108556
+30	0.015708891898966734
+30	0.017582050451887363
+30	0.012548993610507384
+30	0.006897173929631682
+30	0.017972849975034347
+30	0.02357617768080939
+30	0.015019181943840257
+30	0.041566793179171835
+30	0.06157446779593612
+30	-0.01639603885714035
+30	0.016984558007497066
+30	0.029165663511667245
+30	-0.010876152915530136
+30	0.018345432969764115
+30	0.005337914768033551
+30	0.030263447144100876
+30	0.035712648281737557
+30	0.02845173587786716
+30	0.04010753107947987
+30	0.053898377666992126
+30	0.04102966909906995
+30	0.0026897497742153953
+30	0.008434426834175281
+30	-0.03656760945285393
+30	0.03032934495297294
+30	-0.007544592251177541
+30	-0.00048751474132215604
+30	0.01692057089687974
+30	-0.01778532909326453
+30	-0.01159495542230801
+30	0.022389842096483096
+30	0.009179790667865347
+30	0.025835511711456812
+30	0.01616895759314413
+30	0.03272416588031603
+30	0.0034711167976111696
+30	0.03922128767492414
+30	0.028122711587569623
+30	0.01087535683484931
+30	0.033474387675707526
+30	0.03912343558451027
+30	0.030935941057481976
+30	0.025072402326542544
+30	0.038728980773382
+30	0.012142248255001025
+30	0.021916683050546972
+30	0.03429666751286129
+30	0.022408986647351397
+30	0.01092013741838246
+30	0.0044114496073973195
+30	0.03296432065542156
+30	0.03907344366427535
+30	0.029135015674631653
+30	-0.022690098017678056
+30	0.024562647963003927
+30	0.040873113611129185
+30	0.04171718705634394
+30	0.0430179056447894
+30	0.02602077252644761
+30	0.007483772668654231
+30	0.01028635493784255
+30	0.016019824205886945
+30	0.012743097091509406
+30	0.03093426417638223
+30	0.04196076516261605
+30	0.04160470079149173
+30	0.031101162885144255
+30	0.0158711422787149
+30	0.035472520580363334
+30	0.030951110103070965
+30	0.03693180880239315
+30	0.023953016295990753
+30	0.04409946959749498
+30	0.04422476794760512
+30	0.02982762971455417
+30	0.02562604271268392
+30	0.02338774896953797
+30	0.025089688226017284
+30	0.04311820455982187
+30	0.05379032500005986
+30	0.020855680425258677
+30	0.003293162129334715
+30	0.01775768351532142
+30	0.0014311215371372974
+30	0.03100081303699975
+30	0.03196176424392701
+30	0.018944273158413655
+30	0.048492652739113004
+30	0.026602988433286835
+30	0.03762002863433756
+30	0.012008850804772903
+30	0.02531935123595377
+30	0.011183708195471846
+30	-0.0007457028863751991
+30	0.03448177392726282
+30	0.024982014642772957
+30	0.021159503291435636
+30	-0.013646008973563054
+30	-0.016818361666244945
+30	0.023349513516737946
+30	0.0014217095629900285
+30	0.02554879722256017
+30	0.007784391166509739
+30	0.02872619818569015
+30	0.00905433727409897
+30	-0.0016023801898771744
+30	-0.02757784070375675
+30	0.018094336668324853
+30	0.050295715500948655
+30	-0.019329829076945193
+30	0.033271065237003614
+30	0.014663533745964292
+30	0.026243997710725355
+30	0.02159495058947597
+30	0.023691904509901763
+30	0.018938548118751376
+30	0.03523220616370134
+30	0.02760419018564883
+30	0.03742549116745664
+30	0.016730087794427674
+30	0.01789522684430574
+30	0.02322651163475447
+30	0.020631508618808202
+30	0.01235969042847517
+30	0.006487722525382762
+30	0.016631330819596977
+30	0.03384182939214159
+30	0.03035057451759953
+30	0.034188574559525765
+30	0.01408461046606671
+30	0.01578156135718898
+30	0.03500767964149798
+30	0.01556351842854501
+30	0.02162827999527665
+30	0.01773676505216586
+30	0.0005732708630476025
+30	0.02884598127756205
+30	0.02113810124023664
+30	0.008707042541987276
+30	0.03681351754068853
+30	-0.00899459551709636
+30	0.03412910724139736
+30	0.015253738907173705
+30	0.019327736459529052
+30	0.018281473519211597
+30	0.01965069374343095
+30	0.03187603847347155
+30	0.04231148376785832
+30	0.008162962135347618
+30	0.009941836251655067
+30	0.008834071194253761
+30	0.04401360784850588
+30	0.029309107179742087
+30	0.05581010313180826
+30	0.05563824651683005
+30	0.04334423372995988
+30	0.02097894598240681
+30	0.0019772810201486423
+30	0.011066926482730456
+30	0.018068413723808747
+30	0.010195716525327986
+30	0.01859895179536104
+30	0.0334383287635794
+30	0.06982879800478206
+30	0.02574168393527204
+30	0.03842689258427198
+30	0.017770042839970277
+30	0.030317206592539277
+30	0.03923547927792738
+30	0.007833380326614837
+30	-0.0014389695425545308
+30	0.003432243699733878
+30	-0.001602303868702799
+30	-0.018272781174459598
+30	0.007567764892728811
+30	0.032189756742402674
+30	-0.00044131850847954314
+30	-0.01976461394180472
+30	0.02938690371663815
+30	0.02880806399475885
+42	-0.03027254961002649
+42	-0.0008807850662261092
+42	0.019642376013103032
+42	0.013933304897221872
+42	0.00532033555359482
+42	0.007078884647190184
+42	0.024880568935899766
+42	-0.018404693060283903
+42	0.006713191887241225
+42	-0.012519803339920985
+42	-0.01230134149377586
+42	-0.00927742286539617
+42	-0.012940843987023628
+42	0.022880705005259364
+42	0.017463765806356966
+42	0.022322231793788273
+42	0.007035301736565399
+42	-0.015589349416808637
+42	-0.022750143923613405
+42	-0.004424683559711605
+42	-0.016394850110151786
+42	-0.0019146424302465717
+42	0.034253252707020496
+42	0.012047435950502621
+42	-0.005545367454434328
+42	0.003827213271928341
+42	0.01373562595796928
+42	0.005990971331908859
+42	-0.02568701713697746
+42	0.0076211263801605035
+42	-0.008280997335729146
+42	-0.003745944930767553
+42	0.01697611479833347
+42	-0.001913751928380258
+42	-0.03608923305873282
+42	0.02909042515263566
+42	-0.010817317308562469
+42	0.03884575582245173
+42	-0.01278061681728922
+42	0.00045416493089274354
+42	-0.005501673793322448
+42	0.012493051097328269
+42	0.009585941739312959
+42	0.015157516158722044
+42	-0.005378984041034036
+42	-0.004168295783736754
+42	0.031423629648218064
+42	-0.00489404340622223
+42	-0.0025014548967663116
+42	-0.013384462774202794
+42	0.000978505421545094
+42	0.004831283731323492
+42	-0.011373094254534692
+42	0.004431531592531493
+42	-0.014115858841230004
+42	-0.02070582326628662
+42	0.01263133814786681
+42	0.019321693284271035
+42	0.011065709072408093
+42	-0.00048816595193310736
+42	0.025743117194581493
+42	0.03254226674104599
+42	0.025432354282826804
+42	-0.009462227640138328
+42	-0.00416535102413749
+42	0.008483364186116855
+42	0.002912955356634226
+42	0.010001081043336494
+42	-0.002244856546579818
+42	-0.0028922832204216473
+42	0.03129836863855347
+42	0.013722777285107854
+42	0.005092027647394924
+42	0.033981921307417444
+42	0.013006839914855363
+42	0.01752588469634014
+42	-0.007940831202286575
+42	0.0013517676302696572
+42	0.017321296822241688
+42	-0.009591000192886029
+42	0.002781439357753214
+42	0.018159484308262624
+42	-0.010680845410545259
+42	-0.00018283789046439033
+42	-0.008779303262400817
+42	-0.0382360823577265
+42	0.02567359549448765
+42	-0.019547391757501753
+42	0.00453929414360437
+42	0.006815602724718914
+42	-0.005979734038721777
+42	0.013254424826715423
+42	0.005035908985360189
+42	0.011099531750463774
+42	0.030788479174719614
+42	0.012199154449035467
+42	-0.0010059235711216256
+42	0.01362867647080617
+42	0.01499445288967469
+42	0.02992088276760899
+42	0.02671577085157164
+42	0.013095700990227584
+42	0.00041293944351616284
+42	0.015493367438700502
+42	-0.0009336480213109604
+42	-0.01424446508356018
+42	0.02648881256312216
+42	0.033651191024307046
+42	0.006148357179046479
+42	0.011609465498994772
+42	0.003307822713872837
+42	-0.0014024906729462573
+42	0.04095108085272303
+42	0.038852503500938364
+42	0.011062912299667155
+42	0.003238594769798592
+42	0.018263516957336662
+42	0.014873643109456405
+42	0.015650754430444763
+42	0.03225211925112558
+42	0.0154885787567624
+42	0.02529283996182813
+42	-0.01820452457659955
+42	-0.017021802218700272
+42	-0.012404086948700965
+42	0.03562869594067949
+42	-0.03573466095491672
+42	0.015176691987614264
+42	-0.01290883829463861
+42	0.015021277365965747
+42	0.016676349306849112
+42	-0.004442327080002289
+42	-0.005099500326360976
+42	0.011076645006606083
+42	-0.004218635865766391
+42	-0.001248193739240693
+42	0.0006909155320854636
+42	0.034669923323461777
+42	-0.004698588743937996
+42	0.01696285519931471
+42	0.019939276615266635
+42	0.03197457907984596
+42	0.0023236087405626403
+42	-0.01090991351930392
+42	-0.001277870400817257
+42	0.0034973988697273024
+42	-0.0076449887136154655
+42	0.01647367326516403
+42	0.026136644024950164
+42	0.01449373898604102
+42	0.0034764912408078194
+42	0.038885460453255694
+42	0.0035112434815278
+42	-0.0110946175046059
+42	0.008025913521519597
+42	-0.009741503921099721
+42	0.0012953376366538814
+42	0.011710469086153214
+42	0.025613237893735347
+42	0.004772550839421129
+42	-0.015861618146874798
+42	0.015522334187966386
+42	0.013164784044023358
+42	0.02553560595343701
+42	-0.023533217873313632
+42	-0.0222644290448287
+42	-0.02285228147435226
+42	0.006114782029267906
+42	-0.01155444254587132
+42	-0.013978752188669659
+42	-0.006865458843739315
+42	0.005173390912257768
+42	0.010813661700023456
+42	0.002391876294550052
+42	0.004517076753674323
+42	0.015447558614082188
+42	-0.004755621856807972
+42	0.004228129259691718
+42	0.006652858873895047
+42	0.007028609515179383
+42	-0.025507615900847366
+42	-0.033557105007680894
+42	0.0024853106756910683
+42	-0.000515486746317464
+42	0.004866662197583605
+42	-0.0017802225682034404
+42	0.009185874272083948
+42	0.0126116928146609
+42	0.0087643586140719
+42	0.027398938140588972
+42	0.037993284316352585
+42	-0.030528258204316268
+42	0.0065747793282436694
+42	0.004088760761013523
+42	-0.018937480597676377
+42	0.014767642820669466
+42	-0.01093085742991834
+42	0.01726333837978443
+42	0.023578121831336188
+42	0.019678506194111614
+42	0.030830149415917343
+42	0.032612123660268895
+42	0.025073889674983217
+42	-0.00967698299565433
+42	-0.00990316792871353
+42	-0.04807326072982474
+42	0.006317435444699529
+42	-0.015425993377325703
+42	-0.0075422266437707546
+42	0.00735324308912638
+42	-0.023892564974041994
+42	-0.01742964476396853
+42	0.0035849543904979612
+42	-0.0070505111084745485
+42	0.008237444291002564
+42	0.0010424691479039756
+42	0.021886179343950523
+42	-0.01884501270224138
+42	0.025732741883239197
+42	0.01461854774407833
+42	0.001896991039893229
+42	0.015502452494523124
+42	0.02697466730532878
+42	0.02186433755161327
+42	0.010994204783946537
+42	0.02603680805113845
+42	-0.005195565493116614
+42	0.010966314118141664
+42	0.024520346572196983
+42	0.01126450903746227
+42	-0.008872555460658746
+42	-0.012207858695110672
+42	0.014245541585231457
+42	0.01916161764188224
+42	0.022220770046667903
+42	-0.02735976014256081
+42	0.013199373078873188
+42	0.03209336829210712
+42	0.023941760467368664
+42	0.028914994217108272
+42	0.009016344885403866
+42	-0.007863605959061182
+42	-0.00506737592325032
+42	0.012191375927306363
+42	-0.010322485050950401
+42	0.010170349467555665
+42	0.03030586346062547
+42	0.03349671952319819
+42	0.01395588274693218
+42	0.0030324703048021716
+42	0.013276292204497515
+42	0.01897939663482277
+42	0.015903943748977332
+42	0.007424851150291079
+42	0.02113581523597283
+42	0.025785915021464087
+42	0.015085943001953678
+42	0.005213320166506715
+42	0.009406000184362303
+42	0.0004669945948951657
+42	0.028098076103323388
+42	0.043914830514331066
+42	0.010403144655958952
+42	-0.012248626012917712
+42	0.01166458802322513
+42	-0.020282500737815436
+42	0.004248040619520154
+42	0.01545317840293299
+42	0.012113120360526834
+42	0.023701397905448892
+42	0.020190329458112236
+42	0.018245660521721375
+42	-0.0038508759492738606
+42	0.006592819375456374
+42	0.0034546315302438745
+42	-0.015407424805508682
+42	0.025642784267319387
+42	0.01378040175631944
+42	0.010047195367638649
+42	-0.03392063593280139
+42	-0.035382131174965
+42	0.014182948803001487
+42	-0.011480812368864557
+42	0.011646751591424734
+42	-0.009565700659551002
+42	0.017624524188338615
+42	-0.003187469506295987
+42	-0.004564688937624526
+42	-0.037851135138027306
+42	0.006188760100942186
+42	0.03686843831924055
+42	-0.04322509651974849
+42	0.022589466604223698
+42	0.00039912354002996756
+42	0.01284978247212905
+42	0.005807563231361909
+42	0.004595878081917038
+42	0.007155119295067293
+42	0.02977581262614886
+42	0.01809330453719959
+42	0.01505205775533237
+42	0.0014520020246004779
+42	-0.0003721424026684729
+42	0.007529627052095305
+42	0.009054227445761372
+42	0.008696940722717605
+42	0.001180079500564156
+42	0.011906918687929714
+42	0.018358122200579217
+42	0.01506120517784361
+42	0.02096297803219858
+42	-0.005188154258995003
+42	-0.00603890612900787
+42	0.020970359881960353
+42	0.007997791206960739
+42	0.0008347379303922499
+42	0.012502952589462627
+42	-0.021272900931201728
+42	0.020941142234741004
+42	0.012031442383808504
+42	-0.008909889695181649
+42	0.00921355111769791
+42	-0.014076044757311893
+42	0.015470592287822481
+42	-0.004259637803375547
+42	0.011359664179238822
+42	0.0077965488388694795
+42	0.0034543295006838255
+42	0.010627574523310717
+42	0.026916314144206862
+42	-0.009494611335900438
+42	-0.006329220786443503
+42	-0.008610847749074373
+42	0.029253302757174356
+42	0.016859563175047672
+42	0.042413624549137045
+42	0.04407739689844559
+42	0.026787473576643725
+42	0.007784849503077376
+42	-0.012357188993001178
+42	-0.004152669798180723
+42	-0.004913668044435572
+42	-0.002647383614606468
+42	0.010920749817897164
+42	0.010497301190047525
+42	0.04621803526309587
+42	0.012536274142419809
+42	0.029926304085794664
+42	-0.00043624515565170586
+42	0.018345626104979574
+42	0.021908158581007295
+42	-0.01395742230059649
+42	-0.02228277863894636
+42	-0.014203891866587439
+42	-0.011822807302693153
+42	-0.0323104546861167
+42	-0.012371282451817978
+42	0.015278618277910464
+42	-0.017782252112559734
+42	-0.039134605294909315
+42	0.020222593908163153
+42	0.008201297770797438
+49	-0.014098556470778793
+49	0.009116559012178688
+49	0.026135271646530258
+49	0.020387109648165178
+49	0.01247394437007275
+49	0.00780569274919912
+49	0.028523483658584297
+49	-0.01560401287823339
+49	0.012366695720104948
+49	-0.008534564833077678
+49	-0.0022110482438381985
+49	0.004087227531171142
+49	0.005636038863498726
+49	0.020459398877706668
+49	0.02407800345817511
+49	0.029413034175873008
+49	0.017611989437575745
+49	-0.009285500066864306
+49	-0.01808157308264479
+49	0.004379209817858366
+49	-0.001643805321086037
+49	0.008139602332571058
+49	0.03312824442344374
+49	0.013269742441295742
+49	0.0015400421952359122
+49	0.011220230281261727
+49	0.019840269796577117
+49	0.010343199828578809
+49	-0.02110805879259072
+49	0.009880694336787874
+49	-0.0036053924209447684
+49	-0.0001962784914079271
+49	0.019199857922275482
+49	0.00604382821253686
+49	-0.026900703812659847
+49	0.04437631440661619
+49	0.0023778736633654047
+49	0.04385208767865335
+49	-0.005149177884463029
+49	0.0040770643709157565
+49	0.004881773391021355
+49	0.021680314211129138
+49	0.012444465878091691
+49	0.009003399500080056
+49	0.0017755229214886867
+49	0.005797589394720611
+49	0.04336735561438252
+49	-0.0006708503998466624
+49	-0.004378316204694526
+49	-0.00815445621267155
+49	0.005984819288926098
+49	0.017749628067830696
+49	-0.0007354199734068458
+49	0.021875836690265014
+49	-0.007004436038712428
+49	-0.024741397874734318
+49	0.0150498799451509
+49	0.02476565581965422
+49	0.018378495114882914
+49	0.0023092194300890997
+49	0.026648470847514864
+49	0.03286988070065374
+49	0.03431803615034585
+49	-0.000866286839143066
+49	0.0030812376105507256
+49	0.015545488491533602
+49	0.005319766474877702
+49	0.021468027232254428
+49	0.006854161108079943
+49	0.005443396588957102
+49	0.037643801622230015
+49	0.019442467451184945
+49	0.009387579758893446
+49	0.04208852876292282
+49	0.01223104445515506
+49	0.017945576821048716
+49	-0.0024519037824203282
+49	0.011303933298976327
+49	0.021857138443162675
+49	-0.004086369213300747
+49	0.009766040677970893
+49	0.03267930463953185
+49	-0.004779520801014541
+49	0.010330341693912313
+49	0.008090368067148673
+49	-0.03173239489672348
+49	0.013114501358976835
+49	-0.01522162342446717
+49	0.009502295255076062
+49	0.017664206996338284
+49	0.0017084584109872231
+49	0.014191912654335842
+49	0.007904029127376627
+49	0.018386740289282635
+49	0.03602366441638525
+49	0.022698043655563025
+49	0.0011252267777983884
+49	0.024106075410545207
+49	0.018431600081189988
+49	0.037794644325312654
+49	0.0314319010584454
+49	0.018057363723733674
+49	0.003901189997597332
+49	0.019315347039670056
+49	0.0054561501155126315
+49	-0.015956005828555365
+49	0.028615420301303995
+49	0.036226602969267156
+49	0.009710743194429227
+49	0.019803443395691765
+49	0.007210502956027375
+49	0.010274968816979905
+49	0.047820892501474296
+49	0.05244971207087124
+49	0.023629079148225304
+49	0.009082347097036796
+49	0.019665981750076802
+49	0.018008871516258823
+49	0.022294623328301077
+49	0.03527600485255371
+49	0.023472739669702883
+49	0.026830791309469176
+49	-0.01497811980862275
+49	-0.015028689041412758
+49	-0.005933368786647402
+49	0.03772727086591981
+49	-0.021828952724587482
+49	0.02075746208722771
+49	-0.009262004182272195
+49	0.02024662046621433
+49	0.019318370190465253
+49	-0.005130795411816586
+49	-0.0013381315824811011
+49	0.023398458032977423
+49	0.014396864790844876
+49	0.006210740219192338
+49	0.0027049035093605653
+49	0.04403001662574957
+49	0.005871106267863801
+49	0.024779659939081784
+49	0.025348814250695434
+49	0.03684613647226727
+49	0.004127933436025142
+49	-0.009458756570435406
+49	0.008388476441381607
+49	0.007748373410251609
+49	0.006116857377947441
+49	0.019993558170979153
+49	0.03339631629132834
+49	0.024812605179287614
+49	0.013103343765627593
+49	0.045608559439669
+49	0.010036227663176774
+49	-0.006697464601913391
+49	0.00657116047324977
+49	-0.008101840662680167
+49	0.007312416397170564
+49	0.018214436486021602
+49	0.03380133888494374
+49	0.014497903480983561
+49	0.0010540876076045019
+49	0.009816228790413736
+49	0.007894731497147513
+49	0.029918729532064644
+49	-0.015720466528925964
+49	-0.01365476674841984
+49	-0.018743480321564733
+49	0.010884941025834875
+49	-0.008212520029142219
+49	-0.0017705760778753427
+49	-0.007519421242789265
+49	0.0072011037852994664
+49	0.010509024326347328
+49	-0.00337044955317766
+49	0.00540613879961324
+49	0.01903634796527066
+49	0.013068291068131729
+49	0.00559941023872089
+49	0.003308210832914103
+49	0.008019012010792295
+49	-0.0212742092371478
+49	-0.03070722695096846
+49	0.005669140504230329
+49	0.0027188553288367656
+49	0.00671748998861451
+49	0.007428088026441323
+49	0.004948050560943658
+49	0.013987818753448216
+49	0.005721844296436997
+49	0.035598031121994674
+49	0.050672622541637014
+49	-0.029251495979835163
+49	0.012449647225124713
+49	0.016177738883089005
+49	-0.017771078507031378
+49	0.011377642378242056
+49	-0.0028884279843835684
+49	0.019795169894538025
+49	0.030032412544126235
+49	0.021536363851530262
+49	0.03372798698834522
+49	0.042711780448509186
+49	0.031730374760498524
+49	-0.01148964592410905
+49	-0.0018025024522064024
+49	-0.050549600039595896
+49	0.010818011290059016
+49	-0.01703193466588126
+49	-0.0016181958823249516
+49	0.008938989628250174
+49	-0.027598560989990528
+49	-0.02157019871064291
+49	0.004358791328892287
+49	-0.005258078732795767
+49	0.007862405699074784
+49	0.004923207253372353
+49	0.028128186892509247
+49	-0.0031121158331661914
+49	0.02753349315983612
+49	0.02151336592663292
+49	0.00170153295481183
+49	0.02461984056903692
+49	0.03394662765410263
+49	0.027130237737091393
+49	0.016154198276285302
+49	0.030096623098482
+49	0.011643923892398551
+49	0.011085596180863369
+49	0.024875731940325992
+49	0.0073238830547255294
+49	-0.005086936856893887
+49	-0.008412688265517167
+49	0.024910661692997847
+49	0.03018681335663347
+49	0.027203733449117327
+49	-0.031941218240132845
+49	0.013768170346406405
+49	0.03372788321778436
+49	0.03124336204805631
+49	0.03503090493477926
+49	0.01260487768804856
+49	-0.002353931469273183
+49	0.0017409985038434877
+49	0.0060839018984279415
+49	0.003759265178157167
+49	0.021488943334053087
+49	0.036725204775929166
+49	0.03796755768848418
+49	0.028668347159097447
+49	0.010166663921666983
+49	0.022391210681122237
+49	0.0269804447014909
+49	0.024031186220726617
+49	0.019816081446602244
+49	0.03334470832445524
+49	0.03344799077338242
+49	0.016151579743357
+49	0.01887531144965604
+49	0.011777758965579995
+49	0.01061909447989007
+49	0.0351709582545651
+49	0.04473283752879283
+49	0.005896587995677897
+49	-0.004666293825706038
+49	0.009459141946321881
+49	-0.011020391784553076
+49	0.023944499591644613
+49	0.02174587607647518
+49	0.01066436395324946
+49	0.04004741128808007
+49	0.025200460345961354
+49	0.022753054008380996
+49	0.0033177008132902453
+49	0.018396957416668035
+49	0.005931080997570004
+49	-0.005134716454398223
+49	0.0299487513803428
+49	0.015329571487096962
+49	0.019462763245578277
+49	-0.027205428134312197
+49	-0.030946521629279283
+49	0.014009471714825437
+49	-0.012875056194033016
+49	0.01665612102024997
+49	-0.007931954972722402
+49	0.023232076001103066
+49	-0.0034836362720833355
+49	-0.006608510902788811
+49	-0.033416461703321645
+49	0.007594444135966265
+49	0.038470234938937795
+49	-0.034221208470747534
+49	0.031797488079272386
+49	0.004392841078171782
+49	0.01980243262964167
+49	0.0074701019860445046
+49	0.013490815734664202
+49	0.010996949419861566
+49	0.025770385200957487
+49	0.022469439351178067
+49	0.028699714890921515
+49	0.0048606782139188984
+49	0.007209183877687114
+49	0.00917466341731068
+49	0.014800451287136723
+49	0.007719240436628987
+49	-0.00168000359737112
+49	0.011337604384268762
+49	0.021867078508264644
+49	0.02005069545344393
+49	0.027165987469825188
+49	0.0027897185128234964
+49	0.0032251186894936973
+49	0.02193554935975497
+49	0.006256511057671339
+49	0.01124826835587502
+49	0.01308514479362792
+49	-0.011737299061265083
+49	0.024194705171013294
+49	0.014164563862061675
+49	0.003628705012257645
+49	0.02282898239032941
+49	-0.015569164476555828
+49	0.023087229230289878
+49	0.0027667984658115465
+49	0.012179243652926719
+49	0.015432042813987133
+49	0.00973008038679729
+49	0.023637353367616104
+49	0.0385999919276097
+49	-0.009646279172263161
+49	0.0026566352623414034
+49	0.0027774903688732575
+49	0.03386072352724311
+49	0.01928326487934217
+49	0.046889422232552144
+49	0.04935300403980471
+49	0.035452700633951
+49	0.012938707770966638
+49	-0.005521427386041345
+49	0.002286158179889633
+49	0.007406167559263713
+49	0.0038924314383083198
+49	0.011758316500265403
+49	0.025963148047277996
+49	0.05932337303028816
+49	0.016289878379217988
+49	0.030237266865080867
+49	0.006797280564188387
+49	0.021353419548606298
+49	0.028382198028455992
+49	-0.007647642367788473
+49	-0.017467064870441387
+49	-0.0036434090512362147
+49	-0.012553755653675355
+49	-0.029369972095166858
+49	-0.004770390165954712
+49	0.020526837944198587
+49	-0.010066979706571715
+49	-0.033398898930833615
+49	0.021531179172819277
+49	0.011503030963337981
+26	-0.0130692123821104
+26	-0.001475582109518738
+26	0.008123445963120913
+26	0.016745801316307533
+26	0.001383801736443576
+26	-0.003154841792516912
+26	0.0145915978343673
+26	-0.02257062265593066
+26	0.003609044362990244
+26	-0.018142638468828923
+26	-0.013053286369632109
+26	-0.002751942688229756
+26	-0.008596883158318613
+26	-0.0003721980291643097
+26	0.023334083878972876
+26	0.029296322096341094
+26	0.01338641294674689
+26	-0.01843571820945706
+26	-0.020148233586814033
+26	-0.009985830205132782
+26	-0.014171365700797115
+26	-0.008564827760899726
+26	0.02287016757294395
+26	-0.004927448239968851
+26	-0.008913477910790743
+26	-0.002074570600500818
+26	0.009920451604686095
+26	-0.001002478712025405
+26	-0.03407777965736342
+26	-0.003474448278093094
+26	-0.013253516227255902
+26	-0.0066338998173459595
+26	0.011314622713496076
+26	-0.0007578261294796133
+26	-0.03699474516471296
+26	0.02714509140452174
+26	-0.008641624387245155
+26	0.04010482063694484
+26	-0.019861856532749658
+26	-0.0007088010232795412
+26	0.005577590990575631
+26	0.015640612727857085
+26	0.0018055238250541759
+26	0.015174837326622052
+26	-0.0017619041108106633
+26	-0.006078395383825723
+26	0.04190329203202524
+26	-0.011917643098691788
+26	-0.013368848940840374
+26	-0.008872066392825069
+26	0.00037058052873304494
+26	0.022272743700705214
+26	-0.016113051050207557
+26	0.012066823147573867
+26	-0.019222433366926646
+26	-0.027575875350490445
+26	0.013576687688374417
+26	0.02277237525163482
+26	0.011634029452041788
+26	0.0030080660662982132
+26	0.019548299578928664
+26	0.022901597860749738
+26	0.025397029033487107
+26	-0.003481915404977094
+26	-0.011979053427885918
+26	-0.004335564547609283
+26	-0.007868385741658395
+26	0.010688461596811269
+26	0.0019686179195658026
+26	-0.006818121731656358
+26	0.03312182041645218
+26	0.010707889135488757
+26	-0.006885189291169781
+26	0.03188572848585995
+26	0.008979909401304775
+26	0.006981593283890365
+26	0.013557476890618382
+26	0.004131332172775908
+26	0.013308515275194208
+26	-0.019513549998994555
+26	-0.0030349755310430907
+26	0.016901614604686442
+26	-0.014109363714791701
+26	0.005526213191505359
+26	-0.009253056300515258
+26	-0.02033470448212176
+26	0.012686732060280037
+26	-0.015601062247368357
+26	0.0013791631847229072
+26	0.003110210955066779
+26	-0.0060937233118095666
+26	0.008063014688018323
+26	0.005531254238137133
+26	0.016777679589849482
+26	0.03264409699943839
+26	0.005935797494211655
+26	-0.012880846157559184
+26	0.010682216469531491
+26	0.006340475153258705
+26	0.03094147010814955
+26	0.022133229114291816
+26	0.009648258259679746
+26	-0.007028010420955845
+26	0.010005378145321668
+26	-0.0060991334531079345
+26	-0.019720301439796004
+26	0.015122157361033424
+26	0.03023190381787678
+26	-0.0007285435528496714
+26	0.009877140128978092
+26	-0.00030638915340216587
+26	-0.0010079240301317442
+26	0.047573575131722015
+26	0.03431666825784834
+26	0.008128122053443978
+26	-0.005546270931785112
+26	0.010525367088656767
+26	0.0016234609475630844
+26	0.01980945288483464
+26	0.014023931196987187
+26	0.009039084889993573
+26	0.019703974267049305
+26	-0.00587722623311503
+26	-0.020430897913799637
+26	-0.014610860916093324
+26	0.03530906394940142
+26	-0.030677121276088425
+26	0.01492817392549372
+26	-0.018040099496377266
+26	0.008643832485132313
+26	0.015726303783222748
+26	-0.018457501046830964
+26	-0.013087456636170195
+26	0.019925334146448613
+26	0.004843891732567609
+26	-0.005640677127480473
+26	-0.0006685782693620129
+26	0.03186354978727946
+26	0.004456241321496663
+26	0.026201861041895848
+26	0.015638984968443435
+26	0.027896718233294857
+26	-0.0008852362299802212
+26	-0.01330287449317005
+26	0.0019230491786378957
+26	0.004554252521949739
+26	0.0006486773999714232
+26	0.008177470357662699
+26	0.019209964550317267
+26	0.01699475666709516
+26	0.0005772788894361285
+26	0.03999988734136115
+26	-0.003753256664008284
+26	-0.014924741748488872
+26	0.0028579498960954286
+26	-0.018454541970395092
+26	0.00660512153768525
+26	0.014754593960988615
+26	0.027125384221172943
+26	0.014900697280365499
+26	-0.008482898924313392
+26	0.008880911967594022
+26	0.00937521289585194
+26	0.020595052062339934
+26	-0.017058249486111506
+26	-0.023091238435221366
+26	-0.03099711290359423
+26	-0.0014270818197070897
+26	-0.018295171365989495
+26	-0.004350448077264692
+26	-0.011086609453192682
+26	-0.005463261667718176
+26	-0.0035416573206748
+26	-0.00436548898303581
+26	0.012143768231871197
+26	0.011831801010841712
+26	-0.006268900961049956
+26	-0.0021964716423244564
+26	-0.00791074478570924
+26	-0.0009407354441756042
+26	-0.031192677286046157
+26	-0.04459044662302229
+26	-0.006979024924954139
+26	-0.004615447432607388
+26	-0.0014851132626738123
+26	-0.015757360454611118
+26	-0.0008934430274891696
+26	0.010917290488674762
+26	-0.00819856919433265
+26	0.020494364406178644
+26	0.051374453907852995
+26	-0.039032932343891255
+26	0.0002005823083530992
+26	-0.005316790609100842
+26	-0.04201348827875602
+26	0.00643589566372266
+26	-0.010677420045350765
+26	0.011387936419084848
+26	0.022998620379270328
+26	0.01462008105404291
+26	0.022899003543170274
+26	0.03265109676119657
+26	0.02133107997055745
+26	-0.029788928157382228
+26	-0.015604044231043439
+26	-0.056069709182935246
+26	0.008060511575660732
+26	-0.021853247305586528
+26	-0.009329631119925247
+26	0.001116269922956024
+26	-0.0317693944598912
+26	-0.03325725438573426
+26	-0.0010197185954155378
+26	-0.01692035089328863
+26	0.004098766125203495
+26	-0.0037077976054178093
+26	0.01936237978972245
+26	-0.01677716133504811
+26	0.023487909990052503
+26	0.007537335432569332
+26	-0.002890700200675308
+26	0.01790291390415815
+26	0.025711196709883716
+26	0.01635077003533466
+26	0.004446174442698161
+26	0.020540435506753486
+26	0.00684050223324721
+26	0.00436525400808896
+26	0.016276892352639263
+26	0.014902084437827423
+26	-0.007111133165469561
+26	-0.009797017896016334
+26	0.009926483312023593
+26	0.010869158521752196
+26	0.012413503199063309
+26	-0.03332725748439661
+26	0.006885344370808178
+26	0.02412713992674424
+26	0.02011531655307686
+26	0.03346051270398857
+26	0.009415845429907291
+26	-0.016341318843871844
+26	-0.016407365539901284
+26	0.006494027639627116
+26	-0.005376589150328762
+26	0.016222938305487974
+26	0.022912156394087536
+26	0.014767522476573442
+26	0.022152839408847352
+26	-0.001805389102256853
+26	0.025882224756787513
+26	0.018780504435971106
+26	0.014937747552966736
+26	0.003799992672645762
+26	0.023050352504107117
+26	0.024893649095505645
+26	0.010200545454113169
+26	0.0018014533140080433
+26	0.010057819665148966
+26	0.006823714363309534
+26	0.028464564904121626
+26	0.038701227136908524
+26	0.00241735947595942
+26	-0.02607540141982278
+26	-0.002119535707191995
+26	-0.019656848188182384
+26	0.012185026133992204
+26	0.005648662236312254
+26	0.007408801535431595
+26	0.029503801310255092
+26	0.01209890544473652
+26	0.01681013494654182
+26	-0.009635276460104031
+26	0.00408096781566665
+26	0.00032440491474399266
+26	-0.019428361981442658
+26	0.014189479922902811
+26	0.00625995637873961
+26	-0.0010355135474680766
+26	-0.03763155193749439
+26	-0.03209114190351535
+26	0.008344095558375687
+26	-0.009628404322988374
+26	0.002328654668711733
+26	-0.010736070941178668
+26	0.007740076459586673
+26	-0.003953747387368795
+26	-0.009998239323004641
+26	-0.03982237776595917
+26	-0.0016696141780682828
+26	0.019694748811747778
+26	-0.03676116312567351
+26	0.02681826806785049
+26	-0.0006343816596519725
+26	0.010506405185377281
+26	-0.0023210794557598892
+26	0.010870608385871198
+26	0.002096640623479954
+26	0.020971223648012502
+26	0.012195836414241384
+26	0.016918967337233942
+26	-0.005213373492667098
+26	-0.008402521033915112
+26	0.0032080025801324292
+26	0.007347084754093156
+26	-0.00020565127973798007
+26	-0.011528058772570234
+26	0.006209084289446322
+26	0.010739718768808762
+26	0.008898262944751273
+26	0.014306519926633456
+26	-0.008936001840391117
+26	0.0014782076830735002
+26	0.007384584473331538
+26	-0.0020383755903871435
+26	-0.0063954214404326575
+26	-0.00458017887093167
+26	-0.01513573949636711
+26	0.009761308888744772
+26	0.005882531115371774
+26	-0.005345558813730764
+26	0.018851413064382188
+26	-0.012669289155914431
+26	0.018737340673017043
+26	-0.013003406363943709
+26	0.0006488680343694486
+26	-0.0006616555083800072
+26	0.0012907387956071277
+26	0.013915649963733717
+26	0.017899658341562395
+26	-0.026044047231879763
+26	-0.0084310118514459
+26	-0.015456862102242336
+26	0.04073339193672806
+26	0.012348249211805927
+26	0.03869356096108543
+26	0.03698165103266159
+26	0.03197078115307489
+26	0.0012417301497212765
+26	-0.019703776767683485
+26	-0.011451673480533942
+26	-0.0026043502741465146
+26	-0.018010667431738524
+26	0.0015192851423904484
+26	0.0029772597471930187
+26	0.0509606989589389
+26	0.014840307346120043
+26	0.029589283364096396
+26	0.011061461473985101
+26	0.009858347716917137
+26	0.020527665522586162
+26	-0.019284497933122036
+26	-0.026995242061437684
+26	-0.015963296389928786
+26	-0.016574274163014976
+26	-0.03642067981886125
+26	-0.010025541890105395
+26	0.01954577320993992
+26	-0.02273398229861155
+26	-0.03781814134852658
+26	0.013935623603548332
+26	0.008807156187293616
+28	-0.008477709875401546
+28	0.004034441022623795
+28	0.011102295123636873
+28	0.011766527708522673
+28	0.016786443022230285
+28	0.009605076021355557
+28	0.02352433527565855
+28	-0.013077193065944981
+28	0.00845232764216425
+28	-0.0068086344753720005
+28	-0.0011150596451015228
+28	0.006284034310721257
+28	-0.004490114772072046
+28	0.011921349590851733
+28	0.024359935967314967
+28	0.025445678878598305
+28	0.006605936228014105
+28	-0.015530313824331324
+28	-0.02199455026035995
+28	-0.0015392574505606754
+28	-0.011832276142279326
+28	0.00028729259863611304
+28	0.03250460017939117
+28	0.006120735190546491
+28	-6.739124381674169e-05
+28	0.01292796901143385
+28	0.02301678563841584
+28	0.0032241588703774628
+28	-0.02242462856584085
+28	0.005548607787617814
+28	-0.0006893667762068514
+28	-0.0010064631349732927
+28	0.015168690002653907
+28	0.006422433000873985
+28	-0.026623091323077025
+28	0.035562006961963315
+28	0.002043190007286052
+28	0.03419667748807962
+28	-0.009403967648059368
+28	0.002552767917307235
+28	-0.00029266009628365497
+28	0.020905671520127504
+28	0.007275544591356422
+28	0.004231558152538901
+28	-0.0014559514896329343
+28	0.004837676818854628
+28	0.04106700461073189
+28	-0.007494982393976612
+28	-0.010849932086788135
+28	-0.013397551657253924
+28	0.0011867172842254638
+28	0.02124374649762156
+28	0.004328413792832126
+28	0.019875215051306273
+28	-0.00498843517983036
+28	-0.024179696060659922
+28	0.01922677597751211
+28	0.020275499526110848
+28	0.02059109442617539
+28	0.008071596677431974
+28	0.028351744512405023
+28	0.03291944535434627
+28	0.027388528086400597
+28	0.00571978046435565
+28	0.007007680838209616
+28	0.013831399731242651
+28	0.00930912739965144
+28	0.024136054288498698
+28	0.009447205140028945
+28	0.012484209114431561
+28	0.041167430083415085
+28	0.01680124505573372
+28	0.006799078377154487
+28	0.036921609690376896
+28	0.013511346209793842
+28	0.030178627203507623
+28	0.002701505182608266
+28	0.017670238262856488
+28	0.0188818150592872
+28	-0.006095852639850462
+28	0.00216139380702763
+28	0.025978640988645732
+28	-0.005725907975598018
+28	0.012202849667291552
+28	0.009487302859315632
+28	-0.021034214173973824
+28	0.012224036441566506
+28	-0.01798366697958655
+28	0.010640768064122626
+28	0.009592460928545824
+28	-0.00046872871789161737
+28	0.01750094040643329
+28	0.008890194002676837
+28	0.02061955408653593
+28	0.036952562880356046
+28	0.02102500638513957
+28	0.0012876404638245023
+28	0.02233567383436418
+28	0.017332573382282446
+28	0.03551760425816517
+28	0.03391508262351784
+28	0.01986284005488635
+28	0.0012597172720256802
+28	0.016155360608990175
+28	0.007073433151004407
+28	-0.018784957383874964
+28	0.02835766046887896
+28	0.03633485578503153
+28	0.009378858170480644
+28	0.017330449550363326
+28	0.012610298205206791
+28	0.004714850908032303
+28	0.0518835987182292
+28	0.04817218056999533
+28	0.02352777115686753
+28	0.012618116964105664
+28	0.02357332742925884
+28	0.004993658424043252
+28	0.02432759093516337
+28	0.026867042647827313
+28	0.014312449256260169
+28	0.02691723305914614
+28	-0.004805884106268574
+28	-0.014037981987001347
+28	-0.0046711334816272
+28	0.04053919150525299
+28	-0.021811534203570147
+28	0.02096606451483465
+28	-0.00474879919966526
+28	0.019806615132510506
+28	0.02115308466422701
+28	-0.0016885383964022175
+28	-0.011152418777078482
+28	0.02091291550723596
+28	0.012213054383183753
+28	0.003681768325045847
+28	-0.0047782160484710285
+28	0.04181150136292133
+28	0.0009830424715720817
+28	0.02332977986577608
+28	0.02677556450754887
+28	0.033704173491273796
+28	0.0022652033527256117
+28	-0.005677341194051179
+28	0.0028952448334232297
+28	0.0015364729898898828
+28	0.001975830185061543
+28	0.014431535961854565
+28	0.024517610951534995
+28	0.016085798428557146
+28	0.0074269555067061665
+28	0.040925373370523425
+28	0.00604186922228213
+28	-0.010567998202780367
+28	0.00843094853037946
+28	-0.004410196970264255
+28	0.008998492921578252
+28	0.013325965177834697
+28	0.03680646269560662
+28	0.01362104565158201
+28	-0.004868254770720951
+28	0.001997734215572663
+28	0.011332245715362708
+28	0.03453652434596326
+28	-0.013616167157719804
+28	-0.008868752390297392
+28	-0.022301636046173672
+28	0.006738327092214103
+28	-0.0027957718423304396
+28	0.0030023856375367905
+28	-0.009604278562921101
+28	0.002525006530868908
+28	0.004165991920401933
+28	-0.008974983773555652
+28	0.00322159202266759
+28	0.02220779330250878
+28	0.0019488873882795217
+28	0.0037147723236991828
+28	0.002455169307593727
+28	0.011485812282719651
+28	-0.017164586382310342
+28	-0.030853654988770428
+28	0.0021409941249033826
+28	0.007002963259987702
+28	0.005201591821831523
+28	-0.0010870074104421716
+28	0.007138044004774735
+28	0.013016933234123977
+28	0.007180910489666364
+28	0.03268294309438336
+28	0.050747373842103836
+28	-0.025996945690239526
+28	0.0017007030803999406
+28	0.017273922355619323
+28	-0.019036325621805253
+28	0.007013367176899799
+28	-0.0026966114469024445
+28	0.02208471397308729
+28	0.026777952833964485
+28	0.023018106630666512
+28	0.03088930434865701
+28	0.0399424448884886
+28	0.02782177081685323
+28	-0.009534132758280373
+28	-0.005177302835026257
+28	-0.04359399741760102
+28	0.018987122382747204
+28	-0.01629006905886586
+28	-0.006102983929603103
+28	0.0074350011172771195
+28	-0.02828960281048015
+28	-0.021131765818221824
+28	0.006616435507678437
+28	-0.007849991238094524
+28	0.008784361352828797
+28	0.0011311483558363819
+28	0.027027014967903745
+28	-0.005070086169636167
+28	0.02414179581335501
+28	0.015813020574455588
+28	0.010956942447390648
+28	0.023989736403527816
+28	0.03181232247519995
+28	0.02229782923142533
+28	0.015425620447012092
+28	0.025699549885301945
+28	0.0081903554415558
+28	0.013974332803766885
+28	0.020244084418896552
+28	0.009497510381260893
+28	-0.0021259620304939397
+28	-0.01122003095114101
+28	0.017694233004018588
+28	0.028075423740064023
+28	0.03186391114043128
+28	-0.03121558393471387
+28	0.00785171734167279
+28	0.03539411587163647
+28	0.026022592829405784
+28	0.035747041820660345
+28	0.023529242060120144
+28	-0.0072079536048587165
+28	0.004430167768684698
+28	0.008851295178358814
+28	-0.0012307412885772867
+28	0.016724146683295627
+28	0.025511463672286593
+28	0.031019262957889416
+28	0.017223127327608136
+28	0.009322893313145581
+28	0.02567070651262531
+28	0.01963457958319164
+28	0.014736644117152644
+28	0.015042334941315502
+28	0.034389623854724646
+28	0.027823262425198156
+28	0.01351173637094346
+28	0.011124638075544887
+28	0.011341654345035862
+28	0.012540110421190428
+28	0.034924431527527514
+28	0.038699822590853784
+28	0.004734959193380366
+28	-0.018421565193682387
+28	0.009790281786404276
+28	-0.014631060341928247
+28	0.016771088447152395
+28	0.024276475174992086
+28	0.014453662366026975
+28	0.04357661858117927
+28	0.016393437691124352
+28	0.018384846210056965
+28	0.002414188544092482
+28	0.00943249185931401
+28	-0.0002983707596139629
+28	-0.00547792203911393
+28	0.029341051062508453
+28	0.01181985149681943
+28	0.006437836928528515
+28	-0.03183375269275814
+28	-0.03083083723897822
+28	0.01573642337029097
+28	-0.014982848724473804
+28	0.017981089737299085
+28	-0.0001492424916665728
+28	0.022395412567334842
+28	-0.0005484562938208005
+28	-0.007195831900726377
+28	-0.0331493288463828
+28	0.007331741755034949
+28	0.03594072616802907
+28	-0.028055525457856424
+28	0.026212649754432896
+28	0.012480582917883275
+28	0.014657158636093855
+28	0.0006560941803108458
+28	0.014290760802570574
+28	0.006585874766137644
+28	0.017625427520028863
+28	0.010966366044437898
+28	0.020337743521569362
+28	0.0007333377664672646
+28	0.005646674358284436
+28	0.014632398577460303
+28	0.012160697151778862
+28	0.004433694226580931
+28	-0.006074622020423738
+28	0.0044035777306704734
+28	0.020481149191357607
+28	0.02210624884864497
+28	0.033460031537735864
+28	0.006300121750082375
+28	0.006307858267187546
+28	0.02587364347468595
+28	0.002018272367758467
+28	0.007471019167219894
+28	0.009309539362801753
+28	-0.014543765725468227
+28	0.02222246833667863
+28	0.01079515867608406
+28	0.0001309754479389518
+28	0.027473370508868174
+28	-0.012493612406575108
+28	0.022177454089675162
+28	0.0032038019270820375
+28	0.008608548978490067
+28	0.010469609753989516
+28	0.007339938675482185
+28	0.01923051844707227
+28	0.027243563388005126
+28	-0.006600749888730778
+28	0.006386347748559021
+28	-0.0026451413702404513
+28	0.031211268460912506
+28	0.017518146932929784
+28	0.04113501849598282
+28	0.04709196220694681
+28	0.03249994676054277
+28	0.012714896472386536
+28	-0.007473861582608384
+28	0.002496425570614709
+28	0.00245856570162176
+28	-0.0099263369598544
+28	0.004684033592866095
+28	0.013577240960812044
+28	0.06152832674772855
+28	0.016574133200197985
+28	0.031879556777743165
+28	0.012074621577164445
+28	0.020542955055209398
+28	0.0283287447098668
+28	-0.006384069749063573
+28	-0.01283216189095772
+28	-0.009805740846155203
+28	-0.016646567726624026
+28	-0.03473242286595523
+28	-0.003343795273472002
+28	0.021263280310170933
+28	-0.004199962913357091
+28	-0.030282423087882853
+28	0.01963009671211288
+28	0.004877379466523784
+24	-0.014112831354615014
+24	0.00350508566778805
+24	0.013148324525177257
+24	0.01862649288177932
+24	0.003913399821799692
+24	0.005064689547326533
+24	0.024980557378476063
+24	-0.011022686210493593
+24	0.007298993144909758
+24	-0.012797840833191012
+24	-0.011960087345446603
+24	-0.0044815365024342075
+24	-0.005110314275106289
+24	0.014673182056713769
+24	0.023799327276378558
+24	0.02875375296566419
+24	0.015572554274187293
+24	-0.005332532922196284
+24	-0.013975353534179422
+24	-0.0042989162571956795
+24	-0.004779695796372325
+24	-0.003037553843978424
+24	0.03563561310294064
+24	0.0073434694033338065
+24	-0.009713140138674763
+24	0.009642382540312737
+24	0.02226884018180204
+24	0.00774623198813498
+24	-0.01807191342934929
+24	0.005594718823632481
+24	-0.002047337707832626
+24	-0.0012367695298812589
+24	0.0157859796251426
+24	-0.00022486180358163664
+24	-0.023794655028011993
+24	0.04280820764019023
+24	0.0003757958026890579
+24	0.04669310432651559
+24	-0.006896765459921713
+24	0.006194341440963224
+24	0.0019640228696521946
+24	0.01958615895048485
+24	0.01257104323154697
+24	0.018190515257528815
+24	0.0014443549569445027
+24	-0.005253037115800169
+24	0.041438505106086494
+24	-0.005663931599150198
+24	-0.003291932547990639
+24	-0.010334729568125145
+24	0.003670402829684258
+24	0.02542733716015116
+24	-0.004057754700333929
+24	0.019277956664952425
+24	-0.014648439280518831
+24	-0.020630098492657036
+24	0.014352147779526368
+24	0.023809627599933155
+24	0.01329841918986891
+24	0.00632187641789578
+24	0.027750406475327196
+24	0.03339314005106028
+24	0.02852691125863208
+24	0.004208643445788363
+24	0.003629929771649488
+24	0.011887269237428362
+24	0.005100769175216829
+24	0.01734987360912983
+24	0.0056271076898152875
+24	0.005115643108414034
+24	0.034228883183616506
+24	0.009220658222072858
+24	-0.0017025134951128523
+24	0.04052957944551797
+24	0.012455838037882328
+24	0.024656241530862755
+24	0.011744652409289758
+24	0.007837893647738051
+24	0.0186214484871217
+24	-0.005484499421868507
+24	0.0026670700425015233
+24	0.021140414320989485
+24	-0.013944144060126873
+24	0.0033487070250376653
+24	5.990916001260864e-05
+24	-0.022910207419372327
+24	0.0199140638562836
+24	-0.022149812566190346
+24	0.00764315964378025
+24	0.012702186483393867
+24	-0.006720555915863815
+24	0.021206809036974375
+24	-0.0015587627961686445
+24	0.022048483871156963
+24	0.031102091450899257
+24	0.01624492495518663
+24	-0.00566024974981953
+24	0.01744563497571212
+24	0.009942000323833692
+24	0.03302005372032069
+24	0.03427657126295351
+24	0.015489216589118393
+24	0.0036221644504595214
+24	0.01898425362546688
+24	0.0003722880729763341
+24	-0.008752010678624526
+24	0.031097767462493767
+24	0.03988954556930595
+24	0.009175663689037305
+24	0.014430625289457707
+24	0.0032953058294487485
+24	0.0030697238789613546
+24	0.04676239952970132
+24	0.04506298018056156
+24	0.019073628666938066
+24	0.0035419205481918552
+24	0.016626089660141972
+24	0.013555831877953861
+24	0.022008916230780738
+24	0.0317669492065831
+24	0.014397971131023144
+24	0.030140861360261104
+24	0.0007928587919800879
+24	-0.006933604531233362
+24	-0.009740200667634515
+24	0.03857874578138767
+24	-0.03610180681695922
+24	0.017438205331258512
+24	-0.009629850401141228
+24	0.01959792587203273
+24	0.023725052815758017
+24	-0.007463745022883455
+24	-0.006368236269664925
+24	0.024298918942204442
+24	0.008660499145729467
+24	0.01114601564004066
+24	0.006702760965243118
+24	0.04086544094138478
+24	0.0022601955577709644
+24	0.017621204129186132
+24	0.021170252985169714
+24	0.03490192939574975
+24	0.0032292757938429447
+24	-0.012859858481381043
+24	0.006389460202757736
+24	0.005660240703161579
+24	0.008818165183845499
+24	0.01919729779481938
+24	0.029003445915836347
+24	0.02057074634555454
+24	0.01066390694932224
+24	0.04036976796697581
+24	-0.00018870239325683577
+24	-0.011567505410501368
+24	0.010098612873816004
+24	-0.010228206132837345
+24	0.013096451984537443
+24	0.0178524237218844
+24	0.02976187889558728
+24	0.009284635208472967
+24	-0.012929808059273093
+24	0.021922329346367665
+24	0.02240853494641517
+24	0.03500351410850479
+24	-0.017066568905570352
+24	-0.014223412502685072
+24	-0.023182471207357926
+24	0.007473811496842343
+24	-0.004976798554566378
+24	0.0008817351318125479
+24	1.0547826519123498e-05
+24	0.012832711408296274
+24	0.00662507768733795
+24	0.005089539577127955
+24	0.003544930969263033
+24	0.02251395877514477
+24	0.006081260151434868
+24	-0.0013645969134648485
+24	0.005241053806323021
+24	0.014725577476997372
+24	-0.018437838493266665
+24	-0.029356116089994038
+24	0.006871532288341543
+24	0.0026647210750446243
+24	0.011331751056540036
+24	-0.0038443352281654756
+24	0.0013881349275303467
+24	0.015745523252315947
+24	0.0023129134251268363
+24	0.02365061060399777
+24	0.04852887827008644
+24	-0.029617527824186363
+24	0.006492688042662703
+24	0.013363879598882675
+24	-0.023814010824868725
+24	0.009091951185477723
+24	-0.005695788171734675
+24	0.023097584362335145
+24	0.03424648524066463
+24	0.019594128261873848
+24	0.02978211902657202
+24	0.03770105664565965
+24	0.030733149966510567
+24	-0.010947829624751925
+24	-0.006891746069648707
+24	-0.04721155181443462
+24	0.016086972975770008
+24	-0.018506597799378813
+24	-0.004039031834632611
+24	0.015082008497980567
+24	-0.023361279364521554
+24	-0.021709381778567877
+24	0.009546355507368836
+24	-0.0013600697986087531
+24	0.015193156991770944
+24	0.007434379652886783
+24	0.013665676796098144
+24	-0.010303008331394001
+24	0.03186657312145266
+24	0.018188269642354232
+24	0.0024060509746729073
+24	0.012392121167420484
+24	0.028982167330658976
+24	0.0161783974387336
+24	0.012432221006705527
+24	0.02815371082256254
+24	0.0031745897199742675
+24	0.013100396650879824
+24	0.01841216261026559
+24	0.006914370670494026
+24	-0.0033809807643161455
+24	-0.005660950935780077
+24	0.013833759191160302
+24	0.019759534886924945
+24	0.017511628918525347
+24	-0.03235486956517095
+24	0.012924988633917132
+24	0.03188845521431295
+24	0.032980589812474995
+24	0.039754034836669234
+24	0.019580048858940505
+24	-0.0026325088965450127
+24	-0.003667985266517557
+24	0.009016720349658095
+24	0.0015240616769336775
+24	0.015535192765456514
+24	0.031879516373817196
+24	0.027963822777051586
+24	0.021093352246337335
+24	0.0021060993231522035
+24	0.023783007974035923
+24	0.02791406588633334
+24	0.0237782121457803
+24	0.01225995831385572
+24	0.037064290750409394
+24	0.033200881904229415
+24	0.022090767936688908
+24	0.016645368712901096
+24	0.013853340677301366
+24	0.013303175135462891
+24	0.03549280710019355
+24	0.0427071463320379
+24	0.010606893689233952
+24	-0.01564244348747586
+24	0.013828203158651643
+24	-0.011246065819272143
+24	0.015922955935413045
+24	0.025118037011287644
+24	0.01428579687404705
+24	0.038894726873066235
+24	0.0194308245331078
+24	0.02794540016757072
+24	0.008084826502986435
+24	0.014594449729532142
+24	-0.0004186785286948805
+24	-0.01582867746767543
+24	0.0249884493433153
+24	0.01076827119991388
+24	0.010249963678947496
+24	-0.02280273225891111
+24	-0.026617761939268292
+24	0.014023014666289605
+24	-0.005752300156675647
+24	0.013218539951024288
+24	-0.009301100806488995
+24	0.01737527128318512
+24	0.00213852309031073
+24	-0.0021331165112438775
+24	-0.028862960563790948
+24	0.006944216697970717
+24	0.0283619786603473
+24	-0.02633376880113186
+24	0.024482899500719055
+24	0.0015389301674544505
+24	0.015213197091680467
+24	0.010687731358833762
+24	0.011448728868253709
+24	0.012873831878162744
+24	0.034899811527940014
+24	0.018155175526435294
+24	0.022357851254683866
+24	0.007267318732196457
+24	0.005549944665579205
+24	0.012821221370126194
+24	0.018844073041332756
+24	0.0011528994132771247
+24	-0.0004341918439766683
+24	0.009770950435180384
+24	0.01904901497631265
+24	0.01259406371772657
+24	0.0210241759273211
+24	0.003114344427084048
+24	0.0040890941899879565
+24	0.022355978665403006
+24	0.005337359371975196
+24	0.006654940578020045
+24	0.008093457599917437
+24	-0.013977697801541518
+24	0.016648058460022062
+24	0.01432651665343217
+24	0.00013424349676358853
+24	0.027319948103911824
+24	-0.005910100379925398
+24	0.023188090136400198
+24	0.004947204150602662
+24	0.011819553189699128
+24	0.008482354730387439
+24	0.0036747708686540683
+24	0.021102576540357045
+24	0.03145688652387525
+24	-0.006334131464201353
+24	0.0027605105081734416
+24	-0.0010170129062912275
+24	0.0371808294200059
+24	0.021925325847737685
+24	0.04235624687869952
+24	0.040615178303493066
+24	0.03280369361512423
+24	0.010690914186434636
+24	-0.005926543900236227
+24	0.000992555787995367
+24	0.0029026591873408075
+24	-0.002880208642525247
+24	0.012014126575721953
+24	0.018320564826609178
+24	0.05936441032523231
+24	0.016591169212516497
+24	0.02901594306927514
+24	0.006736407723659387
+24	0.01850112081699235
+24	0.03013295732236896
+24	-0.011932434602973666
+24	-0.013132968790287849
+24	-0.0013697424614210235
+24	-0.0074873096239971935
+24	-0.024719940600808312
+24	-0.005411701892873489
+24	0.021770089696947204
+24	-0.0048025500784581185
+24	-0.025795311225804425
+24	0.026147405950608993
+24	0.015794617175791094
+31	-0.021928427195272913
+31	0.004891980366200801
+31	0.01141200714989105
+31	0.007016204528404209
+31	0.012645145360643617
+31	-0.002504492285584251
+31	0.01759894934630656
+31	-0.023603219637811573
+31	0.005665758231229609
+31	-0.01642878234849973
+31	-0.0042530989193223
+31	-0.0042755263869180245
+31	-0.0037343937035674867
+31	0.006513288660075493
+31	0.01788065884814038
+31	0.024274905213654142
+31	0.009528029319625394
+31	-0.02071404226393011
+31	-0.02648894583209271
+31	-0.008044575784203579
+31	-0.013856655193553793
+31	-0.0027804159988812733
+31	0.023995007672062453
+31	0.00017866008420712315
+31	-0.005941536238274401
+31	0.003391860557357413
+31	0.011842904863192585
+31	-0.0011550831225049139
+31	-0.03217026322862397
+31	0.00025968401924808277
+31	-0.007719974446577884
+31	-0.006410632852854395
+31	0.008574692588482587
+31	-0.0018899903521749327
+31	-0.030553140213594995
+31	0.031029462341323352
+31	-0.0007552224930697628
+31	0.03541586244202785
+31	-0.010760436321350214
+31	-0.0011418063744727878
+31	-0.00511720710151123
+31	0.011612676958177779
+31	0.0029647504339795246
+31	0.005343257908123786
+31	-0.008811656210054856
+31	0.005657601345219385
+31	0.033039348969522125
+31	-0.007430702351420234
+31	-0.011672288129127191
+31	-0.01539441862337289
+31	0.0020894009010644678
+31	0.010268422027678654
+31	-0.008517042450596798
+31	0.0036794137967260353
+31	-0.012492953985734948
+31	-0.02825177675030951
+31	0.011953665988158104
+31	0.020177941188666275
+31	0.014906669175708868
+31	-0.005699617102933071
+31	0.017430913725898847
+31	0.028342007799563564
+31	0.019531424888100536
+31	-0.006487530711587246
+31	-0.005492887787082766
+31	0.003726679029624982
+31	-0.006595037124963387
+31	0.015524621611961522
+31	0.00026071082451262337
+31	0.0006375355437991804
+31	0.027278926581022225
+31	0.015085769267515802
+31	-0.0002948780489419601
+31	0.034126317328828884
+31	0.004991514121375516
+31	0.01760531906508986
+31	-0.0073651385753572655
+31	0.00953967381944902
+31	0.01670326044190062
+31	-0.01457602045916943
+31	-0.005436392733317041
+31	0.016163852825670188
+31	-0.008640507091243995
+31	0.0021621106347158143
+31	0.0018524679961058755
+31	-0.032544068164352985
+31	0.011916533884986362
+31	-0.017908739823407484
+31	0.00021778463089712984
+31	0.006667151575467592
+31	-0.009438595026509539
+31	0.004014693081413025
+31	-0.0026755819447207814
+31	0.009593916014308595
+31	0.026717893229689118
+31	0.01627265265208223
+31	-0.009514048700380437
+31	0.018863622845584904
+31	0.0044640180681285
+31	0.02966618330989236
+31	0.025108949364961823
+31	0.008860821532552559
+31	-0.010308119493173453
+31	0.005940834902302502
+31	-0.006411639130607081
+31	-0.028237748983513708
+31	0.0175874842250564
+31	0.028661810508169797
+31	0.0027169102898554633
+31	0.012748923394502055
+31	0.00027150822849133946
+31	-0.002313393945783491
+31	0.04334594457412351
+31	0.04249926410887713
+31	0.012219349751041851
+31	0.004725184741026776
+31	0.0045421146821267985
+31	0.00671954100970447
+31	0.011255210185236017
+31	0.023661498820482036
+31	0.011071427147793276
+31	0.012432170752541476
+31	-0.022574389145391394
+31	-0.020939543483360596
+31	-0.01579909708800751
+31	0.02513957156081574
+31	-0.019845714916242492
+31	0.007869354514224847
+31	-0.022659702221994746
+31	0.008515775199653266
+31	0.013830620678380468
+31	-0.011870534954777886
+31	-0.008288670857061229
+31	0.015795593472952684
+31	0.0034028104764995885
+31	-0.010010359490692414
+31	-0.005315344023350495
+31	0.03793723698507332
+31	0.0024195877472104853
+31	0.02013457543547049
+31	0.013760926892017118
+31	0.027339241302142027
+31	-0.001572847940492732
+31	-0.016206837212446697
+31	-0.0068232794232306925
+31	-0.0021204001394209875
+31	0.00037350635073979914
+31	0.017632008309575915
+31	0.021589329372972622
+31	0.008401757058776821
+31	0.0031925996077638913
+31	0.030692399555270658
+31	-0.0004833579267661175
+31	-0.01398444662083888
+31	-0.004132428684523617
+31	-0.014024654863813456
+31	0.0004506581196060282
+31	0.009318606152132014
+31	0.026951505982501987
+31	0.002798663064562192
+31	-0.010880179060305606
+31	0.005871959572262902
+31	0.00877154999122746
+31	0.03019137517938892
+31	-0.02375965151031759
+31	-0.021147640291097707
+31	-0.02305425249369944
+31	0.00035157259370931297
+31	-0.016068023215525497
+31	-0.01074029853166453
+31	-0.014369573147757393
+31	0.0008021496208194006
+31	0.0012554121881155841
+31	-0.011433214364202306
+31	0.0012729279455090724
+31	0.011225049818370511
+31	0.002839005674281264
+31	-0.0021672133631765677
+31	0.0012798999184025469
+31	-7.584306250488683e-05
+31	-0.02945321321138573
+31	-0.04743463423223175
+31	-0.0032977743111617494
+31	-0.0035861242000128526
+31	-0.004721238702648817
+31	-0.005537056336796264
+31	-0.0017810366573893838
+31	0.0034080044085246937
+31	0.0004184590636628452
+31	0.027209408373261218
+31	0.04559617970863453
+31	-0.032823218920889935
+31	0.0035810112606415798
+31	0.0038336512865629014
+31	-0.02636748769346295
+31	0.004259606271982649
+31	-0.009033672300717189
+31	0.010720072186976942
+31	0.014245932972499042
+31	0.01613112004407094
+31	0.020429150837915532
+31	0.030109313299599077
+31	0.021662071025052212
+31	-0.019185571081644502
+31	-0.008987517950948066
+31	-0.05810477275681598
+31	0.005709046188544376
+31	-0.02141852315191446
+31	-0.0034932624608969296
+31	-0.001989914019262117
+31	-0.03433429032825153
+31	-0.02734051302533846
+31	-0.00430952253135072
+31	-0.014027456877164207
+31	0.005884953628167333
+31	-0.003019521151255865
+31	0.013571603260028795
+31	-0.014116993835674161
+31	0.018391006585763786
+31	0.009801158711157715
+31	-0.009057924711983478
+31	0.0211472816845644
+31	0.027978429423375917
+31	0.014844928391223252
+31	0.002912554017004951
+31	0.014621007637999612
+31	0.005602038466108703
+31	-0.0006780424560125927
+31	0.015333625048656539
+31	-0.003194233463716405
+31	-0.004882275216049223
+31	-0.01669557350968195
+31	0.010549387937887221
+31	0.017427162137626385
+31	0.01911424274434788
+31	-0.03554959659237954
+31	0.010963276061895207
+31	0.025089905234593004
+31	0.02303110037887016
+31	0.029976950295032802
+31	0.004011767034224997
+31	-0.011243939610975128
+31	-0.007568083253680338
+31	-0.005472579451661882
+31	-0.005559813943966636
+31	0.012897538146796382
+31	0.021144927700705637
+31	0.022550960985490393
+31	0.013587270429852161
+31	0.003109848619344267
+31	0.024445776226818563
+31	0.007358598976212016
+31	0.010443328511097172
+31	0.005371829413070426
+31	0.022173458868395567
+31	0.02650500753614229
+31	0.007528101706995951
+31	0.00397887037785561
+31	0.001974237404506038
+31	0.007021579165259784
+31	0.022240166161242057
+31	0.04262924283468661
+31	0.0006480801402758374
+31	-0.00733509262474994
+31	-0.0011724398579766222
+31	-0.023213058520588078
+31	0.013096559581882461
+31	0.01557956382392912
+31	0.005446499452748613
+31	0.020177551121051174
+31	0.00952553439801877
+31	0.012218714747665881
+31	-0.008962211707437237
+31	0.007469584404091688
+31	-0.0010646426707788858
+31	-0.01253264777830338
+31	0.022071487854195788
+31	0.010783446730600747
+31	0.006873400879215851
+31	-0.036316455886073684
+31	-0.03608927023851589
+31	0.005218043514445972
+31	-0.021086971599691307
+31	0.008656799657036349
+31	-0.016000485710458902
+31	0.011672233846640056
+31	-0.011738299834332664
+31	-0.013452471284540897
+31	-0.049517942735065205
+31	0.0029274969013524514
+31	0.028246779434587973
+31	-0.04426334609881759
+31	0.01672644373078599
+31	0.0019484662509782508
+31	0.006010651239418036
+31	-0.0013278579256430457
+31	0.006926730641406697
+31	0.001272918750257011
+31	0.01829173975190067
+31	0.018593110534309898
+31	0.015380299842128575
+31	0.000330239233155621
+31	-0.001269150766064871
+31	0.0071490378468102855
+31	0.0029352699209741684
+31	-0.0006881750330097363
+31	-0.012707120807423214
+31	0.0013750559724905653
+31	0.017808432845624902
+31	0.010147912165261239
+31	0.02015072629133248
+31	-0.0030362191356366427
+31	-0.001143350333760238
+31	0.014688903441131667
+31	-0.00500222161824228
+31	0.009559951074679048
+31	-0.0002872631784065627
+31	-0.019543337933736134
+31	0.011381696486933952
+31	0.0032474089489989305
+31	0.001091046531762751
+31	0.01456513027551917
+31	-0.026673066419873718
+31	0.01939232361366008
+31	-0.003083716910441577
+31	0.002185376027159577
+31	0.008497420074688265
+31	0.0009379795861716409
+31	0.014830433561193934
+31	0.03245337119320663
+31	-0.015514513135991378
+31	-0.00648164226213052
+31	-0.00722340910269745
+31	0.01963872322017541
+31	0.007797085637862723
+31	0.03457560330210764
+31	0.037907635654670715
+31	0.024055916837614953
+31	0.010204334973813442
+31	-0.011201379209754152
+31	-0.006080486182563333
+31	-0.0032248098799892624
+31	-0.009818101381399116
+31	-0.0008359668318493575
+31	0.013932147129009576
+31	0.04264790693209331
+31	0.005443366086390877
+31	0.016016392297219524
+31	-0.004225224460463736
+31	0.009318596260264442
+31	0.015723557861785666
+31	-0.01927066081856382
+31	-0.024704190916488858
+31	-0.009478031957810608
+31	-0.023008410772262393
+31	-0.041157372380587455
+31	-0.006459133032897366
+31	0.007709264150497181
+31	-0.015209288361930116
+31	-0.03715385053889306
+31	0.011269015738723426
+31	0.0009242718172883421
+51	-0.01961816500534217
+51	-0.01096997180696309
+51	-0.001858776194202086
+51	0.011572328106789436
+51	-0.012123255898886487
+51	-0.012677710732463817
+51	0.012853461914380908
+51	-0.028153826785365012
+51	-0.003375755245719108
+51	-0.029365295081208578
+51	-0.029488670389141707
+51	-0.008652988754345088
+51	-0.016253302092286537
+51	-0.003853127729093167
+51	0.007808473796586474
+51	0.018357856999334315
+51	0.007563399720876215
+51	-0.020142142423079365
+51	-0.02845794209238174
+51	-0.016508160700769107
+51	-0.013460984729512397
+51	-0.01516531231661109
+51	0.023753169372106545
+51	-0.010778016623862725
+51	-0.013609229119990636
+51	-0.012825572567802139
+51	-0.0028820938356079458
+51	-0.010774298450431704
+51	-0.03743570555058071
+51	-0.005572514307909268
+51	-0.021775679649313477
+51	-0.017509336179215657
+51	0.004604029948279626
+51	-0.014487138918174975
+51	-0.04661928352388821
+51	0.022580378048936568
+51	-0.015528839341323429
+51	0.03565694793949553
+51	-0.02266485677854779
+51	-0.006442554193513713
+51	-0.013091612299353692
+51	0.006142097337422736
+51	0.0007092648591332292
+51	0.0008298119270412421
+51	-0.011175301628429108
+51	-0.018424232017436266
+51	0.029712017254844122
+51	-0.020000064042797618
+51	-0.013743112660048693
+51	-0.015616967839678813
+51	-0.011105981031095044
+51	0.0110024353777015
+51	-0.02315220213152572
+51	0.0060334754378827534
+51	-0.030093289322698637
+51	-0.03554122433873919
+51	-0.0060831678477328245
+51	0.013258759359748577
+51	-0.0007163722559572573
+51	-0.008858189151232128
+51	0.011234425092133184
+51	0.025333846643084135
+51	0.02098755549386044
+51	-0.01932207421260052
+51	-0.007190418573897523
+51	-0.0036267102829806675
+51	-0.014150844078814747
+51	0.0008659628572819294
+51	-0.014626359961934968
+51	-0.015905573002067328
+51	0.014039375493357358
+51	0.001529239892564313
+51	-0.015666066284833056
+51	0.026059410137020643
+51	-0.002891517831804524
+51	0.003990349709339048
+51	0.004245946050018282
+51	-0.004267734437493116
+51	0.006818502525976442
+51	-0.025055589446488242
+51	-0.013713124856585473
+51	0.013581207604807697
+51	-0.021714217506819317
+51	-0.0007278230270634629
+51	-0.01557106618268055
+51	-0.018808630163949094
+51	0.023027845762849358
+51	-0.028130418286918486
+51	-0.0036269392325729718
+51	-0.002459893004715949
+51	-0.020808218046114022
+51	0.005327124171638063
+51	-0.008671753002462023
+51	0.004949365204879705
+51	0.02094555161243785
+51	-0.00675077711711023
+51	-0.016799067340957628
+51	-0.001661112340492354
+51	-0.0038148005719594383
+51	0.022567836634608575
+51	0.013820893070658577
+51	-0.0034668040735494174
+51	-0.012899021946639116
+51	-0.0003798442863393229
+51	-0.02329596957861847
+51	-0.025530381113300745
+51	0.012812956467293956
+51	0.0175603136767471
+51	-0.009780296108117188
+51	-0.0017679352660384163
+51	-0.010915077929927698
+51	-0.012306154687957474
+51	0.035237705215402586
+51	0.026702908491032927
+51	0.0007425231064724025
+51	-0.013644744857300495
+51	-6.314097164653275e-05
+51	0.0025749243280955517
+51	0.005837305175111186
+51	0.014139639273899208
+51	-0.005483442611442844
+51	0.005322051462029205
+51	-0.02491274148803999
+51	-0.03549934396351956
+51	-0.02489185068490089
+51	0.022419928132831664
+51	-0.04998217902139699
+51	0.000324476792830481
+51	-0.026510567517493706
+51	0.0021826863150909473
+51	0.01773740369591009
+51	-0.02052905542101051
+51	-0.012913218761519338
+51	0.01647211843560882
+51	-0.0040502342122710954
+51	-0.009502437096080918
+51	-0.010715196410785105
+51	0.021605297416837914
+51	-0.0101088449365175
+51	0.01020098928893994
+51	0.005910811898223621
+51	0.025778038056627248
+51	-0.00931818963177551
+51	-0.020085357565768274
+51	-0.004384024927723957
+51	-0.0028459316737921925
+51	-0.001593920227499001
+51	0.003994807538392604
+51	0.010055279206251246
+51	0.019366552512829354
+51	0.005863293209385663
+51	0.034358592621861035
+51	-0.012899047183665089
+51	-0.019467692563292328
+51	-0.011703623241245685
+51	-0.02899153599742656
+51	-0.004283673233854843
+51	0.005570911468570963
+51	0.012876773358696447
+51	-0.00017287130287101983
+51	-0.01873171710926336
+51	0.014326532546424353
+51	0.0025204582850732998
+51	0.02504618317205673
+51	-0.02794727016033555
+51	-0.03666283947044266
+51	-0.05081204373338693
+51	-0.006842517344798921
+51	-0.02673083011161012
+51	-0.025217268296490902
+51	-0.020268266350911206
+51	-0.008150975368900904
+51	-0.007282830426984175
+51	-0.005669836895034286
+51	-0.008054650796040315
+51	0.007910311525716458
+51	-0.005038866100822462
+51	-0.0043961854283268015
+51	-0.006060550138229186
+51	-0.00225592830797597
+51	-0.045029281194568935
+51	-0.04274224550841336
+51	-0.009855336312183624
+51	-0.009467664929118881
+51	5.627274247180307e-05
+51	-0.014753051182677867
+51	-0.012968669473149936
+51	0.005996362541389305
+51	-0.01823996893349649
+51	0.011586211273993468
+51	0.03283990688976814
+51	-0.04966651023409237
+51	-0.002178417455806745
+51	-0.012493372452146408
+51	-0.044852824164657655
+51	-0.00271120816774141
+51	-0.02731574528820413
+51	0.005811835052244213
+51	0.012154365927120431
+51	0.0017380255366356689
+51	0.012488224030172588
+51	0.02585140866372505
+51	0.011072438578657633
+51	-0.03446563230816399
+51	-0.024846772907548095
+51	-0.063814975132683
+51	-0.0063129305630314
+51	-0.03258318924976704
+51	-0.017975559552783005
+51	-0.006092606832955097
+51	-0.0390341141150099
+51	-0.029334602714746156
+51	-0.008462962548231898
+51	-0.02334556933326548
+51	-0.001262354982896592
+51	-0.009620902247072105
+51	0.0031870374547465358
+51	-0.026142161975292295
+51	0.016369162215797452
+51	0.003872559479207568
+51	-0.013359847480622598
+51	0.0053173158249975455
+51	0.020598211678733543
+51	0.010099656423753454
+51	-0.009612541182782706
+51	0.01155051592501889
+51	-0.008278327507814605
+51	-0.0045910454984309824
+51	0.008924938111065815
+51	0.0007912970867757948
+51	-0.025597524227450062
+51	-0.018188029921732657
+51	0.0029736972009246922
+51	-0.0032090355784240117
+51	0.007916874054484576
+51	-0.04434849677429629
+51	-0.0003167553286106667
+51	0.017613163391476304
+51	0.01232916881742451
+51	0.02802673636038193
+51	-0.0009145739602481003
+51	-0.01813220722936753
+51	-0.026032365084798014
+51	-0.004277301578568666
+51	-0.016933324216726355
+51	0.007212113965693552
+51	0.014641866242671706
+51	0.012729951565502053
+51	0.012638090404515022
+51	-0.012320447896879196
+51	0.011301565182068077
+51	0.007354244254502635
+51	0.006789268649916297
+51	-0.006112161868811091
+51	0.013682900534883542
+51	0.017194607186622173
+51	0.009094689454867223
+51	-0.00444597311693342
+51	0.0037055252948177504
+51	-0.0037999676768168578
+51	0.021911374864681275
+51	0.036549164367035265
+51	-0.003926743947491153
+51	-0.01835826269805525
+51	-0.00850623134510313
+51	-0.027258535203491557
+51	0.004727008389809435
+51	-0.0032678216879699095
+51	0.011192107055953318
+51	0.008804591662872813
+51	0.008809694701741557
+51	0.014430613341706904
+51	-0.018673967697402587
+51	-0.006041227367508194
+51	-0.016738007690035556
+51	-0.03236023175238208
+51	0.0046862014004540676
+51	-0.003183486204745863
+51	-0.0013638103777646423
+51	-0.04107846027741534
+51	-0.04393033737690422
+51	0.004716797741141975
+51	-0.018042491655713238
+51	-0.014833183998384776
+51	-0.028717112527798575
+51	-0.0086005957676929
+51	-0.016652601704936577
+51	-0.015495989760718962
+51	-0.05000934219793402
+51	-0.013739526114224484
+51	0.019024539335893976
+51	-0.04965476484248593
+51	0.020464980183579874
+51	-0.008849011744998608
+51	0.0016421780866680206
+51	-0.00868398919934112
+51	-0.00988937377971899
+51	-0.0031030264925513396
+51	0.0152078648409695
+51	-0.001987309233829997
+51	0.00797237153042153
+51	-0.0038206886765274266
+51	-0.011306560225178725
+51	-0.006339859503434634
+51	0.0005553568247816814
+51	-0.00572263922859696
+51	-0.016920839220881712
+51	0.0044046759812398405
+51	0.006099063526853874
+51	-0.004294458506765824
+51	0.00413303755844022
+51	-0.015368881303387046
+51	-0.013051485871419768
+51	0.004083501515185405
+51	-0.0061179682239135775
+51	-0.013110309870070176
+51	-0.010827643677922168
+51	-0.023124847885864743
+51	0.002337167091873741
+51	0.0020369124263888874
+51	-0.013628510945068067
+51	0.005800098340946152
+51	-0.02296978965788593
+51	0.002940984747093145
+51	-0.013594886041682025
+51	-0.00672863555437554
+51	-0.008237517388635063
+51	-0.011602003301268711
+51	0.0032948462208561625
+51	0.009696946455087193
+51	-0.029541615018255543
+51	-0.01905215582583237
+51	-0.019998372842031716
+51	0.034171797369592714
+51	0.005158906843775096
+51	0.035406424504374784
+51	0.026135501377019817
+51	0.01339477400982315
+51	-0.00955589519715801
+51	-0.023589967989089727
+51	-0.016805275485449214
+51	-0.0026264557797276884
+51	-0.02040668168853559
+51	-0.003950063445274115
+51	-0.005620153581089524
+51	0.040693398281304936
+51	-0.002391565166260498
+51	0.013476546318646868
+51	-0.004530842303394669
+51	0.007027411586987935
+51	0.017701427846033953
+51	-0.02772444931830987
+51	-0.03310307248467247
+51	-0.022694505370422217
+51	-0.014319289992946004
+51	-0.031385678232066484
+51	-0.015994057637761787
+51	0.009202946881822004
+51	-0.028000914656746128
+51	-0.04473302850963792
+51	0.007573033073716007
+51	0.0055470037233474965
+23	-0.01389807462012523
+23	0.002549482113087739
+23	0.01459381541840029
+23	0.018323584696706627
+23	0.012702022055198412
+23	0.010632316804855147
+23	0.028072424350010245
+23	-0.017026547260639777
+23	0.00593391332612996
+23	-0.006736113799821226
+23	-0.012410883758705906
+23	-0.0003562851762832465
+23	-0.00682549235618877
+23	0.013996293047382409
+23	0.018324056753676366
+23	0.0282848510777407
+23	0.010612811049491716
+23	-0.011654544839537885
+23	-0.024554180036463622
+23	-0.001202939757190319
+23	-0.014994716696807055
+23	-0.004394540480219749
+23	0.03069825471174945
+23	0.003679686341231668
+23	-0.008574098549154302
+23	0.013548739575249328
+23	0.015240454927000444
+23	-0.0015132857651617437
+23	-0.031057735911915546
+23	0.009028977667022384
+23	-0.004691600456514843
+23	0.003153266839742485
+23	0.013688259758240149
+23	-0.0019757960503997366
+23	-0.025882525242025684
+23	0.03708329641356628
+23	-0.001697274684547873
+23	0.041284093657257936
+23	-0.009959692476977665
+23	0.0034034795397443755
+23	-0.005168969325999586
+23	0.016335310213870195
+23	0.010308444556822848
+23	0.0062933972274591046
+23	-0.003908089747019157
+23	0.001034956430217915
+23	0.03858583023349589
+23	-0.0076298887555190055
+23	-0.010689185023337544
+23	-0.01509281689304404
+23	0.0015984412880790143
+23	0.016625602257701
+23	-0.00741118818848258
+23	0.019976199082468466
+23	-0.011483472251963361
+23	-0.024447073062149785
+23	0.013210389376851164
+23	0.020602636928419737
+23	0.019527981087009254
+23	0.0072840983939071804
+23	0.025435303984593493
+23	0.030557828770574984
+23	0.024124969549843545
+23	0.0033117166340919306
+23	-0.0015308138694370681
+23	0.012815875336159207
+23	0.006533976198725282
+23	0.01806079098700915
+23	0.007973608966937279
+23	0.0014864425123820894
+23	0.03809727254736981
+23	0.01275961356482238
+23	0.004671524982932024
+23	0.03527394188517846
+23	0.01784449070265392
+23	0.019305901928430964
+23	-0.001115935421475873
+23	0.007178424219784858
+23	0.018531403398258206
+23	-0.01148747997676091
+23	0.0026891687400708796
+23	0.02397686682673653
+23	-0.015469392877429485
+23	0.004572339526917743
+23	0.0019536003264965557
+23	-0.03220599311770635
+23	0.011153970641050595
+23	-0.024765507683397314
+23	0.007986420506451678
+23	0.009179918064341333
+23	-0.005415529186865891
+23	0.0103342656356677
+23	0.0005758983930450216
+23	0.011712419444406952
+23	0.030165788924334493
+23	0.015841407147249385
+23	-0.002321190977093193
+23	0.01678221283524973
+23	0.013690931749502719
+23	0.03367427773038939
+23	0.03084401468556296
+23	0.0132606598676152
+23	-0.0037618634999895023
+23	0.013160720869568713
+23	-0.0017537290251808423
+23	-0.017082187138615847
+23	0.023885105857974633
+23	0.03848083019329336
+23	0.008848188340819024
+23	0.009644787800771642
+23	-0.0005231372911515946
+23	0.0001272198176697138
+23	0.0462050240232022
+23	0.042148709998121384
+23	0.017812025770920045
+23	0.007492483815557063
+23	0.015126600134759022
+23	0.010744838212130507
+23	0.017583139878318728
+23	0.029582181297305703
+23	0.015602814265488478
+23	0.02020846515722293
+23	-0.008083892350110047
+23	-0.015120908792354972
+23	-0.013373820417011633
+23	0.03847567741023042
+23	-0.024926722298405053
+23	0.01700326774359911
+23	-0.020758443960084732
+23	0.020737424806526076
+23	0.014991824581733463
+23	-0.006653609013863914
+23	-0.006695668582740431
+23	0.017428097260409767
+23	0.005582065384362895
+23	0.0024261475100560317
+23	-0.0038168518893130173
+23	0.0395176620982756
+23	0.0015332015459607984
+23	0.017144581217362603
+23	0.025237639162723705
+23	0.027245629930076825
+23	0.00011652974606576573
+23	-0.008285459043004274
+23	0.004069888096096453
+23	0.0037187611534362577
+23	-0.0012543538331139172
+23	0.020296463048793022
+23	0.023946103685939576
+23	0.015565642354726513
+23	0.0049021215156835815
+23	0.03975968730428495
+23	4.536972467725691e-05
+23	-0.01910190946824552
+23	0.005612001687794335
+23	-0.007566768796534787
+23	0.007413457709989651
+23	0.012696253134120218
+23	0.02812759483755852
+23	0.011561098795950965
+23	-0.005227536891323319
+23	0.007855128799658731
+23	0.008381993169571946
+23	0.032368696481777745
+23	-0.01923117587655662
+23	-0.018164005480102052
+23	-0.024084951455320063
+23	0.004132440530497998
+23	-0.007874985709872953
+23	-0.009350895120845788
+23	-0.005710991906083911
+23	0.0033984216557173047
+23	0.005868415475508048
+23	-0.002550963216239186
+23	-0.00012086685795368487
+23	0.01574588335611288
+23	0.005327685491633855
+23	0.001944630168196074
+23	0.0004095261749372812
+23	0.005106437645475376
+23	-0.021041048983997036
+23	-0.03978845774541224
+23	0.005912939451623139
+23	-0.0015775882362701846
+23	0.0016775418198772046
+23	-0.002139603789904038
+23	0.008815712603113897
+23	0.008873751543120428
+23	0.004410309326742044
+23	0.03226117743463347
+23	0.04973762227658799
+23	-0.03243242019747726
+23	0.0023163363617009596
+23	0.012752196327103081
+23	-0.02081333959150186
+23	0.008388658100379974
+23	-0.0021128991780897423
+23	0.018616579290404518
+23	0.027119376574122243
+23	0.020996325718503413
+23	0.023010646572519444
+23	0.039080678295132884
+23	0.02681131545206746
+23	-0.012141255071752446
+23	-0.010093166171132132
+23	-0.052839731175777956
+23	0.010010365143717085
+23	-0.017327438708366946
+23	-0.006788409453562822
+23	0.0072348496578964056
+23	-0.02500192101619576
+23	-0.02731757314528186
+23	0.0011688948027279778
+23	-0.009011476159008713
+23	0.008913342566980093
+23	0.0013654641272281094
+23	0.022830987956013817
+23	-0.005828840495650355
+23	0.024762757215300475
+23	0.022546553763579506
+23	0.010054732970135039
+23	0.01692801399759806
+23	0.023940489351361866
+23	0.022471293345268074
+23	0.010171546715075417
+23	0.02129935101945606
+23	0.004927328089908876
+23	0.010842854165776367
+23	0.0279012116620688
+23	0.006192709476287011
+23	-0.001586502993427016
+23	-0.0098054293919882
+23	0.018729721817312226
+23	0.02467117134871245
+23	0.022518489289635554
+23	-0.0341796582344232
+23	0.009390517840575404
+23	0.028378302260664935
+23	0.028123550112718238
+23	0.03508789713957626
+23	0.020562284941460965
+23	-0.009859595301498353
+23	-0.006429783202514935
+23	0.004636757821009004
+23	-0.005694688804648392
+23	0.018133014547042678
+23	0.031008167159438608
+23	0.03052942308912083
+23	0.019774517697220134
+23	-0.000517992821622882
+23	0.021776982748119577
+23	0.021253443460758328
+23	0.01670584443380641
+23	0.012262936541958832
+23	0.03182531146990386
+23	0.03419363363390684
+23	0.013895584202689085
+23	0.011325472103228026
+23	0.008506267174904143
+23	0.010636767575709725
+23	0.037153662476452916
+23	0.04366099623530692
+23	0.010775484762405722
+23	-0.009018665447682612
+23	0.009894860390237955
+23	-0.011588105258822345
+23	0.015232023769796104
+23	0.01965920632556854
+23	0.013782639432713318
+23	0.0335144329467338
+23	0.018159170886936922
+23	0.025869877627981257
+23	-0.001607073042881366
+23	0.012694699912586057
+23	-0.0009405944157030283
+23	-0.0028403872809540996
+23	0.028410201941087253
+23	0.0179515439630117
+23	0.009513657488161537
+23	-0.03209830925768299
+23	-0.03138494130323444
+23	0.01521590353488885
+23	-0.008133629844454088
+23	0.010139095735286305
+23	-0.006849991907683427
+23	0.020371907929111362
+23	-0.00018854233472595462
+23	-0.009644906642864949
+23	-0.033003640216182774
+23	0.008500296300065435
+23	0.03776849923408051
+23	-0.030585215768627147
+23	0.019446278776402766
+23	0.003674577659168868
+23	0.011984132517468311
+23	0.00655765731309709
+23	0.00799808169686661
+23	0.011470314085345545
+23	0.028296785812231412
+23	0.01237688604317737
+23	0.017301289995966796
+23	0.004213555491594396
+23	0.0006423958598340045
+23	0.011164415304616399
+23	0.01272398031104672
+23	0.0036375989283383894
+23	-0.00579666509074047
+23	0.008163440568175006
+23	0.021750272402960857
+23	0.011590747700642444
+23	0.022397530886241575
+23	0.002688028504925004
+23	-0.000919914755143324
+23	0.021121727504964632
+23	0.005993437423410331
+23	0.008183253079279376
+23	0.0072305492985873885
+23	-0.017205398783957774
+23	0.012283086431222119
+23	0.01417027929241711
+23	-0.004689589524773096
+23	0.017298679606920872
+23	-0.015932683188251463
+23	0.01890353146061286
+23	-0.0022696660084914303
+23	0.008683186301240778
+23	0.004842141229890507
+23	0.006300077687075951
+23	0.0177872458063741
+23	0.030771611245868035
+23	-0.009476469799083774
+23	-0.0001583426529838427
+23	-0.009031719801780805
+23	0.028583831924925272
+23	0.007170571948747436
+23	0.04680488443389757
+23	0.043311028282912487
+23	0.029125528086097426
+23	0.012864364667036512
+23	-0.012290039644540063
+23	0.0018544386319855623
+23	-0.0020248681386816694
+23	-0.0012200158012962968
+23	0.012090373068258007
+23	0.0168428464386077
+23	0.05763909628144792
+23	0.01731345209339558
+23	0.026848130593115464
+23	0.008594853055332932
+23	0.018734859155210188
+23	0.02804141476174363
+23	-0.014348770858733484
+23	-0.016179789909814973
+23	-0.011347522296886958
+23	-0.01729557453831916
+23	-0.031398227700377826
+23	-0.00852188598114797
+23	0.016288854905733566
+23	-0.01246312181942208
+23	-0.030629253789817363
+23	0.020942474957954312
+23	0.01234243560901771
Index: src/com/util/lr_scheduler.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/lr_scheduler.py b/src/com/util/lr_scheduler.py
new file mode 100644
--- /dev/null	(date 1616247289000)
+++ b/src/com/util/lr_scheduler.py	(date 1616247289000)
@@ -0,0 +1,107 @@
+import numpy as np
+import warnings
+from torch.optim.optimizer import Optimizer
+
+
+class ReduceLROnPlateau(object):
+    """Reduce learning rate when a metric has stopped improving.
+    Models often benefit from reducing the learning rate by a factor
+    of 2-10 once learning stagnates. This scheduler reads a metrics
+    quantity and if no improvement is seen for a 'patience' number
+    of epochs, the learning rate is reduced.
+    
+    Args:
+        factor: factor by which the learning rate will
+            be reduced. new_lr = lr * factor
+        patience: number of epochs with no improvement
+            after which learning rate will be reduced.
+        verbose: int. 0: quiet, 1: update messages.
+        mode: one of {min, max}. In `min` mode,
+            lr will be reduced when the quantity
+            monitored has stopped decreasing; in `max`
+            mode it will be reduced when the quantity
+            monitored has stopped increasing.
+        epsilon: threshold for measuring the new optimum,
+            to only focus on significant changes.
+        cooldown: number of epochs to wait before resuming
+            normal operation after lr has been reduced.
+        min_lr: lower bound on the learning rate.
+        
+        
+    Example:
+        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
+        >>> scheduler = ReduceLROnPlateau(optimizer, 'min')
+        >>> for epoch in range(10):
+        >>>     train(...)
+        >>>     val_acc, val_loss = validate(...)
+        >>>     scheduler.step(val_loss, epoch)
+    """
+
+    def __init__(self, optimizer, mode='min', factor=0.1, patience=10,
+                 verbose=0, epsilon=1e-4, cooldown=0, min_lr=0):
+        super(ReduceLROnPlateau, self).__init__()
+
+        if factor >= 1.0:
+            raise ValueError('ReduceLROnPlateau '
+                             'does not support a factor >= 1.0.')
+        self.factor = factor
+        self.min_lr = min_lr
+        self.epsilon = epsilon
+        self.patience = patience
+        self.verbose = verbose
+        self.cooldown = cooldown
+        self.cooldown_counter = 0  # Cooldown counter.
+        self.monitor_op = None
+        self.wait = 0
+        self.best = 0
+        self.mode = mode
+        assert isinstance(optimizer, Optimizer)
+        self.optimizer = optimizer
+        self._reset()
+
+    def _reset(self):
+        """Resets wait counter and cooldown counter.
+        """
+        if self.mode not in ['min', 'max']:
+            raise RuntimeError('Learning Rate Plateau Reducing mode %s is unknown!')
+        if self.mode == 'min' :
+            self.monitor_op = lambda a, b: np.less(a, b - self.epsilon)
+            self.best = np.Inf
+        else:
+            self.monitor_op = lambda a, b: np.greater(a, b + self.epsilon)
+            self.best = -np.Inf
+        self.cooldown_counter = 0
+        self.wait = 0
+        self.lr_epsilon = self.min_lr * 1e-4
+
+    def reset(self):
+        self._reset()
+
+    def step(self, metrics, epoch):
+        current = metrics
+        if current is None:
+            warnings.warn('Learning Rate Plateau Reducing requires metrics available!', RuntimeWarning)
+        else:
+            if self.in_cooldown():
+                self.cooldown_counter -= 1
+                self.wait = 0
+
+            if self.monitor_op(current, self.best):
+                self.best = current
+                self.wait = 0
+            elif not self.in_cooldown():
+                if self.wait >= self.patience:
+                    for param_group in self.optimizer.param_groups:
+                        old_lr = float(param_group['lr'])
+                        if old_lr > self.min_lr + self.lr_epsilon:
+                            new_lr = old_lr * self.factor
+                            new_lr = max(new_lr, self.min_lr)
+                            param_group['lr'] = new_lr
+                            if self.verbose > 0:
+                                print('\nEpoch %05d: reducing learning rate to %s.' % (epoch, new_lr))
+                            self.cooldown_counter = self.cooldown
+                            self.wait = 0
+                self.wait += 1
+
+    def in_cooldown(self):
+        return self.cooldown_counter > 0
Index: src/com/util/pereira_word_user_correlation.tsv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/pereira_word_user_correlation.tsv b/src/com/util/pereira_word_user_correlation.tsv
new file mode 100644
--- /dev/null	(date 1616247296000)
+++ b/src/com/util/pereira_word_user_correlation.tsv	(date 1616247296000)
@@ -0,0 +1,2881 @@
+user	correlation
+M04	0.135670218131284
+M04	0.3464328878080602
+M04	0.18512367803906227
+M04	0.14488089265312704
+M04	0.16348065642017245
+M04	0.14795556862440226
+M04	0.1968332582667413
+M04	0.23886915034757536
+M04	0.2547286217358025
+M04	0.23352772351113202
+M04	0.26564333834243076
+M04	0.26332565891065374
+M04	0.29135166831871717
+M04	0.19819628022471306
+M04	0.14800943786203086
+M04	0.17648267561883918
+M04	0.3577236224622553
+M04	0.20456668216129492
+M04	0.2625788587567465
+M04	0.3292651640237493
+M04	0.24519748629153365
+M04	0.09275522635502884
+M04	0.18063464518710656
+M04	0.18053822086842722
+M04	0.3019478955536523
+M04	0.11684677795273832
+M04	0.1907259058328482
+M04	0.034242511229871125
+M04	0.17341487110474127
+M04	0.13954156496003547
+M04	0.24379319191285456
+M04	0.2711207658738839
+M04	0.25089922111988167
+M04	0.08528058219405778
+M04	0.2591901011560665
+M04	0.29082997287114987
+M04	0.1282208441019948
+M04	0.19939895225596593
+M04	0.271372333669491
+M04	0.3250821123610187
+M04	0.20226954889124346
+M04	0.22706169902216486
+M04	0.6276071515299795
+M04	0.2497746219709422
+M04	0.27150658720899645
+M04	0.2727291770568692
+M04	0.17221804874977234
+M04	0.21761818209586145
+M04	0.14547587510427176
+M04	0.23432074675996428
+M04	0.16755449679343726
+M04	0.219594290934575
+M04	0.21716405329013633
+M04	0.13946639611258618
+M04	0.2982255993143712
+M04	0.28341776143668096
+M04	0.14983621983056783
+M04	0.23694565921341593
+M04	0.31662054672946816
+M04	0.08991790907022856
+M04	0.24997655377608166
+M04	0.18484404582438585
+M04	0.22709210141879146
+M04	0.30777897401337795
+M04	0.1625647058762863
+M04	0.31098346392305193
+M04	0.2863231133663809
+M04	0.25625519127780727
+M04	0.15583720057650705
+M04	0.3971099889222859
+M04	0.27453244472410887
+M04	0.28354835809275414
+M04	0.22734860625492523
+M04	0.18348033921581106
+M04	0.36244024316182827
+M04	0.5013168185849258
+M04	0.24272266744700632
+M04	0.20406374516724246
+M04	0.2160353097751184
+M04	0.28695625759502685
+M04	0.129782245393772
+M04	0.1020303045186459
+M04	0.19660306436554484
+M04	0.22838725489955775
+M04	0.1511981453613788
+M04	0.3602353176973712
+M04	0.2658063749319107
+M04	0.24932794839985756
+M04	0.28330563027995836
+M04	0.2495992845423069
+M04	0.27634933906571535
+M04	0.2449708233664205
+M04	0.22720401990306593
+M04	0.2746549262642502
+M04	0.20098230805087738
+M04	0.15388108117064853
+M04	0.2720668813067615
+M04	0.32182239812628394
+M04	0.11376102356263645
+M04	0.3388393860592659
+M04	0.18202951919623467
+M04	0.23965624019747078
+M04	0.22258174881844156
+M04	0.27198228372575795
+M04	0.3767824338346932
+M04	0.2744070012539679
+M04	0.12543972083849858
+M04	0.28872979307841246
+M04	0.2218535189919836
+M04	0.38629546045356894
+M04	0.1784687217009878
+M04	0.3049162060532967
+M04	0.16965938591815946
+M04	0.21521324819272825
+M04	0.20403383108848824
+M04	0.38708131656765143
+M04	0.28598517674931395
+M04	0.1705852074058338
+M04	0.07174038486084806
+M04	0.2613931397128177
+M04	0.3322197196542995
+M04	0.15662644305559506
+M04	0.43016185387395384
+M04	0.16583088719253652
+M04	0.05140993102396625
+M04	0.10226023255601394
+M04	0.27153645713608776
+M04	0.14291630790338258
+M04	0.2579957883647804
+M04	0.3048882771003597
+M04	0.3543499237324681
+M04	0.15942379240218105
+M04	0.4201880628136159
+M04	0.14195803677753713
+M04	0.3145510804621095
+M04	0.24653691515039525
+M04	0.16184860511393628
+M04	0.31425831912066393
+M04	0.36238261140944444
+M04	0.2629346618766394
+M04	0.23409211752788092
+M04	0.3557606698067696
+M04	0.31134307411810885
+M04	0.1817714431981009
+M04	0.20511676085823505
+M04	0.09943738261085269
+M04	0.4029874228221512
+M04	0.245236602500065
+M04	0.2727072827713129
+M04	0.1723426171417697
+M04	0.324652985647871
+M04	0.1747529133257787
+M04	0.1642155020436529
+M04	0.25223499673147376
+M04	0.10545585652628914
+M04	0.2001256785163042
+M04	0.3396140170730537
+M04	0.3205366867207214
+M04	0.3340001129125281
+M04	0.32538713243747086
+M04	0.386761036327511
+M04	0.19997494594745757
+M04	0.18842577929110674
+M04	0.2167292169562795
+M04	0.1493971786186521
+M04	0.1295625643777774
+M04	0.15204659196477469
+M04	0.22025255784972997
+M04	0.21975908914226108
+M04	0.20965650481516088
+M04	0.17216686576081927
+M04	0.2368198925154497
+M04	0.2512974351831335
+M04	0.2313051786056368
+M04	0.29806033892765477
+M04	0.3856947068733614
+M04	0.2959688903905711
+M04	0.19347654569220138
+M04	0.24871667228579633
+M04	0.15808437335477857
+M15	0.14000893581240023
+M15	0.22798061710474882
+M15	0.20057514069768284
+M15	0.10193690192793314
+M15	0.25224672935547804
+M15	0.2147176906792231
+M15	0.28797010092094444
+M15	0.3089619021883398
+M15	0.18812837169483188
+M15	0.19626413042049254
+M15	0.24607933223403197
+M15	0.14315725019195563
+M15	0.25694809535532503
+M15	0.2932953566538251
+M15	0.2680316159661862
+M15	0.09950263340379019
+M15	0.34900919684650317
+M15	0.2045108067155043
+M15	0.27094321614265177
+M15	0.2522415487853146
+M15	0.1980351204147682
+M15	0.11927216975246951
+M15	0.238091600689232
+M15	0.14919989550563417
+M15	0.29520055826975594
+M15	0.3755164060058906
+M15	0.13242202506303424
+M15	0.21065611204437326
+M15	0.240501946588512
+M15	0.18001301508011813
+M15	0.29965186122199494
+M15	0.2738344503966189
+M15	0.17044144951626997
+M15	0.19297034873124252
+M15	0.16705549171163994
+M15	0.3139766776413474
+M15	0.20324144099372293
+M15	0.08665139106560173
+M15	0.18434278100066195
+M15	0.16904576292062146
+M15	0.20374638510382306
+M15	0.2947011498534629
+M15	0.3207155413199929
+M15	0.2618459137384902
+M15	0.2599935919963823
+M15	0.286667288654744
+M15	0.24924496732548895
+M15	0.109491930302667
+M15	0.1472782796186698
+M15	0.33032917786490923
+M15	0.23454855765319885
+M15	0.13622291915130078
+M15	0.2057171945778288
+M15	0.28034018939160915
+M15	0.2950754736340258
+M15	0.2699683794598664
+M15	0.22125764663832992
+M15	0.28582769161326577
+M15	0.3201636141812639
+M15	0.3227774676288207
+M15	0.2076147524538794
+M15	0.2657025091646037
+M15	0.19401600714002856
+M15	0.15976410497405907
+M15	0.17665801194221506
+M15	0.09431316696270504
+M15	0.1926184230268421
+M15	0.20220626169632572
+M15	0.25356008366767874
+M15	0.3141437991699404
+M15	0.25020319934910323
+M15	0.29627743319103844
+M15	0.2521859785650231
+M15	0.3218325730147976
+M15	0.21639736452185077
+M15	0.3428593363395324
+M15	0.19790585770338326
+M15	0.2782323660308892
+M15	0.23521824361269356
+M15	0.2624840118985529
+M15	0.25439236585082725
+M15	0.18951236146508954
+M15	0.07603486557418651
+M15	0.18635796425374623
+M15	0.09687113876190658
+M15	0.1310606430254049
+M15	0.22367923799093145
+M15	0.21155837070057296
+M15	0.17330113741992037
+M15	0.21895985731123957
+M15	0.29578051150079715
+M15	0.21814622456962945
+M15	0.2461656885313424
+M15	0.28103535849869277
+M15	0.12246442492162489
+M15	0.24354233093665553
+M15	0.2797587183235247
+M15	0.2830648442999608
+M15	0.23977498074335524
+M15	0.12578669554150926
+M15	0.2200544424654706
+M15	0.14391172973046834
+M15	0.05556557053821575
+M15	0.25113463416675447
+M15	0.27460351009001766
+M15	0.16335489791402782
+M15	0.24556274590480295
+M15	0.22976570355182696
+M15	0.16117037366066855
+M15	0.3909257195507693
+M15	0.26101164686585065
+M15	0.2070574401823176
+M15	0.20402082392728066
+M15	0.1350934301077153
+M15	0.23308110565842877
+M15	0.24372760214185699
+M15	0.3483410392747799
+M15	0.13706478482012524
+M15	0.1936032365246012
+M15	0.24077332288228698
+M15	0.1531964552733282
+M15	0.21824717799021573
+M15	0.3334258614395657
+M15	0.13477035683969188
+M15	0.11064393836164473
+M15	0.2432766221931202
+M15	0.0154968375917349
+M15	0.15921422912577257
+M15	0.37312133000165537
+M15	0.2584292801895892
+M15	0.14297837903554164
+M15	0.10308753192190175
+M15	0.28468455691766353
+M15	0.12423435613088896
+M15	0.2547025739639563
+M15	0.31692268258289436
+M15	0.29459500191354976
+M15	0.45335608756198714
+M15	0.3096682679261089
+M15	0.169492056125129
+M15	0.27485788843680625
+M15	0.31800272181834294
+M15	0.10572632681991366
+M15	0.2613631399305785
+M15	0.19896771804072552
+M15	0.3006786064451267
+M15	0.3789245905548421
+M15	0.2980394703837066
+M15	0.1803541752605582
+M15	0.23622863818388165
+M15	0.24322358397611402
+M15	0.13375153621993818
+M15	0.2679934999720195
+M15	0.10340116370819406
+M15	0.2522218726129159
+M15	0.13763330639088878
+M15	0.14839828233070984
+M15	0.11836795358153283
+M15	0.17548229268143747
+M15	0.3110402711185113
+M15	0.29740507258170895
+M15	0.07514742178268273
+M15	0.11955837012490773
+M15	0.14654366019311418
+M15	0.22125398585197212
+M15	0.326982050081225
+M15	0.3031680600841215
+M15	0.16687680858001847
+M15	0.20881894021854516
+M15	0.16758388674832791
+M15	0.21020083184010785
+M15	0.2931382696382235
+M15	0.3260846558790206
+M15	0.1345119016105765
+M15	0.37307440352039595
+M15	0.3617594776096081
+M15	0.19538433428343052
+M15	0.24926953361657428
+M15	0.25155713584971606
+M15	0.33872135694451194
+M14	0.22861532810685567
+M14	0.2722624581278529
+M14	0.3285846693954845
+M14	0.16922433312163657
+M14	0.18440244369820605
+M14	0.21098480432713848
+M14	0.296444309924022
+M14	0.21623718318805843
+M14	0.21749060295499845
+M14	0.2577566901518912
+M14	0.13624531256487743
+M14	0.1828199905313145
+M14	0.22405535547853797
+M14	0.21542506152976956
+M14	0.19620646907387607
+M14	0.3068679036256922
+M14	0.1758520023158712
+M14	0.29660950046056733
+M14	0.23303381384246116
+M14	0.3397246197490067
+M14	0.19298936339893463
+M14	0.22028932590502295
+M14	0.11211810711005452
+M14	0.34530386087551146
+M14	0.26390456073212104
+M14	0.11628811659705383
+M14	0.2394923188895032
+M14	0.1351102688616944
+M14	0.3641743976589187
+M14	0.15200694935926226
+M14	0.19890838147032633
+M14	0.13620609616597765
+M14	0.2663909825371705
+M14	0.24056664033452205
+M14	0.20879541893904843
+M14	0.4303502761053381
+M14	0.25397761121621515
+M14	0.22515432232885413
+M14	0.13201622420864514
+M14	0.14035569055118305
+M14	0.3208573349437924
+M14	0.18859908940389916
+M14	0.45031591235750396
+M14	0.1528337453770709
+M14	0.25364360946731773
+M14	0.2126292410592586
+M14	0.1951556392643638
+M14	0.12270273390716832
+M14	0.2518992248410426
+M14	0.13936838605554852
+M14	0.14483128050507427
+M14	0.30630052355183923
+M14	0.10410508218225369
+M14	0.24201664874527432
+M14	0.2599333468543411
+M14	0.3725173110182415
+M14	0.10667010613212503
+M14	0.27702253313804204
+M14	0.4262963459469416
+M14	0.1420566202172255
+M14	0.2851769123796433
+M14	0.17626599250515232
+M14	0.33022737171483124
+M14	0.2970043120854249
+M14	0.20038311055087074
+M14	0.24732671818506627
+M14	0.2990906874061436
+M14	0.19839591942057305
+M14	0.19303790619510727
+M14	0.45015479761448407
+M14	0.3472953190250204
+M14	0.29272008522009596
+M14	0.2218649645677107
+M14	0.2922750257193007
+M14	0.08097592020461616
+M14	0.24794751846038293
+M14	0.1813780319825307
+M14	0.28119929790930037
+M14	0.16899200077616378
+M14	0.19217684041291389
+M14	0.1126577250929207
+M14	0.10729555501452534
+M14	0.24096611540443277
+M14	0.18573642812039326
+M14	0.08432574451153046
+M14	0.26101439013095973
+M14	0.29879259115960116
+M14	0.21397286786182892
+M14	0.3551628892445771
+M14	0.2582322615766861
+M14	0.28971376862522424
+M14	0.30615770105211204
+M14	0.21973657893602835
+M14	0.290740167836925
+M14	0.3890014016141649
+M14	0.28484401707211243
+M14	0.3471759269589585
+M14	0.3208442073932044
+M14	0.19134928205609952
+M14	0.2625166682325221
+M14	0.27252953067698504
+M14	0.1741005781351669
+M14	0.053921646273366805
+M14	0.1686972534675153
+M14	0.3827595771809001
+M14	0.2124698776721943
+M14	0.28334649378793886
+M14	0.11576221340796616
+M14	0.1409543364236961
+M14	0.19276796095278087
+M14	0.22093076782762597
+M14	0.1432965948178294
+M14	0.27324449378931776
+M14	0.15050834685129227
+M14	0.1438998208690566
+M14	0.2821296048302575
+M14	0.3278260945607741
+M14	0.19365003358523897
+M14	0.2117304130400752
+M14	0.16868116960328905
+M14	0.29358633071472523
+M14	0.3144357682630307
+M14	0.4378797766414956
+M14	0.2663730227048559
+M14	0.13463168139372733
+M14	0.21809845139398054
+M14	0.2134358586879705
+M14	0.19003113756745438
+M14	0.32504394512852874
+M14	0.1712685395874499
+M14	0.21597788087585715
+M14	0.07068449888782635
+M14	0.268841624313665
+M14	0.14432279656337135
+M14	0.28200885261313186
+M14	0.3796642883321656
+M14	0.17251949975486258
+M14	0.40537860334629616
+M14	0.2905885119232623
+M14	0.1588914606035277
+M14	0.26849003386363035
+M14	0.27244072815807935
+M14	0.24079021458060906
+M14	0.3084957376027031
+M14	0.24849856697075212
+M14	0.23066034959003293
+M14	0.367305496963717
+M14	0.2609954826442341
+M14	0.22665977070233848
+M14	0.28834862414511125
+M14	0.21406207390754106
+M14	0.25906944724922276
+M14	0.2337348030388199
+M14	0.07875627032588667
+M14	0.2732978380310512
+M14	0.3307981965884347
+M14	0.34013379470857763
+M14	0.16184465461806144
+M14	0.22640939883673034
+M14	0.17250421698919685
+M14	0.4213885960794561
+M14	0.23619269144626504
+M14	0.17909886387123136
+M14	0.2276282136713657
+M14	0.15932653296979898
+M14	0.3006703004683501
+M14	0.2379295575898769
+M14	0.14893651249424195
+M14	0.21412311395998426
+M14	0.2135267982512666
+M14	0.17702304555800588
+M14	0.1446357998124836
+M14	0.20046716309099702
+M14	0.1843571543955998
+M14	0.33838168862352874
+M14	0.30465413043968886
+M14	0.1047954947485384
+M14	0.33099850998979247
+M14	0.28055142554775403
+M14	0.19926540368608475
+M17	0.2412121989703843
+M17	0.3300580016119112
+M17	0.16116649460530588
+M17	0.10625495312233636
+M17	0.3660191413930462
+M17	0.22623297830409392
+M17	0.25346553276247374
+M17	0.16530029574582872
+M17	0.12581525140349
+M17	0.19099405185277005
+M17	0.16989292852978066
+M17	0.16473629217410185
+M17	0.16491102011438266
+M17	0.20581105226782284
+M17	0.15599856699023923
+M17	0.23330341376866431
+M17	0.37955955358389876
+M17	0.1331814072346433
+M17	0.4217612293776826
+M17	0.14685378711161756
+M17	0.09639667291589807
+M17	0.30046850384739615
+M17	0.10924629802371008
+M17	0.3426079302458706
+M17	0.22240921153328536
+M17	0.345979147491763
+M17	0.14063019732621465
+M17	0.25410897666839877
+M17	0.27708423514231456
+M17	0.20110731738502022
+M17	0.20394434094589342
+M17	0.20440693480507108
+M17	0.14314423733186665
+M17	0.25719087341636165
+M17	0.276125928031777
+M17	0.356054761645219
+M17	0.15146236159783982
+M17	0.1465176201041315
+M17	0.34811754628302316
+M17	0.2792601333986265
+M17	0.2081266904220452
+M17	0.34085734763489267
+M17	0.5370371617610774
+M17	0.2814590093740332
+M17	0.1838022717733468
+M17	0.295701902547356
+M17	0.1850591443330408
+M17	0.18758342916614693
+M17	0.2079459250758236
+M17	0.169891074929364
+M17	0.058725939015357144
+M17	0.2586699990332872
+M17	0.12079688304890972
+M17	0.10040419668708436
+M17	0.2649748860190976
+M17	0.3013996484971369
+M17	0.12766151809184115
+M17	0.1661457413701399
+M17	0.27976220443927424
+M17	0.2366344358181492
+M17	0.197922815100509
+M17	0.14120595355975912
+M17	0.14332058334090853
+M17	0.16501802729116327
+M17	0.186362130523359
+M17	0.2594201756934027
+M17	0.25103347965793593
+M17	0.22702610530271922
+M17	0.14647458413690292
+M17	0.3675048875397996
+M17	0.17412793344171942
+M17	0.16884506047027492
+M17	0.2735247369185185
+M17	0.1759697363318026
+M17	0.26116606024723127
+M17	0.29607404834451456
+M17	0.2941285103503184
+M17	0.14032274755315707
+M17	0.24626464530535302
+M17	0.14240522286725235
+M17	0.21502280657217032
+M17	0.2657993775836069
+M17	0.24978790669149922
+M17	0.12384577987713477
+M17	0.2509509912973839
+M17	0.34567417386813865
+M17	0.17035362866335713
+M17	0.11384664436556007
+M17	0.18643280927946518
+M17	0.1821779753537141
+M17	0.10961217205356169
+M17	0.3851147191145568
+M17	0.3611475545683241
+M17	0.2565393635768762
+M17	0.19938377744884614
+M17	0.23379642289952873
+M17	0.1511187603941203
+M17	0.3627263251740178
+M17	0.1928624005837939
+M17	0.25248088170134825
+M17	0.2602243539425085
+M17	0.24212776298179267
+M17	0.23992579494800717
+M17	0.19176844996979842
+M17	0.3261183110785242
+M17	0.2563538005622352
+M17	0.24791059991730952
+M17	0.23094525802754903
+M17	0.17300058236806268
+M17	0.2389751271805617
+M17	0.268242124895465
+M17	0.32621958052827804
+M17	0.1904953752388159
+M17	0.31698629840679055
+M17	0.12439765580726019
+M17	0.2180785639546737
+M17	0.25433545539968083
+M17	0.34008613530706955
+M17	0.2129352112646299
+M17	0.27098537340762
+M17	0.22265118979823934
+M17	0.05865656473953744
+M17	0.43952390947795317
+M17	0.22706834491127878
+M17	0.2515541936202441
+M17	0.18319433539936508
+M17	0.07940742299973617
+M17	0.19274081701446663
+M17	0.1405683787372987
+M17	0.14412718940120206
+M17	0.37018250185793106
+M17	0.0929461361116386
+M17	0.23431423061645307
+M17	0.211087527774617
+M17	0.21658357042961932
+M17	0.3896514803771824
+M17	0.3056595952315395
+M17	0.22033186734159668
+M17	0.31785077096300074
+M17	0.1509289206156085
+M17	0.15720761770995867
+M17	0.2754618274668265
+M17	0.07090313872543362
+M17	0.24245895625282146
+M17	0.1684408793156769
+M17	0.1375181456871218
+M17	0.31084611552595437
+M17	0.19714857971810795
+M17	0.19960432524899568
+M17	0.23792354847195102
+M17	0.2948960113572975
+M17	0.22060565777913008
+M17	0.21661839223109405
+M17	0.1293805426594035
+M17	0.33381645915583585
+M17	0.20895968269361181
+M17	0.2660664954688433
+M17	0.21384212024181723
+M17	0.2896245873061077
+M17	0.28776923696109785
+M17	0.1580734491162706
+M17	0.26378006178537994
+M17	0.2549111304410766
+M17	0.22590908458972286
+M17	0.20002677765395194
+M17	0.12312489717220157
+M17	0.27304749144183044
+M17	0.1012839157757294
+M17	0.15130749185943812
+M17	0.2500061217039683
+M17	0.18587476018132457
+M17	0.27758069616323267
+M17	0.2836287034245287
+M17	0.19488833535536784
+M17	0.2972475060716794
+M17	0.33968239660431754
+M17	0.24869798186381098
+M17	0.24578775169597103
+M17	0.20737744357359036
+M17	0.2599604856843793
+M02	0.2515168446985301
+M02	0.13392886557520037
+M02	0.2752816362235813
+M02	0.06868915713171284
+M02	0.20715558128367195
+M02	0.15435878358570132
+M02	0.21730011057215773
+M02	0.12435238328010217
+M02	0.19029462448220993
+M02	0.18819449203952732
+M02	0.20948028260333026
+M02	0.17146981271804435
+M02	0.18435370802898274
+M02	0.12864902265374745
+M02	0.15053247116669558
+M02	0.25735376667574966
+M02	0.10163534016788145
+M02	0.15168133413823326
+M02	0.3600628799679248
+M02	0.2755494468012902
+M02	0.18117507512655967
+M02	0.28780042888584456
+M02	0.28834078003503066
+M02	0.21880954574636696
+M02	0.2153097784825701
+M02	0.19353985517298392
+M02	0.16660390687555235
+M02	0.2264125727885843
+M02	0.2845427880271533
+M02	0.2767656511160847
+M02	0.20142441876565054
+M02	0.2390771921185973
+M02	0.15213945937968362
+M02	0.20451305090256866
+M02	0.2203997408080829
+M02	0.3455270946105789
+M02	0.17652136042129704
+M02	0.2868969407947766
+M02	0.22543834517465544
+M02	0.23342605186146387
+M02	0.24989992545743434
+M02	0.258854816102342
+M02	0.25223511909620566
+M02	0.23398987541738067
+M02	0.09852393024681053
+M02	0.15618464707659122
+M02	0.2883998815252153
+M02	0.1531817960791899
+M02	0.22820273313334147
+M02	0.26377075462147875
+M02	0.25463759927824053
+M02	0.22551980968913518
+M02	0.27807096831141687
+M02	0.2690876660952434
+M02	0.15800740315275072
+M02	0.38533751338708205
+M02	0.17943155632695004
+M02	0.20363562035527263
+M02	0.3040481671175565
+M02	0.2132993250652351
+M02	0.13005819246402034
+M02	0.16064823770028944
+M02	0.32975941597424807
+M02	0.1820635512640063
+M02	0.2520269580254913
+M02	0.1202882587743496
+M02	0.21972875094487018
+M02	0.2277359922822161
+M02	0.2298358123603999
+M02	0.30698949258617597
+M02	0.30606076347401256
+M02	0.17308031187740433
+M02	0.14476261278045646
+M02	0.20128377923749152
+M02	0.2942008880332578
+M02	0.442536403623263
+M02	0.296888917306109
+M02	0.2590877932769311
+M02	0.23930677410054915
+M02	0.26159315411825096
+M02	0.18649021278653355
+M02	0.2565763785868616
+M02	0.21095714824439063
+M02	0.19759343103225735
+M02	0.10395620203180439
+M02	0.24735655309506246
+M02	0.07235158221773337
+M02	0.117601241035996
+M02	0.17981259608837397
+M02	0.20499207970072847
+M02	0.21803022359789764
+M02	0.3466586948450772
+M02	0.2702454621927763
+M02	0.1405425493123464
+M02	0.37232885370929225
+M02	0.2459890621802557
+M02	0.19576060692514238
+M02	0.19679935942563004
+M02	0.24926164443392299
+M02	0.27645964943239887
+M02	0.19594717939699866
+M02	0.12220093164302122
+M02	0.16406096066321238
+M02	0.27588949665594675
+M02	0.24984505694492012
+M02	0.2793330184936715
+M02	0.15075141542570428
+M02	0.2489517043230063
+M02	0.1687757118729897
+M02	0.2901642073325384
+M02	0.19760474446880413
+M02	0.1470236990977414
+M02	0.28691354588939283
+M02	0.1648398414592559
+M02	0.11904488362883613
+M02	0.1973556603656722
+M02	0.14555767073390863
+M02	0.21211941538626583
+M02	0.19346368499233543
+M02	0.2243183792303957
+M02	0.18505409982556253
+M02	0.16305632840996465
+M02	0.25889176493680666
+M02	0.2068837643357036
+M02	0.18496102227106026
+M02	0.16230716403062048
+M02	0.1975210788680854
+M02	0.23087799199300493
+M02	0.22556449983695093
+M02	0.31832955226879595
+M02	0.22677424290927267
+M02	0.10663693892453699
+M02	0.35386361492274876
+M02	0.31401237293451073
+M02	0.2959304683836513
+M02	0.3320360883175934
+M02	0.23011152149441716
+M02	0.31835100753424644
+M02	0.14102291519057367
+M02	0.27004784940496374
+M02	0.11845581008220386
+M02	0.22474934643609476
+M02	0.1922322086793267
+M02	0.2719132513167641
+M02	0.2637787193942318
+M02	0.2580920145668176
+M02	0.28676388467135105
+M02	0.28955022619341375
+M02	0.23340712273600533
+M02	0.22273716111678551
+M02	0.2850394553712751
+M02	0.26762355027029516
+M02	0.22814367047869213
+M02	0.17222145082154006
+M02	0.153942454846661
+M02	0.3137045745598693
+M02	0.25769959416091653
+M02	0.1499435386880509
+M02	0.20219074021595548
+M02	0.20275931408717662
+M02	0.3172423227876074
+M02	0.22647274436806578
+M02	0.2556702927183032
+M02	0.16134595246826963
+M02	0.13258613084692988
+M02	0.16633821298538082
+M02	0.1989285855514792
+M02	0.18584256429784007
+M02	0.1335237772023902
+M02	0.2384270568473001
+M02	0.167356111110889
+M02	0.22764231812852803
+M02	0.2270452903007977
+M02	0.13253855837899953
+M02	0.26540848248982085
+M02	0.4545949022518522
+M02	0.3227042221894105
+M02	0.20554909641690547
+M02	0.2303979698991046
+M02	0.13209425980289483
+M03	0.16559366168646872
+M03	0.1343239851854948
+M03	0.2902370494331679
+M03	0.15179332909260154
+M03	0.24894179633638977
+M03	0.29917848060547786
+M03	0.20351664211375586
+M03	0.17869622891673767
+M03	0.20109699020775887
+M03	0.10864609482764043
+M03	0.2027018459282721
+M03	0.2954645635632226
+M03	0.3128896777595685
+M03	0.25406122529902936
+M03	0.17326691186466944
+M03	0.38118646520484395
+M03	0.2150794610986046
+M03	0.35368798525597944
+M03	0.23370679417252774
+M03	0.35412162995948787
+M03	0.1465144873538305
+M03	0.11734605683949828
+M03	0.23381540113655008
+M03	0.29283863511921615
+M03	0.12265850557277805
+M03	0.3616034242796299
+M03	0.21775977966379564
+M03	0.24068562594648782
+M03	0.38017232777045457
+M03	0.1766379121022552
+M03	0.20248428587899667
+M03	0.4413740235358119
+M03	0.2996398709631689
+M03	0.08008585977007565
+M03	0.36100968945130996
+M03	0.39320923634048405
+M03	0.17507655185388085
+M03	0.3047807535885562
+M03	0.12108783116824914
+M03	0.2427952208748427
+M03	0.3716770082802568
+M03	0.1954556630120452
+M03	0.4556346538878885
+M03	0.2389737025971973
+M03	0.2813306404117853
+M03	0.36065033174275857
+M03	0.30191443477583363
+M03	0.09055614263886042
+M03	0.23375441431841337
+M03	0.1412918235870647
+M03	0.26551653038296813
+M03	0.15310769201223445
+M03	0.13744828437853476
+M03	0.3023511005034186
+M03	0.23382966433903984
+M03	0.3064678448595409
+M03	0.1282429014854864
+M03	0.08515857592036971
+M03	0.4372056824432396
+M03	0.3362095554273822
+M03	0.28158504060275896
+M03	0.29735195258578795
+M03	0.20261278763557902
+M03	0.10774886966738506
+M03	0.26183829455774865
+M03	0.23377558329040884
+M03	0.3378626904611518
+M03	0.22721052131288855
+M03	0.2785602559406016
+M03	0.19741475569889191
+M03	0.14888073418961145
+M03	0.342114070238508
+M03	0.16880678229811646
+M03	0.2280422749324416
+M03	0.16625739864160446
+M03	0.37243279663933776
+M03	0.32030131311215365
+M03	0.2642040762298936
+M03	0.3246937236567857
+M03	0.2779614637176596
+M03	0.21546919834912606
+M03	0.29689268841100686
+M03	0.2769520031555605
+M03	0.24547709781562532
+M03	0.15850107835143346
+M03	0.3478172257298431
+M03	0.25307183514740267
+M03	0.28294158017587023
+M03	0.3190733215930314
+M03	0.18840151538687439
+M03	0.2681631728544648
+M03	0.16056121163921355
+M03	0.3842032930666879
+M03	0.2656252809789332
+M03	0.21573089584220234
+M03	0.08173824629403546
+M03	0.4803006355921188
+M03	0.3383187170400525
+M03	0.24252181300826925
+M03	0.2303027757768515
+M03	0.2942595853371347
+M03	0.19768232369759964
+M03	0.1407654970650504
+M03	0.2303422943782165
+M03	0.34081369959386276
+M03	0.2611682435838946
+M03	0.19523291903172799
+M03	0.2999885451725863
+M03	0.17175950354048744
+M03	0.4857751677384825
+M03	0.18021323006781012
+M03	0.17266665712596152
+M03	0.07238953715607209
+M03	0.36590054664216076
+M03	0.14513434660471866
+M03	0.4057716062167274
+M03	0.27566145837806694
+M03	0.2583317123782599
+M03	0.2259616186676441
+M03	0.1868229276393186
+M03	0.4587914893618879
+M03	0.3026277731371086
+M03	0.2330338617495142
+M03	0.16778532883871408
+M03	0.13174208872153198
+M03	0.2589257947132431
+M03	0.16024107051750044
+M03	0.2706489691658698
+M03	0.36560891558757247
+M03	0.34657683561619607
+M03	0.36928936572693427
+M03	0.1688840211847194
+M03	0.19285313810998067
+M03	0.1379426935485717
+M03	0.22809912717122255
+M03	0.41672294457860115
+M03	0.15838048548174705
+M03	0.4890088671287229
+M03	0.41212944953613256
+M03	0.31431399003554256
+M03	0.2613868282736505
+M03	0.33993677639133985
+M03	0.18447564056138172
+M03	0.2778167919188065
+M03	0.2193443811205523
+M03	0.104427728357096
+M03	0.328944320344888
+M03	0.25248584289842474
+M03	0.2575185653249829
+M03	0.11250549470338289
+M03	0.4281098891865839
+M03	0.2487413473065094
+M03	0.23454052648340806
+M03	0.23447857567869157
+M03	0.3846493792307137
+M03	0.4126674223040516
+M03	0.27972421033508893
+M03	0.1389677321237401
+M03	0.14593245792974097
+M03	0.36551477544037747
+M03	0.4181944994879972
+M03	0.25954977640202526
+M03	0.3390684006491826
+M03	0.22184928991378192
+M03	0.274604623045817
+M03	0.21862792221426106
+M03	0.18702240280125101
+M03	0.1480206745020948
+M03	0.25055535287333536
+M03	0.11756034629979085
+M03	0.2957113408042901
+M03	0.2068154257279656
+M03	0.4020125174568606
+M03	0.2760945779822879
+M03	0.3413371306667645
+M03	0.5029195862527257
+M03	0.24314009916094187
+M03	0.14166436212814107
+M03	0.18265029574294203
+M03	0.3614678221897948
+M06	0.2093111453444512
+M06	0.31463312074660443
+M06	0.1291705808386922
+M06	0.019650408936089298
+M06	0.37463580057415763
+M06	0.16086655472249353
+M06	0.2652945670415393
+M06	0.2927609344723026
+M06	0.2948278789773617
+M06	0.21241566722501
+M06	0.13132230868244568
+M06	0.11946435637003587
+M06	0.30153205003943073
+M06	0.3000908860828793
+M06	0.24451756993282273
+M06	0.2619081880089779
+M06	0.41257668877981946
+M06	0.21805900478023213
+M06	0.3133871976246586
+M06	0.3314062615155601
+M06	0.12247145818860107
+M06	0.17850821999740554
+M06	0.2715783297568245
+M06	0.11990369429179168
+M06	0.27851117091061794
+M06	0.13477655193402205
+M06	0.1739594308741567
+M06	0.2639157982880143
+M06	0.2284261317799739
+M06	0.19019915255647815
+M06	0.18669729682425268
+M06	0.2095159291233378
+M06	0.2097166971252056
+M06	0.2487756526041039
+M06	0.3252067338656519
+M06	0.22751957519016397
+M06	0.15204910081916612
+M06	0.25178628171379625
+M06	0.3039088986853654
+M06	0.28775417177275203
+M06	0.29585725146868
+M06	0.3617779857607571
+M06	0.4925701631814234
+M06	0.3478197865442879
+M06	0.2354261445358742
+M06	0.3515412575008092
+M06	0.3018918099799349
+M06	0.19158761500961738
+M06	0.16960324269620888
+M06	0.3803316417413607
+M06	0.21644215022361393
+M06	0.2837854297532891
+M06	0.149163469779825
+M06	0.182804222623958
+M06	0.21814001269073305
+M06	0.056839543112068576
+M06	0.20695002379363342
+M06	0.20543580651835733
+M06	0.21042922617467813
+M06	0.13413175608852929
+M06	0.2988357457227624
+M06	0.2947522602757608
+M06	0.3345087654626568
+M06	0.3076248199405635
+M06	0.2214168741638287
+M06	0.1594592362839348
+M06	0.2838403006456297
+M06	0.1832011642682642
+M06	0.27760501106376173
+M06	0.35142048701186823
+M06	0.23638828811693274
+M06	0.30621402576045326
+M06	0.2455109760959114
+M06	0.19302202448237293
+M06	0.3968542920410566
+M06	0.3611751716909567
+M06	0.3163443909358588
+M06	0.269358894475218
+M06	0.3209753493414462
+M06	0.27658547698873254
+M06	0.18295140474472535
+M06	0.27945796624327973
+M06	0.18582217007019386
+M06	0.17175742972190117
+M06	0.17865538535244405
+M06	0.12627426071175255
+M06	0.2835591751922804
+M06	0.26754979132317597
+M06	0.3414837391950814
+M06	0.310044983043605
+M06	0.3164921634872452
+M06	0.2581106257087968
+M06	0.21580402596801676
+M06	0.1937994976906436
+M06	0.17708540162123068
+M06	0.15877212672730734
+M06	0.25784590219752734
+M06	0.36745995785603336
+M06	0.2618762176216195
+M06	0.19274004136230943
+M06	0.2772898550257589
+M06	0.158077341924837
+M06	0.11536970497503984
+M06	0.1282423554644034
+M06	0.38301227466412585
+M06	0.18820381821855084
+M06	0.29741973363467344
+M06	0.2915735737929917
+M06	0.13472676485551613
+M06	0.2001569850954064
+M06	0.2478469564989597
+M06	0.27022187993111574
+M06	0.1557461753071148
+M06	0.25154897144653604
+M06	0.08895688957691289
+M06	0.21790542772072982
+M06	0.2174386980173088
+M06	0.15607390379780112
+M06	0.21962037855539743
+M06	0.24219053793631853
+M06	0.3280349762730536
+M06	0.20058839182016516
+M06	0.22711542717335803
+M06	0.2710860331635092
+M06	0.10613833798402479
+M06	0.2546959893277445
+M06	0.3687178363580374
+M06	0.29167703882284
+M06	0.37134895420036307
+M06	0.24980179136468691
+M06	0.3639557840734707
+M06	0.10400287524907581
+M06	0.3289930873897415
+M06	0.19764537510810307
+M06	0.3004114959891399
+M06	0.11915329176554308
+M06	0.27649986432393503
+M06	0.38251702756472544
+M06	0.27803290277923226
+M06	0.148720199888801
+M06	0.17093516240675122
+M06	0.1428588659065091
+M06	0.18356462941184862
+M06	0.3378479252140003
+M06	0.3171392040005343
+M06	0.060203271804694765
+M06	0.21440017644657994
+M06	0.18519982065916818
+M06	0.18853826624118109
+M06	0.27121368664572887
+M06	0.40407246891041815
+M06	0.3118654441102703
+M06	0.13397374613277124
+M06	0.19636174119667016
+M06	0.1089229339307937
+M06	0.3165473919871639
+M06	0.3039355195932868
+M06	0.2908158299805016
+M06	0.3387724898106415
+M06	0.1312671204602849
+M06	0.17762710331207637
+M06	0.2452108018879079
+M06	0.3353911605689149
+M06	0.24835496302189927
+M06	0.139842508706943
+M06	0.2940631011574549
+M06	0.05594358610850256
+M06	0.21921450735902945
+M06	0.15468412166437576
+M06	0.2614967449483742
+M06	0.24849517066205898
+M06	0.09749386136466832
+M06	0.18911464708860504
+M06	0.2425798628944794
+M06	0.3622231020897076
+M06	0.44891206213729856
+M06	0.31956263399910184
+M06	0.40566926747998755
+M06	0.14830623843139032
+M06	0.16442710717384024
+M05	0.0903986359427209
+M05	0.18430775434608235
+M05	0.19560575211983122
+M05	0.15832073231405047
+M05	0.32702547222011163
+M05	0.19042143833207528
+M05	0.3418645687350776
+M05	0.32566124584197054
+M05	0.17958321931051913
+M05	0.1974599144916198
+M05	0.10649682352992484
+M05	0.1978490626257825
+M05	0.3023973587784288
+M05	0.21313487458679664
+M05	0.20577766562430172
+M05	0.07864866722801318
+M05	0.5062524301162686
+M05	0.2781029923228672
+M05	0.26813096830493066
+M05	0.3249147589052824
+M05	0.19256249714522147
+M05	0.2651824772821114
+M05	0.20036680105575647
+M05	0.2647077922383354
+M05	0.14201121240682027
+M05	0.2456942927356352
+M05	0.15653984363566706
+M05	0.13670442301552888
+M05	0.2820929017368992
+M05	0.20095055870376863
+M05	0.3274452751545537
+M05	0.26957626429317816
+M05	0.19843821279739876
+M05	0.23257046692205452
+M05	0.23989964157403768
+M05	0.3462577360009703
+M05	0.19807037154676044
+M05	0.29230782754466217
+M05	0.17843834326467867
+M05	0.29243332087609
+M05	0.21179635300893399
+M05	0.31734284077193226
+M05	0.3333598410886283
+M05	0.21127049593704456
+M05	0.18081653069825426
+M05	0.2579380863110807
+M05	0.15192859480802975
+M05	0.17717093229362385
+M05	0.14078868926069463
+M05	0.3163952064540042
+M05	0.1402287543292291
+M05	0.2665050145979606
+M05	0.2428378440706018
+M05	0.24904073847736877
+M05	0.16908153497590206
+M05	0.3028234710948328
+M05	0.19048326499843807
+M05	0.19037901023438344
+M05	0.3873032463427305
+M05	0.15291206036170257
+M05	0.18938886719758422
+M05	0.11064697081448985
+M05	0.24828770448370224
+M05	0.294950630689402
+M05	0.19907627212144904
+M05	0.15791709242393043
+M05	0.15985686323431464
+M05	0.27176112856715817
+M05	0.29793084764167904
+M05	0.41976365444682234
+M05	0.2805695435721073
+M05	0.29001028007803314
+M05	0.24838648450496134
+M05	0.20560982414536566
+M05	0.3007378397930094
+M05	0.36041148202853657
+M05	0.2729529157837202
+M05	0.21041367881847758
+M05	0.284912408994471
+M05	0.13096154323580195
+M05	0.20571932431427675
+M05	0.16188448155937413
+M05	0.24468468845779956
+M05	0.06885742014384894
+M05	0.12178566263782457
+M05	0.20599595641726917
+M05	0.26933476600237743
+M05	0.10342316227749945
+M05	0.3367929601818914
+M05	0.16246051195395464
+M05	0.17941408335522452
+M05	0.33454055659752585
+M05	0.2992739728308433
+M05	0.2470924114720798
+M05	0.4137086043302768
+M05	0.1879201474080117
+M05	0.39182142414349325
+M05	0.3138274744104738
+M05	0.1653398034561493
+M05	0.21348389954258168
+M05	0.16265865440215813
+M05	0.20529020993700245
+M05	0.1885564642218362
+M05	0.14290697767210486
+M05	0.23531689792962948
+M05	0.2112491787739303
+M05	0.1967276971131468
+M05	0.26753616094527666
+M05	0.1268906239651527
+M05	0.3248984652725028
+M05	0.15392221750698812
+M05	0.24383640473842577
+M05	0.19309427123192352
+M05	0.2706425266420966
+M05	0.3308546627057405
+M05	0.25491356151886163
+M05	0.168704811801551
+M05	0.20478151473410916
+M05	0.2179160780133148
+M05	0.14380442992166062
+M05	0.2636498961649386
+M05	0.2795714756541981
+M05	0.3900722210470532
+M05	0.3094017557529383
+M05	0.10552223859252821
+M05	0.23090955960883308
+M05	0.030076350673369178
+M05	0.17988211055073658
+M05	0.36995214863137194
+M05	0.17074424439317645
+M05	0.1153568969641661
+M05	0.16698040789352023
+M05	0.28252306533850574
+M05	0.21673118985238723
+M05	0.1956649051382455
+M05	0.11700001307310925
+M05	0.29622919084534544
+M05	0.21581498776484082
+M05	0.40169474173090797
+M05	0.12863006881171263
+M05	0.20683326944536065
+M05	0.3189480563281362
+M05	0.19660091565425905
+M05	0.3922089078887063
+M05	0.2756482661655396
+M05	0.17951446427077833
+M05	0.17217954127426816
+M05	0.2651952327529784
+M05	0.1541217360402325
+M05	0.17314329579829343
+M05	0.21660138248021596
+M05	0.23740152771108552
+M05	0.18423947280305747
+M05	0.20085766539751262
+M05	0.34141271147658436
+M05	0.1881804101754225
+M05	0.31255521331597186
+M05	0.23096620403011553
+M05	0.13961451920302717
+M05	0.11376614998819773
+M05	0.3186181351875794
+M05	0.217655905269303
+M05	0.3084655571984632
+M05	0.05438555734253847
+M05	0.23325649644535387
+M05	0.12205758807639161
+M05	0.27375733304258093
+M05	0.10725988434455754
+M05	0.10463019958983016
+M05	0.2566871588382816
+M05	0.3021482260969649
+M05	0.3161336965998496
+M05	0.13393094785263648
+M05	0.24213170097447068
+M05	0.3884500214567742
+M05	0.29811084154455914
+M05	0.27264222735328314
+M05	0.2608295721644778
+M05	0.21503556579434313
+M05	0.3425577184242506
+M07	0.15912436328051305
+M07	0.3003155617080489
+M07	0.1955168573569687
+M07	0.1548493873439669
+M07	0.24499345138610343
+M07	0.1325395508337929
+M07	0.3714104117266752
+M07	0.16842955940350682
+M07	0.1449248506491849
+M07	0.3314683153713592
+M07	0.23753943169743708
+M07	0.22449256512324767
+M07	0.22687353161069154
+M07	0.3232078986028184
+M07	0.20082007117911058
+M07	0.23661830190384803
+M07	0.5443643658656433
+M07	0.23441026048160848
+M07	0.2020657592421721
+M07	0.3261525589289137
+M07	0.23484315005195824
+M07	0.294916720195176
+M07	0.3110229963414912
+M07	0.29584223485570044
+M07	0.2555845952398809
+M07	0.3366502072086488
+M07	0.1926328582988077
+M07	0.28185674042750947
+M07	0.2810149637661007
+M07	0.21129932653220948
+M07	0.33349884159496823
+M07	0.34224128256825
+M07	0.2908762857637343
+M07	0.20833319518409874
+M07	0.114577888937973
+M07	0.39232828011824006
+M07	0.21167646800826737
+M07	0.2774992343054205
+M07	0.23810287469490363
+M07	0.25732138881308514
+M07	0.24725078862406438
+M07	0.2620510502567994
+M07	0.548880156501468
+M07	0.12320424467503548
+M07	0.344931857175255
+M07	0.23179687074783228
+M07	0.31820898117963836
+M07	0.16942641189621468
+M07	0.21508919453994985
+M07	0.24375034574307597
+M07	0.25305660482091724
+M07	0.24294103589031152
+M07	0.0967758307162154
+M07	0.35250150461503915
+M07	0.3161557570018227
+M07	0.30590588686494957
+M07	0.21942620264924523
+M07	0.27361940123871586
+M07	0.330850427581658
+M07	0.2797483612644694
+M07	0.2754423693764728
+M07	0.16470949088738446
+M07	0.2474604537729085
+M07	0.15324460638506165
+M07	0.17961666063520668
+M07	0.2896255489165384
+M07	0.11804425186738977
+M07	0.2867879229981949
+M07	0.1266576052059517
+M07	0.4929253271018428
+M07	0.192364759052669
+M07	0.21691610227131863
+M07	0.2613820171254132
+M07	0.23943304698601983
+M07	0.09615991197893745
+M07	0.370408788101334
+M07	0.29388061473621024
+M07	0.13628447192760934
+M07	0.28162722373396976
+M07	0.15125570664692495
+M07	0.17597961434715112
+M07	0.1356235338429455
+M07	0.20377318803979147
+M07	0.2708591042501656
+M07	0.2787228516911085
+M07	0.13395479713316014
+M07	0.13577139433943505
+M07	0.20010045439776128
+M07	0.3007408108752441
+M07	0.2333760448451493
+M07	0.07058525951262572
+M07	0.42611393225911176
+M07	0.18577753724942056
+M07	0.2605856862518244
+M07	0.25780444253052986
+M07	0.28117615969356996
+M07	0.4198539919789993
+M07	0.35432740737902435
+M07	0.22879038537036636
+M07	0.0918545697918219
+M07	0.3161609179103435
+M07	0.21788059431697987
+M07	0.1756159212362916
+M07	0.14030715679739594
+M07	0.4259185171244239
+M07	0.1259016632342907
+M07	0.21477249936148776
+M07	0.2645104206396754
+M07	0.23191370373666131
+M07	0.4197700077675483
+M07	0.25463085139003705
+M07	0.16132533233361177
+M07	0.13381461159005423
+M07	0.13534047564177756
+M07	0.29212322917728484
+M07	0.3803257418732292
+M07	0.17390782806598443
+M07	0.2726803376093695
+M07	0.23970069749978637
+M07	0.3432622448553407
+M07	0.4008924765022365
+M07	0.14750180196848311
+M07	0.3382554571211822
+M07	0.24867419199566784
+M07	0.2468895285782952
+M07	0.18287167113798664
+M07	0.3682463499456542
+M07	0.2341475116411221
+M07	0.19841879225331885
+M07	0.2588514555900779
+M07	0.28157658443497496
+M07	0.0796093307808981
+M07	0.2690332636479402
+M07	0.3699979202319636
+M07	0.22699316569785818
+M07	0.4241458916008496
+M07	0.2445019033105156
+M07	0.3072935459252838
+M07	0.1513097224523647
+M07	0.28151745595693545
+M07	0.23037167530415634
+M07	0.17398421104704737
+M07	0.08640471178224313
+M07	0.21337031416847235
+M07	0.2878050329863428
+M07	0.3138916799011052
+M07	0.4034274992225513
+M07	0.3028734685826598
+M07	0.20981377062241055
+M07	0.24716025206452258
+M07	0.19128292136958833
+M07	0.34749167578248796
+M07	0.13685591094417085
+M07	0.07501520677657149
+M07	0.18336213524983383
+M07	0.10912048607053061
+M07	0.22168424497751635
+M07	0.21370629700298097
+M07	0.15060046672811966
+M07	0.18801801634722834
+M07	0.3901589203456415
+M07	0.10745670416698315
+M07	0.21114274576294567
+M07	0.14663650200827846
+M07	0.19081302224805088
+M07	0.3567666937069621
+M07	0.18549147323682305
+M07	0.20759224613672828
+M07	0.22948882547862107
+M07	0.16210118507943433
+M07	0.09614631825195867
+M07	0.24833830885083055
+M07	0.23125618433707582
+M07	0.2121326135943649
+M07	0.17767084564123609
+M07	0.3920029909069051
+M07	0.2998237983833135
+M07	0.303755666548748
+M07	0.288358084302307
+M07	0.2454574614231108
+M10	0.19114101379082019
+M10	0.3623415412977692
+M10	0.1790734527024595
+M10	0.11731077052156351
+M10	0.2966831420959621
+M10	0.15651407291108224
+M10	0.22395080936861878
+M10	0.26267670698070966
+M10	0.28109920455348153
+M10	0.28287270779651047
+M10	0.2194500048840759
+M10	0.1916170530069875
+M10	0.22869468601806822
+M10	0.203241476505948
+M10	0.17505289821298414
+M10	0.3331354582652293
+M10	0.37967798820237925
+M10	0.21036108870600936
+M10	0.44442894496055707
+M10	0.3176336502468169
+M10	0.2967055480612376
+M10	0.10526952279691365
+M10	0.2684487850264078
+M10	0.17289089478736294
+M10	0.20062841995155126
+M10	0.13370792448979377
+M10	0.2443863101297982
+M10	0.2821930214399636
+M10	0.3066690253367852
+M10	0.3505707827441702
+M10	0.153451848261362
+M10	0.3279339391840206
+M10	0.27577460562539763
+M10	0.23404412260247007
+M10	0.24778734378746653
+M10	0.26363876697577887
+M10	0.21018099069540505
+M10	0.2797779767577293
+M10	0.28414160520599463
+M10	0.12103266805458493
+M10	0.3256732223254926
+M10	0.15856598352242252
+M10	0.253912343055816
+M10	0.295136240721441
+M10	0.1910064131032687
+M10	0.25998510471954084
+M10	0.24287492980222108
+M10	0.11335995904339323
+M10	0.16612994957391797
+M10	0.16183738223938526
+M10	0.14103999069561438
+M10	0.2812454595179007
+M10	0.23683956090686506
+M10	0.08661388706135716
+M10	0.15824409605282597
+M10	0.271734625616115
+M10	0.1847786607771896
+M10	0.2565859409462589
+M10	0.16804451648917987
+M10	0.19422494259882483
+M10	0.16709782203398227
+M10	0.0814636203127036
+M10	0.33393311173189355
+M10	0.1471078184680128
+M10	0.18970932371752408
+M10	0.2647862524281659
+M10	0.2957477463288909
+M10	0.24340329514286857
+M10	0.14766221551630773
+M10	0.3976656518022509
+M10	0.39511035106997333
+M10	0.21791580955411222
+M10	0.19995123658549846
+M10	0.32093423700886486
+M10	0.33553573728990377
+M10	0.41007137173477276
+M10	0.26464715839119723
+M10	0.21366851250237182
+M10	0.18479459384539515
+M10	0.17146333952355888
+M10	0.21982557183981177
+M10	0.13163015421508092
+M10	0.18920844945575566
+M10	0.24653191695851007
+M10	0.2181851001856958
+M10	0.19169970398725658
+M10	0.17565064866999555
+M10	0.26835113281776896
+M10	0.24005286269407755
+M10	0.19557010784398643
+M10	0.22311206027599648
+M10	0.31045979015977226
+M10	0.27356023243549854
+M10	0.3366483222492503
+M10	0.4521777070932297
+M10	0.2488601568387257
+M10	0.1825485378536771
+M10	0.2824925624488729
+M10	0.1240990505740126
+M10	0.2475318095717634
+M10	0.19958281553227256
+M10	0.2183195717142242
+M10	0.2176284222429988
+M10	0.21692789932932993
+M10	0.2564478424133147
+M10	0.2013722181640054
+M10	0.37686038674089867
+M10	0.12567158535716558
+M10	0.20847329865536557
+M10	0.3747392425720831
+M10	0.22501523938592416
+M10	0.3215969275721294
+M10	0.1654495027408641
+M10	0.11592527732132232
+M10	0.1987886463751461
+M10	0.2264053028714583
+M10	0.2783627060546001
+M10	0.19049488648371646
+M10	0.1873970158098429
+M10	0.13722142714872135
+M10	0.30548873771862173
+M10	0.36710513294582897
+M10	0.45211455276533674
+M10	0.1736059149513337
+M10	0.1481583354563142
+M10	0.16742477308135045
+M10	0.3662505373332849
+M10	0.2293743488483551
+M10	0.12990202796292966
+M10	0.18647094865515185
+M10	0.1893333242968242
+M10	0.0947461467228206
+M10	0.16930510979314184
+M10	0.3393163771205298
+M10	0.20745419075846278
+M10	0.3350045359645127
+M10	0.3624855840441095
+M10	0.17782737392873751
+M10	0.31304277909914363
+M10	0.1839685004798738
+M10	0.13930926742998156
+M10	0.28447795538377224
+M10	0.31021792678307153
+M10	0.278940971125616
+M10	0.16830241469028667
+M10	0.24125936084862704
+M10	0.3596018666371923
+M10	0.3900010219429976
+M10	0.12525455752564654
+M10	0.2514097307302187
+M10	0.3770114217086333
+M10	0.23127182738539342
+M10	0.31764545252755483
+M10	0.20513560940055123
+M10	0.3123871240575765
+M10	0.4108079278394662
+M10	0.20153401863581244
+M10	0.12681812978072846
+M10	0.15527065942157153
+M10	0.3371933812443937
+M10	0.32871598280630404
+M10	0.15367575660052005
+M10	0.2951968832339148
+M10	0.13512414488024319
+M10	0.14900227112225808
+M10	0.24495100661429098
+M10	0.14759392901616172
+M10	0.14595224475020505
+M10	0.19569733424975566
+M10	0.11868644283358604
+M10	0.2312347919607902
+M10	0.2390662015412685
+M10	0.3786368805365476
+M10	0.2485354799594114
+M10	0.41231065635364805
+M10	0.4652297660921212
+M10	0.18071138210925075
+M10	0.22336429373163288
+M10	0.2603794897906231
+M10	0.3040884154825486
+M16	0.19968668463910125
+M16	0.30653286899118254
+M16	0.24352003540900477
+M16	0.0783629984694286
+M16	0.18715004487502074
+M16	0.22838014050319952
+M16	0.34855912315407506
+M16	0.1868995015576056
+M16	0.253053617506845
+M16	0.19004150521148372
+M16	0.20508224057355706
+M16	0.14029175076609698
+M16	0.2541137419004544
+M16	0.15283313684626987
+M16	0.17209633846217096
+M16	0.2955388605390562
+M16	0.14456027832144538
+M16	0.20851682860321588
+M16	0.3615362913712839
+M16	0.21656312811048736
+M16	0.29094578084988926
+M16	0.2959232797812984
+M16	0.24732734173158355
+M16	0.2982486898568773
+M16	0.22000441150030065
+M16	0.30148681200920835
+M16	0.13466586371259728
+M16	0.16119020386203273
+M16	0.1233677820892705
+M16	0.3095272374314106
+M16	0.15733498224319584
+M16	0.20568825905258215
+M16	0.23800187337121506
+M16	0.17456736378249219
+M16	0.17941669721703293
+M16	0.37820505239926117
+M16	0.19594250787968245
+M16	0.34332167037461825
+M16	0.13489934140717713
+M16	0.16383156007590913
+M16	0.11883796807467367
+M16	0.307803512926991
+M16	0.5720104837486636
+M16	0.2851553289196088
+M16	0.3074095052483587
+M16	0.2622628201285207
+M16	0.23704963223656825
+M16	0.1606450049043513
+M16	0.10494990356667855
+M16	0.30911478332104353
+M16	0.23667393926801117
+M16	0.304191288810052
+M16	0.13726884310215565
+M16	0.09728789556962213
+M16	0.2588335144582878
+M16	0.2665374556553085
+M16	0.21602479101588784
+M16	0.13111935169816924
+M16	0.2806782853367986
+M16	0.32388340676445126
+M16	0.16899013953257336
+M16	0.14698518866237256
+M16	0.21599634825054456
+M16	0.17359756965211606
+M16	0.2382144868668426
+M16	0.134214178762909
+M16	0.19739920086647486
+M16	0.2858267124511451
+M16	0.2276705226980722
+M16	0.3215452723831678
+M16	0.22747885073714488
+M16	0.23744201751297114
+M16	0.16672037531438738
+M16	0.23448212016159867
+M16	0.2372012964865402
+M16	0.4681267551734784
+M16	0.21467764713495552
+M16	0.26639253832172677
+M16	0.2668044915376202
+M16	0.09821541333798117
+M16	0.16614130269885985
+M16	0.25311434237203323
+M16	0.2742238648454166
+M16	0.22511553966051168
+M16	0.23406676090260284
+M16	0.2858503737013152
+M16	0.217793769261871
+M16	0.12159074225102258
+M16	0.2598905316543492
+M16	0.20413136545457003
+M16	0.1634067714482642
+M16	0.2008252914967468
+M16	0.37146442582543077
+M16	0.2873991672459811
+M16	0.20233426862928824
+M16	0.2106348253801696
+M16	0.23105783225578252
+M16	0.23603975580885717
+M16	0.24392298538354937
+M16	0.166873055715867
+M16	0.10162382376614773
+M16	0.09726582521895567
+M16	0.19994068530598064
+M16	0.14904725998059662
+M16	0.3657833360385994
+M16	0.1386497218872164
+M16	0.2648451426073643
+M16	0.14231134469864362
+M16	0.2265114229704599
+M16	0.2474364461330971
+M16	0.15378398811602476
+M16	0.3118822630653066
+M16	0.24479466900846716
+M16	0.27811127197806323
+M16	0.182421244843984
+M16	0.29903308786264726
+M16	0.31662163227981144
+M16	0.24423239652892592
+M16	0.19627982419707693
+M16	0.19789411919044803
+M16	0.1493954100577819
+M16	0.28513844202776056
+M16	0.32080139190589385
+M16	0.11646699931739925
+M16	0.1885002191650159
+M16	0.1927336928835031
+M16	0.25253924682937895
+M16	0.2249815140938955
+M16	0.21507286436285009
+M16	0.12204270713991386
+M16	0.24206528115675388
+M16	0.1396861210626516
+M16	0.3153386298719223
+M16	0.33992357594839295
+M16	0.25686757705535607
+M16	0.27388067532514304
+M16	0.18104697279595744
+M16	0.4087537370930066
+M16	0.2985952037939648
+M16	0.18026042859945754
+M16	0.13581177170674014
+M16	0.18237992235147518
+M16	0.23281298015188548
+M16	0.3137975028331922
+M16	0.2414665091042404
+M16	0.2527821657463619
+M16	0.26551433018120424
+M16	0.3313964689807142
+M16	0.2239245335965309
+M16	0.2063754914350111
+M16	0.38633450092858007
+M16	0.16995032762114395
+M16	0.1477472995097425
+M16	0.1401424692568101
+M16	0.33261191584174393
+M16	0.2944099667473256
+M16	0.31142335938615445
+M16	0.18948523676521611
+M16	0.20509472773874182
+M16	0.3682918689446813
+M16	0.19356062702754268
+M16	0.25297243600804115
+M16	0.2655126040767032
+M16	0.15026635012407938
+M16	0.11731167396857999
+M16	0.2956660720642206
+M16	0.21760691246946165
+M16	0.1449600665029536
+M16	0.17528518128931242
+M16	0.19689729826046717
+M16	0.2135299359402422
+M16	0.21830551172793258
+M16	0.34578770302803624
+M16	0.24343872128009136
+M16	0.1877227101229087
+M16	0.39224471706032665
+M16	0.21273936281424116
+M16	0.2899885008652565
+M16	0.15276570407234558
+M16	0.1768978603130449
+P01	0.18954813449171062
+P01	0.22982322098066169
+P01	0.2020217370636401
+P01	0.17262667682558058
+P01	0.3027863559544728
+P01	0.1910443034452155
+P01	0.24246236884578629
+P01	0.1466441608423783
+P01	0.14479941944558838
+P01	0.12791576740402483
+P01	0.20826541966868814
+P01	0.15722019416382807
+P01	0.25788335526739065
+P01	0.13865865532918675
+P01	0.22802112222164475
+P01	0.24339647295297337
+P01	0.36797726339964565
+P01	0.2021530267533817
+P01	0.33934226168663495
+P01	0.10692546489517112
+P01	0.19099830181566818
+P01	0.13596030842605336
+P01	0.244719548377273
+P01	0.19237756419686383
+P01	0.11682622460464874
+P01	0.12420175219485913
+P01	0.21495871784286427
+P01	0.1269062386577544
+P01	0.1521822060651478
+P01	0.17985147780189198
+P01	0.27171115296797865
+P01	0.3027837465812063
+P01	0.2492324786881886
+P01	0.11963153698132786
+P01	0.24915173873043056
+P01	0.16847429163431266
+P01	0.18955510461425332
+P01	0.19845467216893428
+P01	0.2760728871632258
+P01	0.17792265529794712
+P01	0.1511521584097205
+P01	0.14056193699124941
+P01	0.4296304233804068
+P01	0.24393136342588814
+P01	0.22576022849065608
+P01	0.10632682343780604
+P01	0.2842552292247318
+P01	0.19178638247207055
+P01	0.2882807284942695
+P01	0.2114322937183942
+P01	0.23193169434239463
+P01	0.1444877726058281
+P01	0.20054572328649176
+P01	0.24724914984811178
+P01	0.21591532291183424
+P01	0.19723448782776934
+P01	0.1421394722487471
+P01	0.23450843343055
+P01	0.24894319732731807
+P01	0.2451983327173021
+P01	0.2422682601451815
+P01	0.1936707561669127
+P01	0.16620817557396644
+P01	0.12741756103099902
+P01	0.19226722631550056
+P01	0.2697314952659276
+P01	0.1928167351845413
+P01	0.24873328213666215
+P01	0.21335913006350546
+P01	0.30083608270542894
+P01	0.21474572155060628
+P01	0.1848179485877358
+P01	0.22449994960074732
+P01	0.30382394824577
+P01	0.2777149933020849
+P01	0.1938756219071709
+P01	0.2128609967402797
+P01	0.2313539233294168
+P01	0.2357893074745853
+P01	0.25064370527850444
+P01	0.22332678793415883
+P01	0.1488700334147463
+P01	0.2262681672497651
+P01	0.1241669705709779
+P01	0.17789997571750404
+P01	0.261750703486104
+P01	0.18101455460073496
+P01	0.10959784011004368
+P01	0.2015718673912616
+P01	0.287037060319445
+P01	0.18302372048868512
+P01	0.33049959517763344
+P01	0.26900605398366234
+P01	0.252644119372465
+P01	0.18560163611750843
+P01	0.10212564718026183
+P01	0.38303500584925043
+P01	0.21230566040738902
+P01	0.12926663893110568
+P01	0.10265222218601
+P01	0.2098043717402737
+P01	0.23039192096233155
+P01	0.14923934199517802
+P01	0.16654815440152543
+P01	0.22862774523421733
+P01	0.21674457102129313
+P01	0.27964346171359367
+P01	0.17742183366182795
+P01	0.1816189236916814
+P01	0.20767020221002336
+P01	0.17131775609335095
+P01	0.15341270402402546
+P01	0.21665802272997056
+P01	0.14919419829842973
+P01	0.24105609181519683
+P01	0.16746377443622662
+P01	0.3667591845399244
+P01	0.25749817476026393
+P01	0.11248362410175122
+P01	0.22477826880234902
+P01	0.2566850083537622
+P01	0.2884520490323239
+P01	0.4175975767012578
+P01	0.17768659757397792
+P01	0.21124952042230752
+P01	0.2694106442034331
+P01	0.2935988915604457
+P01	0.14883415770153602
+P01	0.28356023292547805
+P01	0.15257379498060072
+P01	0.2908335735726583
+P01	0.15706600383028016
+P01	0.3510737760806174
+P01	0.26883415276385486
+P01	0.25098973130332786
+P01	0.20706083007229956
+P01	0.3232357176153948
+P01	0.2895224250508842
+P01	0.23897561399492884
+P01	0.22989696418242206
+P01	0.2985003738882745
+P01	0.243518826106997
+P01	0.16143956297247603
+P01	0.30993247346932534
+P01	0.20112347703386116
+P01	0.20833281841382195
+P01	0.11473614136347829
+P01	0.24834057197791035
+P01	0.18001529297195795
+P01	0.242058060682824
+P01	0.2696610416754109
+P01	0.24173131153996905
+P01	0.19647576131045744
+P01	0.19200831781856542
+P01	0.3141586108281423
+P01	0.3941746341919581
+P01	0.2539229138502773
+P01	0.1395406419479806
+P01	0.19359896788920228
+P01	0.3298703278235275
+P01	0.21908151349975757
+P01	0.13821115776110807
+P01	0.18069403207490847
+P01	0.09996699403894829
+P01	0.16625891701813217
+P01	0.08728420462918891
+P01	0.1791020974047021
+P01	0.14596277039817174
+P01	0.16865037527671223
+P01	0.1319596635998674
+P01	0.1913705021278408
+P01	0.10087384260908332
+P01	0.3139792357832865
+P01	0.2524681832449438
+P01	0.19931103805430597
+P01	0.4262981934280705
+P01	0.20538418644521414
+P01	0.2999637651164642
+P01	0.2528414899453229
+P01	0.3151660024283799
+M09	0.17849321139017066
+M09	0.2053595890927473
+M09	0.20652371154472837
+M09	0.09267551566404075
+M09	0.3365549116329523
+M09	0.29771513091505786
+M09	0.18480967950250304
+M09	0.30784437943367676
+M09	0.1729154580151834
+M09	0.18352202613969626
+M09	0.006157400809338795
+M09	0.2364302976539095
+M09	0.1838752999396054
+M09	0.18242037064993435
+M09	0.2681091070587075
+M09	0.3351222301888563
+M09	0.3594440047645746
+M09	0.2606821091104428
+M09	0.28053054478047273
+M09	0.20260188855987496
+M09	0.13953483446338916
+M09	0.10014386088356696
+M09	0.11954898669494426
+M09	0.2528056653859408
+M09	0.12912833695158996
+M09	0.26866536234821525
+M09	0.23811373004283753
+M09	0.27905079635438224
+M09	0.2570247588143494
+M09	0.2014106495193377
+M09	0.21746108161591055
+M09	0.3438223723439933
+M09	0.19478435718524414
+M09	0.1991486242136212
+M09	0.10964311059536945
+M09	0.22138642547294862
+M09	0.13174799440558155
+M09	0.33204195663637825
+M09	0.2965417728141192
+M09	0.2952014931731243
+M09	0.2922350935294072
+M09	0.25996673344364185
+M09	0.1159284775620302
+M09	0.3546861591215158
+M09	0.3345091409349446
+M09	0.27322311061500915
+M09	0.14032436050094704
+M09	0.09497209853727058
+M09	0.17456110041358736
+M09	0.2843967348770972
+M09	0.0813827678267207
+M09	0.14610060196595764
+M09	0.31899307199868404
+M09	0.3064138263382679
+M09	0.1266577585052121
+M09	0.14651263376830703
+M09	0.2811404334707403
+M09	0.16598539182565014
+M09	0.15012339139452596
+M09	0.30467211835994307
+M09	0.1549316791955304
+M09	0.14968266280105394
+M09	0.2709018941746113
+M09	0.18550654005576464
+M09	0.1933452732093568
+M09	0.2326369178402478
+M09	0.2170201560518189
+M09	0.2133254041416752
+M09	0.21757413517660515
+M09	0.4270601362377729
+M09	0.26719238853383037
+M09	0.21711876853022805
+M09	0.23568007235963473
+M09	0.2555331235692009
+M09	0.3366762268879966
+M09	0.2648885859814901
+M09	0.22210627155620655
+M09	0.2178266758247289
+M09	0.2531545483391735
+M09	0.11037458311381115
+M09	0.2562696751482552
+M09	0.26725035881643694
+M09	0.08060968501385976
+M09	0.08360844932884914
+M09	0.1279597720390687
+M09	0.3011372052154329
+M09	0.1562277141800891
+M09	0.2139616403582736
+M09	0.18474567624683996
+M09	0.21232975518419853
+M09	0.30381123865166737
+M09	0.3623561386035276
+M09	0.3727333359358361
+M09	0.2640186244249097
+M09	0.1081713045126692
+M09	0.2085923100147303
+M09	0.37142967547105415
+M09	0.3104982715894569
+M09	0.14392172305931272
+M09	0.1835365295902619
+M09	0.12446183588319552
+M09	0.23936450145480223
+M09	0.15814091338091488
+M09	0.21265619752151352
+M09	0.2761645745662351
+M09	0.20321471125314472
+M09	0.30223212405615035
+M09	0.08287114791401796
+M09	0.06527764457589481
+M09	0.3945381695005499
+M09	0.1913732600076525
+M09	0.17577439000578007
+M09	0.15831942829768275
+M09	0.21188841638339065
+M09	0.23273619511000393
+M09	0.2913114810520981
+M09	0.15271959223083656
+M09	0.15856150493966062
+M09	0.1412964688353006
+M09	0.17461393294860572
+M09	0.14196310007687066
+M09	0.29439947605112105
+M09	0.35175877796608207
+M09	0.2783543433907042
+M09	0.2824276670697463
+M09	0.2555378987195695
+M09	0.15862688812947973
+M09	0.13256923459806808
+M09	0.17458568795584953
+M09	0.28374873844570064
+M09	0.28365287907572156
+M09	0.15782026964436893
+M09	0.39383750755791386
+M09	0.20068080618587955
+M09	0.2505652331108462
+M09	0.28249249433126306
+M09	0.24626715250961856
+M09	0.25649322165806004
+M09	0.2699841205725952
+M09	0.2145210116423807
+M09	0.24508884996269964
+M09	0.27002144022311075
+M09	0.22842004765302873
+M09	0.289755887152534
+M09	0.09334923654700157
+M09	0.25992644179009716
+M09	0.3260608280889307
+M09	0.22569849389102145
+M09	0.16302004244491525
+M09	0.21328087157589665
+M09	0.1423661189773022
+M09	0.1929348257771534
+M09	0.25711289887451566
+M09	0.18344880346526196
+M09	0.3739686740626799
+M09	0.42082091777549435
+M09	0.18573188044461844
+M09	0.24823359405411557
+M09	0.21450410419091037
+M09	0.2655333264971706
+M09	0.1788772703666673
+M09	0.22236136786053906
+M09	0.18564827475216644
+M09	0.17814061353355798
+M09	0.20525012970703466
+M09	0.15303553210862128
+M09	0.17375763226818405
+M09	0.1738302820224564
+M09	0.232635834121221
+M09	0.1933801346106742
+M09	0.08318225803932917
+M09	0.23397819306799542
+M09	0.3343355347160099
+M09	0.13448789669018582
+M09	0.1669565813319526
+M09	0.38659101189264694
+M09	0.169232973904028
+M09	0.2245272428478946
+M09	0.24160388707475577
+M09	0.27914939928105553
+M01	0.11471442767365345
+M01	0.2067703970716361
+M01	0.3351561322556325
+M01	0.12924864868320213
+M01	0.28406805316974537
+M01	0.040022520268096655
+M01	0.24842719139829944
+M01	0.33467875618447684
+M01	0.28768723899956505
+M01	0.32859280365763166
+M01	0.2011821351503914
+M01	0.10153282658592198
+M01	0.24470943958633137
+M01	0.23042434588216745
+M01	0.17829879044998956
+M01	0.3446408830629524
+M01	0.4152657723615235
+M01	0.2732517218614615
+M01	0.4029179870933187
+M01	0.2965215131727211
+M01	0.2441685334163592
+M01	0.2854898831288572
+M01	0.24670890017340896
+M01	0.18305133966297282
+M01	0.26423664873507186
+M01	0.09727959061754014
+M01	0.10337284585533528
+M01	0.2030325526568517
+M01	0.41274512393572854
+M01	0.31173408293980115
+M01	0.27265349070228434
+M01	0.3643014873830706
+M01	0.22428358978108032
+M01	0.2631595719243453
+M01	0.13302252797902975
+M01	0.29136375751979354
+M01	0.28301591362942163
+M01	0.3831854098260667
+M01	0.16965229505565213
+M01	0.20727233860137462
+M01	0.32909939104981245
+M01	0.23992095764369648
+M01	0.5694212891959454
+M01	0.12615024730960278
+M01	0.3509075006768256
+M01	0.3184246877945697
+M01	0.2801611178954593
+M01	0.19850184923828657
+M01	0.2593567674780984
+M01	0.2849058938354072
+M01	0.1552173775572868
+M01	0.20929292399721036
+M01	0.19463135536564602
+M01	0.26875256012741244
+M01	0.2071412371071825
+M01	0.36820113763645934
+M01	0.17516266537591638
+M01	0.20813103120926593
+M01	0.36050524690933206
+M01	0.2236705936169546
+M01	0.32794413153463786
+M01	0.10351382063960292
+M01	0.25283408098149535
+M01	0.1995617845822515
+M01	0.07319437568477596
+M01	0.21110384130754828
+M01	0.08927366931528427
+M01	0.14875512231229576
+M01	0.1937938742358672
+M01	0.33319072865984983
+M01	0.28421459556927914
+M01	0.1632427382466282
+M01	0.16117479890670144
+M01	0.15447828081265122
+M01	0.32821898697813234
+M01	0.42192344043758717
+M01	0.32613109764331655
+M01	0.17711441373348058
+M01	0.35021585732246663
+M01	0.15815535723165816
+M01	0.23100335714128953
+M01	0.12581443175543863
+M01	0.2758464455904516
+M01	0.1334719386999288
+M01	0.24801459541515514
+M01	0.2578049671272867
+M01	0.311248424368666
+M01	0.186392425080514
+M01	0.2927090540350291
+M01	0.2108554030189936
+M01	0.1533431916832625
+M01	0.22393936666207848
+M01	0.3900900998589438
+M01	0.1970338933669767
+M01	0.47656714747222756
+M01	0.09472187808480173
+M01	0.24894202854841094
+M01	0.2523572698311993
+M01	0.08036949777667757
+M01	0.31713467869430756
+M01	0.1566754217000205
+M01	0.21012161945541225
+M01	0.14584412027111704
+M01	0.2431421349439564
+M01	0.4316381226630973
+M01	0.17133566408232356
+M01	0.1521451108817043
+M01	0.29249945879823097
+M01	0.18986852758378103
+M01	0.4064074232966488
+M01	0.1883677266290722
+M01	0.282112035928449
+M01	0.12345256181637576
+M01	0.166488960434148
+M01	0.14639057541201372
+M01	0.31308635323897743
+M01	0.2780226688356189
+M01	0.3349233882643851
+M01	0.22118859608536162
+M01	0.24920237803985767
+M01	0.2565355930105207
+M01	0.41019015330041186
+M01	0.2430666168097075
+M01	0.27156497952059316
+M01	0.25506155323515944
+M01	0.2213969907042674
+M01	0.2797695631881497
+M01	0.1639573578376584
+M01	0.240631488381306
+M01	0.22680769997918393
+M01	0.3039123440174279
+M01	0.16959332624814097
+M01	0.38008839791604565
+M01	0.37227624485627736
+M01	0.3158960324409252
+M01	0.259119187363866
+M01	0.32316748094946685
+M01	0.2932683731872161
+M01	0.38151579269783376
+M01	0.30720805037150584
+M01	0.18235765541316762
+M01	0.34754588579084056
+M01	0.16168757076611856
+M01	0.23793713932326127
+M01	0.22376304509276512
+M01	0.12325723333272257
+M01	0.3722844483809014
+M01	0.30638482927103566
+M01	0.2428330994382363
+M01	0.24973939022538227
+M01	0.3798974854681284
+M01	0.2024841292998493
+M01	0.19449450227214576
+M01	0.19261899769478125
+M01	0.22304257999491545
+M01	0.16769168847070623
+M01	0.18727292969676984
+M01	0.21931514052388354
+M01	0.2087549393658803
+M01	0.25231126691070244
+M01	0.31374411488176424
+M01	0.17693167191388723
+M01	0.23339940708094373
+M01	0.15527087091472636
+M01	0.15779098564861455
+M01	0.36026239099012086
+M01	0.11352146298689375
+M01	0.24171227034684106
+M01	0.27378012955740694
+M01	0.2586419826490164
+M01	0.1261203157039444
+M01	0.24265344231108021
+M01	0.28441965223534216
+M01	0.24533823870513877
+M01	0.3502941592916762
+M01	0.3676539483649537
+M01	0.2839865415213003
+M01	0.35884008463868394
+M01	0.13449957998134887
+M01	0.20417656386375754
+M08	0.139362383094205
+M08	0.19884334305560844
+M08	0.3647092686124795
+M08	0.05674333196195396
+M08	0.3698223052614406
+M08	0.29466260092163815
+M08	0.3988855182437864
+M08	0.34779798033876025
+M08	0.2303355297407281
+M08	0.2643517156467664
+M08	0.16118897722083256
+M08	0.2774449089989418
+M08	0.3085021840509739
+M08	0.0838520351614055
+M08	0.20170010968741675
+M08	0.20691056323659016
+M08	0.4573019917262763
+M08	0.3082550288501705
+M08	0.4575410376592465
+M08	0.2733347996850801
+M08	0.24298584082819516
+M08	0.35701159891432466
+M08	0.29424523947006415
+M08	0.36663927943703944
+M08	0.08868494439839035
+M08	0.17895212401388016
+M08	0.14314538938019516
+M08	0.13936607326334496
+M08	0.19605127459246763
+M08	0.37852177218131144
+M08	0.3039333757581647
+M08	0.24330588014291474
+M08	0.27057034384957046
+M08	0.12864844208366613
+M08	0.3131846553377749
+M08	0.39783064481385516
+M08	0.18918704812753379
+M08	0.3366885771944665
+M08	0.20163856702032734
+M08	0.2849521297332769
+M08	0.25584748591884043
+M08	0.42948929469993957
+M08	0.5609004674845929
+M08	0.29340113114188393
+M08	0.2208954906097575
+M08	0.1299758116906564
+M08	0.3008231671657961
+M08	0.1973479966428075
+M08	0.1385320463053753
+M08	0.4221234178149376
+M08	0.18294449605546126
+M08	0.32320144427949843
+M08	0.30740552677485145
+M08	0.33241581634218575
+M08	0.04327637077381331
+M08	0.197407337961745
+M08	0.3077485359435758
+M08	0.0776869008481891
+M08	0.42897572546126206
+M08	0.1949632989136331
+M08	0.2708469009461372
+M08	0.1634699480605952
+M08	0.3760225669693634
+M08	0.15307012512926768
+M08	0.26960184695545214
+M08	0.3181395057016202
+M08	0.18167047783227155
+M08	0.151136541056705
+M08	0.10727431768307728
+M08	0.43113888258181676
+M08	0.36674548368007265
+M08	0.20250926474674147
+M08	0.2337512051227507
+M08	0.30767213373055396
+M08	0.32448541967363753
+M08	0.2879714746226774
+M08	0.3852741579092654
+M08	0.25734187745717024
+M08	0.3836932495313783
+M08	0.1555840617913649
+M08	0.22685355135747048
+M08	0.17287332491920948
+M08	0.13818577240760177
+M08	0.23864547368081904
+M08	0.10424155050363385
+M08	0.36654098395291956
+M08	0.2792494897330368
+M08	0.2705332182824922
+M08	0.3037064397117072
+M08	0.34254716476328895
+M08	0.27522481269678506
+M08	0.43178170182583153
+M08	0.2773061157984804
+M08	0.1921308566218545
+M08	0.46684441488663564
+M08	0.11202726251678917
+M08	0.44235087686979846
+M08	0.26111867265115635
+M08	0.2983692615914076
+M08	0.11737284705336112
+M08	0.10562591479512251
+M08	0.12595104808990307
+M08	0.08283429700397522
+M08	0.136321824786021
+M08	0.3620766119342333
+M08	0.1343811337629712
+M08	0.29080111796497315
+M08	0.1939809808830645
+M08	0.2120326284504096
+M08	0.43954761445503737
+M08	0.29051259123649414
+M08	0.1841334738730038
+M08	0.20596625110552874
+M08	0.3308435069778546
+M08	0.11034586961010186
+M08	0.19677264885418433
+M08	0.25187540018667826
+M08	0.33035472356799644
+M08	0.1368637166026408
+M08	0.27930066338248244
+M08	0.4318339796504217
+M08	0.27851417819064067
+M08	0.3265661547475826
+M08	0.2615805898571083
+M08	0.23345087599403266
+M08	0.20303662475920697
+M08	0.18706746473246505
+M08	0.28409015725483955
+M08	0.38159870952540575
+M08	0.22292487589925045
+M08	0.20974531381892383
+M08	0.19953129588844284
+M08	0.12740978452004695
+M08	0.2700227602863304
+M08	0.12340504146339537
+M08	0.23975208336533838
+M08	0.20066523926107846
+M08	0.48444602605234466
+M08	0.4677615109833201
+M08	0.16209468305697713
+M08	0.15701272814936382
+M08	0.2802161308137892
+M08	0.3356729031149013
+M08	0.1686419336962145
+M08	0.16581466373594123
+M08	0.19519048344380352
+M08	0.1750945830238784
+M08	0.36832642941762284
+M08	0.17530688097535824
+M08	0.30608811474194886
+M08	0.08177878183812137
+M08	0.20451955763182517
+M08	0.28070051241642824
+M08	0.14039052436918514
+M08	0.19496880795833693
+M08	0.1937614541825859
+M08	0.35466641798739756
+M08	0.2750441575576947
+M08	0.3042551212460168
+M08	0.10059496187778788
+M08	0.3412494631606242
+M08	0.1590012334955467
+M08	0.2307244907728155
+M08	0.28040377647197334
+M08	0.23523496464588148
+M08	0.3661403128584089
+M08	0.22119668404726883
+M08	0.0695733487391954
+M08	0.12814643768712103
+M08	0.2778961521967172
+M08	0.31239819883292
+M08	0.3387834841775264
+M08	0.12251259700892937
+M08	0.27758399341454293
+M08	0.21857856130889916
+M08	0.39556266040333055
+M08	0.08553828279827475
+M08	0.24943939176864785
+M08	0.25248568111423003
+M08	0.24072807052407666
+M13	0.18716452144889867
+M13	0.21420783797162793
+M13	0.329885390874135
+M13	0.10001630394967502
+M13	0.26663031741750143
+M13	0.20818974934845572
+M13	0.1876054874402924
+M13	0.31417389152050873
+M13	0.2953776560378217
+M13	0.27520755095501453
+M13	0.11801265160946073
+M13	0.3022004230537978
+M13	0.2492787198684618
+M13	0.294413714212779
+M13	0.1647466695229261
+M13	0.16721064399274743
+M13	0.23774105706261253
+M13	0.28663293926965827
+M13	0.24372713683524297
+M13	0.29553886023126313
+M13	0.26460506266635514
+M13	0.26981214765601136
+M13	0.25409375286082514
+M13	0.24323629136465996
+M13	0.2665602670114481
+M13	0.34258909296429135
+M13	0.28505906161132194
+M13	0.2409244099507468
+M13	0.30276442710865786
+M13	0.2746114851342279
+M13	0.30855634488904154
+M13	0.2253404621159945
+M13	0.276000652834754
+M13	0.13236420124992562
+M13	0.23513844542047146
+M13	0.18424105450935632
+M13	0.15170314242818198
+M13	0.2275233209213358
+M13	0.14508274808821223
+M13	0.3351969390060197
+M13	0.21278049068544105
+M13	0.3659377396417213
+M13	0.17063314800915055
+M13	0.3122037377215521
+M13	0.1258127211942734
+M13	0.2818444501195836
+M13	0.21453912747343926
+M13	0.19809641354258078
+M13	0.1864308541826153
+M13	0.3756353466522784
+M13	0.22151020703036223
+M13	0.17871889215928718
+M13	0.2028039206284377
+M13	0.051503173565771096
+M13	0.2880822607542726
+M13	0.17456715674597073
+M13	0.2585410480910895
+M13	0.12950686336037168
+M13	0.16200547154628903
+M13	0.19606230476134845
+M13	0.24354447207949179
+M13	0.2198843409486218
+M13	0.3174993047215005
+M13	0.30531259257548254
+M13	0.1937320171224574
+M13	0.06556127489363663
+M13	0.16009493386432824
+M13	0.25425831988166686
+M13	0.1576494171369434
+M13	0.3983064488730841
+M13	0.2705190164604656
+M13	0.27697117198932414
+M13	0.204531976613201
+M13	0.29720691731294285
+M13	0.241004009106796
+M13	0.1535287934774979
+M13	0.21402655905618806
+M13	0.2798991742691761
+M13	0.21578308445776262
+M13	0.17653056315935298
+M13	0.255622962842386
+M13	0.21575678465681253
+M13	0.2834791687810271
+M13	0.1065158501505491
+M13	0.18968839337099497
+M13	0.34001764135633467
+M13	0.20255084584542546
+M13	0.14971685121792375
+M13	0.2857547345827503
+M13	0.26547004565442195
+M13	0.08977331021862782
+M13	0.22895555488662167
+M13	0.2377334190219246
+M13	0.3230792915887557
+M13	0.3848940320841032
+M13	0.19137575457635717
+M13	0.4105470624004252
+M13	0.2805900504870908
+M13	0.1898058157351486
+M13	0.24687774981643612
+M13	0.253128446316827
+M13	0.297827337481519
+M13	0.17904334240520595
+M13	0.16609379600951174
+M13	0.29210233440205174
+M13	0.11912777268014806
+M13	0.13382145131387774
+M13	0.20522314522812257
+M13	0.21389839351982318
+M13	0.36748191451953593
+M13	0.28361925521614884
+M13	0.25972522220412714
+M13	0.13329082976480394
+M13	0.15987751295502178
+M13	0.28729501927351314
+M13	0.26789555389029956
+M13	0.20211163192747966
+M13	0.2857128343140601
+M13	0.12245568022154588
+M13	0.1579770550222211
+M13	0.3666961804357026
+M13	0.1943692757074751
+M13	0.20906111842322395
+M13	0.26507120675902196
+M13	0.2974701995096349
+M13	0.25878966895470806
+M13	0.30190643176972753
+M13	0.2795977554444838
+M13	0.14311315029279337
+M13	0.15605351497644565
+M13	0.2814174783551041
+M13	0.14222968151260992
+M13	0.29850117412325977
+M13	0.3998147323153626
+M13	0.21633819172498428
+M13	0.3367653069284291
+M13	0.2709927098181026
+M13	0.1748392403352964
+M13	0.23459658958864366
+M13	0.07858478917158132
+M13	0.12035196224262255
+M13	0.2975021871630305
+M13	0.1999303319972592
+M13	0.12805170332317772
+M13	0.28863024585957525
+M13	0.269945780596242
+M13	0.25128484575627447
+M13	0.3142453420253039
+M13	0.23159593303363987
+M13	0.1985298178245355
+M13	0.26108441897225726
+M13	0.2939636848474513
+M13	0.2964870640106861
+M13	0.13629434450963032
+M13	0.341764001482624
+M13	0.245969352467848
+M13	0.183196717015614
+M13	0.29658370751246993
+M13	0.09801171414744322
+M13	0.33435164516164767
+M13	0.3544851018506317
+M13	0.2628381635874926
+M13	0.12052296396047946
+M13	0.1691140242915055
+M13	0.2542678343694048
+M13	0.23879563170892118
+M13	0.1962404222691197
+M13	0.16871160091415127
+M13	0.23258076854760099
+M13	0.14447515152177803
+M13	0.2190011630458453
+M13	0.20592731000481806
+M13	0.20197030547791708
+M13	0.30921108541986303
+M13	0.2824645585771863
+M13	0.41851425408636145
+M13	0.2904482942505831
+M13	0.3033797399208293
+M13	0.27560812452386635
+M13	0.3505885616373527
Index: src/com/util/data_format.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/data_format.py b/src/com/util/data_format.py
new file mode 100644
--- /dev/null	(date 1695462012000)
+++ b/src/com/util/data_format.py	(date 1695462012000)
@@ -0,0 +1,75 @@
+import numpy as np
+
+
+
+def make_print_to_file(path='.'):
+    '''
+    path， it is a path for save your log about fuction print
+    example:
+    use  make_print_to_file()   and the   all the information of funtion print , will be write in to a log file
+    :return:
+    '''
+    import os
+    # import config_file as cfg_file
+    import sys
+    import datetime
+
+    class Logger(object):
+        def __init__(self, filename="Default.log", path="./"):
+            self.terminal = sys.stdout
+            self.log = open(os.path.join(path, filename), "a", encoding='utf8', )
+
+        def write(self, message):
+            self.terminal.write(message)
+            self.log.write(message)
+
+        def flush(self):
+            pass
+
+    fileName = datetime.datetime.now().strftime('day and time:' + '%Y_%m_%d')
+    sys.stdout = Logger(fileName + '.log', path=path)
+
+    #############################################################
+    # print -> log
+    #############################################################
+    print(fileName.center(60, '*'))
+
+def standardization(data, type):
+    from sklearn.preprocessing import StandardScaler
+    s = StandardScaler()
+    shape = data.shape
+    if type == 'valid':
+        s.fit(data)
+        # 验证集 直接用transform
+        return s.transform(
+            data.numpy().astype(np.float32).reshape(-1, 1)).reshape(shape)
+    else:
+        s.fit(data)
+        return s.fit_transform(
+            data.numpy().astype(np.float32).reshape(-1, 1)).reshape(shape)
+
+
+def normalization(data):
+    minVals = data.min()
+    maxVals = data.max()
+    ranges = maxVals - minVals
+    # normData = np.zeros(np.shape(data))
+    # m = normData.shape[0]
+    normData = data - np.tile(minVals, np.shape(data))
+    # print(np.shape(data))
+    # print(ranges)
+    # print(np.tile(ranges, np.shape(data)))
+    normData = np.divide(normData, np.tile(ranges, np.shape(data)), out=np.zeros_like(normData), where=np.tile(ranges, np.shape(data)) != 0)
+    # normData = normData /
+
+    return normData, ranges, minVals
+
+
+def adjust_learning_rate(learning_rate, learning_rate_decay, optimizer, epoch):
+    """Sets the learning rate to the initial LR multiplied by learning_rate_decay(set 0.98, usually) every epoch"""
+    learning_rate = learning_rate * (learning_rate_decay ** epoch)
+
+    for param_group in optimizer.param_groups:
+        param_group['lr'] = learning_rate
+
+    return learning_rate
Index: src/com/util/pereira_user_correlation.tsv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/util/pereira_user_correlation.tsv b/src/com/util/pereira_user_correlation.tsv
new file mode 100644
--- /dev/null	(date 1616247293000)
+++ b/src/com/util/pereira_user_correlation.tsv	(date 1616247293000)
@@ -0,0 +1,7411 @@
+user	correlation
+M17	0.24944727990182272
+M17	0.3840158055593228
+M17	0.29072542923904793
+M17	0.19943033740240287
+M17	0.4184206531001369
+M17	0.27423324809962674
+M17	0.3944085384335331
+M17	0.2798419391696119
+M17	0.3068833662745092
+M17	0.3111732695320577
+M17	0.26134640357594957
+M17	0.3331644214517081
+M17	0.3175807643622356
+M17	0.3401290142831152
+M17	0.29918330294358997
+M17	0.33439660787772124
+M17	0.5557549295087428
+M17	0.2780206853092402
+M17	0.48395379807818956
+M17	0.3326350798798185
+M17	0.2302248620255942
+M17	0.35722879417153014
+M17	0.22054885040569147
+M17	0.3567448318666549
+M17	0.30223000069784933
+M17	0.4485637638922808
+M17	0.1481771493212575
+M17	0.21429788826481083
+M17	0.47758426739889304
+M17	0.30211305493479684
+M17	0.36361004598550684
+M17	0.3696364176286909
+M17	0.2517831445319903
+M17	0.1973805111214017
+M17	0.3412538993228185
+M17	0.46996199435476105
+M17	0.2621418767683127
+M17	0.41965616141327317
+M17	0.3405089034508947
+M17	0.3964396189790363
+M17	0.4207468415039142
+M17	0.454281738706861
+M17	0.6761739932088262
+M17	0.34063573844533535
+M17	0.2850990923632082
+M17	0.3815279838270045
+M17	0.22491789491764327
+M17	0.21316377343767412
+M17	0.2691790202751049
+M17	0.29878602871546134
+M17	0.26405644434604464
+M17	0.36517005291276716
+M17	0.2436846183850611
+M17	0.262148375557246
+M17	0.3415055892087942
+M17	0.4194117336766842
+M17	0.25907871560705464
+M17	0.345894735310825
+M17	0.4586742012128329
+M17	0.3699306482997623
+M17	0.2929573957096777
+M17	0.29595695071094996
+M17	0.25243166302270725
+M17	0.3177097687964698
+M17	0.29433917818573485
+M17	0.2048087287427308
+M17	0.3441544096214622
+M17	0.28340177736073274
+M17	0.195433972201761
+M17	0.5573352528612076
+M17	0.32276393848713947
+M17	0.29759208312590446
+M17	0.3883050295149854
+M17	0.31083536879466356
+M17	0.42020650815010635
+M17	0.4676703269824257
+M17	0.4361516538466915
+M17	0.28341089538465997
+M17	0.2885428440846427
+M17	0.27813993355488054
+M17	0.30729460495135585
+M17	0.29446535476382446
+M17	0.2975504566193643
+M17	0.3083722847542599
+M17	0.25731033690566846
+M17	0.43733799055030376
+M17	0.31950752796044257
+M17	0.13595342218057535
+M17	0.35645389647290926
+M17	0.28210404019353713
+M17	0.30756970300542646
+M17	0.5189990290844708
+M17	0.37499166863798744
+M17	0.33433342729282994
+M17	0.31371829237990695
+M17	0.32008784396961304
+M17	0.3960690619206419
+M17	0.3833445665191322
+M17	0.2959090887497597
+M17	0.4109408111606502
+M17	0.35844920777050815
+M17	0.3272324872656865
+M17	0.24398352617582106
+M17	0.2742627750449467
+M17	0.4270789562437032
+M17	0.35618823959211293
+M17	0.3756155834255873
+M17	0.28087094724985995
+M17	0.1928753942277218
+M17	0.4165735553458573
+M17	0.2822761786364875
+M17	0.43302300856883363
+M17	0.22070327628477934
+M17	0.3726049541973752
+M17	0.1692530007146098
+M17	0.383778248702326
+M17	0.296724321022121
+M17	0.3734433151960217
+M17	0.18117460992165987
+M17	0.381659376588853
+M17	0.39305682459143987
+M17	0.3545419908331869
+M17	0.5136081083567812
+M17	0.2975820897812276
+M17	0.33872647280238977
+M17	0.3303650792505354
+M17	0.32054487408836857
+M17	0.2775032454798178
+M17	0.3047124295252864
+M17	0.24129276368969052
+M17	0.4458773087880101
+M17	0.20180089525334596
+M17	0.39353793044197877
+M17	0.34773534774204473
+M17	0.3360452799541122
+M17	0.47685027907873917
+M17	0.38252417496041585
+M17	0.4688923140549807
+M17	0.5033048402070308
+M17	0.3438982316676296
+M17	0.29298144093739964
+M17	0.40898386020130356
+M17	0.18910996488019932
+M17	0.36947755617746897
+M17	0.23775082126187697
+M17	0.22521906624571258
+M17	0.4763376174969928
+M17	0.2894692760803135
+M17	0.22801530913809853
+M17	0.27071595738073695
+M17	0.4663376022121787
+M17	0.28882482314272134
+M17	0.24262660741330563
+M17	0.28756560844722984
+M17	0.4617774541066357
+M17	0.4203975875392663
+M17	0.4169793611234197
+M17	0.32012769075318076
+M17	0.40065436180547187
+M17	0.39439883481308596
+M17	0.38558172701667315
+M17	0.30254038337594524
+M17	0.3410041010096098
+M17	0.27879320941413493
+M17	0.17374951289319118
+M17	0.3010471518354748
+M17	0.3106726219969848
+M17	0.2069721922532401
+M17	0.2181428461415371
+M17	0.27808198860277644
+M17	0.2873255577475027
+M17	0.3584026579495706
+M17	0.30151476989404496
+M17	0.32389840752592836
+M17	0.46649028429117717
+M17	0.570491192674748
+M17	0.2596767369256839
+M17	0.39128274284517656
+M17	0.28090530137920244
+M17	0.38992925901533176
+M14	0.2751182820439386
+M14	0.4014041617422875
+M14	0.4049822311237352
+M14	0.24772639642647462
+M14	0.4399790041534241
+M14	0.3037999478270987
+M14	0.43138073135201693
+M14	0.4224945803724446
+M14	0.36976739743125164
+M14	0.34051934496961955
+M14	0.3150814311724969
+M14	0.3786731698573569
+M14	0.3575638179975769
+M14	0.3392929583488531
+M14	0.32739544601608134
+M14	0.4467676010052748
+M14	0.43423587767764893
+M14	0.42273152358071425
+M14	0.4569743812899282
+M14	0.42052108970417323
+M14	0.32678514115654056
+M14	0.3936926805119227
+M14	0.2499720056469181
+M14	0.3863131702204356
+M14	0.3585541635362801
+M14	0.4092196935847812
+M14	0.24648238788714277
+M14	0.23191792659725644
+M14	0.5143070635506329
+M14	0.4099570543183031
+M14	0.3571993752382218
+M14	0.502188886228425
+M14	0.3620893738330757
+M14	0.24417509698900228
+M14	0.3965974576168244
+M14	0.5130356916259277
+M14	0.29700620726799487
+M14	0.4970553048761178
+M14	0.38451745791685676
+M14	0.3546541659717476
+M14	0.42607040804830215
+M14	0.4281655440366817
+M14	0.6738065364363909
+M14	0.29231062115781214
+M14	0.34748745057119695
+M14	0.4044686892537759
+M14	0.35415154682967215
+M14	0.24628290526307067
+M14	0.34674979090984565
+M14	0.3913351900024112
+M14	0.29493271429171963
+M14	0.40001969925438385
+M14	0.31026243359745054
+M14	0.3356433872060299
+M14	0.37025531542211226
+M14	0.47094146809168513
+M14	0.30093876491616556
+M14	0.37463357822960286
+M14	0.5282664301946186
+M14	0.4043304180420859
+M14	0.3332103457354959
+M14	0.3012436839722026
+M14	0.4134896213313675
+M14	0.3595233268147126
+M14	0.2954953543992494
+M14	0.34266791767993793
+M14	0.3698954275409047
+M14	0.3227148012330787
+M14	0.28963331858574504
+M14	0.5765022761622872
+M14	0.47092427519358754
+M14	0.34354862444684653
+M14	0.43127477422706734
+M14	0.4031677447374678
+M14	0.38941989147357275
+M14	0.5397333231558928
+M14	0.4673906930786499
+M14	0.31174470845451785
+M14	0.3534247777316456
+M14	0.29740363796545816
+M14	0.29867819313747285
+M14	0.3069697268797361
+M14	0.28432325561730526
+M14	0.27873751045760137
+M14	0.23453869487761406
+M14	0.4552278478665006
+M14	0.392835289330043
+M14	0.33145876325248336
+M14	0.4826786931931859
+M14	0.37764732829030756
+M14	0.36701612736105127
+M14	0.5526467092035009
+M14	0.4176772789751417
+M14	0.4408169852966484
+M14	0.5505572071911304
+M14	0.3403441519999204
+M14	0.5439100886868258
+M14	0.3904328803002611
+M14	0.29256651370036857
+M14	0.4167336481036299
+M14	0.3712300720748887
+M14	0.326779160380318
+M14	0.26381667154313676
+M14	0.32325142071000246
+M14	0.4896502759582434
+M14	0.3394507641074592
+M14	0.386042490198767
+M14	0.244973909865317
+M14	0.22551316933570706
+M14	0.500199328914844
+M14	0.3110497411528758
+M14	0.3882370771721175
+M14	0.30039085051376063
+M14	0.3469870503551809
+M14	0.3173200235325873
+M14	0.4426658812592302
+M14	0.4858244275740228
+M14	0.37209409262081344
+M14	0.23500240149358345
+M14	0.3706887002939023
+M14	0.5187211234748795
+M14	0.44098097117971613
+M14	0.5813234966244114
+M14	0.3504567265922499
+M14	0.3637472256490926
+M14	0.2838762436665264
+M14	0.4235808639858795
+M14	0.22967674429214208
+M14	0.4573125310270086
+M14	0.41628132138253143
+M14	0.448047146438711
+M14	0.239700494911012
+M14	0.4694565179933276
+M14	0.3450801907501135
+M14	0.38880397528489485
+M14	0.4896307442229502
+M14	0.3966784676199384
+M14	0.5663628916516439
+M14	0.48399598309319025
+M14	0.34607084368675917
+M14	0.35735967134007723
+M14	0.3747230312893856
+M14	0.3694705144050571
+M14	0.41469748173108373
+M14	0.3205884777425089
+M14	0.3115667341422033
+M14	0.4980265903526801
+M14	0.3687167258188705
+M14	0.23132920149709316
+M14	0.31643863491663005
+M14	0.4455046687798623
+M14	0.34129485850026225
+M14	0.36682291292850344
+M14	0.28894832459068664
+M14	0.4331342657819811
+M14	0.506373199975206
+M14	0.4487985377229917
+M14	0.36802742118631726
+M14	0.4103703182163815
+M14	0.38668821795961983
+M14	0.5580757859063125
+M14	0.31849979933495587
+M14	0.34617758055545816
+M14	0.3140353213828249
+M14	0.2788821650916385
+M14	0.39493283359877507
+M14	0.29105322919770943
+M14	0.23508387670174252
+M14	0.2797919488859176
+M14	0.29555626467887397
+M14	0.30711822603888567
+M14	0.3465299748829216
+M14	0.42559770022659543
+M14	0.3753206890008222
+M14	0.4947323447327985
+M14	0.580949323114591
+M14	0.31256568977238114
+M14	0.5014046328188487
+M14	0.3021695709613227
+M14	0.3654670092137076
+M14	0.6078680434615682
+M14	0.35656749913916186
+M14	0.4318758252582662
+M14	0.47535218139708213
+M14	0.7177704561447193
+M14	0.6306773983574125
+M14	0.4738628242562359
+M14	0.5358212548471314
+M14	0.5965986619859989
+M14	0.5461787874788679
+M14	0.6516005829534652
+M14	0.6041839114174765
+M14	0.6596383712549007
+M14	0.6377122955791197
+M14	0.5548743176277758
+M14	0.6240172710481101
+M14	0.6621917778582223
+M14	0.682785297289175
+M14	0.6344771716853048
+M14	0.6696643844573148
+M14	0.5092162976680829
+M14	0.384417109279932
+M14	0.3238000123536286
+M14	0.4339967552906021
+M14	0.5815427348879935
+M14	0.6443328173264328
+M14	0.5912884055487584
+M14	0.4920225293826486
+M14	0.5510092670877067
+M14	0.5944300398755784
+M14	0.4810629273352603
+M14	0.4845585907236088
+M14	0.5862446857772796
+M14	0.6078759424737722
+M14	0.5644218974147468
+M14	0.6196364493504632
+M14	0.5513992396593895
+M14	0.5176278608031478
+M14	0.6264423077212113
+M14	0.49258361951677854
+M14	0.5645467421776152
+M14	0.5642298784517631
+M14	0.41508136345017554
+M14	0.4500795314940711
+M14	0.5253097015452244
+M14	0.45920085820800655
+M14	0.5231082095765194
+M14	0.28640736552522783
+M14	0.6331401320332134
+M14	0.5494337553747364
+M14	0.4328890045659194
+M14	0.43339836503718404
+M14	0.34580456403294363
+M14	0.4564478001916855
+M14	0.5035669556698166
+M14	0.6335645894453642
+M14	0.6647495889191958
+M14	0.5998228891962913
+M14	0.6719086735204973
+M14	0.7543808687061369
+M14	0.5455224822373672
+M14	0.7283523238909885
+M14	0.7097637045206364
+M14	0.6433855828657027
+M14	0.6656613952191762
+M14	0.6217189576159604
+M14	0.5635910998272563
+M14	0.5907036163742915
+M14	0.6878267168187591
+M14	0.5591664462538806
+M14	0.5396554120343182
+M14	0.39680500897926724
+M14	0.47164298336912946
+M14	0.3157507609032123
+M14	0.5263828840552996
+M14	0.4805985070217568
+M14	0.567676385079369
+M14	0.5718511807776178
+M14	0.4519221746190991
+M14	0.6617829849420629
+M14	0.5470604745698728
+M14	0.6304086750424462
+M14	0.7469845117730095
+M14	0.6509538965855911
+M14	0.6558223260078313
+M14	0.5116323712567058
+M14	0.6300629580916516
+M14	0.6392234859630802
+M14	0.5656192803752269
+M14	0.6191154393297633
+M14	0.5333142034594509
+M14	0.5997809027189995
+M14	0.6682850368856412
+M14	0.6406486110041868
+M14	0.5412346692354564
+M14	0.5433017658700531
+M14	0.6227201329540903
+M14	0.6138635729801875
+M14	0.5789763736891524
+M14	0.5987505172548371
+M14	0.5949443909735215
+M14	0.5103839464523832
+M14	0.533151129405984
+M14	0.5877016646096805
+M14	0.580649044484478
+M14	0.537089055185218
+M14	0.5526426480133505
+M14	0.6277637032310713
+M14	0.6383407816934202
+M14	0.6729254066716146
+M14	0.5839277253432338
+M14	0.6601825478755353
+M14	0.6892157980968273
+M14	0.432493797420861
+M14	0.536330149799362
+M14	0.650708623551717
+M14	0.6189023454215646
+M14	0.6984262263609622
+M14	0.6890309736184635
+M14	0.5185549209073517
+M14	0.573886979604277
+M14	0.5791419247107226
+M14	0.497790221962923
+M14	0.5244798194807816
+M14	0.6761366973261789
+M14	0.7196159973322935
+M14	0.5787120671247551
+M14	0.6374279435408412
+M14	0.6145384694618421
+M14	0.6414611067129778
+M14	0.43826335738544464
+M14	0.4830475789209669
+M14	0.6363227164471864
+M14	0.5639636053187207
+M14	0.6574242484663027
+M14	0.607935318706178
+M14	0.5423007157704324
+M14	0.4978589295641357
+M14	0.6320122171221669
+M14	0.6016174632746085
+M14	0.5782627613207397
+M14	0.6838434299970644
+M14	0.6265000074465967
+M14	0.49948395660418665
+M14	0.37483086735684956
+M14	0.19828686992878577
+M14	0.2892760015178254
+M14	0.3431653988034035
+M14	0.6362177128528889
+M14	0.5206133767368746
+M14	0.6914878347244617
+M14	0.6883607209786237
+M14	0.5837505137637414
+M14	0.5665701197824985
+M14	0.5627671463200845
+M14	0.6417781720341299
+M14	0.40706113769513913
+M14	0.5510333163594473
+M14	0.5693756202091516
+M14	0.6582003124838062
+M14	0.5924682283756023
+M14	0.5436487188977853
+M14	0.6684298171782289
+M14	0.5640923575585864
+M14	0.6664202630138405
+M14	0.4982800172894626
+M14	0.5065607573792102
+M14	0.5327608514857213
+M14	0.6325411326431899
+M14	0.3567696925767533
+M14	0.5083545945610121
+M14	0.6886982073680387
+M14	0.7116072963620516
+M14	0.6449876461652434
+M14	0.49965224827219573
+M14	0.4120274869766076
+M14	0.6250386747324946
+M14	0.5895528847206056
+M14	0.49139011693435075
+M14	0.6048960401159231
+M14	0.5678291165364788
+M14	0.6053716114969044
+M14	0.5335754686089981
+M14	0.6876323724256947
+M14	0.6863397715107799
+M14	0.7584468033047284
+M14	0.7007511120077496
+M14	0.5788688729780078
+M14	0.6714365035340627
+M14	0.6466334282792443
+M14	0.6332583278892804
+M14	0.6218318400760041
+M14	0.6289804706270893
+M14	0.5926813554052939
+M14	0.6395722683101678
+M14	0.6197851857505658
+M14	0.5066243539421323
+M14	0.46337078747945526
+M14	0.4645976578946315
+M14	0.6075622051462785
+M14	0.5171437645519946
+M14	0.6318422944266782
+M14	0.6149415028464921
+M14	0.6005343161600917
+M14	0.5245040270383714
+M14	0.39208038345123086
+M14	0.33453406258509355
+M14	0.5096582408928156
+M14	0.5397753986875167
+M14	0.6461534401781119
+M14	0.6244390590203095
+M14	0.527696888138206
+M14	0.7107834879966319
+M14	0.6175275662184992
+M14	0.6457135246303141
+M14	0.5912367164330022
+M14	0.6465155034604995
+M14	0.7156687092396685
+M14	0.6578875897965659
+M14	0.6558868097637981
+M14	0.7262857881184847
+M14	0.6700585877266815
+M14	0.5793806832065039
+M14	0.6815994902683582
+M14	0.6119980531964633
+M14	0.5524319517116532
+M14	0.5920127596869496
+M14	0.6113398996469204
+M14	0.5509811179809512
+M14	0.6003151174394405
+M14	0.5100315924306507
+M14	0.5408286667669678
+M14	0.4227386487416668
+M14	0.5051811225538928
+M14	0.44848663971652736
+M14	0.5860331937976706
+M14	0.22824828832478186
+M14	0.5496203969506016
+M14	0.3844918855341389
+M14	0.4439783281097385
+M14	0.6381021967794044
+M14	0.5943121770034191
+M14	0.5045558249256676
+M14	0.5127855129899049
+M14	0.6042128378871294
+M14	0.6344382097053906
+M14	0.6252756375521935
+M14	0.46796474177414826
+M14	0.6068302879377927
+M14	0.6109492462258166
+M14	0.3840245859805644
+M14	0.36044757284185835
+M14	0.6082103988581006
+M14	0.7090431888806924
+M14	0.7417915443591128
+M14	0.7100543211497445
+M14	0.6802272426777191
+M14	0.6507834127123968
+M14	0.6307955170135896
+M14	0.6260509809235815
+M14	0.5924348727946707
+M14	0.5599411857296238
+M14	0.6824683061336756
+M14	0.6584083109990505
+M14	0.5094791841752453
+M14	0.5408334847080333
+M14	0.6550510622668133
+M14	0.723606502661627
+M14	0.6443376286636655
+M14	0.6393686774526023
+M14	0.5763218203172474
+M14	0.5178855343762976
+M14	0.6206669151671881
+M14	0.5344139566287301
+M14	0.40480540766896667
+M14	0.5713186800279766
+M14	0.6045889973009054
+M14	0.608890008012478
+M14	0.5383831637766295
+M14	0.6352656912031514
+M14	0.6600408977164325
+M14	0.7347382770118421
+M14	0.5863417587949923
+M14	0.6788988190781283
+M14	0.6386822687869089
+M14	0.593709760380748
+M14	0.6456872501307631
+M14	0.6239080482994426
+M14	0.6661838393110061
+M14	0.5738033767458762
+M14	0.5702386121001649
+M14	0.49693802463668413
+M14	0.7052825600311791
+M14	0.4550523866573632
+M14	0.44674398062658816
+M14	0.6905563984086316
+M14	0.5884055271659969
+M14	0.5177265096435212
+M14	0.5524044611422421
+M14	0.634993211948785
+M14	0.45643985041574414
+M14	0.3947874570366121
+M14	0.5876834147107614
+M14	0.5187249196645426
+M14	0.5655961982328074
+M14	0.6479591697398157
+M14	0.5099234152637816
+M14	0.5132983453778721
+M14	0.5963561997859663
+M14	0.5369722847714741
+M14	0.6187775754757487
+M14	0.6365829757127722
+M14	0.6264871340172735
+M14	0.5648048892689453
+M14	0.5129815702722453
+M14	0.4450000889601722
+M14	0.6154941493281548
+M14	0.582479510708933
+M14	0.5557267532931971
+M14	0.6382449285879628
+M14	0.4437546743014057
+M14	0.5895412570064849
+M14	0.634695581141148
+M14	0.561128452743052
+M14	0.6861105551682773
+M14	0.5873473297817037
+M14	0.5612535041569955
+M14	0.552935186817238
+M14	0.7013004885920202
+M14	0.5739911289054153
+M14	0.5143635611458433
+M14	0.5856772907945376
+M14	0.6179576498433079
+M14	0.6676510811072329
+M14	0.5850822971924594
+M14	0.631903160625866
+M14	0.5939741670980592
+M14	0.5837411255401154
+M14	0.5541740725089213
+M14	0.51066160177735
+M14	0.5882131905299884
+M14	0.6961851427318099
+M14	0.5493860302283039
+M14	0.5660793859205284
+M14	0.6372137211733784
+M14	0.5684071427401284
+M14	0.6176048904432716
+M14	0.7181481516906342
+M14	0.3563176193639477
+M14	0.5334222098053953
+M14	0.4930335006764827
+M14	0.5511599634069143
+M14	0.48596757121315626
+M14	0.5631152987608452
+M14	0.571941940534343
+M14	0.5363254154982141
+M14	0.2883718155546029
+M14	0.5160253446377379
+M14	0.5936993531048762
+M14	0.5289454584302926
+M14	0.6160417699201907
+M14	0.5602915261867414
+M14	0.6879718740801706
+M14	0.5236947954863687
+M14	0.559933933507971
+M14	0.6723863959228875
+M14	0.5800393328163652
+M14	0.6211151351197376
+M14	0.6186513148078856
+M14	0.6803949034500821
+M14	0.49515479402397183
+M14	0.5724272795373065
+M14	0.6671942533395733
+M14	0.6728971015168911
+M14	0.5497984227171528
+M14	0.5449842071464454
+M14	0.6863630095720383
+M14	0.6439850997915051
+M14	0.6299689961854442
+M14	0.5784428707702406
+M14	0.5028734407158926
+M14	0.6437706056788174
+M14	0.6151452877871069
+M14	0.6393964128514892
+M07	0.27916855513991207
+M07	0.3928630409814095
+M07	0.3224835772589223
+M07	0.19474970758718455
+M07	0.4121434740093282
+M07	0.2666399458873877
+M07	0.40729422102757734
+M07	0.36685267447210523
+M07	0.3203464173721704
+M07	0.33783869842669734
+M07	0.29394923967459646
+M07	0.3634058757644211
+M07	0.31504823113507663
+M07	0.39778038148882056
+M07	0.32870933222443816
+M07	0.38556504988811535
+M07	0.6024682432620903
+M07	0.41343079673480904
+M07	0.4079340764058678
+M07	0.41254983167374415
+M07	0.30756851714503747
+M07	0.3752709283027045
+M07	0.27867050420113226
+M07	0.3659125487569061
+M07	0.34342817194347564
+M07	0.43948113682173084
+M07	0.1871388947487155
+M07	0.2970021525461069
+M07	0.440655649849915
+M07	0.4107571032140596
+M07	0.4016794439794489
+M07	0.4397286459457103
+M07	0.3376700192496525
+M07	0.17367193870730957
+M07	0.3015681772540989
+M07	0.49292420178445195
+M07	0.24895451055871737
+M07	0.5050661694166938
+M07	0.3705626147664511
+M07	0.3941034486091308
+M07	0.390320246022181
+M07	0.4207761974205337
+M07	0.6930188219238156
+M07	0.35024166616112795
+M07	0.37666978588983324
+M07	0.42814082002405446
+M07	0.3503941467335661
+M07	0.2792909762574903
+M07	0.3410591637206025
+M07	0.3717826243101556
+M07	0.28159823175785537
+M07	0.37559479307247506
+M07	0.2050078608820983
+M07	0.28658964693987155
+M07	0.37324322417915534
+M07	0.4718209028923157
+M07	0.3045145507067633
+M07	0.3638116204234681
+M07	0.5347672578379689
+M07	0.3793912874754796
+M07	0.2964232475991735
+M07	0.29146486439249275
+M07	0.40446139351608085
+M07	0.2779702352605047
+M07	0.2950453686526795
+M07	0.33672040344102405
+M07	0.2255988829800851
+M07	0.31035580815903285
+M07	0.2530049503272425
+M07	0.5833154328990491
+M07	0.4009633322509633
+M07	0.31895671563106637
+M07	0.42817592864425835
+M07	0.39553845672789467
+M07	0.3911180336807624
+M07	0.5378984595662624
+M07	0.3701113928136205
+M07	0.16332172282395496
+M07	0.356227139101324
+M07	0.3117367187100771
+M07	0.35995758292247343
+M07	0.24555213297838338
+M07	0.3250657205555079
+M07	0.27131512689974857
+M07	0.2804640954946734
+M07	0.33727568817080367
+M07	0.2910955419194714
+M07	0.27826168002777046
+M07	0.4955128744497724
+M07	0.25000164234545735
+M07	0.29151247801102054
+M07	0.5527651939033646
+M07	0.32838509498988455
+M07	0.4396725178121541
+M07	0.5390690401672378
+M07	0.3293328335457989
+M07	0.5345782824159672
+M07	0.40312461040770775
+M07	0.33330623984493685
+M07	0.33186125830693913
+M07	0.3200716816475165
+M07	0.30256706455249854
+M07	0.2345216352947095
+M07	0.3027775899835281
+M07	0.5571130025470166
+M07	0.23975152037687614
+M07	0.3390909961337291
+M07	0.28437353626361733
+M07	0.2599562369124482
+M07	0.5025803557110832
+M07	0.3123800525146624
+M07	0.42525201827216547
+M07	0.24871874643696898
+M07	0.2712037053489082
+M07	0.33971001983391114
+M07	0.4537889177987998
+M07	0.3383035006915588
+M07	0.4036839809698001
+M07	0.17366076026490732
+M07	0.3751261137594897
+M07	0.49516343570679483
+M07	0.33757317356850053
+M07	0.5383763523254457
+M07	0.23269492219782623
+M07	0.33066792183793664
+M07	0.2750370099788786
+M07	0.4096927285339761
+M07	0.2759628718652344
+M07	0.41346505423677726
+M07	0.43132368305396024
+M07	0.38856827580017195
+M07	0.20785440644110528
+M07	0.40606670932003763
+M07	0.3607139419421913
+M07	0.35707944734844466
+M07	0.49532471041751047
+M07	0.34246139357118566
+M07	0.5450213064209489
+M07	0.3727849681461478
+M07	0.34143816851753395
+M07	0.36658184464751886
+M07	0.3941401849723023
+M07	0.26339987705881035
+M07	0.2847881628606268
+M07	0.33871387708393796
+M07	0.3193693290824137
+M07	0.49600189361895103
+M07	0.4088112805257996
+M07	0.20500000772023677
+M07	0.31759612927227315
+M07	0.46256630174732594
+M07	0.3282408157227428
+M07	0.25609663692474477
+M07	0.2732342983173176
+M07	0.4230712864412404
+M07	0.39785239581321236
+M07	0.43352379339504243
+M07	0.31175891385368426
+M07	0.3960228393119459
+M07	0.38336171417055503
+M07	0.5300017168341205
+M07	0.22045208412979467
+M07	0.3314098637121851
+M07	0.30138405347879005
+M07	0.27106643467512853
+M07	0.3969157992240506
+M07	0.19522920409612265
+M07	0.2045058540254212
+M07	0.25045328794914756
+M07	0.21822711775641465
+M07	0.187034146939423
+M07	0.37731560664714153
+M07	0.44934736827425104
+M07	0.32214409020131207
+M07	0.4452690703734051
+M07	0.566186119818431
+M07	0.3315858037584437
+M07	0.44701316537981123
+M07	0.28652802195364807
+M07	0.4281627108931032
+M07	0.5482657983466835
+M07	0.5346042383647079
+M07	0.6476611606282252
+M07	0.4329263356282713
+M07	0.5854464934573979
+M07	0.5264856962848595
+M07	0.342517121266252
+M07	0.6360758602760865
+M07	0.6428126554393845
+M07	0.5086253594722484
+M07	0.6502160085216623
+M07	0.5752110625854275
+M07	0.634710523148354
+M07	0.6144371663607625
+M07	0.546447783395519
+M07	0.518546811657355
+M07	0.5324651901144646
+M07	0.4721795329751724
+M07	0.4861834098631379
+M07	0.4824313750254064
+M07	0.6556173883956814
+M07	0.46954340285688645
+M07	0.49487535502251057
+M07	0.5388717426974445
+M07	0.6272865527865542
+M07	0.5973900524329039
+M07	0.4388701316938789
+M07	0.6789862392715937
+M07	0.6010764511147384
+M07	0.38457932815077017
+M07	0.4533799326607757
+M07	0.632476352469011
+M07	0.6391437590824641
+M07	0.43984011765468767
+M07	0.43261465283211414
+M07	0.5498737792076756
+M07	0.6685672797239283
+M07	0.6667510928301745
+M07	0.6076836804318119
+M07	0.641003798357673
+M07	0.6493171823790166
+M07	0.7091337845075223
+M07	0.4895196600815759
+M07	0.6552063117782075
+M07	0.623682105036739
+M07	0.5406223387104049
+M07	0.5572034968330383
+M07	0.5989066123055344
+M07	0.6135821658316477
+M07	0.5961567112218167
+M07	0.4851246753636942
+M07	0.5984337009578432
+M07	0.667727237583712
+M07	0.6557126246254856
+M07	0.6260146771887488
+M07	0.6178729469905768
+M07	0.6301864817468863
+M07	0.5189115991078421
+M07	0.5102134158218833
+M07	0.585712659850915
+M07	0.626977731575529
+M07	0.6292153375142199
+M07	0.7206214131963943
+M07	0.6511043140340803
+M07	0.6564870373438557
+M07	0.5223127345552127
+M07	0.5897808236705683
+M07	0.6215826588911048
+M07	0.5148402908266546
+M07	0.6596288403048157
+M07	0.6259943872659834
+M07	0.5062162614608533
+M07	0.5366720026347261
+M07	0.4877364076121448
+M07	0.5999249427422036
+M07	0.6317338246878126
+M07	0.5460795314576791
+M07	0.4564470449301971
+M07	0.4511461417841442
+M07	0.5201140334031729
+M07	0.5607756663040813
+M07	0.7050025525555538
+M07	0.7596752769373104
+M07	0.6948619350277093
+M07	0.7097752355809452
+M07	0.579145204413971
+M07	0.691859520869421
+M07	0.620300892512286
+M07	0.6641903857495394
+M07	0.6980309432857902
+M07	0.6722445109262367
+M07	0.45771761005735967
+M07	0.6565106947800392
+M07	0.5922529560733553
+M07	0.5570729365813032
+M07	0.480429472019217
+M07	0.5807487525510808
+M07	0.6323732422852273
+M07	0.6002737463478477
+M07	0.6579781509968304
+M07	0.4643599839184507
+M07	0.6898517551594455
+M07	0.6096999614306041
+M07	0.4750435698701595
+M07	0.6531252737395432
+M07	0.7044132143124472
+M07	0.6300096180252823
+M07	0.550415160241865
+M07	0.665014738237147
+M07	0.5491715140056034
+M07	0.4533991584267736
+M07	0.6446753999492144
+M07	0.6708700776538696
+M07	0.5505481824498346
+M07	0.6002206316145828
+M07	0.6623759166727964
+M07	0.5727157749816001
+M07	0.5560858381696373
+M07	0.36588839007941276
+M07	0.5212658540409292
+M07	0.542215414709948
+M07	0.5228775948639068
+M07	0.6278433345559933
+M07	0.6548529669583584
+M07	0.6584472961284971
+M07	0.6744700478194461
+M07	0.53235457973197
+M07	0.4906617511731761
+M07	0.6662832081070644
+M07	0.6286952022395659
+M07	0.6151707757757471
+M07	0.5960555655631602
+M07	0.5763685636411565
+M07	0.5217614025462177
+M07	0.6508390199083106
+M07	0.5402078744102671
+M07	0.6124379773342469
+M07	0.452096864179601
+M07	0.6961259723644249
+M07	0.4367392072717517
+M07	0.4169940347638956
+M07	0.6434576678371524
+M07	0.4848562254719121
+M07	0.5810505112965626
+M07	0.6340701390836958
+M07	0.5180043909500356
+M07	0.649639673365984
+M07	0.5663153974210825
+M07	0.7080306441098367
+M07	0.610104225261553
+M07	0.6734139652866209
+M07	0.567841004123781
+M07	0.5508373262484825
+M07	0.572865972021026
+M07	0.4875565689213298
+M07	0.4804171826499896
+M07	0.5940025144526386
+M07	0.6512343483543188
+M07	0.4682116107106699
+M07	0.5166488904897905
+M07	0.5960485795297463
+M07	0.30633299513196055
+M07	0.5735275726259228
+M07	0.6087204191868453
+M07	0.4952646122750063
+M07	0.38851731518891064
+M07	0.4793384664832072
+M07	0.46339453767524486
+M07	0.6265153710021145
+M07	0.5540487379937297
+M07	0.37524796816833567
+M07	0.5839042503266009
+M07	0.7034233571770641
+M07	0.6867610055604245
+M07	0.5751610669950556
+M07	0.4984066052475092
+M07	0.5795297141150453
+M07	0.6279019498927125
+M07	0.5329799135126836
+M07	0.616905388246925
+M07	0.5480338998753579
+M07	0.5567135593549503
+M07	0.5608435137239187
+M07	0.5609563365017302
+M07	0.6829763206090428
+M07	0.7268031122875604
+M07	0.6746047299161045
+M07	0.5868635252021799
+M07	0.5830378802933127
+M07	0.5666090167909386
+M07	0.6379552348688577
+M07	0.5414563615739879
+M07	0.5456680618055658
+M07	0.5004260634466648
+M07	0.6053349442756142
+M07	0.6712908907557279
+M07	0.6629776346376183
+M07	0.6290371579022582
+M07	0.605372825009938
+M07	0.6164618754441068
+M07	0.6580543162728048
+M07	0.6070215718679922
+M07	0.5981927899631347
+M07	0.4124290796836144
+M07	0.5968047127325122
+M07	0.609443818469925
+M07	0.4906675906116765
+M07	0.5593280536973527
+M07	0.3773198665808032
+M07	0.6956978257133309
+M07	0.5306619342017149
+M07	0.7133503159698398
+M07	0.684708699295843
+M07	0.5307878492981105
+M07	0.6246816035417196
+M07	0.6073212500314272
+M07	0.4949519780130013
+M07	0.6804336438737109
+M07	0.5472959808575546
+M07	0.48851936535633395
+M07	0.709050166585025
+M07	0.6905619401879683
+M07	0.6154197191639578
+M07	0.5816921469840991
+M07	0.6474049388242566
+M07	0.5617656803045286
+M07	0.5622537670957055
+M07	0.6308486557292796
+M07	0.5424553726296957
+M07	0.6124100151500952
+M07	0.5536109719303444
+M07	0.5827477095089966
+M07	0.5855664325574803
+M07	0.4973233618186854
+M07	0.5425299864371014
+M07	0.5008095465927733
+M07	0.3780400375626926
+M07	0.7461249962954835
+M07	0.5619878935959124
+M07	0.45789505839459294
+M07	0.6321015196482234
+M07	0.6780058807131009
+M07	0.6497789136406891
+M07	0.43962533763047196
+M07	0.651894155356819
+M07	0.7075160204607657
+M07	0.5581896012181466
+M07	0.6302566466259018
+M07	0.6124879489931138
+M07	0.6603866645331986
+M07	0.4237446769523166
+M07	0.5257361140312485
+M07	0.6461758788942239
+M07	0.7224953198894956
+M07	0.4848324829073117
+M07	0.6305650952319157
+M07	0.6846391063098963
+M07	0.5643727054386398
+M07	0.5368248918836279
+M07	0.6274550459434549
+M07	0.6136649870080467
+M07	0.6260759290498653
+M07	0.6392533710207382
+M07	0.6287154393374287
+M07	0.6522416060971569
+M07	0.5289850569066264
+M07	0.5798652757445403
+M07	0.6590745258205118
+M07	0.630790638140317
+M07	0.6002196290131024
+M07	0.5518013148474848
+M07	0.5093901804168977
+M07	0.3904886353509517
+M07	0.6263539953844456
+M07	0.5481721584253438
+M07	0.6835932529841275
+M07	0.6410072030247295
+M07	0.41561387062329314
+M07	0.4915849047377866
+M07	0.7151169006147475
+M07	0.6465797765036473
+M07	0.5470055326932792
+M07	0.5674123030800644
+M07	0.6683814107066937
+M07	0.6290119567054252
+M07	0.5950271835403464
+M07	0.66911654912279
+M07	0.6183397670133493
+M07	0.6550577405845869
+M07	0.46888146659439406
+M07	0.5867020046548403
+M07	0.6077613888648441
+M07	0.5913949560089978
+M07	0.5510950941927101
+M07	0.5243368859605967
+M07	0.5606461125239837
+M07	0.6684760255995599
+M07	0.6372671499781188
+M07	0.5605717787817447
+M07	0.6181948100482857
+M07	0.55363451817446
+M07	0.49177328892745
+M07	0.6461437129263603
+M07	0.5466527690503479
+M07	0.5864523713426871
+M07	0.662647261041337
+M07	0.6155866807642372
+M07	0.6381687501728884
+M07	0.5989820790818686
+M07	0.5269821298538889
+M07	0.5484266890162919
+M07	0.6336864099806683
+M07	0.596119334218288
+M07	0.5642327310706489
+M07	0.4818846650989704
+M07	0.6671506998280082
+M07	0.6260330968074294
+M07	0.5890460445993613
+M07	0.561140528793009
+M07	0.49128221668444355
+M07	0.6158230393222667
+M07	0.585920349987846
+M07	0.6364160041664411
+M07	0.4760869429474578
+M07	0.6733334285158101
+M07	0.6049057153158357
+M07	0.5715967941771679
+M07	0.6115036536075825
+M07	0.7164699902852419
+M07	0.6117959198588473
+M07	0.48704940926046175
+M07	0.6149232042221201
+M07	0.6559326976138639
+M07	0.5892010491511391
+M07	0.5765384149028511
+M07	0.652184043038357
+M07	0.596834230211454
+M07	0.5734700952397898
+M07	0.5762802969240916
+M07	0.36508737379169043
+M07	0.5066077339128837
+M07	0.6947897272235318
+M07	0.5503740374680094
+M07	0.5566974851869948
+M07	0.6549237459899324
+M07	0.5285370737212319
+M07	0.6309742963596837
+M07	0.5439091119288564
+M07	0.6241728250655647
+M07	0.437445320015512
+M07	0.597707035725538
+M07	0.5639067402051046
+M07	0.4164173253648783
+M07	0.6060008010886796
+M07	0.5743967719228642
+M07	0.5591719655200315
+M07	0.4944216889955411
+M07	0.5697709609455596
+M07	0.6276121311769547
+M07	0.4680049160901988
+M07	0.5311870290099938
+M07	0.5558811323894401
+M07	0.6245154159694172
+M07	0.4997584083675347
+M07	0.5867889062637283
+M07	0.5567287677274733
+M07	0.594778196784284
+M07	0.6133488608873807
+M07	0.39270535710416726
+M07	0.721263207368416
+M07	0.6098705779644856
+M07	0.652442517802945
+M07	0.6427978084917647
+M07	0.6791300136634406
+M07	0.49876317638855094
+M07	0.5442834631419954
+M07	0.4957978465061689
+M07	0.4243834588170172
+M07	0.6033106991543089
+M07	0.5272238410668114
+M07	0.5358550240748496
+M07	0.6663611152006537
+M07	0.6323591691548358
+M07	0.6447284559052286
+M07	0.724835886785933
+M07	0.6544401331718382
+M07	0.5795662556752961
+M07	0.7033702720172703
+M07	0.6565720711210399
+M07	0.6439400687340522
+M07	0.5454278153577188
+M07	0.6152345361786383
+M07	0.6896688665555136
+M07	0.5328629819290914
+M07	0.6478650900459603
+M07	0.7543500533941012
+M07	0.6370044547579408
+M07	0.5529187551305418
+M07	0.6513174328835585
+M07	0.6332472361504408
+M07	0.5175243467583538
+M07	0.6344474901940061
+M07	0.7109107788024871
+M07	0.6619283443705322
+M07	0.7030046431298178
+M07	0.652619470293436
+M07	0.7266630004547174
+M07	0.7554217535785492
+M07	0.7016045837609731
+M07	0.6857963137327192
+M07	0.6486476127873277
+M07	0.5894523792102583
+M07	0.5559296658263877
+M07	0.6345389011941488
+M07	0.6326955652166337
+M07	0.6726422160564046
+M07	0.6522068083038354
+M07	0.6773991938417083
+M07	0.7198047524951766
+M07	0.6098641115958277
+M07	0.5700007575481655
+M07	0.6376503225510133
+M07	0.5597003562298264
+M07	0.5943762418496518
+M07	0.5747730356976319
+M07	0.7134205158670271
+M07	0.5626429829544152
+M07	0.6405521217691302
+M07	0.6260654841688311
+M07	0.6107878861647512
+M07	0.7011341914963488
+M07	0.6000141320035621
+M07	0.49203412007337716
+M07	0.591072159729638
+M07	0.5856613271524105
+M07	0.6371883780636325
+M07	0.5284993328956299
+M07	0.7262890509527479
+M07	0.6883033672794245
+M07	0.656659921988142
+M07	0.5531678089288877
+M07	0.4652284599617668
+M07	0.7077212716260375
+M07	0.5895825652693225
+M07	0.6671370478566011
+M07	0.631160182260226
+M07	0.6130488972898003
+M07	0.5570568445391398
+M07	0.6085248267710653
+M07	0.6252751554398117
+M07	0.5963833365229279
+M07	0.6167173969114516
+M07	0.5530726659122729
+M07	0.6208931989231138
+M07	0.6721266877369018
+M07	0.5843638170250575
+M07	0.7566731380786592
+M07	0.5031344185428016
+M07	0.567170062737934
+M07	0.5956135413700223
+M07	0.6090630084089701
+M07	0.6466134650250028
+M07	0.6548743149347838
+M07	0.6352591338677621
+M07	0.6242496341460855
+M07	0.6347546329586218
+M07	0.6906743956069148
+M07	0.5328321406599956
+M07	0.6275655516051021
+M07	0.7387429661211842
+M07	0.6697760069643383
+M07	0.6882683662333426
+M07	0.6113024501160618
+M07	0.6245346844967
+M07	0.5618234252370373
+M07	0.5751496265937956
+M07	0.6092447557843836
+M07	0.5714158972040215
+M07	0.68894895506089
+M07	0.7009550703520279
+M07	0.6332409763045329
+M07	0.5819192767030831
+M07	0.6627020358727674
+M07	0.7240513397211097
+M07	0.6897975129997059
+M07	0.6996308766286459
+M07	0.6461990232260969
+M07	0.7181224839514263
+M07	0.6050907815001141
+M07	0.46465091041898315
+M07	0.629197103092967
+M07	0.5905489291290316
+M07	0.6950721591112027
+M07	0.741571902274331
+M07	0.6845491977216012
+M07	0.5728352230819959
+M07	0.349437548681594
+M07	0.4718416374077193
+M07	0.612909722982211
+M07	0.541956955764221
+M07	0.5656654287773073
+M07	0.5456739377065714
+M07	0.456087246681771
+M07	0.6430537551853805
+M07	0.6052417433802789
+M07	0.5977253947513594
+M07	0.6214088793126136
+M07	0.4729484531554352
+M07	0.6667483268835017
+M07	0.6866106749984111
+M07	0.561579386110347
+M07	0.5805425174768225
+M07	0.67237928640976
+M07	0.5257866805117405
+M07	0.6076095988231957
+M07	0.7360085790784611
+M07	0.5943173554772411
+M07	0.6116221192254884
+M07	0.6640129234677774
+M07	0.6543216889465311
+M07	0.6129709050067786
+M07	0.652115728328559
+M07	0.5900340036772594
+M07	0.4987873109717782
+M07	0.6822993245432597
+M07	0.6049573952112934
+M07	0.5957326724456964
+M07	0.5832992609425177
+M07	0.7249748911085699
+M07	0.6718955149632191
+M07	0.6817524109172602
+M07	0.6742853004036781
+M07	0.6167201413618729
+M07	0.5517904302489818
+M07	0.350329690355999
+M07	0.6564848592585337
+M07	0.6483558532124941
+M07	0.5695626600232566
+M07	0.6549878640306432
+M07	0.5957781637384314
+M07	0.590507328542133
+M07	0.6022528753626638
+M07	0.6934468964837818
+M07	0.6026544595363806
+M07	0.6625872236709924
+M07	0.42576182917583577
+M07	0.5935618926102043
+M07	0.6268603661088923
+M07	0.5444884626426568
+M07	0.5886068486098528
+M07	0.5878391050553131
+M07	0.6347777575473383
+M07	0.6432289038132637
+M07	0.7386682800217067
+M07	0.6217448056914368
+M07	0.6280037005546639
+M07	0.6930322893705606
+M07	0.4476863964886562
+M07	0.49986622215164134
+M07	0.6459148328506877
+M07	0.5311551985732015
+M07	0.4437755017271391
+M07	0.5266328319062074
+M07	0.7083318996099013
+M07	0.6854621625701153
+M07	0.7233303324680652
+M07	0.5820405767528275
+M07	0.6409923634179685
+M07	0.7149490685923571
+M07	0.6213758115228752
+M07	0.6594884500131087
+M07	0.6541510030793061
+M07	0.5719267107187417
+M07	0.5460582253194645
+M07	0.648904985740503
+M07	0.6180407926999146
+M07	0.5795601106616066
+M07	0.6448832441192923
+M07	0.4596726774639844
+M07	0.5804905428639406
+M07	0.49769553595414917
+M07	0.7058706822798586
+M07	0.6619347658205597
+M07	0.6003213831377558
+M07	0.585107033499849
+M07	0.5473939993233982
+M07	0.6885797119205526
+M07	0.4120613148946239
+M07	0.5383810559993066
+M07	0.5406567364066781
+M07	0.6180800406451735
+M07	0.5761766303940676
+M07	0.5866738679859095
+M07	0.49158842140896386
+M07	0.6389888814403695
+M07	0.6535418918384397
+M07	0.6537231532946417
+M07	0.6183013133812323
+M07	0.5927788109586554
+M07	0.7192971118822986
+M07	0.6663503691204311
+M07	0.5752120344007523
+M07	0.6575266629522153
+M07	0.6292776375659932
+M07	0.6234865165540083
+M07	0.5648309057703805
+M07	0.6654239755911018
+M07	0.5715034062652004
+M07	0.5647180583041624
+M07	0.6455111669630411
+M07	0.6932821230698357
+M07	0.4907236298618335
+M07	0.4585993644621977
+M07	0.5137542996959571
+M07	0.5851387909456351
+M07	0.4756969075664387
+M07	0.5425287807781928
+M07	0.5982710389725452
+M07	0.6782423861317335
+M07	0.6224605398046216
+M07	0.6194432037724321
+M07	0.3454447179872686
+M07	0.5902105723647635
+M07	0.5755992238126048
+M07	0.5871327481997549
+M07	0.6374775478108884
+M07	0.5192036406793389
+M13	0.26506805710249903
+M13	0.3350516026993205
+M13	0.3917540878470851
+M13	0.2250589822968088
+M13	0.3728000402929125
+M13	0.2570191384164338
+M13	0.3358746805268379
+M13	0.3899979806136367
+M13	0.3280535194261888
+M13	0.34822368534781367
+M13	0.15993968875488396
+M13	0.3410591322652972
+M13	0.3618899199423839
+M13	0.35954455179870815
+M13	0.2932855170787875
+M13	0.35623897232908824
+M13	0.5445034251688111
+M13	0.40491355950480223
+M13	0.49481936236514995
+M13	0.38415914101707616
+M13	0.28912350873611425
+M13	0.3517961941895967
+M13	0.3091056716125643
+M13	0.29782626370861687
+M13	0.28154308404331413
+M13	0.4288492226654737
+M13	0.2562439514889684
+M13	0.2533032989041815
+M13	0.48091012075481737
+M13	0.41426957593905256
+M13	0.39114750219867894
+M13	0.3926657280690049
+M13	0.3345065432587763
+M13	0.17054016660546645
+M13	0.3417564150601133
+M13	0.44341874597161235
+M13	0.20929024081688172
+M13	0.4045569224986387
+M13	0.3495838186614148
+M13	0.4141056658584666
+M13	0.41740604422256505
+M13	0.4284142577665858
+M13	0.5362129719488883
+M13	0.36720127705246447
+M13	0.21361739073697233
+M13	0.33890851314972553
+M13	0.2917729067640071
+M13	0.2395304239083888
+M13	0.2595448189628769
+M13	0.4452611135143668
+M13	0.2747718984835511
+M13	0.26533037526337533
+M13	0.28578639063251
+M13	0.13060769895797283
+M13	0.3571737249788815
+M13	0.39157043389744123
+M13	0.27516649261864995
+M13	0.31686232327478786
+M13	0.349027954730361
+M13	0.3479602859717787
+M13	0.2698311202831907
+M13	0.31622140925413206
+M13	0.3995672260785833
+M13	0.3529526420020781
+M13	0.29673051481036167
+M13	0.26596528364999444
+M13	0.32526368246388865
+M13	0.2832442155006301
+M13	0.2829687985145854
+M13	0.5668469656047339
+M13	0.391579147134477
+M13	0.32896117635103056
+M13	0.4095669146410338
+M13	0.3376712016969973
+M13	0.36542232904835986
+M13	0.41876741349378466
+M13	0.3244959570001126
+M13	0.2943217304363838
+M13	0.37318088392725635
+M13	0.2872622403833553
+M13	0.29146451735809553
+M13	0.3076593666097598
+M13	0.29488926286805994
+M13	0.25561486161512775
+M13	0.24826135860103585
+M13	0.4204753377293775
+M13	0.3290015792401911
+M13	0.27538092515257406
+M13	0.418049774791297
+M13	0.34280982354480405
+M13	0.29717503899979464
+M13	0.48932402768150246
+M13	0.3933404936820787
+M13	0.43401834840729847
+M13	0.49364956917345704
+M13	0.27491232931032183
+M13	0.5433187081491685
+M13	0.34742660945041387
+M13	0.33556441339939147
+M13	0.3366328888354184
+M13	0.34561958649447977
+M13	0.3035693334865046
+M13	0.22590680751332318
+M13	0.32637716327548383
+M13	0.5001729304513701
+M13	0.24256234432470714
+M13	0.3046870374931726
+M13	0.23066972204955577
+M13	0.2098224513219232
+M13	0.4675038269689362
+M13	0.30034841897707004
+M13	0.37929154255959746
+M13	0.20288981099032993
+M13	0.3195489764317324
+M13	0.34412614300184174
+M13	0.4006147070883144
+M13	0.38281484163585106
+M13	0.3238427027492125
+M13	0.19768756982632837
+M13	0.332584812412696
+M13	0.4792926056179419
+M13	0.38016168828958646
+M13	0.416555899329418
+M13	0.3868391634437192
+M13	0.32812812252020446
+M13	0.3142030363931806
+M13	0.40140118255809676
+M13	0.2943350615666481
+M13	0.36098132543722294
+M13	0.32198353684954434
+M13	0.3777712784116528
+M13	0.17035814494901436
+M13	0.4436255725489352
+M13	0.40304426688997264
+M13	0.3020313369646479
+M13	0.4542572598543938
+M13	0.387477654593537
+M13	0.38181229932586597
+M13	0.47462559244713554
+M13	0.28358444767434093
+M13	0.28937873473757086
+M13	0.4113356705946231
+M13	0.32889458534947397
+M13	0.21664537169583847
+M13	0.34589990735218284
+M13	0.33625903950677016
+M13	0.4450184145737232
+M13	0.3342330748993504
+M13	0.27055219038414746
+M13	0.29035325898573683
+M13	0.442587506508579
+M13	0.294590277093511
+M13	0.31298447601082535
+M13	0.25856988540455106
+M13	0.42603141831852065
+M13	0.4213462130478231
+M13	0.36363777800732383
+M13	0.36395273794507205
+M13	0.21729113959599633
+M13	0.45809322304727307
+M13	0.46212591298238137
+M13	0.3161627907474575
+M13	0.22743428002175958
+M13	0.22284567499336158
+M13	0.2600122872703078
+M13	0.31622556991665557
+M13	0.20352305051427635
+M13	0.20350386282312116
+M13	0.22213932073913656
+M13	0.26977755440306006
+M13	0.26720411957454815
+M13	0.36336956323250014
+M13	0.2674099193995188
+M13	0.3467051155778361
+M13	0.45514506690134643
+M13	0.5421297409633455
+M13	0.3091393777480495
+M13	0.4649367300869201
+M13	0.2727930920075072
+M13	0.390406143254379
+P01	0.25105219701277176
+P01	0.3731760287432486
+P01	0.35396874281374063
+P01	0.24614763701886763
+P01	0.4208979186429121
+P01	0.2563224085088228
+P01	0.39804144631606014
+P01	0.342729772438143
+P01	0.34027555263331566
+P01	0.34913588777107313
+P01	0.2996963264268632
+P01	0.34139707869818514
+P01	0.33160018499002053
+P01	0.33327489988830467
+P01	0.30134686074029055
+P01	0.4139700850030028
+P01	0.5753746904940104
+P01	0.3273531806772124
+P01	0.4413013933418964
+P01	0.3387716016590725
+P01	0.2931192556146389
+P01	0.3022220764104768
+P01	0.30003335954704546
+P01	0.34415187896963156
+P01	0.29989390566920465
+P01	0.31900399689228104
+P01	0.23347703036978537
+P01	0.2742315774682564
+P01	0.3792848395632444
+P01	0.4386651172762229
+P01	0.3520542630540213
+P01	0.4890964681783579
+P01	0.32781065909610935
+P01	0.22256668178249067
+P01	0.39196471424070994
+P01	0.45940856014244963
+P01	0.26416510443895674
+P01	0.4763186447408344
+P01	0.38700010679349006
+P01	0.3254016274228711
+P01	0.38961887405623863
+P01	0.38424256862339706
+P01	0.6309884608424305
+P01	0.3522025878014956
+P01	0.33716283766537775
+P01	0.3573592979597335
+P01	0.31952204631431175
+P01	0.2800929691788154
+P01	0.30069306121780165
+P01	0.3885773868743226
+P01	0.31030695947019926
+P01	0.3586721636979141
+P01	0.2966816135356434
+P01	0.2941406451053645
+P01	0.3653818914624142
+P01	0.3879096074732568
+P01	0.30510954511231186
+P01	0.3697704862878155
+P01	0.4997273568077155
+P01	0.4090161188729098
+P01	0.30479162033884966
+P01	0.2867665405057399
+P01	0.3157229905416928
+P01	0.2777081872137583
+P01	0.26818269277744095
+P01	0.3473716387820756
+P01	0.3512345542301887
+P01	0.286429928067299
+P01	0.2712409485944612
+P01	0.5611122636636908
+P01	0.3990311670406597
+P01	0.3123526854142391
+P01	0.36505933376321575
+P01	0.385899586667026
+P01	0.4207577965725838
+P01	0.48428429603077505
+P01	0.43003244280243946
+P01	0.25017137264382977
+P01	0.3212123436294096
+P01	0.28693874454799995
+P01	0.3129731290557745
+P01	0.31306422615280044
+P01	0.3045972376573217
+P01	0.2523331593435751
+P01	0.2880612854673108
+P01	0.4267858146338487
+P01	0.31091254057529905
+P01	0.2912681184576645
+P01	0.45751124666688253
+P01	0.33324102039396486
+P01	0.2935142107337996
+P01	0.51365883495951
+P01	0.34751606775764055
+P01	0.4218230019267317
+P01	0.5365059548576026
+P01	0.2892646367844984
+P01	0.5080306493420392
+P01	0.33817459592908344
+P01	0.33306040771141615
+P01	0.2912435855431608
+P01	0.34505208752011646
+P01	0.29776968760135253
+P01	0.26700375971182594
+P01	0.3169556414888369
+P01	0.4095470863832975
+P01	0.30903486319578044
+P01	0.37607536522782065
+P01	0.27564480405394937
+P01	0.22915901223417678
+P01	0.39980841426576114
+P01	0.2550919274958809
+P01	0.4213049088019032
+P01	0.2936428253704326
+P01	0.3004856941851986
+P01	0.3244825750226138
+P01	0.40522913663967863
+P01	0.4469970333527181
+P01	0.3143761646813669
+P01	0.19605961326147367
+P01	0.3925641600629026
+P01	0.3878686675871826
+P01	0.40547157591548316
+P01	0.5129790390477407
+P01	0.3531847481208235
+P01	0.34177762456858496
+P01	0.3551779031117135
+P01	0.3991853769893605
+P01	0.25386714849536307
+P01	0.41633745754670115
+P01	0.4015937606737241
+P01	0.4022637600590555
+P01	0.2166666605187761
+P01	0.4196337753853399
+P01	0.39741162810208863
+P01	0.33658020759850626
+P01	0.4168108092765942
+P01	0.3501262768150227
+P01	0.5139208890998184
+P01	0.4638591691471118
+P01	0.323422776439906
+P01	0.3403769118564617
+P01	0.38680954765848974
+P01	0.31670230196708293
+P01	0.37578898329995597
+P01	0.38930971117542174
+P01	0.31698168411453786
+P01	0.3736375556199111
+P01	0.37225568504148737
+P01	0.272232215941715
+P01	0.287301033150851
+P01	0.4036408618957277
+P01	0.33074640808989786
+P01	0.33843626307198915
+P01	0.2725367875318847
+P01	0.447133456578337
+P01	0.4618383745291599
+P01	0.3693487772206533
+P01	0.38126092232570885
+P01	0.43093927219146594
+P01	0.4098767496385072
+P01	0.43724784196820476
+P01	0.2758273094728163
+P01	0.31538137905822494
+P01	0.29517341619776266
+P01	0.2625541502295622
+P01	0.30779344268905673
+P01	0.28185060515345606
+P01	0.2240255324149891
+P01	0.24418213298352376
+P01	0.2605927265639896
+P01	0.2976082108493593
+P01	0.2687218809236972
+P01	0.4299918576707297
+P01	0.3375429070798391
+P01	0.3692874181599207
+P01	0.5519354905524984
+P01	0.26766896337400026
+P01	0.4062615902095982
+P01	0.2891821838913971
+P01	0.39544328736448053
+P01	0.6601719470912428
+P01	0.5647731152506436
+P01	0.6510005022086648
+P01	0.6265989252657381
+P01	0.7001524087429136
+P01	0.6263742180116694
+P01	0.5612170524769471
+P01	0.6039933944406785
+P01	0.6076617768638909
+P01	0.546481556189276
+P01	0.5734090482136233
+P01	0.5837011941627531
+P01	0.5557494775525844
+P01	0.6044939779134922
+P01	0.6042340001941033
+P01	0.59879656565433
+P01	0.6802623085562793
+P01	0.6477470247344779
+P01	0.6169747722949422
+P01	0.6397523388668546
+P01	0.5791503585592709
+P01	0.46453530390094855
+P01	0.5626140917483285
+P01	0.5774665676381603
+P01	0.6189316814384475
+P01	0.5438428229814447
+P01	0.5815138286412261
+P01	0.5933251407066134
+P01	0.6521630938909879
+P01	0.6791803803147652
+P01	0.5265308317362853
+P01	0.6185833448925557
+P01	0.671478471159737
+P01	0.5863949076096189
+P01	0.5933524786409838
+P01	0.5862241762196214
+P01	0.6878031808827235
+P01	0.6423982176214922
+P01	0.5757247300901086
+P01	0.5394439176314851
+P01	0.6324726462413534
+P01	0.6447533554731011
+P01	0.5228874579696909
+P01	0.6293652623877256
+P01	0.39969698206404713
+P01	0.6342082998546142
+P01	0.5596487665805843
+P01	0.5883069682456755
+P01	0.6203398859803203
+P01	0.583367276861045
+P01	0.5090143731353975
+P01	0.6608886623627415
+P01	0.5261159210945359
+P01	0.6136475359479014
+P01	0.6133046006714098
+P01	0.5407769669009586
+P01	0.6085277746597496
+P01	0.6021261529721804
+P01	0.6591071868689309
+P01	0.7251763102113586
+P01	0.6419350253567032
+P01	0.569251590836578
+P01	0.573403605612664
+P01	0.6270810367634368
+P01	0.6542249847834528
+P01	0.5692718675544339
+P01	0.5825631510237043
+P01	0.44958183243851
+P01	0.7009064916554747
+P01	0.6209509178950288
+P01	0.6044104949751604
+P01	0.45372963396326665
+P01	0.5539854386679424
+P01	0.5450032489848048
+P01	0.6039138454936592
+P01	0.6144695844393495
+P01	0.48284991410559647
+P01	0.6546936784271681
+P01	0.546216324767738
+P01	0.6630836014607921
+P01	0.6198444392113844
+P01	0.6888051612358519
+P01	0.7201213844880752
+P01	0.3816916071589175
+P01	0.5959334330418502
+P01	0.5341487275758103
+P01	0.6574636246213179
+P01	0.5886254239708243
+P01	0.47804312100198393
+P01	0.664989376837645
+P01	0.5792481791810915
+P01	0.6388992416527675
+P01	0.6642277375888371
+P01	0.6463317456542723
+P01	0.6290590026897867
+P01	0.43791550461395123
+P01	0.5945858017993426
+P01	0.6126716450984749
+P01	0.5972935946725172
+P01	0.647831552050427
+P01	0.5742921036085679
+P01	0.6224284588584165
+P01	0.5899125563007105
+P01	0.5613388280427624
+P01	0.6156184974946933
+P01	0.6316540072743304
+P01	0.6234322656763102
+P01	0.637097074800719
+P01	0.5331614443771727
+P01	0.627150915922206
+P01	0.5883643763481445
+P01	0.7029279303768848
+P01	0.6866504368712988
+P01	0.5394164900698155
+P01	0.5127668098373228
+P01	0.6256776628053166
+P01	0.6629538401047007
+P01	0.640748261283038
+P01	0.45403796277855263
+P01	0.5988061425642196
+P01	0.4547709569829914
+P01	0.6158552253995923
+P01	0.5760979070449688
+P01	0.517318358117003
+P01	0.6698497645691852
+P01	0.7102901960916801
+P01	0.5879994673206711
+P01	0.6290836917174716
+P01	0.4800252118740859
+P01	0.6334636811061733
+P01	0.4970238265902228
+P01	0.5794301592704499
+P01	0.6486006459194952
+P01	0.545163735856519
+P01	0.5983453894377526
+P01	0.5329700099694985
+P01	0.6322018659842206
+P01	0.628508170527111
+P01	0.6563573053316185
+P01	0.40305220704469336
+P01	0.5891836471056869
+P01	0.6779425047204564
+P01	0.6610115031446628
+P01	0.6210128437462494
+P01	0.6177363798759816
+P01	0.5046940758695685
+P01	0.5533217485587438
+P01	0.6541326110675653
+P01	0.40324145421305263
+P01	0.6513326347915378
+P01	0.5538104462677702
+P01	0.590924733745761
+P01	0.5214591999730418
+P01	0.563279226109945
+P01	0.47718630965777276
+P01	0.526498694291153
+P01	0.5645975436530233
+P01	0.6261590316009049
+P01	0.6053647081063762
+P01	0.6450059670781203
+P01	0.4976918374448445
+P01	0.5423983452337456
+P01	0.6713845177094553
+P01	0.6142141781554813
+P01	0.6442815459292675
+P01	0.6052669502070616
+P01	0.5634564822685603
+P01	0.5793062571085899
+P01	0.5718297143452744
+P01	0.6043307809605297
+P01	0.5458832072093592
+P01	0.6833772799772336
+P01	0.6158757360159144
+P01	0.5793361647361374
+P01	0.49778973276480626
+P01	0.5608574769480135
+P01	0.6206894725707881
+P01	0.6226703504158349
+P01	0.4637348784051873
+P01	0.48864984535525685
+P01	0.6800093909097279
+P01	0.6033527761550321
+P01	0.5825028308809144
+P01	0.6373532318430629
+P01	0.6577236896480282
+P01	0.6461943029853233
+P01	0.6771194305305143
+P01	0.5879831518883747
+P01	0.679819776637162
+P01	0.6210200786498691
+P01	0.5653568131014013
+P01	0.5281380169091202
+P01	0.5396252581524384
+P01	0.596884324266289
+P01	0.610899469254364
+P01	0.41695378379771514
+P01	0.638040364568222
+P01	0.5957906087226303
+P01	0.6742562496080101
+P01	0.6234105330348794
+P01	0.6228608773622191
+P01	0.6333065096118679
+P01	0.6076917864596789
+P01	0.5644834895702058
+P01	0.6092652157433561
+P01	0.6360808627896722
+P01	0.47632859759553026
+P01	0.563187536643553
+P01	0.40058422705256785
+P01	0.7314165474637495
+P01	0.6137385447988134
+P01	0.6404768216330083
+P01	0.575696714218079
+P01	0.6402765681199956
+P01	0.5981797586191232
+P01	0.5760045017478648
+P01	0.5374548595191481
+P01	0.6980146490629333
+P01	0.7011465649737774
+P01	0.6604683074204943
+P01	0.5005954319506893
+P01	0.5842937480414063
+P01	0.5839660162564405
+P01	0.6595340682802342
+P01	0.6337216043078135
+P01	0.5954154598727825
+P01	0.5504838958134348
+P01	0.5840160962951694
+P01	0.5633105479752125
+P01	0.43978901787403085
+P01	0.5882747978695545
+P01	0.6143299834008829
+P01	0.5615536739293685
+P01	0.5926298570871767
+P01	0.5935855447697804
+P01	0.6257548555760265
+P01	0.43313093766455957
+P01	0.7103494805563406
+P01	0.5532497130864673
+P01	0.606862348609859
+P01	0.5977413776829099
+P01	0.5053672334539229
+P01	0.5602271778907207
+P01	0.5488571814611278
+P01	0.5479836607656977
+P01	0.6739623827824545
+P01	0.6197450203230133
+P01	0.579141663399538
+P01	0.5910507171046864
+P01	0.6098551096409692
+P01	0.41033786184708454
+P01	0.49250608098697435
+P01	0.5361741158232411
+P01	0.6847949473905086
+P01	0.6189114117326021
+P01	0.5708194854857829
+P01	0.44117968133034186
+P01	0.6044270696258165
+P01	0.4846553316730948
+P01	0.5723047143232605
+P01	0.5911545143901903
+P01	0.4732089074966045
+P01	0.6756446439541656
+P01	0.6753307270932787
+P01	0.6257954989842677
+P01	0.477115416636084
+P01	0.6494273300407383
+P01	0.5792699314610071
+P01	0.5968891981535916
+P01	0.6233074522235823
+P01	0.5661164808877625
+P01	0.5580980968301176
+P01	0.619810771493437
+P01	0.6625508371113121
+P01	0.5872268592733081
+P01	0.6410081290219065
+P01	0.49810399640533887
+P01	0.5935705374504675
+P01	0.6400170640285816
+P01	0.6753855551965618
+P01	0.5807035919812554
+P01	0.7356213765384659
+P01	0.5614143320204065
+P01	0.6351228118515383
+P01	0.3952543382094402
+P01	0.4598281622401461
+P01	0.5870765628549488
+P01	0.39025360898570255
+P01	0.6351205951482951
+P01	0.5771508757611675
+P01	0.5302461180664118
+P01	0.5079949575997988
+P01	0.6407858881369141
+P01	0.6118523568356025
+P01	0.49350183163880373
+P01	0.5662356653057806
+P01	0.40608172516768754
+P01	0.6511663043204804
+P01	0.5396120130177857
+P01	0.4212105854021708
+P01	0.5760124166373158
+P01	0.5701602861881271
+P01	0.5937791883007311
+P01	0.48747511560076673
+P01	0.5696196915452048
+P01	0.6308386493918874
+P01	0.5968237362221519
+P01	0.5369396370085437
+P01	0.6089569617858882
+P01	0.516165354954607
+P01	0.5204790141008331
+P01	0.5370338958858161
+P01	0.6017767454467516
+P01	0.6333174832622919
+P01	0.5798713991628456
+P01	0.5396105268728467
+P01	0.5734608367097788
+P01	0.550970087186307
+P01	0.5691810121050436
+P01	0.5773910865906325
+P01	0.6175006391573493
+P01	0.569879978628378
+P01	0.6179555002605871
+P01	0.5995535004410086
+P01	0.5777452295190778
+P01	0.5831964224489884
+P01	0.5843847726424894
+P01	0.5715883645066351
+P01	0.4922649892033769
+P01	0.6188593730790432
+P01	0.3076294397906161
+P01	0.2297462385689643
+P01	0.4676727975143541
+P01	0.6740989112529642
+P01	0.6018409249007575
+P01	0.6286576673707683
+P01	0.5299855014898981
+P01	0.6082224846980528
+P01	0.5704774234124601
+P01	0.4693238019983192
+P01	0.5531747747549371
+P01	0.6596429667711445
+P01	0.6260473722984058
+P01	0.5193657628669237
+P01	0.636676779621188
+P01	0.5442313536987595
+P01	0.5871189996728897
+P01	0.6108206993375671
+P01	0.4350740294489798
+P01	0.6055245620123413
+P01	0.5111717415594563
+P01	0.47895766653676175
+P01	0.5030943982930811
+P01	0.5704002186214377
+P01	0.5425720495898357
+P01	0.5566725738497299
+P01	0.5588212796745003
+P01	0.5699651009348168
+P01	0.6169257637501242
+P01	0.4958201384537383
+P01	0.6112414484666769
+P01	0.537174856856538
+P01	0.6084752737117329
+P01	0.4846081930182863
+P01	0.6525614816225372
+P01	0.6463969727471053
+P01	0.6333907283967557
+P01	0.6125762667879847
+P01	0.554044825417564
+P01	0.697478719593601
+P01	0.568263069515125
+P01	0.5702122842312238
+P01	0.5626033693211666
+P01	0.6137872170316933
+P01	0.5903266721798772
+P01	0.559574602202537
+P01	0.6483075736806041
+P01	0.6218836669702473
+P01	0.5878726166575408
+P01	0.544475044672459
+P01	0.49529034626761703
+P01	0.6517181349839692
+P01	0.6319495723704291
+P01	0.6458786246647563
+P01	0.5880097205397605
+P01	0.6060447619958356
+P01	0.6908234010401944
+P01	0.660218761286703
+P01	0.6006312928184402
+P01	0.5081178664182517
+P01	0.6057382206906042
+P01	0.6018649395925778
+P01	0.49493550679278736
+P01	0.6224033810360936
+P01	0.7073226483539122
+P01	0.548711244038992
+P01	0.5121933562274584
+P01	0.6457584150179625
+P01	0.6670150558930712
+P01	0.37314788247325065
+P01	0.40545391811178905
+P01	0.51081220634402
+P01	0.5544479377296625
+P01	0.6522623263895007
+P01	0.6278584762010864
+P01	0.6146640298125697
+P01	0.5917292793302854
+P01	0.5987600543579836
+P01	0.6960229149761056
+P01	0.40887388431101035
+P01	0.5434755093778464
+P01	0.5238022899660315
+P01	0.5815821965061834
+P01	0.6143526369710863
+P01	0.4726335057746732
+P01	0.6144171008252083
+P01	0.6475143332437214
+P01	0.5706096296451313
+P01	0.5856033129094609
+P01	0.660990072070924
+P01	0.4319173340826772
+P01	0.491671052510089
+P01	0.49902608240365925
+P01	0.5145461689696856
+P01	0.6850153031239932
+P01	0.7192510880787144
+P01	0.6289021383814327
+P01	0.5896307099393084
+P01	0.5006834143525395
+P01	0.6054982021408526
+P01	0.7135575567148024
+P01	0.6320870320099009
+P01	0.5534510282755336
+P01	0.5706976953425579
+P01	0.6104664836304379
+P01	0.5859903046457289
+P01	0.6502590378532834
+P01	0.6386204727973878
+P01	0.6498514482325528
+P01	0.6396186647481577
+P01	0.5555166606001097
+P01	0.5294266995103865
+P01	0.6111892205762864
+P01	0.5689261921083199
+P01	0.6665337827100005
+P01	0.4913411094629861
+P01	0.6081108680020273
+P01	0.5755224396484513
+P01	0.5546608427703806
+P01	0.4446998918281129
+P01	0.5552050263149793
+P01	0.36847008976913465
+P01	0.5875289204050149
+P01	0.6467291694144272
+P01	0.5361404758737196
+P01	0.6325411165746097
+P01	0.7523348880607895
+P01	0.6088271497970139
+P01	0.636223875857533
+P01	0.5561660900176898
+P01	0.5666210844202502
+P01	0.6878142907603602
+P01	0.5076833559298017
+P01	0.6570281361650029
+P01	0.43809804856074586
+P01	0.5094140079100956
+P01	0.6190978857796171
+P01	0.321627915236842
+P01	0.6006124319304642
+P01	0.6012784818591772
+P01	0.539606191607012
+P01	0.556478929049308
+P01	0.6355947812796027
+P01	0.5977771247931338
+P01	0.3907094710013061
+P01	0.5424508406749381
+P01	0.5534688110555656
+P01	0.6742645755718963
+P01	0.7117687507384305
+P01	0.47736598960025783
+P01	0.5023346065610534
+P01	0.5843094331685712
+P01	0.6590013765902464
+P01	0.7154953435462099
+P01	0.6780981461164393
+P01	0.6473215238670338
+P01	0.5136698750048049
+P01	0.5265279280073796
+P01	0.5953315265533033
+P01	0.636970183945484
+P01	0.6704343543642238
+P01	0.6036505847010885
+P01	0.5146835273911107
+P01	0.5759875078867176
+P01	0.644302630911966
+P01	0.6202381473874791
+P01	0.4041081751755117
+P01	0.42348871137914185
+P01	0.4587543796338395
+P01	0.36289337809123023
+P01	0.3863411516991247
+P01	0.4779984343267111
+P01	0.5822307234337871
+P01	0.46710403022104474
+P01	0.4751990181220927
+P01	0.5897093596122057
+P01	0.5648667341886234
+P01	0.47594477563848797
+P01	0.6739831651956288
+P01	0.6637821088602907
+P01	0.5581656208862054
+P01	0.562222230015385
+P01	0.6792761246420979
+P01	0.6005027908500167
+P01	0.7018577008675756
+P01	0.5298148898705463
+P01	0.4418067874070642
+P01	0.6228623827037338
+P01	0.6215706113901118
+P01	0.5677701776592319
+P01	0.6420705838345334
+P01	0.4923127720068693
+P01	0.48426072881222776
+P01	0.6575389890730622
+P01	0.6376751739688942
+P01	0.610181814190906
+P01	0.663679149346272
+P01	0.5183922410897757
+P01	0.6828478408889153
+P01	0.6752937775847276
+P01	0.5646672894673433
+P01	0.6042757248396049
+P01	0.35386117377898385
+P01	0.5294584893016429
+P01	0.47635264218645096
+P01	0.6300049212976493
+P01	0.6808987827227024
+P01	0.6677058629407869
+P01	0.6669059027565025
+P01	0.5609760647011446
+P01	0.4933423944716599
+P01	0.5009066675975589
+P01	0.5074963676609636
+P01	0.6062648745950768
+P01	0.5082936362381825
+P01	0.4349300229876559
+P01	0.5932900783427643
+P01	0.47655912168760295
+P01	0.4659691721985616
+P01	0.5416101459586583
+P01	0.49387410873585275
+P01	0.5714380852207288
+P01	0.42318622369792797
+P01	0.7184015343928589
+P01	0.4374013395136424
+P01	0.6101292726861719
+P01	0.5795233696683934
+P01	0.548833102054793
+P01	0.5131882507679624
+P01	0.5492382760441367
+P01	0.5975873445707702
+P01	0.4594886056046263
+P01	0.6254491958539097
+P01	0.5866800186924277
+P01	0.6030117746506722
+P01	0.5372229346089213
+P01	0.5193553398270615
+P01	0.411709429831858
+P01	0.6686130525548926
+P01	0.5461638131197285
+P01	0.6222990689817703
+P01	0.6340429813932352
+P01	0.528748223498568
+P01	0.46673248937038475
+P01	0.5641724357676635
+P01	0.5299544208814257
+P01	0.62220295566492
+P01	0.5744524518582665
+P01	0.5548110914291831
+P01	0.5125442207799523
+P01	0.4789213480668698
+P01	0.6571461007695556
+P01	0.38918417096337266
+P01	0.4562366890263343
+P01	0.41658549430873654
+P01	0.3949618276614367
+P01	0.48748424575659977
+P01	0.41303839190590147
+P01	0.6535060760093558
+P01	0.4867983327343679
+P01	0.6318906834927074
+P01	0.658571113118646
+P01	0.5908367397004385
+P01	0.5402187712488629
+P01	0.48010553252414895
+P01	0.45471891172756235
+P01	0.5480693921610975
+P01	0.5413265649915593
+P01	0.6000458822161698
+P01	0.6511010376092915
+P01	0.7282287428945123
+P01	0.660272702185567
+P01	0.6750731191637596
+P01	0.6079094224553302
+P01	0.6166702724546739
+P01	0.515122228834549
+P01	0.566567871081954
+P01	0.5704297656373589
+P01	0.5173579652236253
+P01	0.4381737387184256
+P01	0.6910183724974583
+P01	0.5507942832239545
+P01	0.320722612040568
+P01	0.3232018032194244
+P01	0.5388903128009883
+P01	0.41490950347269673
+P01	0.4807045671253887
+P01	0.6021143391791741
+P01	0.6615379957537165
+P01	0.579943478973324
+P01	0.6342417983608963
+P01	0.6005132211462098
+P01	0.5790361770004991
+P01	0.514131993573404
+P01	0.6181038774163401
+P01	0.5936873759276573
+P01	0.5530197000276883
+M05	0.12437105039030232
+M05	0.3713968603299406
+M05	0.34146178482578804
+M05	0.21805194373037176
+M05	0.40328747672207804
+M05	0.2463454284026971
+M05	0.4000260623324485
+M05	0.36996154172496826
+M05	0.32823964136970135
+M05	0.3200373738859929
+M05	0.27024759180441693
+M05	0.35432703162054474
+M05	0.3687157308101388
+M05	0.38234899078870493
+M05	0.2472450231467731
+M05	0.34326895279929154
+M05	0.5756691263493664
+M05	0.40134690331518597
+M05	0.49374167018508036
+M05	0.3899581923208109
+M05	0.25354902520118944
+M05	0.37312316224186887
+M05	0.28217537948647237
+M05	0.3442144240073885
+M05	0.3016809838191968
+M05	0.42411567053298715
+M05	0.14167838493611318
+M05	0.2903587381805263
+M05	0.49294064146470745
+M05	0.39451265827327087
+M05	0.3988532992607498
+M05	0.49778458929224406
+M05	0.25406740737360956
+M05	0.23518291322833598
+M05	0.39153773250412116
+M05	0.47267299061568196
+M05	0.22250259884963486
+M05	0.44263701143645395
+M05	0.35869751392210075
+M05	0.42431580942638036
+M05	0.391051258848816
+M05	0.44276065946337073
+M05	0.597086760822846
+M05	0.35639059120180955
+M05	0.3464820704179877
+M05	0.3624931489633015
+M05	0.2664930227639297
+M05	0.28347855331039234
+M05	0.30023530880586224
+M05	0.4368987601893091
+M05	0.19376134779039597
+M05	0.3788024159025251
+M05	0.30652602958287245
+M05	0.2749302848664608
+M05	0.28385118407851445
+M05	0.4420060634938988
+M05	0.28885350416336214
+M05	0.3423066146580849
+M05	0.49971918499096607
+M05	0.32599826802574905
+M05	0.22757166044358737
+M05	0.21813141891035906
+M05	0.3345701344827709
+M05	0.35541865059999406
+M05	0.270971114960686
+M05	0.27025475792739784
+M05	0.34851303189697913
+M05	0.27387852815460423
+M05	0.2768398697097442
+M05	0.5702347725719864
+M05	0.4314610265957999
+M05	0.3015211791056406
+M05	0.4118679310822599
+M05	0.3846662157792497
+M05	0.33948217438805695
+M05	0.5036437392024743
+M05	0.43060561986763246
+M05	0.2756810704120543
+M05	0.3036426429554448
+M05	0.21579116328047504
+M05	0.32470998210001434
+M05	0.3012717243672842
+M05	0.2762440895555053
+M05	0.16447257166243343
+M05	0.25115067653912854
+M05	0.3826339972002254
+M05	0.3603373166414731
+M05	0.20789317142784788
+M05	0.4423327973792476
+M05	0.3596631480283729
+M05	0.1854046333172662
+M05	0.5451862302363394
+M05	0.39256641952656385
+M05	0.3500913094273406
+M05	0.5277703900217023
+M05	0.3045785228152397
+M05	0.5375354355292584
+M05	0.3781292658982921
+M05	0.2616765458339711
+M05	0.4312276981790385
+M05	0.3089002026919814
+M05	0.2598849212092998
+M05	0.22016472678088173
+M05	0.19083969644840676
+M05	0.4276539005604374
+M05	0.34513086182121117
+M05	0.38212959789284234
+M05	0.2547456929190882
+M05	0.24014361161866613
+M05	0.46073244337810887
+M05	0.3202247364792987
+M05	0.35848293183179164
+M05	0.2351468942719298
+M05	0.3524432025992692
+M05	0.34057934429234327
+M05	0.4257359998587213
+M05	0.3910134712055609
+M05	0.35703383318598403
+M05	0.2160352664721442
+M05	0.31675547421028194
+M05	0.47868438025624516
+M05	0.4187881161505707
+M05	0.5626735929068931
+M05	0.3435520999689808
+M05	0.3087255171474393
+M05	0.263889904767294
+M05	0.28666016502899405
+M05	0.253709515014595
+M05	0.45772497304679327
+M05	0.3721466823344431
+M05	0.3165666098775275
+M05	0.17152532215976612
+M05	0.3845977762836517
+M05	0.3600147629588509
+M05	0.33521101052624197
+M05	0.3546611704287122
+M05	0.36114145924281094
+M05	0.5042266686909894
+M05	0.5068160122088206
+M05	0.29967145416463575
+M05	0.3521223655742513
+M05	0.4199234282767006
+M05	0.31455909424447387
+M05	0.3948223625925589
+M05	0.3665252283111955
+M05	0.29156423806758747
+M05	0.3793422198808042
+M05	0.3856490889151811
+M05	0.20253137041861013
+M05	0.21178240019462655
+M05	0.3993496710357751
+M05	0.29873050584568284
+M05	0.3318154653400915
+M05	0.18712800528229992
+M05	0.4336135159865458
+M05	0.4218693854350871
+M05	0.40662910687338444
+M05	0.362228950292385
+M05	0.3206546776286491
+M05	0.31285252372966604
+M05	0.4862982106486561
+M05	0.28926776561305295
+M05	0.3454502129144921
+M05	0.2609122357599443
+M05	0.23780930420598242
+M05	0.30911394941635423
+M05	0.28710677750194663
+M05	0.17122929557859545
+M05	0.12504248355860628
+M05	0.2927117975635105
+M05	0.3063121271680999
+M05	0.38906504907732514
+M05	0.36885983526505806
+M05	0.34866916865450254
+M05	0.4507491356472665
+M05	0.5339306236592423
+M05	0.29637170479655
+M05	0.44985055764116266
+M05	0.26711347810327557
+M05	0.4115524925170839
+M08	0.2024057268338106
+M08	0.3441924190229762
+M08	0.38962034667819145
+M08	0.1958059116553032
+M08	0.4427492314435855
+M08	0.3155359588693787
+M08	0.4311988604056919
+M08	0.4273608151935077
+M08	0.38304541403721687
+M08	0.35662217506099975
+M08	0.30279514032792715
+M08	0.3714426511643578
+M08	0.3767519303136164
+M08	0.25937093523337257
+M08	0.3383633843202722
+M08	0.37724649833779894
+M08	0.5875969262284123
+M08	0.40965679144478384
+M08	0.5480595901339691
+M08	0.39892311096190264
+M08	0.30855077371448325
+M08	0.3790374863383777
+M08	0.32384932795034355
+M08	0.3736112117130564
+M08	0.293399119973384
+M08	0.39434271880143684
+M08	0.23312292672481244
+M08	0.2719315826448931
+M08	0.43305350675257015
+M08	0.4465740175047285
+M08	0.4036386475752638
+M08	0.5178115586800535
+M08	0.3428621946706455
+M08	0.24968968183361454
+M08	0.37936236318820077
+M08	0.4758365151582697
+M08	0.25213042704717104
+M08	0.4891078787288122
+M08	0.324696042569088
+M08	0.4239860165643779
+M08	0.44718037961315243
+M08	0.463842715671812
+M08	0.7067006420201661
+M08	0.3747645378353649
+M08	0.3021934235256673
+M08	0.33403198783033966
+M08	0.34325501246015755
+M08	0.26677813429530833
+M08	0.27400079554778034
+M08	0.4766211963925701
+M08	0.2808535365896357
+M08	0.3898572989526565
+M08	0.3405382734752402
+M08	0.33492677635403323
+M08	0.19630560305209147
+M08	0.4432983401408453
+M08	0.3235868547663888
+M08	0.19553719797260158
+M08	0.5396245862752974
+M08	0.33358829155930764
+M08	0.3195105060053186
+M08	0.2967649905467577
+M08	0.41959720903036407
+M08	0.34827774855834914
+M08	0.2985433156582106
+M08	0.3181223390877426
+M08	0.33246155602354877
+M08	0.3265741870682948
+M08	0.23615582544845135
+M08	0.5867937608259357
+M08	0.46856955435636855
+M08	0.3002938779881158
+M08	0.38048916111978537
+M08	0.4099734709066085
+M08	0.43573913704364053
+M08	0.5107394777516097
+M08	0.4463473212765833
+M08	0.3121332420588117
+M08	0.4146774903495448
+M08	0.2698713573868294
+M08	0.3364130258619847
+M08	0.3048703693104418
+M08	0.2980952416974927
+M08	0.29530413058384514
+M08	0.23926265417744833
+M08	0.4549873581635165
+M08	0.3741064030939587
+M08	0.3166964413468684
+M08	0.4531905768286461
+M08	0.3741760271829474
+M08	0.355349796042545
+M08	0.5713789569162003
+M08	0.3877952890830251
+M08	0.3654376282072817
+M08	0.5546673626241824
+M08	0.2937998953676942
+M08	0.4967366250498425
+M08	0.37553717327208175
+M08	0.3369773903354285
+M08	0.2985945276908842
+M08	0.27397606820870346
+M08	0.2911226387629664
+M08	0.18849806628426435
+M08	0.31537792096164546
+M08	0.5457329909728745
+M08	0.2678084068846512
+M08	0.38850464399095913
+M08	0.26679962893631365
+M08	0.2565177070757927
+M08	0.5107314282321077
+M08	0.3348333173534065
+M08	0.37094173009547154
+M08	0.29372773058463386
+M08	0.3873880602715438
+M08	0.3296803796461837
+M08	0.36701291545579157
+M08	0.44565289544240905
+M08	0.3765972271787647
+M08	0.15586177091221712
+M08	0.39856089385472937
+M08	0.529448875094499
+M08	0.41551412945864385
+M08	0.48844168123067216
+M08	0.3722736838334668
+M08	0.3598836434492628
+M08	0.32653088909213646
+M08	0.40348368716925753
+M08	0.2982529877686199
+M08	0.42131538116200734
+M08	0.37758298851461913
+M08	0.43808234366962157
+M08	0.2311841906148159
+M08	0.3568130595305432
+M08	0.4166476796546445
+M08	0.27114320376644807
+M08	0.45447355807588485
+M08	0.3540113417253259
+M08	0.5474550306773498
+M08	0.5354202013768471
+M08	0.32097676227976407
+M08	0.31056235057694614
+M08	0.4328513709892141
+M08	0.359290950849763
+M08	0.29093949847356015
+M08	0.3359657147534832
+M08	0.31303629237194364
+M08	0.4618838674357844
+M08	0.4117802658222774
+M08	0.22492602695674985
+M08	0.31797392811885117
+M08	0.3052280290278862
+M08	0.35377036827273656
+M08	0.41317869165293797
+M08	0.2812843154870618
+M08	0.4482405464368827
+M08	0.42852238695110634
+M08	0.44355128395849835
+M08	0.36626913209602424
+M08	0.4667214106533094
+M08	0.34442260228344906
+M08	0.47164835582204373
+M08	0.27369981773023716
+M08	0.3542598843325294
+M08	0.29999763368322563
+M08	0.29428924501008785
+M08	0.39181971061224863
+M08	0.2988235934731251
+M08	0.1962968988733985
+M08	0.2645530614399597
+M08	0.2931301785224546
+M08	0.3565830205951734
+M08	0.3821128779690078
+M08	0.36334309134794235
+M08	0.32080350890622433
+M08	0.40232588288143456
+M08	0.5898282153695802
+M08	0.2222409362644549
+M08	0.45931406965716537
+M08	0.3138876856207284
+M08	0.3208440731642957
+M08	0.6782822768863259
+M08	0.490908969786216
+M08	0.6631832515624849
+M08	0.6412879089527198
+M08	0.6863672542613903
+M08	0.6808442785250405
+M08	0.5788124403766066
+M08	0.6405838832611406
+M08	0.5622763887257106
+M08	0.41416771160724214
+M08	0.605975369146987
+M08	0.5910339580345861
+M08	0.508204340382441
+M08	0.5012338809901323
+M08	0.46627684728844526
+M08	0.6277803873181829
+M08	0.5591293437575552
+M08	0.6720912464102683
+M08	0.632716771890748
+M08	0.5440439133976711
+M08	0.6685737570964132
+M08	0.43541639648127506
+M08	0.5295451755491312
+M08	0.39714687515409325
+M08	0.6391131626027178
+M08	0.6443964989694211
+M08	0.45162382591380357
+M08	0.6010445666423088
+M08	0.531686473832323
+M08	0.661585151706791
+M08	0.5571224587556126
+M08	0.5731746470081462
+M08	0.6591080735813947
+M08	0.4107241485757666
+M08	0.4821084195868006
+M08	0.6212544731733557
+M08	0.6974534117751809
+M08	0.6003937741139007
+M08	0.5992995151055163
+M08	0.6047838197987129
+M08	0.6321179230591801
+M08	0.6751981210465907
+M08	0.5197348934826674
+M08	0.5376752880993948
+M08	0.6526141335491994
+M08	0.6251512820117979
+M08	0.5774481956028763
+M08	0.6105827597789881
+M08	0.6625467597702038
+M08	0.6139921195743248
+M08	0.5767560053270537
+M08	0.5978462472654239
+M08	0.678737934031422
+M08	0.6306394343640213
+M08	0.39040131941962275
+M08	0.5566785247027998
+M08	0.6428749561195539
+M08	0.603492597584479
+M08	0.6563241570648788
+M08	0.641295877494566
+M08	0.6927479010473623
+M08	0.5969531095296593
+M08	0.5913790330978146
+M08	0.5774608846272021
+M08	0.6569207938869909
+M08	0.6011989095023966
+M08	0.5936687864324889
+M08	0.6192027336482683
+M08	0.43467835005083155
+M08	0.6442087330463426
+M08	0.5954004336049512
+M08	0.22528757262089363
+M08	0.6431619298277945
+M08	0.6046455980540882
+M08	0.5400718676313426
+M08	0.6491859164038322
+M08	0.5387388515924418
+M08	0.6628484071891022
+M08	0.33973175981117737
+M08	0.6766387982937895
+M08	0.6234703500046258
+M08	0.6414183410480793
+M08	0.7037687347698718
+M08	0.6276161710282278
+M08	0.7092917699228951
+M08	0.4692520024101358
+M08	0.43493003754382537
+M08	0.6418205058056328
+M08	0.5784587403698945
+M08	0.6792662823564826
+M08	0.6059333690780068
+M08	0.682919578976283
+M08	0.6783481360148962
+M08	0.5608061255190729
+M08	0.3806965207810177
+M08	0.199990689985694
+M08	0.556609292016561
+M08	0.36876371835676786
+M08	0.4919328738624835
+M08	0.6455341747069254
+M08	0.5363109901581918
+M08	0.6619673285957067
+M08	0.593260576277707
+M08	0.5204788224541296
+M08	0.6897822040811378
+M08	0.7140068277713849
+M08	0.5346203971487639
+M08	0.6002612942029938
+M08	0.5935309928744557
+M08	0.6185517532631013
+M08	0.5819319380272585
+M08	0.5837906251139707
+M08	0.647286491061691
+M08	0.5705536698482149
+M08	0.6157179515777291
+M08	0.5702266073708347
+M08	0.6756377861513283
+M08	0.679751813037546
+M08	0.5653891167521186
+M08	0.5155185798840398
+M08	0.6468181994650123
+M08	0.5944788148261232
+M08	0.48723448760982613
+M08	0.641477515347083
+M08	0.6804027307354246
+M08	0.6530623333735168
+M08	0.5725220146668826
+M08	0.6403774655603968
+M08	0.6689080110665274
+M08	0.5820020055976375
+M08	0.6107021613680556
+M08	0.4648384252837202
+M08	0.6746841291727084
+M08	0.5567102138958868
+M08	0.6547370996122767
+M08	0.5751680338373154
+M08	0.6519530426286582
+M08	0.6694545389508414
+M08	0.7150153713124461
+M08	0.5415005338784089
+M08	0.4148762695917165
+M08	0.6153802630787956
+M08	0.6009637498352344
+M08	0.5480375363748422
+M08	0.693636887405821
+M08	0.532592340809089
+M08	0.6786020261001047
+M08	0.46514648795763924
+M08	0.6738455100659141
+M08	0.6508918743066902
+M08	0.6758166526593435
+M08	0.6867481765021974
+M08	0.6547138458498596
+M08	0.523691812597478
+M08	0.6144290043870569
+M08	0.6049093481597944
+M08	0.6348669112797363
+M08	0.6231767785207071
+M08	0.6192962359997416
+M08	0.7258045873879824
+M08	0.4817281275133185
+M08	0.47465823195950657
+M08	0.6472753372243732
+M08	0.5870099940108353
+M08	0.6898201023674968
+M08	0.6544749988949041
+M08	0.5471480764799848
+M08	0.5391800973320078
+M08	0.6669665064005297
+M08	0.5184140550947833
+M08	0.5908908400627642
+M08	0.6024609807547542
+M08	0.6544981019067347
+M08	0.6790626138991146
+M08	0.5656114697331452
+M08	0.3797501281777845
+M08	0.6667475927032223
+M08	0.6002181973374925
+M08	0.4494031551183409
+M08	0.36571475443387275
+M08	0.6506409922053388
+M08	0.6886681790834523
+M08	0.6055992433647401
+M08	0.5058557607043812
+M08	0.5769757543801289
+M08	0.6507102238388907
+M08	0.7310396844596938
+M08	0.5351312890415706
+M08	0.7199021265464488
+M08	0.6594998542571269
+M08	0.6404858681980092
+M08	0.5909915803699073
+M08	0.6165066811865075
+M08	0.6206729524706647
+M08	0.4647749866983587
+M08	0.5179321785131509
+M08	0.6750869315969309
+M08	0.5512652203571891
+M08	0.5921586773320767
+M08	0.6481226360109317
+M08	0.5573377001189481
+M08	0.570925134348758
+M08	0.4965972197983562
+M08	0.5381715500902914
+M08	0.597880951441604
+M08	0.5171165326985097
+M08	0.29994348162636353
+M08	0.5262486555465142
+M08	0.5044274675520231
+M08	0.7204429354103419
+M08	0.6135006253192293
+M08	0.7128778452322199
+M08	0.6822996734485051
+M08	0.6263099072709333
+M08	0.5597189021580645
+M08	0.46276208089725435
+M08	0.6620601627318291
+M08	0.6557463233178229
+M08	0.7153994188977494
+M08	0.6097070270524368
+M08	0.6629544609977454
+M08	0.47644668194353107
+M08	0.30987933393250466
+M08	0.5224365465536758
+M08	0.6743543202901079
+M08	0.5808822374077564
+M08	0.4429342352437822
+M08	0.574703281333497
+M08	0.49451030960830356
+M08	0.5387878241634072
+M08	0.549654934060824
+M08	0.6039570955004961
+M08	0.6065571917175648
+M08	0.5227270145403721
+M08	0.5834946858870744
+M08	0.615702037272213
+M08	0.4210272055675747
+M08	0.7245564792724778
+M08	0.5838678593703408
+M08	0.6034346234292677
+M08	0.548797719708782
+M08	0.6158659067648824
+M08	0.5383982461209155
+M08	0.5425487666906746
+M08	0.6401386407885185
+M08	0.6965907179756483
+M08	0.5625289379679024
+M08	0.6043058835295441
+M08	0.4915679880113526
+M08	0.6204674417300365
+M08	0.3926127375441499
+M08	0.46320994058957793
+M08	0.6692245376952592
+M08	0.7369932933754765
+M08	0.674718250749168
+M08	0.5723473290286387
+M08	0.5884864534979404
+M08	0.6298166970372542
+M08	0.5793053015549967
+M08	0.6517299784290754
+M08	0.5167180927954136
+M08	0.6009029331484067
+M08	0.6568652083193897
+M08	0.6106249669228175
+M08	0.6454873082357648
+M08	0.5014133375168895
+M08	0.6115657322786522
+M08	0.5934268711043182
+M08	0.6527014797530309
+M08	0.6439822471791938
+M08	0.423730110423649
+M08	0.5734520522277882
+M08	0.6413038497245365
+M08	0.6050819772510272
+M08	0.5282864453550892
+M08	0.6727075270004673
+M08	0.5399065578487273
+M08	0.6206835231341198
+M08	0.6367573500087806
+M08	0.5979547482041048
+M08	0.6726077777618961
+M08	0.5385141304723724
+M08	0.5742077860191297
+M08	0.6057317848778231
+M08	0.6074599606268506
+M08	0.5068015200889775
+M08	0.658218532083704
+M08	0.5703747787450529
+M08	0.7104363024575882
+M08	0.6116315280018693
+M08	0.6463758926780134
+M08	0.522459115272225
+M08	0.6903230071528741
+M08	0.6255788816889701
+M08	0.49297868097567915
+M08	0.5550678589298554
+M08	0.6608942392362493
+M08	0.6614215195690952
+M08	0.5942024502916683
+M08	0.658296108512796
+M08	0.5944674434218213
+M08	0.56283220077597
+M08	0.6490191386884466
+M08	0.640871615677247
+M08	0.5866862537509102
+M08	0.5895289491633494
+M08	0.57319309458995
+M08	0.5412379394499217
+M08	0.568967692714052
+M08	0.48569714481605814
+M08	0.5451329933406222
+M08	0.6374879179790748
+M08	0.622150024353383
+M08	0.5959072236959309
+M08	0.4712517983653638
+M08	0.5736936621300889
+M08	0.6039175086453521
+M08	0.6080408827554781
+M08	0.4564924474455062
+M08	0.5907810812265323
+M08	0.5909331175008128
+M08	0.5892757488946365
+M08	0.6129761537525099
+M08	0.6240083844664163
+M08	0.6488392502520808
+M08	0.5619440386667289
+M08	0.5989235622576318
+M08	0.5656007552932044
+M08	0.7230838469277733
+M08	0.627522733060962
+M08	0.5227432634451722
+M08	0.6012850156264598
+M08	0.5824665873209033
+M08	0.6883600509727759
+M08	0.6204871604858654
+M08	0.625317706414758
+M08	0.527515110707467
+M08	0.5508723283945565
+M08	0.5922163537788057
+M08	0.4024821893875098
+M08	0.619017986508359
+M08	0.6828244330446266
+M08	0.6480066259926486
+M08	0.5735915141947838
+M08	0.6770018321910554
+M08	0.4825032483984771
+M08	0.704588883829091
+M08	0.6188816834188874
+M08	0.6467442619512663
+M08	0.6206496511250479
+M08	0.5605938361663658
+M08	0.5410085221544572
+M08	0.3907385625743566
+M08	0.5682821262511062
+M08	0.5595883329838242
+M08	0.580932307167642
+M08	0.5338849746194174
+M08	0.5830223402727728
+M08	0.6160577488238271
+M08	0.5214125879939486
+M08	0.5686247640702202
+M08	0.4518898953428198
+M08	0.525508902225189
+M08	0.41227739720082895
+M08	0.667502118424473
+M08	0.6508657505158438
+M08	0.6372241107164766
+M08	0.5704067914345308
+M08	0.6735855356535849
+M08	0.681652190412013
+M08	0.4511137130088902
+M08	0.6452300563200045
+M08	0.6979149874953537
+M08	0.6571191685677616
+M08	0.6022486744988446
+M08	0.5925876109800968
+M08	0.6335322521790514
+M08	0.6390671232513155
+M08	0.63869517211287
+M08	0.5436854286871423
+M08	0.34703480032758505
+M08	0.6509208913950558
+M08	0.6263912068302503
+M08	0.513643962421305
+M16	0.24559854808045636
+M16	0.36889516779149506
+M16	0.3722248226468796
+M16	0.1343572516342854
+M16	0.3772817325048669
+M16	0.28451940947033594
+M16	0.41788314091416623
+M16	0.3600947255100485
+M16	0.3348134561052426
+M16	0.3107709936422017
+M16	0.2937240499010467
+M16	0.2761709873183967
+M16	0.3625090856709777
+M16	0.2902277429071791
+M16	0.3053832590897105
+M16	0.27221767253470436
+M16	0.4106194070235196
+M16	0.3617991351769279
+M16	0.4935635117323147
+M16	0.34644806752005347
+M16	0.30140922137495985
+M16	0.351546543927618
+M16	0.3008072179065003
+M16	0.3165708525911809
+M16	0.32486821927180076
+M16	0.4226576760869853
+M16	0.14851125015945993
+M16	0.2779065461758939
+M16	0.3418981333280923
+M16	0.40788752208687373
+M16	0.3388596696914611
+M16	0.37713663161653277
+M16	0.28669124323643547
+M16	0.23750722574461838
+M16	0.3043101744630667
+M16	0.47546137918823955
+M16	0.2859502517827552
+M16	0.4624769470804351
+M16	0.3012458548033251
+M16	0.280986772244138
+M16	0.3472100075485469
+M16	0.4295935523478827
+M16	0.6892383140765298
+M16	0.3578383138201525
+M16	0.32119512190853017
+M16	0.34293463036360494
+M16	0.24769730575174073
+M16	0.2697045526108808
+M16	0.26614834537637
+M16	0.4366379864066644
+M16	0.28998350079077495
+M16	0.26700993373649695
+M16	0.27438620451733536
+M16	0.17145260105755494
+M16	0.3396920032917318
+M16	0.4277720399533116
+M16	0.21815785111813307
+M16	0.19878493050840101
+M16	0.46102123244748616
+M16	0.4198771455655124
+M16	0.213612824718664
+M16	0.29279589405848505
+M16	0.3447017613926692
+M16	0.33094731344210193
+M16	0.2272599508344678
+M16	0.2998913541376938
+M16	0.31211457448828456
+M16	0.2863161609197477
+M16	0.27879194170079424
+M16	0.5572976132286779
+M16	0.4215108704719171
+M16	0.28313340034289514
+M16	0.38741902952422747
+M16	0.37806581664408806
+M16	0.32886604736478886
+M16	0.5476814445313526
+M16	0.4029637544445844
+M16	0.26180173724041433
+M16	0.3205628993183914
+M16	0.2591692746147817
+M16	0.2385740671967572
+M16	0.3151989279600188
+M16	0.3101019886468593
+M16	0.11442855106443857
+M16	0.2377726778990688
+M16	0.33443653487799974
+M16	0.3609351229020093
+M16	0.28284100832221254
+M16	0.41363874025639963
+M16	0.3407253837404883
+M16	0.26795039013114424
+M16	0.3941939859581481
+M16	0.41098922936892
+M16	0.3742791208065366
+M16	0.45169094412629146
+M16	0.26619590970515045
+M16	0.4726260089517479
+M16	0.33552591316959346
+M16	0.33602666809266524
+M16	0.25459574167501
+M16	0.3269623800448926
+M16	0.1640493539939473
+M16	0.25936811667599013
+M16	0.25777388430182857
+M16	0.5173115823002188
+M16	0.16435031119324525
+M16	0.3689021332555746
+M16	0.2556194375986256
+M16	0.25075969336843257
+M16	0.4191988605262225
+M16	0.25984840750621585
+M16	0.41296127991345744
+M16	0.280591831004086
+M16	0.35570545749194454
+M16	0.34605257126695044
+M16	0.41192426545844757
+M16	0.44008383776257237
+M16	0.3475369960417463
+M16	0.14507264747241969
+M16	0.37374363912287456
+M16	0.4077538374850213
+M16	0.37788217748372666
+M16	0.5423307322011282
+M16	0.35378851295289887
+M16	0.3211032350048388
+M16	0.287899558051686
+M16	0.3411686104356778
+M16	0.24241782080087995
+M16	0.3870761781856999
+M16	0.30541138387751426
+M16	0.4299015565373666
+M16	0.21326941080186113
+M16	0.38344234711011355
+M16	0.37263203632538927
+M16	0.3137424334374392
+M16	0.3764738302112773
+M16	0.29157958329346106
+M16	0.5151321097921688
+M16	0.4414425546402371
+M16	0.3350654286220695
+M16	0.3350665453941376
+M16	0.34321460712679797
+M16	0.34288658782989806
+M16	0.3677396316538385
+M16	0.3390508217492833
+M16	0.31471375995599865
+M16	0.4087320351181847
+M16	0.3842445688166222
+M16	0.19714985775373403
+M16	0.24608366564918932
+M16	0.451026633928712
+M16	0.2797293199929661
+M16	0.21635277847198292
+M16	0.25608616153446506
+M16	0.4315933545806275
+M16	0.467624824102055
+M16	0.37915624485788896
+M16	0.3453134913911158
+M16	0.3960249116285141
+M16	0.4126815735521172
+M16	0.4313523301584386
+M16	0.2842569213461532
+M16	0.31835123342935273
+M16	0.2716573481890679
+M16	0.26067269672837756
+M16	0.3486458815093957
+M16	0.24839648414014132
+M16	0.1454015632246238
+M16	0.22659620554986865
+M16	0.2726534720287703
+M16	0.2851194659857768
+M16	0.3445254741046277
+M16	0.42357688682617844
+M16	0.3393914432212559
+M16	0.4261413191800939
+M16	0.56846667519333
+M16	0.2833535843690655
+M16	0.4120938337764317
+M16	0.2611648919319179
+M16	0.3557961243863275
+M03	0.21061811022493282
+M03	0.2851749701818295
+M03	0.37724287573443227
+M03	0.17074102932809612
+M03	0.4281108113224036
+M03	0.29633261040628317
+M03	0.4053579926894068
+M03	0.3455649478594779
+M03	0.3669283898755192
+M03	0.266340499781367
+M03	0.2589537610248358
+M03	0.37570392250925205
+M03	0.3850816116799112
+M03	0.3847169331241772
+M03	0.2863493004876322
+M03	0.4560976367360769
+M03	0.4808689834363382
+M03	0.4286171199480147
+M03	0.4961403741232553
+M03	0.4251008806779355
+M03	0.27973851883935896
+M03	0.29466241998877213
+M03	0.31624945126920717
+M03	0.3736880600353068
+M03	0.26266262520134587
+M03	0.46498435546440325
+M03	0.2628676781556644
+M03	0.28703171964284163
+M03	0.5196056114963468
+M03	0.39696563374903526
+M03	0.375350182272588
+M03	0.5365847955105624
+M03	0.33250189331415575
+M03	0.22088697663768672
+M03	0.40322793407102914
+M03	0.49766727624014406
+M03	0.3039503173875011
+M03	0.47400468496410453
+M03	0.2593650590142597
+M03	0.4082338255941298
+M03	0.4394975079111227
+M03	0.3582708668506466
+M03	0.6889756899952764
+M03	0.4032282631014676
+M03	0.3305770353412347
+M03	0.43522439619339337
+M03	0.34980681762222154
+M03	0.2255047725356273
+M03	0.33116108444724895
+M03	0.32777469153606237
+M03	0.28386026201628856
+M03	0.3225058261228883
+M03	0.27107551139648944
+M03	0.33386303391463584
+M03	0.3880941753834651
+M03	0.4653080993017285
+M03	0.26780885449342906
+M03	0.3146989280789106
+M03	0.5283683134635125
+M03	0.43157709684014745
+M03	0.31892070756218244
+M03	0.30975642889524346
+M03	0.37317981740287726
+M03	0.2670716962342278
+M03	0.3237220357468844
+M03	0.31665074250017655
+M03	0.3731984794726475
+M03	0.2922363740449288
+M03	0.28606718356085764
+M03	0.5299138942505508
+M03	0.35349620759539163
+M03	0.3436866776538976
+M03	0.34730881032018185
+M03	0.38226041088446233
+M03	0.4094491101856277
+M03	0.5809182389101927
+M03	0.4655628380448651
+M03	0.3074118446147375
+M03	0.39510697393998007
+M03	0.3007264508184661
+M03	0.32720627706879823
+M03	0.3289965495677367
+M03	0.31532545918385607
+M03	0.2684076634906617
+M03	0.25148748988693914
+M03	0.4467995595173286
+M03	0.3768392031467792
+M03	0.3255468494711656
+M03	0.4581959093593773
+M03	0.35401712530137
+M03	0.35536866193589145
+M03	0.4025226069397994
+M03	0.41452439320215906
+M03	0.4058135955696804
+M03	0.4759155008119471
+M03	0.24545747800699466
+M03	0.5790616240484284
+M03	0.4051876703287796
+M03	0.33457172942767605
+M03	0.4162559189535069
+M03	0.34076482506326966
+M03	0.30542704022616785
+M03	0.25120615450703276
+M03	0.3549126852968024
+M03	0.5473278673338908
+M03	0.34112303173332975
+M03	0.3644678940596407
+M03	0.289684736080765
+M03	0.26214845563921846
+M03	0.5238027710554023
+M03	0.25462536316957485
+M03	0.3384389746655403
+M03	0.14833929101999047
+M03	0.38069014873624485
+M03	0.335636468253029
+M03	0.4368969082524826
+M03	0.4633756175780339
+M03	0.38116916969852727
+M03	0.23788176761253343
+M03	0.3622192981675603
+M03	0.5235132910536661
+M03	0.46366765608503213
+M03	0.47082133729918724
+M03	0.352049702419319
+M03	0.34316531570840725
+M03	0.3025726083398
+M03	0.3545471835673699
+M03	0.2835467333906316
+M03	0.4503209650676607
+M03	0.4321371499497518
+M03	0.4580629313411919
+M03	0.2247345960091919
+M03	0.4151154899396002
+M03	0.30954420759480267
+M03	0.3563052626710376
+M03	0.4842851153919581
+M03	0.3179770946199796
+M03	0.5732202124245163
+M03	0.5207854812014919
+M03	0.3779057847263672
+M03	0.37860212671899823
+M03	0.4378115512270953
+M03	0.3271169613982536
+M03	0.39793837263354936
+M03	0.32930249772612824
+M03	0.2730334143782824
+M03	0.4694959566328743
+M03	0.3487962915480526
+M03	0.2772788299339163
+M03	0.2539045838174168
+M03	0.48282373667802
+M03	0.3167345241506125
+M03	0.3462233984601908
+M03	0.2904421090619352
+M03	0.4762488373607247
+M03	0.5233805859127508
+M03	0.39584893973656077
+M03	0.347264855820184
+M03	0.3096100079154091
+M03	0.48400956857637795
+M03	0.5492735782427643
+M03	0.30100036758528864
+M03	0.3690981770455593
+M03	0.27816052954674036
+M03	0.25179906626779497
+M03	0.37238723292101317
+M03	0.30584530254906456
+M03	0.20043011865025367
+M03	0.2749598040230471
+M03	0.24686687899340093
+M03	0.34795811225314877
+M03	0.39234018085398914
+M03	0.47038902900580076
+M03	0.36331446698959335
+M03	0.4959251477583112
+M03	0.6233919793070778
+M03	0.3269323720201891
+M03	0.32561368166880206
+M03	0.2787617591690825
+M03	0.40968838453350914
+M03	0.6428995353772645
+M03	0.6908899300325487
+M03	0.6091473300019595
+M03	0.6703643975205631
+M03	0.7147197419035117
+M03	0.6901878652063317
+M03	0.43588694829699115
+M03	0.41142966190892843
+M03	0.6923247364718527
+M03	0.4990901017217193
+M03	0.5664559978146229
+M03	0.7559283808489898
+M03	0.6760666990774816
+M03	0.6515257927973298
+M03	0.6468822175361167
+M03	0.6630980114951031
+M03	0.6006839028226821
+M03	0.7204494894047346
+M03	0.6382467786701065
+M03	0.5935312986517058
+M03	0.6535438356218962
+M03	0.5614694540214661
+M03	0.7315330103705261
+M03	0.6976393478345266
+M03	0.6759254128442735
+M03	0.6251441850956457
+M03	0.6375863988981546
+M03	0.5833223117057654
+M03	0.7217936037852557
+M03	0.49825874640963214
+M03	0.5774166647604129
+M03	0.6900989134636598
+M03	0.6399910496198468
+M03	0.7207459456883784
+M03	0.6487256153496378
+M03	0.6656903120042146
+M03	0.5587857875017954
+M03	0.6750485646963729
+M03	0.4872148229961766
+M03	0.2627030555015891
+M03	0.4412185450853599
+M03	0.7320350169933767
+M03	0.6232152722733876
+M03	0.6004310350096812
+M03	0.7514097553186324
+M03	0.6136021056746074
+M03	0.6563819920821138
+M03	0.6580423870158213
+M03	0.3802626558848262
+M03	0.5608675734754872
+M03	0.5449730900182655
+M03	0.7041362388539683
+M03	0.5929582665518689
+M03	0.7013788916011171
+M03	0.7414135636813551
+M03	0.72114399429232
+M03	0.5192814500142924
+M03	0.47967985777362565
+M03	0.5504654086973358
+M03	0.47076921055933546
+M03	0.5633375047545235
+M03	0.6811506523630496
+M03	0.5532099890250067
+M03	0.397819356566716
+M03	0.6596596157801499
+M03	0.6427927231939986
+M03	0.5974413109175825
+M03	0.6200298333787416
+M03	0.6338469609435493
+M03	0.6576725349164843
+M03	0.6067198484116002
+M03	0.5151005138516858
+M03	0.6476704737471894
+M03	0.5246653913801727
+M03	0.33471552870306176
+M03	0.5008328032800397
+M03	0.6149252880100518
+M03	0.6159238554574111
+M03	0.6621793004330958
+M03	0.6568039922221555
+M03	0.6150767097763629
+M03	0.6980986254034537
+M03	0.6621608736102288
+M03	0.5781365385347994
+M03	0.6688373449383012
+M03	0.7162298011504965
+M03	0.7125802374479073
+M03	0.6332715804795186
+M03	0.6456867246595899
+M03	0.6248076426607956
+M03	0.5928021603589686
+M03	0.6757677468674094
+M03	0.6693671481669687
+M03	0.7467329729662728
+M03	0.7431204472375378
+M03	0.6854339384577027
+M03	0.5889760060868164
+M03	0.6413110132695415
+M03	0.646098007892657
+M03	0.6938103707615682
+M03	0.6407394235696576
+M03	0.6595801288238612
+M03	0.5586124257437232
+M03	0.72702169334407
+M03	0.5773512414850521
+M03	0.5750152853029581
+M03	0.7143589518289135
+M03	0.6578888752673321
+M03	0.6346030541865579
+M03	0.6256943915702199
+M03	0.7064040122584256
+M03	0.621945266485449
+M03	0.37917126278904356
+M03	0.5915237536219164
+M03	0.46961208567050605
+M03	0.47226202119596944
+M03	0.5671847707690321
+M03	0.595419926988668
+M03	0.6217396001067266
+M03	0.5593121170179021
+M03	0.3698055297954015
+M03	0.5988196319319598
+M03	0.5653255141371029
+M03	0.6484243008033947
+M03	0.713183639719571
+M03	0.6955958457918842
+M03	0.5814897938759956
+M03	0.593968214686417
+M03	0.6866787860805419
+M03	0.5663637468250968
+M03	0.6767641361557595
+M03	0.6826232004452395
+M03	0.5954310009733206
+M03	0.6313745354083825
+M03	0.7086340758710213
+M03	0.6963929129577877
+M03	0.6790048263842495
+M03	0.6859348259574545
+M03	0.6967762432569758
+M03	0.6797696309688518
+M03	0.6870642499231909
+M03	0.5648358711587631
+M03	0.6467707483184033
+M03	0.3681179842674405
+M03	0.5925832661179312
+M03	0.639704792295688
+M03	0.6391683743014295
+M03	0.6808398332427933
+M03	0.6586510942627499
+M03	0.6045797376365134
+M03	0.5696471714467507
+M03	0.6966110910699426
+M03	0.5501050939422619
+M03	0.6632743534747692
+M03	0.5677069249157942
+M03	0.4640050099805049
+M03	0.6320305510954722
+M03	0.6226623865990631
+M03	0.7292800349689124
+M03	0.5923603667518187
+M03	0.6904390681328425
+M03	0.5646299974269859
+M03	0.5852040494012161
+M03	0.5852950922578543
+M03	0.5842668831185251
+M03	0.6476237476481177
+M03	0.5816110630313789
+M03	0.6155317905859586
+M03	0.5237571262742095
+M03	0.6460715308635393
+M03	0.49891721668943256
+M03	0.5570031848413811
+M03	0.6889586755186325
+M03	0.5602599353736073
+M03	0.4855521657368785
+M03	0.6711818463909948
+M03	0.6399285616920203
+M03	0.5136984343720835
+M03	0.5120273917368103
+M03	0.6665329319622445
+M03	0.705098418858185
+M03	0.7226904145037304
+M03	0.5954448930682844
+M03	0.45918970076037297
+M03	0.5610579015509009
+M03	0.3823154505663267
+M03	0.5043568312405367
+M03	0.5671325647202156
+M03	0.5615511696690436
+M03	0.6378344467186525
+M03	0.634912244972641
+M03	0.7071831909876526
+M03	0.6777354931564444
+M03	0.6839512098851912
+M03	0.5899828944255283
+M03	0.5924981433094173
+M03	0.673041116235417
+M03	0.6035794462774191
+M03	0.7057398781223185
+M03	0.6919818152850238
+M03	0.5811312848389529
+M03	0.5700687280519664
+M03	0.610111435306517
+M03	0.42127281578148496
+M03	0.6873948945904238
+M03	0.5630687297005509
+M03	0.6398145200789885
+M03	0.6310652324970962
+M03	0.6302821064682312
+M03	0.6392655535009776
+M03	0.645617129576755
+M03	0.5187331533349597
+M03	0.4339857524317273
+M03	0.484544194758609
+M03	0.6514617251877522
+M03	0.6029065493810336
+M03	0.6990777735406483
+M03	0.6639957590860767
+M03	0.6135293624059742
+M03	0.7662911814968295
+M03	0.6388614385512108
+M03	0.6314876343813794
+M03	0.5907180956206707
+M03	0.5519806453089088
+M03	0.49233351528328095
+M03	0.5025168916662766
+M03	0.5416008892223317
+M03	0.6277001407449865
+M03	0.49775287361300435
+M03	0.46088370256994277
+M03	0.6776888479664201
+M03	0.4790715369944068
+M03	0.5166622155906679
+M03	0.6368684754113382
+M03	0.6674573896386619
+M03	0.6201410967297777
+M03	0.7361409902944926
+M03	0.5707125557148954
+M03	0.6306969392896524
+M03	0.5894743572850318
+M03	0.5330098141528506
+M03	0.6078356289193546
+M03	0.5730391143910785
+M06	0.21154410805464777
+M06	0.3871488051408393
+M06	0.2870680298189898
+M06	0.20891195151739214
+M06	0.4441720643312028
+M06	0.2170326768904517
+M06	0.41348391584394517
+M06	0.38482278171957723
+M06	0.3863058119990857
+M06	0.3377128344388274
+M06	0.29766508273726816
+M06	0.3073024796074453
+M06	0.3738265314014364
+M06	0.37546615533314237
+M06	0.30988432307715896
+M06	0.40285624792784036
+M06	0.5447038434369721
+M06	0.35087226573843455
+M06	0.5130673050057527
+M06	0.4173819648761111
+M06	0.2779079950580144
+M06	0.3439213465905077
+M06	0.2778782861481663
+M06	0.2745729399559976
+M06	0.3332339170219366
+M06	0.3797965574193311
+M06	0.20065392194081344
+M06	0.26325360776187817
+M06	0.4477669141858903
+M06	0.37066978229569336
+M06	0.3863168092349529
+M06	0.3701708194998715
+M06	0.30293095784522417
+M06	0.25335888452674243
+M06	0.3923130039903059
+M06	0.43769338965617693
+M06	0.20517730353794847
+M06	0.4286471215840796
+M06	0.40750065204477515
+M06	0.4068110789948963
+M06	0.3881545051172085
+M06	0.4578821202501249
+M06	0.6837585817719395
+M06	0.3909462832196139
+M06	0.3540806176604743
+M06	0.40478211340116116
+M06	0.2895732255759621
+M06	0.2527785961743129
+M06	0.2861356149536676
+M06	0.4511825439505355
+M06	0.2859236364026415
+M06	0.35182910186651306
+M06	0.27940476005454423
+M06	0.297701627891853
+M06	0.3649670412831275
+M06	0.31641884153054806
+M06	0.26312343085696693
+M06	0.33714302400569934
+M06	0.4316625475033395
+M06	0.2973900668979287
+M06	0.31699602221039497
+M06	0.31678322539060394
+M06	0.41940741525898917
+M06	0.37009879302909293
+M06	0.23398772716451172
+M06	0.2463596219851985
+M06	0.3376310669897255
+M06	0.26629038420842127
+M06	0.28995339405684
+M06	0.5427341744697555
+M06	0.39365081672310803
+M06	0.32703532723389644
+M06	0.399776802104173
+M06	0.3719195017586819
+M06	0.4454331733279235
+M06	0.4367832949698158
+M06	0.4601688185531274
+M06	0.28622449586604864
+M06	0.3883098674443091
+M06	0.3014721142637465
+M06	0.2845803652954833
+M06	0.3195463181215058
+M06	0.2641987179691857
+M06	0.2630841271625722
+M06	0.24276486676958584
+M06	0.34375528925731624
+M06	0.3739893442176544
+M06	0.307169028826781
+M06	0.4174989607816566
+M06	0.31811752015428685
+M06	0.3136584602542619
+M06	0.5201265815031804
+M06	0.3797855051798778
+M06	0.3995296444451531
+M06	0.4254172634850456
+M06	0.2823771937274111
+M06	0.5122276118228004
+M06	0.3601249831404163
+M06	0.3257590825876797
+M06	0.3226884453933702
+M06	0.3565956848680913
+M06	0.2605958090941156
+M06	0.1550743634915599
+M06	0.31500202011607203
+M06	0.5395129335189794
+M06	0.289281819221877
+M06	0.3949412815291584
+M06	0.286787589829569
+M06	0.18809792364531328
+M06	0.4231992879079218
+M06	0.32554404984640817
+M06	0.38704821348720747
+M06	0.289544633093406
+M06	0.36295025984173335
+M06	0.2793338024489124
+M06	0.3045612736680238
+M06	0.43299024092040195
+M06	0.32429568446906704
+M06	0.18508547162358846
+M06	0.36408785544451244
+M06	0.4746998395297795
+M06	0.3872130512841527
+M06	0.47281799044889494
+M06	0.35658698085340684
+M06	0.29928375555444925
+M06	0.3029424151778667
+M06	0.41275976902226647
+M06	0.2601936088190723
+M06	0.4493225092067403
+M06	0.38003763740315466
+M06	0.44203464275752635
+M06	0.09936525778346068
+M06	0.43795804871745614
+M06	0.28455012973351124
+M06	0.3754286508799701
+M06	0.3783576874655496
+M06	0.38216775433610395
+M06	0.4713781406912754
+M06	0.45607337960066324
+M06	0.30727262213229956
+M06	0.31444344436563165
+M06	0.31832945691737397
+M06	0.35967124354276137
+M06	0.3973507644036665
+M06	0.3493921493935788
+M06	0.22382564690515944
+M06	0.4212756799310407
+M06	0.3130966171828075
+M06	0.20817104611289597
+M06	0.27699263049907
+M06	0.4635489979666055
+M06	0.32893933015694465
+M06	0.35379905519498994
+M06	0.24424437382068634
+M06	0.33707690428226983
+M06	0.49392037177144354
+M06	0.41096569827418494
+M06	0.39776227574333206
+M06	0.4373459140760273
+M06	0.326612957664806
+M06	0.45930685533982674
+M06	0.2832880860267311
+M06	0.34143310750324635
+M06	0.260870265031748
+M06	0.19534818082100996
+M06	0.3809477388101869
+M06	0.2528284631405488
+M06	0.2131043424515344
+M06	0.21172412881303182
+M06	0.2695793678916191
+M06	0.2883270739294583
+M06	0.267162447490981
+M06	0.3678072683881453
+M06	0.3350832290656565
+M06	0.4738254584674461
+M06	0.5976157861194198
+M06	0.33173771024152426
+M06	0.4772280723365545
+M06	0.2905948196434259
+M06	0.366322803685807
+M10	0.24856056340712138
+M10	0.38593593007302707
+M10	0.31257257487438533
+M10	0.13612848838477334
+M10	0.3898021326846306
+M10	0.2600971058204065
+M10	0.3970537275064799
+M10	0.3920219235015452
+M10	0.3313323909066825
+M10	0.3459412549671728
+M10	0.26088052479023816
+M10	0.340446258395375
+M10	0.36306120387783175
+M10	0.32020905190668436
+M10	0.2628406241895553
+M10	0.41998106550129527
+M10	0.5793501904485645
+M10	0.3908188650656767
+M10	0.4935516800509545
+M10	0.3879159593445862
+M10	0.2996877525070279
+M10	0.3223281149628985
+M10	0.28872085417886517
+M10	0.31611517359123603
+M10	0.24783771040437186
+M10	0.32933009694683946
+M10	0.24524955874675447
+M10	0.2888905189600873
+M10	0.4589484475859481
+M10	0.43507220723086343
+M10	0.36029187205577273
+M10	0.37584163574491064
+M10	0.33917637049364213
+M10	0.23745560022096843
+M10	0.3576051591375212
+M10	0.4382700538832432
+M10	0.2632977670240554
+M10	0.45526536857140254
+M10	0.37597171057070206
+M10	0.3594558824668561
+M10	0.42810534829623414
+M10	0.3544665622146379
+M10	0.5407253070875886
+M10	0.38353684905181307
+M10	0.24219877918569732
+M10	0.40047837551897153
+M10	0.3252880067909847
+M10	0.24405546659420568
+M10	0.2721447620777869
+M10	0.2691108220741148
+M10	0.27281154835367444
+M10	0.3219553355172009
+M10	0.2907032189988272
+M10	0.2079874340561327
+M10	0.3559500266081253
+M10	0.42182062576576057
+M10	0.30048836773095644
+M10	0.35380373312266267
+M10	0.4155281820511867
+M10	0.4061648813268678
+M10	0.29987897084490306
+M10	0.1849216999983475
+M10	0.41839784070892133
+M10	0.2711216629462497
+M10	0.3019625373581178
+M10	0.33146168170404633
+M10	0.3593268611390316
+M10	0.31218624797575417
+M10	0.26290060177397473
+M10	0.5847436156797475
+M10	0.4492507287435623
+M10	0.328800106635956
+M10	0.4028719042170041
+M10	0.3725725384838031
+M10	0.42496662818637587
+M10	0.5160003648815927
+M10	0.4311430754105052
+M10	0.2720031243017686
+M10	0.33953665700771135
+M10	0.275979469250352
+M10	0.30922770755593626
+M10	0.19890820351542554
+M10	0.26160172225766337
+M10	0.24535366497795585
+M10	0.282541156915919
+M10	0.37870690462986406
+M10	0.30098603552390674
+M10	0.3121232427033076
+M10	0.40396861298457265
+M10	0.27074646204542907
+M10	0.3455186693278939
+M10	0.513770534889693
+M10	0.368840142524328
+M10	0.3629169163730263
+M10	0.5483009227503706
+M10	0.28697977494654053
+M10	0.35459666873398304
+M10	0.3643316725990666
+M10	0.23529323924922926
+M10	0.3029459941329086
+M10	0.2841390462772743
+M10	0.25189469608809123
+M10	0.26534458501934327
+M10	0.35101013482965465
+M10	0.5130186829264369
+M10	0.29051184733989427
+M10	0.3833942832829036
+M10	0.23565978493169185
+M10	0.2066432167005972
+M10	0.5020773328132976
+M10	0.22314251952001363
+M10	0.41029298464885466
+M10	0.21217138601447727
+M10	0.30516352060251184
+M10	0.33891642458402
+M10	0.35483029166680347
+M10	0.4481531048866937
+M10	0.35934915809472917
+M10	0.1776905946647411
+M10	0.28469086806143606
+M10	0.42632532163681985
+M10	0.4377829149966384
+M10	0.555528328462518
+M10	0.32145017268290377
+M10	0.3322139880647244
+M10	0.21525261890063946
+M10	0.39968794054630713
+M10	0.30020613813857955
+M10	0.29448934017153844
+M10	0.36522505820083984
+M10	0.4321969834947136
+M10	0.10123089480355967
+M10	0.3714515721227652
+M10	0.36517528908928426
+M10	0.25604742368547817
+M10	0.45981251457539013
+M10	0.36972652734383465
+M10	0.42667624903056117
+M10	0.472596438859065
+M10	0.24748386602878156
+M10	0.2743368164539331
+M10	0.3692350774300784
+M10	0.381172518452687
+M10	0.349985044374641
+M10	0.3335207201613608
+M10	0.2906352271427782
+M10	0.46432846909718145
+M10	0.38584131316555575
+M10	0.14508791507604865
+M10	0.27140641286118217
+M10	0.4745047254052711
+M10	0.3217912865202847
+M10	0.3460010942202927
+M10	0.19007031594865567
+M10	0.45110026892582794
+M10	0.4682753380979885
+M10	0.31695105650016303
+M10	0.33192641761808206
+M10	0.280800737970518
+M10	0.39828980328610636
+M10	0.4498480818513006
+M10	0.27731543085345756
+M10	0.34744137402947484
+M10	0.20874528433465478
+M10	0.17766416628147097
+M10	0.3644804333079641
+M10	0.27273690062901856
+M10	0.17697740725358124
+M10	0.22989046219395382
+M10	0.26778216253219733
+M10	0.3081874297680655
+M10	0.3635876356016012
+M10	0.46577341338873796
+M10	0.334637842944364
+M10	0.4804182790651328
+M10	0.5780882168061241
+M10	0.3107627757412381
+M10	0.4350360643151633
+M10	0.28900963537756946
+M10	0.38361832880111846
+M04	0.177105158146608
+M04	0.37860306025951884
+M04	0.3821929338713624
+M04	0.10181606970432891
+M04	0.367358963161647
+M04	0.292028693926145
+M04	0.29481175358687156
+M04	0.3685004820225463
+M04	0.3499364382506618
+M04	0.31678705136258717
+M04	0.2785599550800788
+M04	0.3331814596810362
+M04	0.3419527730639281
+M04	0.27119169951188726
+M04	0.31239907241363296
+M04	0.3513396745111547
+M04	0.5545232128950663
+M04	0.3221913255294795
+M04	0.45649407592029684
+M04	0.3790144092668351
+M04	0.31688868299299217
+M04	0.21490874410727911
+M04	0.21421674503577728
+M04	0.35885348228576325
+M04	0.3293489013178105
+M04	0.30386507921067407
+M04	0.26354370003059285
+M04	0.19496522679071648
+M04	0.37482317830260053
+M04	0.22523800652545467
+M04	0.36868353897056877
+M04	0.5132371646362242
+M04	0.3250243481336556
+M04	0.20996239345980677
+M04	0.39116624854256704
+M04	0.4368075177776379
+M04	0.29522070709445225
+M04	0.37013704966550204
+M04	0.36342339885049935
+M04	0.4173226621904477
+M04	0.3526232681586477
+M04	0.4441653876249909
+M04	0.6813089405526961
+M04	0.39775778032870196
+M04	0.2989245293178056
+M04	0.3770759418121449
+M04	0.257875174158875
+M04	0.2657887399028713
+M04	0.28604946295217687
+M04	0.3350896740302183
+M04	0.2801844544169058
+M04	0.3104666012578903
+M04	0.2742451730572879
+M04	0.2481409882293654
+M04	0.3644729542077482
+M04	0.4483756407241762
+M04	0.26752705493036844
+M04	0.33537003666329884
+M04	0.5067478221020983
+M04	0.25944729098894675
+M04	0.3052545328138779
+M04	0.2436972935296724
+M04	0.3782028981241331
+M04	0.3364695617725939
+M04	0.2938589116108957
+M04	0.33648068430293226
+M04	0.37450659082120047
+M04	0.26121338930094173
+M04	0.18330740357320283
+M04	0.5380883666583828
+M04	0.44337375665681317
+M04	0.3298587064540368
+M04	0.38089561485753975
+M04	0.36557667596004384
+M04	0.3932364774421919
+M04	0.5562970219616878
+M04	0.4544807773154418
+M04	0.28473480473173984
+M04	0.3104875215740471
+M04	0.3224519700287412
+M04	0.26247264504714296
+M04	0.24409547554073033
+M04	0.28656537666691834
+M04	0.2704185225907736
+M04	0.26475544203541945
+M04	0.42871779232323765
+M04	0.37712509340920647
+M04	0.3214818814213785
+M04	0.3879906414832321
+M04	0.2580837110378713
+M04	0.3427845892007087
+M04	0.5243192408912994
+M04	0.3980993669397593
+M04	0.4160982041441324
+M04	0.40760769357959037
+M04	0.3013069588113057
+M04	0.5490616758446605
+M04	0.36008207578385365
+M04	0.24588642162048013
+M04	0.406996213051839
+M04	0.35394772403923536
+M04	0.31020321241049426
+M04	0.2578160032755362
+M04	0.35672167545075234
+M04	0.5314304153073071
+M04	0.3493329314928689
+M04	0.18950070090618124
+M04	0.2862020896615474
+M04	0.2624840379769226
+M04	0.5063820057793936
+M04	0.2871522947933386
+M04	0.41145807916136096
+M04	0.2514838666468565
+M04	0.35736504167895217
+M04	0.28788528585420997
+M04	0.44105937108903687
+M04	0.43326200045114516
+M04	0.2638858733775115
+M04	0.2273085488935159
+M04	0.38927352859368863
+M04	0.4974198096513934
+M04	0.2706982848069851
+M04	0.5635725130180876
+M04	0.36443096829429705
+M04	0.23680829245116497
+M04	0.30457614342122213
+M04	0.3940699922451069
+M04	0.1620829129631956
+M04	0.37848110086835046
+M04	0.42050212106517426
+M04	0.421339976657918
+M04	0.24159104047803906
+M04	0.39938971026411935
+M04	0.29219630195086066
+M04	0.36808131182632164
+M04	0.4654936696836831
+M04	0.3002293414451174
+M04	0.5077403908311275
+M04	0.4904369602248754
+M04	0.35277322701541947
+M04	0.3092313708084841
+M04	0.41878335266418176
+M04	0.34524410485241236
+M04	0.21857904537419592
+M04	0.346577908449651
+M04	0.1610229040966561
+M04	0.5037263567203507
+M04	0.34939190292921585
+M04	0.2370272559195984
+M04	0.261135746631501
+M04	0.41184405719695727
+M04	0.2807470277818158
+M04	0.355152934847826
+M04	0.29313548792241656
+M04	0.24665117854911636
+M04	0.3987627570816059
+M04	0.41374743364278926
+M04	0.3958348936296642
+M04	0.40542737432900827
+M04	0.45404854764005065
+M04	0.4360758718934947
+M04	0.29057704436438003
+M04	0.2943282441727425
+M04	0.29070010528112955
+M04	0.15362501230465916
+M04	0.256481546049441
+M04	0.21651183123742235
+M04	0.21979250056132676
+M04	0.25696447830090224
+M04	0.2607169679542265
+M04	0.32226295075128797
+M04	0.308166909764297
+M04	0.43404103098438246
+M04	0.3027824961957274
+M04	0.46381493662944473
+M04	0.5870301624093989
+M04	0.3003041439225252
+M04	0.3347520768940701
+M04	0.2686215124103944
+M04	0.26641057480149277
+M04	0.666789835045993
+M04	0.5450465778272
+M04	0.6477663878258385
+M04	0.5204069337962677
+M04	0.5050351391584786
+M04	0.5367816146514187
+M04	0.5729331134490204
+M04	0.6315709323086397
+M04	0.5510068405515092
+M04	0.42465194985755705
+M04	0.43182062691495693
+M04	0.5988484224924474
+M04	0.6479166855417975
+M04	0.6341437746838714
+M04	0.5202100606956256
+M04	0.5790508720837183
+M04	0.6894084958988046
+M04	0.6541557690403563
+M04	0.6251841347209636
+M04	0.5271534453494358
+M04	0.6562029008663688
+M04	0.4050602823185937
+M04	0.56089072164881
+M04	0.6028697177701788
+M04	0.6122044129091113
+M04	0.5772722330881292
+M04	0.5686630464709254
+M04	0.6506476108022266
+M04	0.7063337993766378
+M04	0.4641786441777613
+M04	0.5891961695404948
+M04	0.6309987779598966
+M04	0.5618016205660817
+M04	0.5046892336347057
+M04	0.5937460251601535
+M04	0.4506716497980958
+M04	0.6855960459685991
+M04	0.6594867308468914
+M04	0.6169827092876434
+M04	0.6397367667223741
+M04	0.532176808942572
+M04	0.5664585251963125
+M04	0.5142875066849615
+M04	0.6227556684969356
+M04	0.6213498746918185
+M04	0.5849823583662961
+M04	0.6209340543416062
+M04	0.57777117442266
+M04	0.6492523714167533
+M04	0.5478876805775734
+M04	0.553728481561265
+M04	0.6745090073600267
+M04	0.6364762303551931
+M04	0.6496096187715528
+M04	0.6317961490946915
+M04	0.5450475463905347
+M04	0.5107170534648282
+M04	0.4486650700624311
+M04	0.546588446265295
+M04	0.7193763976364376
+M04	0.6880986048817529
+M04	0.7104525835017359
+M04	0.6937712716390624
+M04	0.6043659221042023
+M04	0.6696751250574691
+M04	0.6140973078869859
+M04	0.559713949316321
+M04	0.5214771275208941
+M04	0.6782643225583479
+M04	0.6487064426998453
+M04	0.6212338243486629
+M04	0.58293728418367
+M04	0.5997367534227132
+M04	0.5757165977048151
+M04	0.5636570203738853
+M04	0.6261546597910405
+M04	0.5481191423481956
+M04	0.6412971601559064
+M04	0.5560846793110701
+M04	0.6957392982028653
+M04	0.4995358108831462
+M04	0.5602063625743271
+M04	0.754584344450249
+M04	0.6384484958242531
+M04	0.6397559147887559
+M04	0.47043351831854496
+M04	0.5537507630210277
+M04	0.5865807652972507
+M04	0.6463096906597755
+M04	0.594979721865826
+M04	0.5959502753218866
+M04	0.6365888928817803
+M04	0.6841108893806479
+M04	0.6150456793614477
+M04	0.6222777370247694
+M04	0.44337258194130896
+M04	0.5948430992251089
+M04	0.6474504222310008
+M04	0.6198535768076964
+M04	0.6513977786127649
+M04	0.5308198330672634
+M04	0.6542759043816146
+M04	0.6328025233308254
+M04	0.6396477266915279
+M04	0.589579559787317
+M04	0.6520503604054876
+M04	0.6855898939065147
+M04	0.44736920827784443
+M04	0.6184369575245312
+M04	0.5427049018105069
+M04	0.5849860535461259
+M04	0.7152370875283117
+M04	0.6071263038832032
+M04	0.5370239260309269
+M04	0.5762789415628508
+M04	0.5933336389471588
+M04	0.6790011308489825
+M04	0.5642575794784171
+M04	0.5522315404451056
+M04	0.5801529686302646
+M04	0.6051434519162601
+M04	0.6257924037770121
+M04	0.5383259747257388
+M04	0.5617883694165534
+M04	0.6793849545224837
+M04	0.719153959047833
+M04	0.5708363258307987
+M04	0.6148661558178014
+M04	0.520111114829089
+M04	0.5744065888411264
+M04	0.5729881045596844
+M04	0.5933725417124485
+M04	0.5554113435821185
+M04	0.5567115127004519
+M04	0.6484991579535908
+M04	0.6002153157854203
+M04	0.6312221943699358
+M04	0.6288255690939185
+M04	0.6795746140046964
+M04	0.5789137363156387
+M04	0.5509885990401318
+M04	0.6797385438032296
+M04	0.6666303929557724
+M04	0.6377313946775459
+M04	0.7056660499081964
+M04	0.5283718826726373
+M04	0.629303880738502
+M04	0.6605548246892552
+M04	0.6545039192880234
+M04	0.6326304088936218
+M04	0.6884807804443617
+M04	0.6754154020714112
+M04	0.6633048747781917
+M04	0.5863992943960324
+M04	0.5933194044777871
+M04	0.6196647799747546
+M04	0.37887565505446597
+M04	0.5574917927121655
+M04	0.6328076694845931
+M04	0.7036460718363199
+M04	0.5486239077012353
+M04	0.5631142670110721
+M04	0.6789134466927851
+M04	0.6184482320967433
+M04	0.6619983409224812
+M04	0.3518047701983135
+M04	0.4548281149411733
+M04	0.4599526245549356
+M04	0.6899762982630488
+M04	0.5931648302629847
+M04	0.5755487537233416
+M04	0.7234248193698057
+M04	0.6980927287064522
+M04	0.7003960109112879
+M04	0.5778258634871356
+M04	0.6103546168381484
+M04	0.4521780628236203
+M04	0.46430355879306856
+M04	0.4291233885469247
+M04	0.4258727037761505
+M04	0.686965067726479
+M04	0.6318294678605502
+M04	0.4797681019737849
+M04	0.6677881800109206
+M04	0.6223530890655011
+M04	0.6500346708082481
+M04	0.6470220615860736
+M04	0.5628846879371547
+M04	0.5486047721305044
+M04	0.6523768053517404
+M04	0.6198866974612594
+M04	0.5828392316869526
+M04	0.6011834385122764
+M04	0.5653553536718064
+M04	0.4462964880982585
+M04	0.5076290463904679
+M04	0.6143807934203004
+M04	0.6368136089791777
+M04	0.6541282554729455
+M04	0.6360905804771121
+M04	0.6576141711054128
+M04	0.6380712843381463
+M04	0.6150824553502202
+M04	0.5194581136709979
+M04	0.6059552227526083
+M04	0.644249007543997
+M04	0.49160011204409765
+M04	0.5066932800989277
+M04	0.5438477666097058
+M04	0.7117662527670907
+M04	0.6347408476536356
+M04	0.6928412185634422
+M04	0.7095256175085075
+M04	0.6673800666347568
+M04	0.6446271857019523
+M04	0.5629679686547984
+M04	0.5988498397971042
+M04	0.6711969020967737
+M04	0.6732483073578976
+M04	0.6441697708106691
+M04	0.6617391758008807
+M04	0.6701844716185291
+M04	0.6011954355737816
+M04	0.6854079128142234
+M04	0.6610906773968953
+M04	0.5462364466081979
+M04	0.5632356017022155
+M04	0.6347748229825577
+M04	0.6543674281776735
+M04	0.5169709336870192
+M04	0.5430969570162574
+M04	0.4952188181556061
+M04	0.4310411170944588
+M04	0.4834792136869304
+M04	0.5584961363615003
+M04	0.6190728552235799
+M04	0.41313616026872346
+M04	0.7477563026591755
+M04	0.5793914487713239
+M04	0.50654202306873
+M04	0.5963964812983499
+M04	0.5972817396622832
+M04	0.6022725225874599
+M04	0.5590114572003945
+M04	0.614805798991637
+M04	0.6541568743173586
+M04	0.5464070829143373
+M04	0.6239385518539569
+M04	0.5605955775507356
+M04	0.6581912130038915
+M04	0.5107988445926015
+M04	0.5627972848954718
+M04	0.5489471184903963
+M04	0.7190505958337088
+M04	0.7239696962055622
+M04	0.6976605494450023
+M04	0.6594533090669444
+M04	0.6315089524488071
+M04	0.5029769035857143
+M04	0.5055635073805131
+M04	0.6232413768426484
+M04	0.62312468497818
+M04	0.6035978864889826
+M04	0.6592153771755478
+M04	0.5416151330754535
+M04	0.48271775070873335
+M04	0.6589688198892765
+M04	0.7126326949269869
+M04	0.5099135326978612
+M04	0.5865728727426137
+M04	0.5234226082624385
+M04	0.5890559802072497
+M04	0.6677133693943377
+M04	0.5807875066202628
+M04	0.6431829318695867
+M04	0.6447796598113197
+M04	0.6549401911158954
+M04	0.6082596288045767
+M04	0.6259399726176114
+M04	0.6958499859738811
+M04	0.5991839181135119
+M04	0.5341062035920422
+M04	0.46609240058743323
+M04	0.6574741582483086
+M04	0.6380166218975671
+M04	0.579542609610822
+M04	0.6354706598178267
+M04	0.5872540445520997
+M04	0.662301776273754
+M04	0.5522088416701261
+M04	0.6352883986126509
+M04	0.6122207074033574
+M04	0.6793008315143051
+M04	0.5413403247033478
+M04	0.49191926195884267
+M04	0.6139183663001205
+M04	0.6487406077538155
+M04	0.6403764937922576
+M04	0.5180059082998125
+M04	0.6094745300653358
+M04	0.47504366223390915
+M04	0.5724312311064319
+M04	0.6396405930980206
+M04	0.6211435451094808
+M04	0.5515418359358011
+M04	0.6594516197354348
+M04	0.6320336826580886
+M04	0.6491347784604605
+M04	0.5942721988953604
+M04	0.4542797405837854
+M04	0.5937694861502044
+M04	0.5893330589900725
+M04	0.5361716574700118
+M04	0.5320730913393212
+M04	0.6001454589152689
+M04	0.6543269639955683
+M04	0.5157588518911704
+M04	0.5533768552413314
+M04	0.5017106058863515
+M04	0.6180693659568943
+M04	0.5387485302092142
+M04	0.5401814026707791
+M04	0.5732897178076294
+M04	0.5840839261409302
+M04	0.6538800105423112
+M04	0.5363232076872837
+M04	0.6378882850155211
+M04	0.620747012126079
+M04	0.5823256986300713
+M04	0.5469999178565464
+M04	0.42636871467127885
+M04	0.5293877811911494
+M04	0.6451406803972127
+M04	0.7039236770332457
+M04	0.5756044531097534
+M04	0.613641132502296
+M04	0.5978636815735789
+M04	0.6088463578269216
+M04	0.5428066854754939
+M04	0.40001125655853315
+M04	0.43468591345649027
+M04	0.6695598252861855
+M04	0.46510537289137327
+M04	0.5424999609428965
+M04	0.6229935746715534
+M04	0.5651219633397782
+M04	0.6325693659959395
+M04	0.713726515255991
+M04	0.5577864635536448
+M04	0.6460836894373873
+M04	0.5247688747196102
+M04	0.5744180467029202
+M04	0.47664048112561536
+M04	0.5853648705684236
+M04	0.46817940394855995
+M04	0.5528262271999804
+M04	0.5327382286923092
+M04	0.5839855187924953
+M04	0.6256052581039467
+M04	0.4241743593815046
+M04	0.5805124811117237
+M04	0.580002832376787
+M04	0.6829043220183902
+M04	0.5536093303296671
+M04	0.6403556988937581
+M04	0.6753083074925003
+M04	0.5047675370320491
+M04	0.6319576295892947
+M04	0.6457598196054467
+M04	0.6709664497773721
+M04	0.5724744957765602
+M04	0.6474031493158507
+M04	0.6393251494929059
+M04	0.6697128314888842
+M04	0.573537259176347
+M04	0.5179967212665411
+M04	0.45406059454510517
+M04	0.6047180106951718
+M04	0.44847560753392957
+M04	0.48711347423738854
+M04	0.5546144145769643
+M04	0.6422623441593424
+M04	0.6112904201101388
+M04	0.49398123341549705
+M04	0.7045351317305899
+M04	0.6354705480211535
+M04	0.7155665895209993
+M04	0.6254061028333375
+M04	0.667027771909049
+M04	0.6266868478822297
+M04	0.5928726711421305
+M04	0.6136989413170988
+M04	0.5336072774983085
+M04	0.46408380540345096
+M04	0.6962162429946877
+M04	0.6815773607551348
+M04	0.6282132404022721
+M04	0.6166796370538014
+M04	0.6662539745333586
+M04	0.5020642933825618
+M04	0.6502632674389406
+M04	0.6867523930981213
+M04	0.453215626829436
+M04	0.7139986613086133
+M04	0.6977696713733079
+M04	0.5807341983922173
+M04	0.5884065462694386
+M04	0.6047564159215981
+M04	0.642624673692888
+M04	0.6872196968982173
+M04	0.6298844140252536
+M04	0.6105690563294863
+M04	0.6701548015013117
+M04	0.628632359529514
+M04	0.5787186242825788
+M04	0.7027421454703492
+M04	0.5095698348272385
+M04	0.534747929194504
+M04	0.5323867704841363
+M04	0.6199830282138141
+M04	0.5685932176952818
+M04	0.626931852942354
+M04	0.4273564578090763
+M04	0.5732605839744769
+M04	0.5840908288358206
+M04	0.6835561898157674
+M04	0.6455488033387464
+M04	0.6009835584998914
+M04	0.7311996509553459
+M04	0.5657307065928335
+M04	0.6777189366557795
+M04	0.6600176745529448
+M04	0.5671855896993208
+M04	0.5995924566672489
+M04	0.6057847379728091
+M04	0.709751833884113
+M04	0.6732526352054107
+M04	0.6659269529108134
+M04	0.5575077685937115
+M04	0.651551255706499
+M04	0.5751596639204081
+M04	0.6006244024728502
+M04	0.7044337699995202
+M04	0.5220478002188207
+M04	0.6967840390775258
+M04	0.6369275659219192
+M04	0.5228207754831431
+M04	0.4803244675372702
+M04	0.6745735097142221
+M04	0.6031128700299866
+M04	0.5784062019552794
+M04	0.5767300600149353
+M04	0.6418396710501239
+M04	0.6365763739317488
+M04	0.5593511409857567
+M04	0.5546455297971311
+M04	0.6034517436822131
+M04	0.5621932571204776
+M04	0.6040208441897951
+M04	0.5305310792629608
+M04	0.6120402661063258
+M04	0.6458273458557197
+M04	0.6508416289147674
+M04	0.6116524811445315
+M04	0.6158402697041737
+M04	0.6057846443730771
+M04	0.7044575551833842
+M04	0.4309857173495444
+M04	0.5548086383007893
+M04	0.6762232611045018
+M04	0.6523694505579071
+M04	0.6934612351953952
+M04	0.636064426354535
+M04	0.5640712048176564
+M04	0.602891677909797
+M04	0.5887153792787577
+M04	0.5749797827374912
+M04	0.7106572111510878
+M04	0.5254876273805469
+M04	0.6553434477040612
+M04	0.5854016816399917
+M04	0.6267031771311112
+M04	0.6858329255813654
+M04	0.6806109226728377
+M04	0.703054643332264
+M04	0.6687680800608206
+M04	0.6514409664243134
+M04	0.6961083218863348
+M04	0.5910733282906726
+M04	0.5690276949137443
+M04	0.6925130504129696
+M04	0.599523585300881
+M04	0.6112062935683215
+M04	0.715439087164151
+M04	0.7254233023356494
+M04	0.4984052217907047
+M04	0.47426687733787165
+M04	0.5531556027779351
+M04	0.6208333832766707
+M04	0.30220485569166067
+M04	0.34468343205155055
+M04	0.6213030753439066
+M04	0.5386014297065645
+M04	0.642328790839417
+M04	0.5884926511317015
+M04	0.572262058284152
+M04	0.5340215021615221
+M04	0.4559778781318304
+M04	0.5315777980346177
+M04	0.6088542878262535
+M04	0.49604506189888486
+M04	0.5917175892068648
+M04	0.6229126076286361
+M04	0.6185198936621071
+M04	0.6951645675298046
+M04	0.7262256345854886
+M04	0.4349194783356436
+M04	0.3513270664814656
+M04	0.441583331773647
+M04	0.680024109493337
+M04	0.5861772735383395
+M04	0.6239994973504979
+M04	0.583348057929727
+M04	0.661523088895554
+M04	0.584064586626844
+M04	0.6224331228333354
+M04	0.6813304592485746
+M04	0.6057031559473774
+M04	0.6850357966621228
+M04	0.7307878148408538
+M04	0.6042310600828724
+M04	0.6105836243258896
+M04	0.6605887462557877
+M04	0.5078191987874905
+M04	0.5652541074036407
+M04	0.6433494238833968
+M04	0.6577508322780624
+M04	0.6390721586254293
+M04	0.7070658248657627
+M04	0.5626484440688285
+M04	0.6154752399547531
+M04	0.5527521681866785
+M04	0.6559883165325847
+M04	0.6247418935452851
+M04	0.6595978766198269
+M04	0.49072211695870216
+M04	0.6591762595181169
+M04	0.5660943310008766
+M04	0.5168357124154499
+M04	0.6732051135839822
+M04	0.565215150676689
+M04	0.5718565441504184
+M04	0.5475932113523699
+M04	0.6043649859801141
+M04	0.41145424756728394
+M04	0.620868577318795
+M04	0.6862040315890258
+M04	0.5735676579347985
+M04	0.6052116445199613
+M04	0.6504273082080055
+M04	0.6780575233336897
+M04	0.569657882087003
+M04	0.6048503751450801
+M04	0.6101432941402217
+M04	0.6098089068819942
+M04	0.6870738698641012
+M04	0.5868920149812963
+M04	0.575150526890674
+M04	0.6931856417854816
+M04	0.608688245375303
+M04	0.5868443043978928
+M04	0.6473418224150224
+M04	0.5514822205977536
+M04	0.4566488978481875
+M04	0.5848025438094093
+M04	0.5681772158350172
+M04	0.5264188190047954
+M04	0.564366524723108
+M04	0.5792028206848447
+M04	0.6516980269535585
+M04	0.6643855613702535
+M04	0.6878766617522036
+M04	0.6521344758269537
+M04	0.6711568060611194
+M04	0.5964391541757562
+M04	0.5365020232574056
+M04	0.6465287830795017
+M04	0.4112878755529838
+M04	0.6497229835851425
+M04	0.5404253780873529
+M04	0.6414524886655264
+M04	0.6329169065473633
+M04	0.5623499770210136
+M04	0.6125722848026914
+M04	0.6195285683259567
+M04	0.5640164521237186
+M04	0.5444844463787732
+M04	0.6199651717606114
+M04	0.6010336374812186
+M04	0.6637406586500842
+M04	0.6390459382876684
+M04	0.5505566913983366
+M04	0.6388698653347579
+M04	0.5129952084251599
+M04	0.608806556525805
+M04	0.6161083497520076
+M04	0.6421146951598896
+M04	0.5364881402148243
+M04	0.5065916552762133
+M04	0.5628168034750247
+M04	0.570787748054214
+M04	0.533950940367367
+M04	0.31256258504950224
+M04	0.4463564018308639
+M04	0.6134855697001318
+M04	0.4431450509318065
+M04	0.557296925646459
+M04	0.6287855174796039
+M04	0.6551946365712309
+M04	0.5292801809721648
+M04	0.5441472289389601
+M04	0.6227193461451311
+M04	0.6026636488761894
+M04	0.504797754190057
+M04	0.35539204563280996
+M04	0.6171353578951208
+M04	0.44288891150097515
+M09	0.24620555903606484
+M09	0.3948158486474247
+M09	0.39481545382333016
+M09	0.22589188373235244
+M09	0.4164325799200406
+M09	0.2696971379051062
+M09	0.4341657495140628
+M09	0.41819605673328464
+M09	0.35327106383480583
+M09	0.3372666306708152
+M09	0.2977732204334537
+M09	0.34687758866526064
+M09	0.35363218995062423
+M09	0.3933248834580169
+M09	0.30304441344393646
+M09	0.4175981710506036
+M09	0.6031179891317191
+M09	0.40642699730870574
+M09	0.4699630755122161
+M09	0.4304061770774626
+M09	0.25593731956086846
+M09	0.3893366881721898
+M09	0.3183866804178089
+M09	0.3440232929590851
+M09	0.33378698170451826
+M09	0.4656435842855631
+M09	0.250737303731089
+M09	0.2662954632867349
+M09	0.47263510682857535
+M09	0.3852864062767294
+M09	0.35377380042510803
+M09	0.5092403496521741
+M09	0.2959857814376935
+M09	0.20764951017309577
+M09	0.3396672507796114
+M09	0.4905114461474987
+M09	0.2867108983717546
+M09	0.496328663697664
+M09	0.38357211625818866
+M09	0.4044420101601225
+M09	0.40503455890391044
+M09	0.4059091093663914
+M09	0.7204344220814699
+M09	0.3850960726925079
+M09	0.3484533084971692
+M09	0.36591232531632306
+M09	0.25561342540173115
+M09	0.2952452178892852
+M09	0.26606090530103366
+M09	0.4421019757388839
+M09	0.2755984209185306
+M09	0.3941165392814342
+M09	0.3102916544481169
+M09	0.316555560420699
+M09	0.38030397875526445
+M09	0.3794383728782678
+M09	0.2841061517688109
+M09	0.372299825334455
+M09	0.5207966671644374
+M09	0.4242498502228559
+M09	0.27660129089199487
+M09	0.296260726505322
+M09	0.4195207722605183
+M09	0.3397706290385904
+M09	0.29617011959363765
+M09	0.3242797657389006
+M09	0.3205705497763428
+M09	0.3036336907541656
+M09	0.25327073184557103
+M09	0.5930601212500446
+M09	0.44535929041797256
+M09	0.30439668795546676
+M09	0.40703431681559293
+M09	0.3718968623462827
+M09	0.4490581976821987
+M09	0.5649769215826788
+M09	0.40943788032414885
+M09	0.30524832529191953
+M09	0.36546228016868887
+M09	0.25628953470202054
+M09	0.29853743326483584
+M09	0.30670991618607113
+M09	0.23570638037167485
+M09	0.30415804040527145
+M09	0.2881092739589294
+M09	0.43125097454292444
+M09	0.3313994064413522
+M09	0.29645998289684555
+M09	0.4776296209981818
+M09	0.35908515001309255
+M09	0.345374391953075
+M09	0.5451107259031465
+M09	0.37322401305899067
+M09	0.4005259837788507
+M09	0.44141009110991664
+M09	0.34960028196771725
+M09	0.5415106573842747
+M09	0.3735165606776926
+M09	0.3058938077153504
+M09	0.3812251623057208
+M09	0.3644996673826102
+M09	0.2926577287484254
+M09	0.2581052609274248
+M09	0.3369417240958422
+M09	0.5379167111065762
+M09	0.2559735300647637
+M09	0.40093175535017933
+M09	0.28069283104742215
+M09	0.2534944005947054
+M09	0.5178337713274452
+M09	0.26827077770070223
+M09	0.4584473623203238
+M09	0.2609993680670876
+M09	0.3795707753965285
+M09	0.3294009642783761
+M09	0.3836629020875285
+M09	0.3513596826488039
+M09	0.3846422546675543
+M09	0.22097584438309953
+M09	0.33675766668589097
+M09	0.45408343520857314
+M09	0.41135029184505073
+M09	0.5707863583054645
+M09	0.3661614214366847
+M09	0.31819548959033495
+M09	0.2891229228394635
+M09	0.4207870887983795
+M09	0.2323625731105838
+M09	0.4053892938630206
+M09	0.4325682129242587
+M09	0.44002391773658167
+M09	0.19164850428018346
+M09	0.46252382375257584
+M09	0.3828012594137682
+M09	0.37604749841551377
+M09	0.49805475003641403
+M09	0.358095087432385
+M09	0.4921672800226002
+M09	0.4943295294586075
+M09	0.3104770922998274
+M09	0.37815590381211434
+M09	0.4351456407703839
+M09	0.373657737334982
+M09	0.39268962300583854
+M09	0.3661966291329069
+M09	0.3043989970592146
+M09	0.5104280378848925
+M09	0.41280820587861544
+M09	0.2300769849221541
+M09	0.24486873427225286
+M09	0.48813556180436357
+M09	0.30711172214781507
+M09	0.3344846689574606
+M09	0.28548927865035373
+M09	0.4517827421584506
+M09	0.5066910675726242
+M09	0.43735831263675773
+M09	0.4099227871904444
+M09	0.46194655837188114
+M09	0.49033453713294156
+M09	0.5487673555142134
+M09	0.2804120154200782
+M09	0.3128503215977568
+M09	0.2987260814319371
+M09	0.24863089010632214
+M09	0.3092972121808167
+M09	0.2727863855298464
+M09	0.23909235690151248
+M09	0.24156832245490287
+M09	0.26237164441933325
+M09	0.3239975522389573
+M09	0.3554415443127115
+M09	0.43902650504734586
+M09	0.36586821470556624
+M09	0.49384373117039576
+M09	0.6191971044701686
+M09	0.28433448451191934
+M09	0.4861518927704656
+M09	0.25970641152397456
+M09	0.40169891233083355
+M09	0.6614059242030057
+M09	0.24642568130834733
+M09	0.6569457976081841
+M09	0.6468855669560868
+M09	0.7016393229326255
+M09	0.6937250140513309
+M09	0.557451148250703
+M09	0.6287251672735722
+M09	0.637888148757263
+M09	0.5844232841047053
+M09	0.6202372577236562
+M09	0.5925622619292857
+M09	0.6492475092813366
+M09	0.5776719314319484
+M09	0.36501571313890674
+M09	0.6013137649790189
+M09	0.6312447439599946
+M09	0.6229240061673669
+M09	0.6144902167198713
+M09	0.6625886008802231
+M09	0.611133650984098
+M09	0.29268931056692393
+M09	0.5023254427690367
+M09	0.5290568970957915
+M09	0.46511312782958103
+M09	0.5411919509304614
+M09	0.6207679559056417
+M09	0.45470215351248633
+M09	0.6662275249110302
+M09	0.5419194139035699
+M09	0.5963999364002721
+M09	0.6079680810909657
+M09	0.6559723444469933
+M09	0.6218777913985735
+M09	0.6149972366280297
+M09	0.5592700750728586
+M09	0.3641688026231279
+M09	0.46766327030902566
+M09	0.4409341263259563
+M09	0.4960828946310811
+M09	0.33507050540447664
+M09	0.6831005719476413
+M09	0.30718724817615967
+M09	0.6105721980652127
+M09	0.5581500968499735
+M09	0.5672693761751539
+M09	0.6298013285714759
+M09	0.6122018442560344
+M09	0.6287613806158695
+M09	0.5484483233416041
+M09	0.5239210449266556
+M09	0.6377801913557107
+M09	0.5972185716129723
+M09	0.6621648162151371
+M09	0.5331376258244296
+M09	0.6231829198620383
+M09	0.4952395752798406
+M09	0.5299894279478136
+M09	0.6029851515467043
+M09	0.6038061803056305
+M09	0.594812249720579
+M09	0.7262632660022008
+M09	0.7304326004430766
+M09	0.6653056876785292
+M09	0.6956612289364988
+M09	0.5159185768163155
+M09	0.6104600860660314
+M09	0.6196817810750889
+M09	0.6170174993933124
+M09	0.49757468947976696
+M09	0.2949718260707447
+M09	0.41305206086215307
+M09	0.4778749497896014
+M09	0.553381754751153
+M09	0.5771811195738472
+M09	0.6396652118972019
+M09	0.3865662547049783
+M09	0.4390946366867644
+M09	0.5294346522013397
+M09	0.713803566127512
+M09	0.6085212797668668
+M09	0.6579745026282012
+M09	0.7710719814577272
+M09	0.6138622726784647
+M09	0.5032405321163722
+M09	0.3580577703287693
+M09	0.5344628106299877
+M09	0.5635109903915976
+M09	0.6445729344497835
+M09	0.5779386029446347
+M09	0.5834924561620202
+M09	0.6597386446214011
+M09	0.6641211167093518
+M09	0.6626207214732551
+M09	0.64387123306601
+M09	0.5328854674685841
+M09	0.6223889479691964
+M09	0.5913865067470797
+M09	0.5915903935818974
+M09	0.6423807692714522
+M09	0.6210653794230018
+M09	0.6805167735244054
+M09	0.5293741394246171
+M09	0.5345526592082314
+M09	0.7162336789495833
+M09	0.6778733274187707
+M09	0.5435675699620591
+M09	0.5521239465600862
+M09	0.5743868597824264
+M09	0.627220440342816
+M09	0.5183475598970905
+M09	0.7201650222011171
+M09	0.7213597363937694
+M09	0.5011132988953765
+M09	0.546072922119871
+M09	0.36626058215076585
+M09	0.6740338523036646
+M09	0.4669647746114605
+M09	0.6490238714722931
+M09	0.5761162288042495
+M09	0.5777415311786159
+M09	0.5154762778839347
+M09	0.6244572224770704
+M09	0.45824480757958175
+M09	0.6706514950727138
+M09	0.6807644011905477
+M09	0.6174098622371365
+M09	0.5723033868132535
+M09	0.6211095224012044
+M09	0.6181948557198184
+M09	0.610045310409014
+M09	0.6004342568384432
+M09	0.6844907883095297
+M09	0.5015738176969605
+M09	0.62309893267239
+M09	0.48984101561429705
+M09	0.6042642867210388
+M09	0.6308436581142337
+M09	0.6977562182666655
+M09	0.5926785788876343
+M09	0.5751605654887956
+M09	0.6768711091147079
+M09	0.5994430929230469
+M09	0.5645272496537354
+M09	0.6265003456309189
+M09	0.4032259685306878
+M09	0.6334456860809103
+M09	0.6446849037837137
+M09	0.7133810173949305
+M09	0.6609448517704011
+M09	0.6653540903404312
+M09	0.5700834826975995
+M09	0.659644407583136
+M09	0.6047603633504965
+M09	0.5578512898968947
+M09	0.3969347991573869
+M09	0.619661210620012
+M09	0.5708872818749152
+M09	0.6587662125107462
+M09	0.45692670606321667
+M09	0.5904830655785469
+M09	0.5657882529608973
+M09	0.6312683504893132
+M09	0.6203610314289142
+M09	0.6640009903076469
+M09	0.6235033279818649
+M09	0.6115169345569111
+M09	0.4880770781592955
+M09	0.6832348704376239
+M09	0.5983848795150569
+M09	0.5818683867800568
+M09	0.6878620278644948
+M09	0.5371287722645672
+M09	0.5533017346789304
+M09	0.6062884216002742
+M09	0.5837834933311381
+M09	0.6516175634837846
+M09	0.5457909782961512
+M09	0.5552308481169009
+M09	0.594961462291569
+M09	0.5724572815044
+M09	0.6879825054423302
+M09	0.5835902765754205
+M09	0.6581924584710915
+M09	0.43683163563727434
+M09	0.7688077337526159
+M09	0.7115877494464202
+M09	0.5774991197469683
+M09	0.595310496922133
+M09	0.6345490991265992
+M09	0.5793832081701702
+M09	0.43471901543140656
+M09	0.5878646932349882
+M09	0.31050347461365646
+M09	0.5989054248213674
+M09	0.5719824533686745
+M09	0.6677865498811406
+M09	0.6309093445758371
+M09	0.6398720416727202
+M09	0.6127490365662461
+M09	0.6438016391559443
+M09	0.6513918861972253
+M09	0.664661570055445
+M09	0.543661091356072
+M09	0.6349479791750147
+M09	0.6175710418999542
+M09	0.5139594788210129
+M09	0.45513654077571364
+M09	0.5073229730425995
+M09	0.6672407395409761
+M09	0.5102790342596937
+M09	0.5800496522026057
+M09	0.6969177987927415
+M09	0.6528670167055175
+M09	0.636361533860927
+M09	0.4997688037534724
+M09	0.4112997764589862
+M09	0.5428545203510029
+M09	0.6111840739891723
+M09	0.6357141440872424
+M09	0.7291964072430858
+M09	0.6822485303256337
+M09	0.6038371640078875
+M09	0.7045129852375507
+M09	0.47900429517686155
+M09	0.536642017978097
+M09	0.45262422076138736
+M09	0.438138948770357
+M09	0.6452606862430502
+M09	0.6032211445288291
+M09	0.5257133787918417
+M09	0.4528522529348289
+M09	0.5920148882756908
+M09	0.6031496436451262
+M09	0.6010080946679298
+M09	0.6411467038148027
+M09	0.40105321201495714
+M09	0.7629501000965416
+M09	0.5126634917357257
+M09	0.635040840230265
+M09	0.6587539161274364
+M09	0.6848751881394363
+M09	0.6223292282333244
+M09	0.5826885125266963
+M09	0.3337073174193933
+M09	0.6117443293680639
+M09	0.38194933678927806
+M09	0.6357321398963023
+M09	0.599723023845856
+M09	0.6786980087967057
+M09	0.526930779143327
+M09	0.5284573723249907
+M09	0.5384331262252635
+M09	0.6100061562030749
+M09	0.6983667052319057
+M09	0.70607528713194
+M09	0.6490697636320373
+M09	0.6327694788770591
+M09	0.6193884207711099
+M09	0.64699165959982
+M09	0.5697184926102132
+M09	0.5971921555281454
+M09	0.6517389240977853
+M09	0.6215958048200194
+M09	0.5405031574924334
+M09	0.471055830071932
+M09	0.4382442541319232
+M09	0.46418151167646615
+M09	0.6115517760213663
+M09	0.6196960978944709
+M09	0.5650507910096341
+M09	0.5931268761180677
+M09	0.6566289408653856
+M09	0.6861630909746889
+M09	0.6096755196190481
+M09	0.6233430008406463
+M09	0.6157417641829532
+M09	0.5814551385050937
+M09	0.6430223533140089
+M09	0.6516934152004151
+M09	0.7145642986989925
+M09	0.7370996729992619
+M09	0.5802842301260617
+M09	0.5728846675710916
+M09	0.3850513752138698
+M09	0.4890915270706432
+M09	0.6348880541273836
+M09	0.556963064364106
+M09	0.7133121521136205
+M09	0.6140747272432797
+M09	0.6273118223953397
+M09	0.49138653241282326
+M09	0.6705819851267492
+M09	0.4969164336427393
+M09	0.3666142625045911
+M09	0.6489330156329551
+M09	0.5704569438419816
+M09	0.5830033374575088
+M09	0.5931726600840209
+M09	0.6614687521364443
+M09	0.5867528691807016
+M09	0.4825210250272749
+M09	0.6204171844664034
+M09	0.5302356158534177
+M09	0.5066265872167917
+M09	0.6542408510128277
+M09	0.5496956091283228
+M09	0.5099876262237726
+M09	0.591048618875664
+M09	0.452146072090296
+M09	0.5621570190336993
+M09	0.6044854323306578
+M09	0.5726760722554869
+M09	0.6089356236854789
+M09	0.5862945605266067
+M09	0.646529677691741
+M09	0.6117382242312579
+M09	0.5347943123933634
+M09	0.5844237033744757
+M09	0.6532086105062039
+M09	0.5763956338075661
+M09	0.521309586372615
+M09	0.637685057153101
+M09	0.5787887764882658
+M09	0.6838077514975066
+M09	0.5312583334643328
+M09	0.6189100446392204
+M09	0.6540016644640501
+M09	0.7193575832951142
+M09	0.6551781287447336
+M09	0.5144874695629594
+M09	0.6151516595352777
+M09	0.6301059877162968
+M09	0.6546603084433745
+M09	0.6066324986714665
+M09	0.4715908119655192
+M09	0.5935782069408937
+M09	0.6059499822792896
+M09	0.5511614114613252
+M09	0.5174427429395921
+M09	0.574317096743785
+M09	0.6943720503869286
+M09	0.6103167304334859
+M09	0.6144745456785876
+M09	0.6520426773048561
+M09	0.5495805883633558
+M09	0.6759154179495137
+M09	0.6885235378183573
+M09	0.5317174049855771
+M09	0.5678434316524074
+M09	0.5992994833627265
+M09	0.5162800343661367
+M09	0.46464159663427507
+M09	0.6121165473155967
+M09	0.5583574721545982
+M09	0.4724249981204705
+M09	0.5642654388061383
+M09	0.5008260446965734
+M09	0.6521828321926278
+M09	0.4662737643852922
+M09	0.5789828298817459
+M09	0.5747530101485746
+M09	0.6648670517668858
+M09	0.6264060432851983
+M09	0.6696727926823027
+M09	0.6642862265219472
+M09	0.6463352243594871
+M09	0.6471049355516196
+M09	0.6364736740343291
+M09	0.5833716728645869
+M09	0.6029125645570698
+M09	0.6087075498838044
+M09	0.6752729144191009
+M09	0.643685003159432
+M09	0.6147516821772091
+M09	0.5205257720510417
+M09	0.6416593683688642
+M09	0.6307598202377127
+M09	0.5687523388686628
+M09	0.4797429689372655
+M09	0.5626762170098617
+M09	0.6379764424645952
+M09	0.5928470368748283
+M09	0.6458819608685408
+M01	0.18552717512553676
+M01	0.34423874429892987
+M01	0.40085683233759756
+M01	0.2445656842643939
+M01	0.4125208973345468
+M01	0.10958581057511031
+M01	0.3894463272790612
+M01	0.40305432903674243
+M01	0.33664148692762147
+M01	0.342638448307639
+M01	0.28605282663851916
+M01	0.2587117306093814
+M01	0.36115185632573493
+M01	0.38438685755339513
+M01	0.20251180353621673
+M01	0.40698332976830376
+M01	0.5509549191221178
+M01	0.4167851589284333
+M01	0.4192379756971553
+M01	0.39447950411390303
+M01	0.2665917212441062
+M01	0.3757329427663056
+M01	0.281838746883395
+M01	0.3472370519254497
+M01	0.3234888734597156
+M01	0.27610731280368794
+M01	0.1182680307585708
+M01	0.25330276338704705
+M01	0.5149447160485661
+M01	0.3914735223731941
+M01	0.39310650719149515
+M01	0.4764458190753373
+M01	0.3406055141381135
+M01	0.21839408373363128
+M01	0.2539756184655083
+M01	0.4409343142462494
+M01	0.2841063373449171
+M01	0.4785116680868929
+M01	0.29968133842714184
+M01	0.3606325097658951
+M01	0.39877981113787825
+M01	0.4333194911530902
+M01	0.7041120317616271
+M01	0.37504887765481837
+M01	0.3073696829425746
+M01	0.37372827621783067
+M01	0.34803474561745507
+M01	0.2229876273416782
+M01	0.33606722313492515
+M01	0.42015591724055623
+M01	0.17414886987390782
+M01	0.40005223395458966
+M01	0.28933730708048655
+M01	0.32084764955649314
+M01	0.35088014770477327
+M01	0.454943239081389
+M01	0.21262651028762994
+M01	0.2935951553349123
+M01	0.5080136876700048
+M01	0.3536656411568511
+M01	0.3120312817955264
+M01	0.20381860945129512
+M01	0.33402719365085615
+M01	0.32760011053339094
+M01	0.23970870525025362
+M01	0.32955866093974373
+M01	0.2584849946967293
+M01	0.23335848982953325
+M01	0.28656819600258926
+M01	0.5811674850283558
+M01	0.42476941883175445
+M01	0.28991120882835847
+M01	0.35402380491865565
+M01	0.2911769175286332
+M01	0.4466014237840706
+M01	0.5541141286235689
+M01	0.4499563665877308
+M01	0.27338730278417933
+M01	0.3756365363770192
+M01	0.2942567002010192
+M01	0.28013496256293224
+M01	0.28737350237225295
+M01	0.3163817709383835
+M01	0.2586481529441115
+M01	0.2663875489048407
+M01	0.4100701136297126
+M01	0.37227242966290064
+M01	0.28353953153775124
+M01	0.43652371711160404
+M01	0.30177910356126636
+M01	0.17891971811006757
+M01	0.4206986519164201
+M01	0.40778774792130146
+M01	0.31725043297855615
+M01	0.525170220913029
+M01	0.29071228275065963
+M01	0.5391007014314777
+M01	0.35864140233024294
+M01	0.2547989736011117
+M01	0.41287227562776213
+M01	0.3456963545856325
+M01	0.316291827923396
+M01	0.18408862379036056
+M01	0.361220733795789
+M01	0.5612689477244273
+M01	0.2817933083574384
+M01	0.3128220779846835
+M01	0.25892866871695674
+M01	0.24781484444432972
+M01	0.5020777509456053
+M01	0.2700922729037634
+M01	0.4083149559921326
+M01	0.2058761111583174
+M01	0.3348096927310133
+M01	0.3298252471362621
+M01	0.41269948741169615
+M01	0.3337244087722776
+M01	0.37494711831142513
+M01	0.17092311088774387
+M01	0.35177389947657395
+M01	0.47689741812131986
+M01	0.46127728598366347
+M01	0.4676168650714051
+M01	0.3527605091056717
+M01	0.3581209356198067
+M01	0.2559358478333558
+M01	0.37138235538357023
+M01	0.2781242793909927
+M01	0.401293805482939
+M01	0.4160565822663907
+M01	0.34263356003720963
+M01	0.16979431321973437
+M01	0.4490294595757419
+M01	0.4140483401435553
+M01	0.34501901046053324
+M01	0.46909259446078705
+M01	0.3677683217828932
+M01	0.5296470920131054
+M01	0.47338058534786404
+M01	0.3749411129692097
+M01	0.36846486468951595
+M01	0.4485568619554325
+M01	0.29187820709148843
+M01	0.3408366585519685
+M01	0.34815666424070074
+M01	0.2687369206684254
+M01	0.4368368351118656
+M01	0.38366285845391773
+M01	0.22949372989952158
+M01	0.2805181217164194
+M01	0.4702704142871783
+M01	0.3102436984947936
+M01	0.3402961896621192
+M01	0.28209640694304366
+M01	0.4082384864106881
+M01	0.4745463483062862
+M01	0.2791240571137858
+M01	0.38480303350870476
+M01	0.3946138155313427
+M01	0.48114933346108296
+M01	0.4792146119825492
+M01	0.2831976517153227
+M01	0.3211361307530807
+M01	0.2846184634655023
+M01	0.19437397472686369
+M01	0.39022666876263623
+M01	0.24506314997653414
+M01	0.2276166178693257
+M01	0.2618566719452272
+M01	0.2963469683210766
+M01	0.19056258686936733
+M01	0.3619026058530526
+M01	0.4379212327951469
+M01	0.2866852890912208
+M01	0.46213523654229033
+M01	0.4699027906172139
+M01	0.29740598183569666
+M01	0.47066490849451253
+M01	0.2589988774820793
+M01	0.38800339321916144
+M02	0.25562207217995037
+M02	0.377079548085495
+M02	0.38201839392565495
+M02	0.26016220082508534
+M02	0.4286467025718982
+M02	0.30208095129460855
+M02	0.39703150546247584
+M02	0.35536029578477196
+M02	0.34594377505088647
+M02	0.3367171703430332
+M02	0.3004418132826703
+M02	0.3620363885811449
+M02	0.3520548396951445
+M02	0.3464715278792007
+M02	0.29273992976823304
+M02	0.4088459440766598
+M02	0.4193019437077293
+M02	0.39523528020205734
+M02	0.5337180458764407
+M02	0.4123115536841725
+M02	0.2933445139989934
+M02	0.41352486055622323
+M02	0.3190193758517901
+M02	0.3624837211522492
+M02	0.3298063266111217
+M02	0.44843051883198265
+M02	0.23131161619333704
+M02	0.2998910935267604
+M02	0.48914000473518027
+M02	0.448001298226952
+M02	0.3952109005968992
+M02	0.4393335877238141
+M02	0.34184939666128694
+M02	0.2483884390020688
+M02	0.38283225005336036
+M02	0.47343582859217054
+M02	0.2990319141539463
+M02	0.512307842557608
+M02	0.3602583122401828
+M02	0.41578122461931594
+M02	0.42310129078553427
+M02	0.4569678000615419
+M02	0.6541988323755351
+M02	0.39438346068886104
+M02	0.34769622583703436
+M02	0.2808862738095513
+M02	0.3168944937004606
+M02	0.28257525431770625
+M02	0.32624430968041046
+M02	0.45149775507872425
+M02	0.27364756025610815
+M02	0.3799811873337779
+M02	0.32064776332308054
+M02	0.3244422969090745
+M02	0.37030205158294577
+M02	0.47604242968210236
+M02	0.3038256505101421
+M02	0.32973017463753784
+M02	0.5053057713241661
+M02	0.4096955392608256
+M02	0.304454790730571
+M02	0.2665879599533132
+M02	0.40974616789346086
+M02	0.30983567659601846
+M02	0.2705031789360504
+M02	0.3264784101387327
+M02	0.37710526506563524
+M02	0.32777027832682404
+M02	0.2685851192900389
+M02	0.5786736585688005
+M02	0.45118056451260424
+M02	0.2911883544532312
+M02	0.4223512053603014
+M02	0.3797380771887868
+M02	0.4428811450585722
+M02	0.5470412588449796
+M02	0.4423223590332026
+M02	0.2914160824156477
+M02	0.3837033679663056
+M02	0.31255594561046113
+M02	0.3568868427932119
+M02	0.30282277358343074
+M02	0.2843743622405857
+M02	0.26709651035773396
+M02	0.2555056574202832
+M02	0.4450693566838286
+M02	0.3055891918628504
+M02	0.3213449682660836
+M02	0.4339855065205863
+M02	0.27548461542610414
+M02	0.2547270518792048
+M02	0.5486442074742705
+M02	0.38781233837036494
+M02	0.40240028959856805
+M02	0.5299687820897802
+M02	0.34239465102914834
+M02	0.5411746022876502
+M02	0.3392044292399982
+M02	0.3458236352032568
+M02	0.4101232254186599
+M02	0.360583418749225
+M02	0.2651388394881618
+M02	0.26826617930891594
+M02	0.36914575065154753
+M02	0.5391178998933656
+M02	0.3151471615978223
+M02	0.3560968841546306
+M02	0.302727829681203
+M02	0.24425824262384713
+M02	0.48744193708871647
+M02	0.2955506242099992
+M02	0.3848500772803996
+M02	0.2809894922326896
+M02	0.3655946645917917
+M02	0.34465980232408727
+M02	0.3639255206061961
+M02	0.4293566810796299
+M02	0.36870985419965796
+M02	0.17528577454624975
+M02	0.3869203748722883
+M02	0.4047092066928778
+M02	0.31332459118305084
+M02	0.531652909584508
+M02	0.38023208697837585
+M02	0.32234555494719613
+M02	0.35721777040275077
+M02	0.4137982968530577
+M02	0.28408163737136577
+M02	0.4261056951557693
+M02	0.43406259663520086
+M02	0.4114579979752785
+M02	0.20092940512376029
+M02	0.4656818302318497
+M02	0.4034022879041429
+M02	0.3785604601303087
+M02	0.4650999696893829
+M02	0.3896805013507149
+M02	0.5473179304476882
+M02	0.2947793961326203
+M02	0.3600914733484818
+M02	0.30655945583332833
+M02	0.37819065463679374
+M02	0.3604531042650462
+M02	0.3744466488447227
+M02	0.38871123648574524
+M02	0.27625896336704603
+M02	0.49032882095835184
+M02	0.4104019386034641
+M02	0.2580483255065758
+M02	0.30121069877924606
+M02	0.46379957916792236
+M02	0.31539464992196603
+M02	0.38297577173584835
+M02	0.24285830827685106
+M02	0.38307710795102556
+M02	0.4806513408228262
+M02	0.42508572211223494
+M02	0.3558082595746324
+M02	0.39256454868550655
+M02	0.45151814809190804
+M02	0.5410943810648294
+M02	0.3138869261033844
+M02	0.3471699548213026
+M02	0.2810695045627499
+M02	0.27604218533124
+M02	0.37889330345111893
+M02	0.30605170635233503
+M02	0.20233401383326013
+M02	0.26616989365453947
+M02	0.2644128781648513
+M02	0.3275827103244735
+M02	0.3634679669396793
+M02	0.42625971361819753
+M02	0.29045889863241203
+M02	0.47659110917124536
+M02	0.5870622709360591
+M02	0.3198500238309773
+M02	0.39286196875599494
+M02	0.30599125927814985
+M02	0.3214737709711416
+M02	0.6171903716728963
+M02	0.5200584072929498
+M02	0.6560692647305689
+M02	0.6439867969948827
+M02	0.7131932766915384
+M02	0.6703512729444837
+M02	0.5609402695062472
+M02	0.4751380202173237
+M02	0.4691153951817819
+M02	0.553278920247045
+M02	0.5542031980433055
+M02	0.5255865415546779
+M02	0.5109001732330112
+M02	0.5646631745339096
+M02	0.5142116752939793
+M02	0.5773524069705761
+M02	0.4838707068909351
+M02	0.6052218188139934
+M02	0.5473208960636149
+M02	0.6617240019796885
+M02	0.5884407656446361
+M02	0.44090527828187615
+M02	0.5605287518396534
+M02	0.574791340540517
+M02	0.5524466889596583
+M02	0.5470137640480665
+M02	0.6404552254937581
+M02	0.630761866710482
+M02	0.5883859951613895
+M02	0.5663835720930669
+M02	0.6213164569054953
+M02	0.4777922902262829
+M02	0.649741272552248
+M02	0.5982002669568751
+M02	0.6075889670765464
+M02	0.6002285458294295
+M02	0.5235419204091866
+M02	0.6571977746126199
+M02	0.5945890192220973
+M02	0.5985971007521215
+M02	0.6465741834882912
+M02	0.5500311099648304
+M02	0.42650327857792075
+M02	0.51092035246109
+M02	0.5493617770829419
+M02	0.603275903557361
+M02	0.6167156988308798
+M02	0.5971767271908056
+M02	0.6086972762325491
+M02	0.4934462550330879
+M02	0.5396741725926266
+M02	0.6243232836157108
+M02	0.6005194215957868
+M02	0.5739638706461844
+M02	0.6009788141438005
+M02	0.5994945836003925
+M02	0.5847284877336726
+M02	0.5783632762985611
+M02	0.6388058869460631
+M02	0.7174680516056465
+M02	0.6505631295642661
+M02	0.6709919437611099
+M02	0.6547521317193966
+M02	0.47037221777069976
+M02	0.6024682851681514
+M02	0.38904952238122176
+M02	0.5295047753069706
+M02	0.5829616821545602
+M02	0.46049022533281997
+M02	0.5247499536650209
+M02	0.5199438603522905
+M02	0.5293415890787531
+M02	0.46334263915728197
+M02	0.5790654696743125
+M02	0.5644725275162611
+M02	0.6234257053662167
+M02	0.513439945584368
+M02	0.349524078156637
+M02	0.5568806852060026
+M02	0.6923238850672886
+M02	0.5876533904012611
+M02	0.43047828943028155
+M02	0.6495331154119363
+M02	0.6617432143795526
+M02	0.701460303192035
+M02	0.579151793708354
+M02	0.6054260846810268
+M02	0.5493062479757748
+M02	0.6555803868463137
+M02	0.6230607142728797
+M02	0.40091158960979767
+M02	0.3758175405300384
+M02	0.6269829824893455
+M02	0.5984925966257644
+M02	0.5986039264040732
+M02	0.5242980751029032
+M02	0.4999962730539795
+M02	0.5204781001235087
+M02	0.3841401913457045
+M02	0.5852248581145696
+M02	0.5722027798094487
+M02	0.580366498273256
+M02	0.6272079166638987
+M02	0.5311063549663305
+M02	0.5072376589193214
+M02	0.6270735974362996
+M02	0.4781317647444879
+M02	0.5944077302250063
+M02	0.6416951157754294
+M02	0.6203297352688145
+M02	0.6056282905554188
+M02	0.6663339761167377
+M02	0.6674276521689015
+M02	0.5386301900591444
+M02	0.558761291110642
+M02	0.3982357381051367
+M02	0.47039685786553925
+M02	0.6670960510886523
+M02	0.6256603056192539
+M02	0.626164782969351
+M02	0.5852529723636467
+M02	0.5867017814251879
+M02	0.5851780084047938
+M02	0.6416821054345974
+M02	0.5907147229180236
+M02	0.5839698239794084
+M02	0.6032863028623108
+M02	0.468619082204215
+M02	0.6378955125101392
+M02	0.5550165103767908
+M02	0.585349761557175
+M02	0.5896850942633779
+M02	0.6718110813523301
+M02	0.49335899162213087
+M02	0.6269899000912497
+M02	0.5320082797822095
+M02	0.6007309710779782
+M02	0.6557035699294149
+M02	0.6056754253092713
+M02	0.42626793531370993
+M02	0.40290684673055244
+M02	0.6660275686223702
+M02	0.6411676380321828
+M02	0.5339566558209125
+M02	0.6778439050830961
+M02	0.5192590893693878
+M02	0.6695136617932443
+M02	0.6421289490965918
+M02	0.6038025246287333
+M02	0.6119446287203502
+M02	0.49028485297027086
+M02	0.3357913852187861
+M02	0.6239812902036636
+M02	0.6030672488816725
+M02	0.49615667049927975
+M02	0.6294206418273736
+M02	0.6667384415152033
+M02	0.622909878829663
+M02	0.6203322304688353
+M02	0.6661964332068064
+M02	0.4852233355297407
+M02	0.26769051519491993
+M02	0.4904953716031315
+M02	0.5722632855651154
+M02	0.6709102189407505
+M02	0.5818990308504635
+M02	0.5219007078364829
+M02	0.5073026793155178
+M02	0.44936285285827643
+M02	0.5608816709757801
+M02	0.5354264992676769
+M02	0.6430612414511636
+M02	0.5900288799596533
+M02	0.6833845008613
+M02	0.5717279962923444
+M02	0.6386362885290191
+M02	0.4896167172767403
+M02	0.6101640522814143
+M02	0.4792965589996034
+M02	0.5971854779099584
+M02	0.6727510850211845
+M02	0.6574242212191599
+M02	0.5498878547578901
+M02	0.6811566933599618
+M02	0.6427291100301054
+M02	0.6705723184816909
+M02	0.6929475897066596
+M02	0.3474440725110904
+M02	0.7112095211032345
+M02	0.65822392764721
+M02	0.6224346023180157
+M02	0.5786772130608968
+M02	0.5031865678596984
+M02	0.551074744515566
+M02	0.6355973608321918
+M02	0.6140888542327948
+M02	0.5482647818814798
+M02	0.6396689090250459
+M02	0.5337619028433431
+M02	0.5458407167858211
+M02	0.6419242377426354
+M02	0.49819469137083505
+M02	0.5118599097771807
+M02	0.42789294623668095
+M02	0.6197700466557263
+M02	0.6361225743191099
+M02	0.41568492565897563
+M02	0.5774657107167886
+M02	0.4304389781383794
+M02	0.6602429503917832
+M02	0.6203665717231531
+M02	0.5835005721513018
+M02	0.6993806361083322
+M02	0.6153923643287502
+M02	0.64642703722265
+M02	0.5844327719159205
+M02	0.6451443964644169
+M02	0.6194219942821947
+M02	0.5067460060328771
+M02	0.6830474736409845
+M02	0.7231973114948159
+M02	0.593186012381712
+M02	0.45859511755728755
+M02	0.6261846069375676
+M02	0.6071146175747492
+M02	0.34784126602493565
+M02	0.5438047591138734
+M02	0.41071444798195156
+M02	0.650731163297351
+M02	0.5548884197556568
+M02	0.5860467160739407
+M02	0.6053683132685475
+M02	0.5834887941832376
+M02	0.5861008342053039
+M02	0.4887164169824558
+M02	0.600764839925047
+M02	0.44434800847825895
+M02	0.7183796780206432
+M02	0.5943448159512815
+M02	0.6023256086832924
+M02	0.5165045538044967
+M02	0.5232833526121142
+M02	0.5791622389247537
+M02	0.5338646900860515
+M02	0.6505110207619121
+M02	0.7008471403836652
+M02	0.6147993786458373
+M02	0.5272702391612828
+M02	0.4614207849933811
+M02	0.6421003822742171
+M02	0.29159676903420617
+M02	0.3974839347267498
+M02	0.5871220148940647
+M02	0.7290585277336064
+M02	0.6797974681497133
+M02	0.6955069583483259
+M02	0.6180970644723102
+M02	0.6140879695649699
+M02	0.5943146848570189
+M02	0.6101569238001384
+M02	0.6154226600903469
+M02	0.5682957216803907
+M02	0.5874600105032901
+M02	0.6289747030275444
+M02	0.6406477483251773
+M02	0.5583499252332582
+M02	0.6524243766781086
+M02	0.64586333572453
+M02	0.5534285980270576
+M02	0.5942685617050182
+M02	0.3968606013150563
+M02	0.5106867627582442
+M02	0.6282367058464741
+M02	0.6842266836713017
+M02	0.5695963099395744
+M02	0.6723969231149458
+M02	0.6588939229668966
+M02	0.6089114557756026
+M02	0.603375085578578
+M02	0.6969606783072545
+M02	0.6992548978886118
+M02	0.6715991734888932
+M02	0.4630455516946872
+M02	0.5110815101247844
+M02	0.529683599588696
+M02	0.5245070276184554
+M02	0.5948722641201712
+M02	0.558481960693563
+M02	0.6741508772053869
+M02	0.6016369888202409
+M02	0.6126002932387994
+M02	0.6159516784988656
+M02	0.6823997119655916
+M02	0.6196431232814876
+M02	0.5106738830194509
+M02	0.6428866618138611
+M02	0.6388517523190841
+M02	0.6392162680600203
+M02	0.5761900904797019
+M02	0.6342673393300736
+M02	0.5167237046040076
+M02	0.5536768980115092
+M02	0.3988891967289328
+M02	0.582104911586552
+M02	0.5954543144554236
+M02	0.6393960520503329
+M02	0.6177568934654627
+M02	0.5352450426416087
+M02	0.5721021848386979
+M02	0.5199682143122449
+M02	0.4690813529295931
+M02	0.44750163073376237
+M02	0.6014806730775888
+M02	0.6036425435677857
+M02	0.46550802214614195
+M02	0.4672117472247011
+M02	0.590001867320164
+M02	0.3377400395693352
+M02	0.3324477423869508
+M02	0.35903907455365386
+M02	0.4491314218265687
+M02	0.5337672171995763
+M02	0.49830465309755423
+M02	0.511892115435467
+M02	0.6032801525420196
+M02	0.41261722112832155
+M02	0.4607294745921804
+M02	0.3722491998106422
+M02	0.5969780866247721
+M02	0.5801192107148815
+M02	0.3391106981967857
+M02	0.5508266408174239
+M02	0.5134965834097549
+M02	0.6858312389648528
+M02	0.5928992273447958
+M02	0.5933575226250091
+M02	0.5521446109551914
+M02	0.5739693582465674
+M02	0.5514123466795431
+M02	0.5057269162402485
+M02	0.48753726683255055
+M02	0.6712794296447402
+M02	0.6188308189126869
+M02	0.5647268566292885
+M02	0.6272015961572049
+M02	0.5503633058677125
+M02	0.6578001414345722
+M02	0.5986301854141051
+M02	0.582034544243236
+M02	0.5532532729039177
+M02	0.3551628048348692
+M02	0.5346266228948222
+M02	0.472079030871168
+M02	0.5762653051343786
+M02	0.4683008491595214
+M02	0.3432021254942949
+M02	0.5601394807513888
+M02	0.46201472076337724
+M02	0.5168217948124398
+M02	0.3974027389644345
+M02	0.5712098087783717
+M02	0.5188071930750007
+M02	0.650477452606969
+M02	0.4968756380265787
+M02	0.4808832345408183
+M02	0.45608401692880346
+M02	0.39197041779039304
+M02	0.46924508412396154
+M02	0.6483184094196346
+M02	0.6467165369629464
+M02	0.6164068097147097
+M02	0.562060167353338
+M02	0.5061103719273123
+M02	0.5695713420878251
+M02	0.5229659942210666
+M02	0.5793345504799496
+M02	0.6319321539441369
+M02	0.6207802493528839
+M02	0.5996838463573351
+M02	0.5358225485440969
+M02	0.4507827100155659
+M02	0.5527062185944752
+M02	0.5370278092424964
+M02	0.595402850129427
+M02	0.6742419625353359
+M02	0.3777190872019376
+M02	0.631310111308121
+M02	0.6999242025913361
+M02	0.7575716586690798
+M02	0.5837017691128993
+M02	0.6012087255311114
+M02	0.5932943776768398
+M02	0.621440005143701
+M02	0.533389327153614
+M02	0.7185224804362769
+M02	0.7366552016813377
+M02	0.5593988331151704
+M02	0.4185696095552991
+M02	0.5718365958834839
+M02	0.5090609977374186
+M02	0.44975507742350823
+M02	0.6366026124953846
+M02	0.6818612710604
+M02	0.6618663454089547
+M02	0.665193905273213
+M02	0.6819633809541389
+M02	0.6464349577280292
+M02	0.6851118637432347
+M02	0.6578634854383782
+M02	0.694307649282829
+M02	0.3549427845576915
+M02	0.43794227404594305
+M02	0.6486441007536937
+M02	0.59715352448872
+M02	0.6108882002780122
+M02	0.3631980184210748
+M02	0.6085432499517879
+M02	0.7035536495020183
+M02	0.6892844546769528
+M02	0.7095139353901333
+M02	0.5793601389031972
+M02	0.6568976873089504
+M02	0.5767915788564439
+M02	0.5707343375454214
+M02	0.6385817343930725
+M02	0.4956901499110722
+M02	0.622596305288674
+M02	0.5828459844231436
+M02	0.6404817343873115
+M02	0.5932817000451557
+M02	0.5809095212371165
+M02	0.6492082940659891
+M02	0.5554357584698957
+M02	0.5777061176049357
+M02	0.5339378837613075
+M02	0.6938638316663085
+M02	0.5651441190876632
+M02	0.5279264773785041
+M02	0.735395055399342
+M02	0.7037970539630433
+M02	0.5198987322513274
+M02	0.6038892565512479
+M02	0.6913669602554489
+M02	0.5705027635109009
+M02	0.6636315115338459
+M02	0.6712299931135218
+M02	0.6164755847944551
+M02	0.6338829670016265
+M02	0.6365218102098846
+M02	0.5141755844952932
+M02	0.5839624018374667
+M02	0.612438017874131
+M02	0.5637241321066324
+M02	0.4442762871148759
+M02	0.6300867864607671
+M02	0.6674128552047862
+M02	0.6942611655804466
+M02	0.5399412573037945
+M02	0.5869312646716233
+M02	0.5243106913757465
+M02	0.6022055395901325
+M02	0.5771718630938969
+M02	0.6818152598537838
+M02	0.6205863104563722
+M02	0.5995369074653828
+M02	0.6506595749557516
+M02	0.68437488652929
+M02	0.36621379327928316
+M02	0.6620102947100126
+M02	0.5500234988920798
+M02	0.6495469775032324
+M02	0.5803867511031088
+M02	0.6542501450883397
+M02	0.6255028758949216
+M02	0.4765470994195799
+M02	0.5956131134143979
+M02	0.43716288414143606
+M02	0.49951276308735176
+M02	0.5730534564997206
+M02	0.5241050790671903
+M02	0.6351976424828363
+M02	0.5468854238383681
+M02	0.688582071101637
+M02	0.7311238895418445
+M02	0.6985257967080569
+M02	0.6926570150854231
+M02	0.655397573104597
+M02	0.6027824945766816
+M02	0.5718769754136329
+M02	0.6252343557162119
+M02	0.6660962436976976
+M02	0.6273032576707626
+M02	0.6592194702889188
+M02	0.6648092944346622
+M02	0.6709138916072553
+M02	0.4293257042729284
+M02	0.4298313448628097
+M02	0.6017762782468106
+M02	0.5630535549670942
+M02	0.5542065822489128
+M02	0.4765445157554427
+M02	0.6187259733737702
+M02	0.5106775386306616
+M02	0.6161047857598494
+M02	0.6010872948696806
+M02	0.6049708867204276
+M02	0.4796521899750806
+M02	0.5159611902651324
+M02	0.6417536434971347
+M02	0.6522499449552136
+M02	0.4150476555899408
+M02	0.47999012567180754
+M02	0.673742601837602
+M02	0.5448512889985381
+M02	0.6903734340959446
+M02	0.7217459109465658
+M02	0.5928722534000678
+M02	0.6031360087357055
+M02	0.5983460862377299
+M02	0.6587432033264576
+M02	0.6622319267102634
+M02	0.6579211696044621
+M02	0.6617530553196578
+M02	0.6177156545505289
+M02	0.4183957301898417
+M02	0.6225673797740314
+M02	0.6270798622440051
+M02	0.5701682524932722
+M02	0.7098037861863621
+M02	0.6157142401880011
+M02	0.6546924769252164
+M02	0.619593289008557
+M02	0.6586785700148015
+M02	0.5679465651709865
+M02	0.5737474634855462
+M02	0.5096314407586399
+M02	0.45406336460646485
+M02	0.5631688594387456
+M02	0.7253477674366904
+M02	0.5297099156477241
+M02	0.6145866126493043
+M02	0.6414977540791934
+M02	0.7299103397640822
+M02	0.622816085257335
+M02	0.6762511773659611
+M02	0.5631627461919473
+M02	0.6377695526118442
+M02	0.5139987140254796
+M02	0.5381020239884595
+M02	0.6395042141839333
+M02	0.598490814227281
+M02	0.5891787535591667
+M02	0.5163321082205883
+M02	0.7063836678578034
+M02	0.5909276336442787
+M02	0.6011188746010157
+M02	0.506367141994173
+M02	0.553636715209522
+M02	0.5050639017460838
+M02	0.5443319909881995
+M02	0.666619687871524
+M02	0.4098935428512717
+M02	0.5770895958373191
+M02	0.70807223928869
+M02	0.6637477644545143
+M02	0.6214057919181821
+M02	0.5423681114886074
+M02	0.5914256088584279
+M02	0.6213257608702922
+M02	0.5830571748773493
+M02	0.6658492164787684
+M02	0.6042643826498362
+M02	0.516493357539297
+M02	0.600373780969284
+M02	0.6266165425887218
+M02	0.7019373919668889
+M02	0.6932882446338894
+M02	0.5189684402091669
+M02	0.4789790064218355
+M02	0.6410845162170525
+M02	0.5929012763356998
+M02	0.6968126245275367
+M02	0.6313546024473878
+M02	0.6928397852971021
+M02	0.36695142141914644
+M02	0.5378441601327146
+M02	0.6753988425969905
+M02	0.4132883846601311
+M02	0.6294871184707237
+M02	0.544495645726732
+M02	0.5976417404442296
+M02	0.6889248502881591
+M02	0.5729985542809893
+M02	0.6330769360705591
+M02	0.6153831809918078
+M02	0.5618445447779166
+M02	0.6029497594397927
+M02	0.584689410995331
+M02	0.5442157849619444
+M02	0.692650627944797
+M02	0.7576403037116018
+M02	0.6028332742220586
+M02	0.6572390071192107
+M02	0.7345504705196916
+M02	0.595904233887253
+M02	0.6141162421380729
+M02	0.6391318764571745
+M02	0.5551155992357476
+M02	0.4949271818286765
+M02	0.5916480488150992
+M02	0.6482370349455943
+M02	0.6994888873253668
+M02	0.4650029768638498
+M02	0.5161282421000555
+M02	0.5478608170323123
+M02	0.43106818519764656
+M02	0.48481286918018623
+M02	0.5250047987549684
+M02	0.6560559279795048
+M02	0.5846698470650132
+M02	0.6113027633283298
+M02	0.6112309207914663
+M02	0.6141989162020687
+M02	0.5623040342624169
+M02	0.6247320721681004
+M02	0.487305414220859
+M02	0.5657162160982973
+M15	0.2276575295684517
+M15	0.392019586169226
+M15	0.3303514218492971
+M15	0.19007101237399465
+M15	0.400815015885644
+M15	0.31525571965984694
+M15	0.3817587097217731
+M15	0.4229248230248237
+M15	0.35398524661893427
+M15	0.3342776360164593
+M15	0.2431875085330122
+M15	0.28483563706209636
+M15	0.3963621189120035
+M15	0.3493894771463121
+M15	0.31380763678078005
+M15	0.30842152835014014
+M15	0.5542319388038883
+M15	0.3844060866536428
+M15	0.4491574497747357
+M15	0.41597947158480725
+M15	0.296650722025831
+M15	0.2851734818987208
+M15	0.3069485257559159
+M15	0.30839982292439977
+M15	0.3038945398688603
+M15	0.42485094714387167
+M15	0.23957842974075394
+M15	0.28502397259201323
+M15	0.48640057597779496
+M15	0.3117116765145949
+M15	0.38789720220576646
+M15	0.512479774849097
+M15	0.33215537875271084
+M15	0.23867021041946915
+M15	0.395182922267304
+M15	0.38829922767997016
+M15	0.2967262569072056
+M15	0.28426625774720654
+M15	0.34983790063022674
+M15	0.33349556554979404
+M15	0.37257505346384767
+M15	0.4414382834857689
+M15	0.6653800164948522
+M15	0.3718895227537539
+M15	0.33284079624343954
+M15	0.41095673893330764
+M15	0.3336681197813496
+M15	0.2668239353164889
+M15	0.26307966043803066
+M15	0.4518008668962265
+M15	0.28918894642087256
+M15	0.35451981868110266
+M15	0.3028768115118106
+M15	0.3004580163318647
+M15	0.38302906785895197
+M15	0.4452195386030507
+M15	0.2730053147114605
+M15	0.32884753390991694
+M15	0.5278299995431519
+M15	0.39599975875242127
+M15	0.2897902488872355
+M15	0.30878423637729896
+M15	0.35852833114339694
+M15	0.2998275803861236
+M15	0.2785987370920534
+M15	0.2586856323612536
+M15	0.37687782280831
+M15	0.2791003185087688
+M15	0.2841899016238848
+M15	0.5568843612857391
+M15	0.3708629706198895
+M15	0.3050956724156723
+M15	0.37305349851062447
+M15	0.3589276038766677
+M15	0.449395321989353
+M15	0.44231254040975954
+M15	0.42549838225918124
+M15	0.2932245603749644
+M15	0.3678340281692995
+M15	0.29708374360180256
+M15	0.3513774287527422
+M15	0.3115743004515554
+M15	0.27211573604108424
+M15	0.3068622084867922
+M15	0.20699797796087022
+M15	0.28872899847225714
+M15	0.35544757674851535
+M15	0.30727605089608745
+M15	0.4170552030555714
+M15	0.3579590482693372
+M15	0.36231960246420297
+M15	0.5388648278347565
+M15	0.38327486659515325
+M15	0.43620288588032197
+M15	0.4666103000681014
+M15	0.34381720906542224
+M15	0.5250296387447341
+M15	0.3805688743079657
+M15	0.33911103105732743
+M15	0.41876027678035
+M15	0.3504413539793293
+M15	0.28518127139766186
+M15	0.21931474763097308
+M15	0.35193343131305566
+M15	0.5363844329038482
+M15	0.3229990499060258
+M15	0.34685023779997154
+M15	0.2778960481269517
+M15	0.22954313693404324
+M15	0.4646325281930661
+M15	0.31881463877281796
+M15	0.4283509839475216
+M15	0.26347129811432196
+M15	0.236497344581351
+M15	0.30437802507123035
+M15	0.42342367417934423
+M15	0.4563495452961793
+M15	0.2861575582300379
+M15	0.23622641792674862
+M15	0.3844341702067147
+M15	0.4092252848672748
+M15	0.426574706140332
+M15	0.5715626027260942
+M15	0.30283365162404935
+M15	0.29362582292915346
+M15	0.34594712933892907
+M15	0.33349283965111726
+M15	0.30881262971479717
+M15	0.43544069022903126
+M15	0.4426722364818718
+M15	0.3680822437320322
+M15	0.23248250101940118
+M15	0.34587680397200155
+M15	0.38086197632303265
+M15	0.327898435408057
+M15	0.47283884304883156
+M15	0.3548434092560997
+M15	0.4729371650188311
+M15	0.45209418094280607
+M15	0.29533304078901207
+M15	0.36299612910500695
+M15	0.37162287307947556
+M15	0.3400135361008547
+M15	0.3693406325633539
+M15	0.3664477590159067
+M15	0.3019821607304912
+M15	0.44686936624651696
+M15	0.3857138987912656
+M15	0.24539723429851734
+M15	0.2978065308607198
+M15	0.4164357780562636
+M15	0.30136535999841857
+M15	0.3579823079085826
+M15	0.2603923861940583
+M15	0.44275475488392785
+M15	0.40843845578680354
+M15	0.3781365369721563
+M15	0.30474112587437097
+M15	0.40224280475839735
+M15	0.46632994958258833
+M15	0.4094563234143341
+M15	0.2003980971784746
+M15	0.24823286718563498
+M15	0.28682771458869155
+M15	0.27996325005753575
+M15	0.37625461315237035
+M15	0.2805334627663192
+M15	0.20721084394377567
+M15	0.29205686631553635
+M15	0.2756246877474283
+M15	0.3188936920246444
+M15	0.37885767624198485
+M15	0.47303199215619435
+M15	0.2671081285253049
+M15	0.44928786122617204
+M15	0.5356415500381452
+M15	0.3024055260421067
+M15	0.4686418000351763
+M15	0.2987520074383955
+M15	0.4199360257048522
+M15	0.6685581010097222
+M15	0.49059673506601825
+M15	0.5669258894411486
+M15	0.6545956387528371
+M15	0.5203479285518724
+M15	0.6420217546476854
+M15	0.5079034373188852
+M15	0.6167862930145115
+M15	0.5464103485496069
+M15	0.5140298495084094
+M15	0.48006411517840636
+M15	0.3704700705124485
+M15	0.6097757533533675
+M15	0.6071092402773166
+M15	0.554205904766156
+M15	0.592432979588912
+M15	0.681088789973746
+M15	0.6434922758358145
+M15	0.5627460974464066
+M15	0.3913106898507966
+M15	0.6215136985024365
+M15	0.4490676627799822
+M15	0.5430976530484312
+M15	0.5607002355283494
+M15	0.5602421994140101
+M15	0.5952367343324886
+M15	0.5597532001021521
+M15	0.6653559187794807
+M15	0.5270154825789919
+M15	0.39218709157070347
+M15	0.43198311084046676
+M15	0.5009531653656928
+M15	0.6116630590474366
+M15	0.4951233485403349
+M15	0.6044943892314137
+M15	0.6276290383358248
+M15	0.34484978457282
+M15	0.22168221063097035
+M15	0.5418812815822076
+M15	0.6237054861308735
+M15	0.6416428025060619
+M15	0.6914980919279446
+M15	0.41951179225320806
+M15	0.6209959832491344
+M15	0.5908992629629756
+M15	0.6540910840685822
+M15	0.5438223777821528
+M15	0.5968981214896185
+M15	0.3815490736445977
+M15	0.5570436855248958
+M15	0.5665636984057297
+M15	0.6549848035437643
+M15	0.6550017564570121
+M15	0.6372906434479666
+M15	0.609313890482645
+M15	0.5710340457377563
+M15	0.5942066269478914
+M15	0.49869831425169214
+M15	0.4858431255704615
+M15	0.628977803063597
+M15	0.5995466940391683
+M15	0.5912484683526232
+M15	0.543088666512958
+M15	0.6471137412122033
+M15	0.6525134498359565
+M15	0.60411579996228
+M15	0.5903005569670013
+M15	0.5700712844974146
+M15	0.6788798095560534
+M15	0.5718629975575865
+M15	0.564133408354867
+M15	0.33567520725684413
+M15	0.5759646299116706
+M15	0.5852513144736522
+M15	0.511569474025155
+M15	0.6179164469997753
+M15	0.538799960614827
+M15	0.5961835629404182
+M15	0.37409603446202616
+M15	0.6245791519720831
+M15	0.5785024805325922
+M15	0.605590136435185
+M15	0.7458614829300442
+M15	0.6665154437648534
+M15	0.6902027328940177
+M15	0.5537859122229218
+M15	0.6418885544977002
+M15	0.5035236641928018
+M15	0.6020240370483734
+M15	0.6788403065464436
+M15	0.62853358470166
+M15	0.6555921491607573
+M15	0.5946307949297134
+M15	0.6014822003695073
+M15	0.6165588687211495
+M15	0.5304579053035461
+M15	0.6084077114265909
+M15	0.6236546792902811
+M15	0.609386063913986
+M15	0.5704999226066539
+M15	0.5300077427785664
+M15	0.6394368072026483
+M15	0.47459793601069233
+M15	0.5846147046706197
+M15	0.6704162009771204
+M15	0.6057603686961869
+M15	0.41360728829364246
+M15	0.6286280662364863
+M15	0.6485015591209362
+M15	0.45523939126071133
+M15	0.6075947568483047
+M15	0.7050650642200835
+M15	0.5984839601299059
+M15	0.5172672908941873
+M15	0.41361684903245377
+M15	0.36415142177270027
+M15	0.6827172553920616
+M15	0.6724380769588826
+M15	0.6616090017624571
+M15	0.4854513959901914
+M15	0.6069998927719499
+M15	0.5925671117725493
+M15	0.5925035439708287
+M15	0.5962012127965983
+M15	0.6711155822144479
+M15	0.5413666907890422
+M15	0.5734595294593775
+M15	0.5919651160894993
+M15	0.6439522916033853
+M15	0.6155252274726191
+M15	0.6271389100174145
+M15	0.2732380001630056
+M15	0.5841491433769443
+M15	0.528835928177154
+M15	0.6035698760380923
+M15	0.6024231503473929
+M15	0.5349769479460396
+M15	0.5065164116429766
+M15	0.6511414618746978
+M15	0.48344845785834817
+M15	0.2489758760116575
+M15	0.6658597189785657
+M15	0.6205837017903765
+M15	0.4728722987510249
+M15	0.6199665131175923
+M15	0.509652350363696
+M15	0.6242433664602928
+M15	0.6039432326036684
+M15	0.6997880680729621
+M15	0.6506358869368953
+M15	0.5271318669444733
+M15	0.605117797724471
+M15	0.6492146166617694
+M15	0.5616966621623564
+M15	0.5408742128531571
+M15	0.626649104072909
+M15	0.6476548778585458
+M15	0.6318013954849179
+M15	0.5367959956552091
+M15	0.6884014155487469
+M15	0.5425810602487054
+M15	0.5456624635857082
+M15	0.6247890221858712
+M15	0.5993090264290264
+M15	0.5658806092510849
+M15	0.5389189261454674
+M15	0.5711391386689942
+M15	0.505925963914388
+M15	0.622768790972127
+M15	0.5922039498369408
+M15	0.5424093542508543
+M15	0.5845409317821422
+M15	0.6595944967052731
+M15	0.5995141933689838
+M15	0.5479015441050411
+M15	0.6182168546369154
+M15	0.502687045564473
+M15	0.4597387242435645
+M15	0.3827495742072015
+M15	0.34017885480957166
+M15	0.646991064726098
+M15	0.5267869709806817
+M15	0.5472533767751365
+M15	0.6414189760245995
+M15	0.5761240344914879
+M15	0.7394244288575841
+M15	0.686678171323461
+M15	0.5738289408648762
+M15	0.7069177703993791
+M15	0.5350544438010607
+M15	0.4944554264310739
+M15	0.2917241384482516
+M15	0.5341614315851676
+M15	0.42668944923503804
+M15	0.6160991325380314
+M15	0.6069225038018036
+M15	0.5459097386431563
+M15	0.6310007241847208
+M15	0.6351451720007812
+M15	0.6360647494284917
+M15	0.6624811612396821
+M15	0.36309623905778265
+M15	0.3579326919653152
+M15	0.4161831022999634
+M15	0.46335016171527305
+M15	0.6827199830466291
+M15	0.4988403553462712
+M15	0.4580972992333023
+M15	0.279608962102182
+M15	0.6741773945172457
+M15	0.5748147501432781
+M15	0.6518243743509959
+M15	0.6995819416512983
+M15	0.655871564431862
+M15	0.614901028425554
+M15	0.453666836203662
+M15	0.6238565683985116
+M15	0.617361318726258
+M15	0.690275292283554
+M15	0.5632867174281585
+M15	0.6806298097787343
+M15	0.6649329189701558
+M15	0.510113227972024
+M15	0.5378516842289399
+M15	0.5416261656129482
+M15	0.5830859180790858
+M15	0.4455492616564917
+M15	0.6259417378971495
+M15	0.6067810176173128
+M15	0.48263690310297674
+M15	0.5965531323708952
+M15	0.569503694324302
+M15	0.5469891017165215
+M15	0.5884879201716865
+M15	0.5569266869690819
+M15	0.5407091784860183
+M15	0.44795396367393725
+M15	0.6982732496881516
+M15	0.43403879836073705
+M15	0.6264732377154568
+M15	0.49602874585169926
+M15	0.6137193425121983
+M15	0.46936205289390837
+M15	0.5539654143139553
+M15	0.6003099275253014
+M15	0.6658250402444549
+M15	0.5046144137629939
+M15	0.5340235441502093
+M15	0.5874671875895954
+M15	0.5932637004596026
+M15	0.4663961035106655
+M15	0.549100580057287
+M15	0.6415115042324575
+M15	0.7100895263433116
+M15	0.6756653885781632
+M15	0.6534902513989941
+M15	0.6608308019824672
+M15	0.5295802840064155
+M15	0.5904392766736852
+M15	0.5511231103732124
+M15	0.44627804273893357
+M15	0.6020411885809364
+M15	0.6055982482378579
+M15	0.6460667071116379
+M15	0.42457909605642663
+M15	0.3883326829572301
+M15	0.4137399155434499
+M15	0.7202505164940504
+M15	0.5239886497206059
+M15	0.50634599688524
+M15	0.4648798258882079
+M15	0.5353331070774056
+M15	0.6139019287694439
+M15	0.6646578948591015
+M15	0.46242362429450856
+M15	0.6595765859903019
+M15	0.6559779321826696
+M15	0.3983786832563268
+M15	0.3189887884019099
+M15	0.5852433538358056
+M15	0.5409272062537784
+M15	0.6732900713165177
+M15	0.46250544827239953
+M15	0.48264927057822293
+M15	0.5983953486933051
+M15	0.5540161428734137
+M15	0.545215032745698
+M15	0.5954952415965203
+M15	0.6065166634643137
+M15	0.4844934895758648
+M15	0.6099773126880789
+M15	0.6032207988579239
+M15	0.6967057518555013
+M15	0.525231961406406
+M15	0.47796843055660454
+M15	0.4230321113444016
+M15	0.6150753967997242
+M15	0.613287511925547
+M15	0.5238786046407307
+M15	0.6580209037276226
+M15	0.5129951652800682
+M15	0.5005497138702135
+M15	0.6194635942590913
+M15	0.6184530170711771
+M15	0.506547783885503
+M15	0.663478343377769
+M15	0.6268708244448971
+M15	0.6028285326687208
+M15	0.5502219846853463
+M15	0.5125776255050234
+M15	0.5563610682864931
+M15	0.5593724176940988
+M15	0.5523794231438819
+M15	0.621472087803445
+M15	0.6160368259283401
+M15	0.6475143203399908
+M15	0.5829538049835045
+M15	0.5726289829290201
+M15	0.5351589009764489
+M15	0.4950815928910877
+M15	0.41680668873677007
+M15	0.5609447415383374
+M15	0.5207442687264291
+M15	0.38205373224167605
+M15	0.607945346398254
+M15	0.5208750486411665
+M15	0.4567945258194477
+M15	0.32415117376107944
+M15	0.6416720935940795
+M15	0.6065876877166174
+M15	0.3346438486633436
+M15	0.5791146699721329
+M15	0.4728650183727117
+M15	0.559580473663955
+M15	0.5756740584371663
+M15	0.5507795834544422
+M15	0.4892823636410579
+M15	0.5621353453945132
+M15	0.37415495068425125
+M15	0.48938669564423176
+M15	0.5949254028615689
+M15	0.6563458559539265
+M15	0.609438171745044
+M15	0.554293658852219
+M15	0.6569065382793916
+M15	0.48054633343247477
+M15	0.45596760366215
+M15	0.63422671359042
+M15	0.5987481891003537
+M15	0.6005776626623985
+M15	0.6142867112508412
+M15	0.5456111214990077
+M15	0.49183025649130535
+M15	0.6318497512768251
+M15	0.5581997548931081
+M15	0.5639084259405936
+M15	0.5446674054867311
+M15	0.41910241554137323
+M15	0.4791591494994969
+M15	0.40288327031387344
+M15	0.4868508811638069
+M15	0.5346421200133468
+M15	0.4882663389563418
+M15	0.5579241291637806
+M15	0.6196081238134474
+M15	0.6320145931396525
+M15	0.5865300349009009
+M15	0.6191988264188327
+M15	0.40405485669922003
+M15	0.5577294960776342
+M15	0.608209032316704
+M15	0.44269387993835524
+M15	0.621310672702206
+M15	0.5882089401310094
+M15	0.4123767730335401
+M15	0.49388301461366424
+M15	0.649712162755486
+M15	0.6148128409225364
+M15	0.5534602120199784
+M15	0.5482580659826136
+M15	0.4194072792969757
+M15	0.6356013982369872
+M15	0.5518247389943629
+M15	0.45959960921884696
+M15	0.6999901234570411
+M15	0.6203081691777752
+M15	0.5468351841805176
+M15	0.48596583100767426
+M15	0.7216213182721618
+M15	0.6463775024265394
+M15	0.5557338595775193
+M15	0.516974083006624
+M15	0.6825318617770997
+M15	0.54144310007955
+M15	0.6515863135003104
+M15	0.6331307408207097
+M15	0.6718014480363615
+M15	0.5328739492243099
+M15	0.4929814365797404
+M15	0.40875312995429636
+M15	0.5269859730210538
+M15	0.42913760642175963
+M15	0.4609774660852886
+M15	0.6528558906251312
+M15	0.6332455414619097
+M15	0.6083646827571542
+M15	0.639711006498063
+M15	0.6202488523405536
+M15	0.6768473185477282
+M15	0.46612023347158993
+M15	0.6068262447539904
+M15	0.6099420062310479
+M15	0.6883369709621374
+M15	0.6817456376198776
+M15	0.5673198735900508
+M15	0.7120524307251604
+M15	0.6527722699173514
+M15	0.6933171810806227
+M15	0.6005850419421952
+M15	0.6787748848011658
+M15	0.52034141182597
+M15	0.49160728192703884
+M15	0.5837535527832418
+M15	0.5694629736407523
+M15	0.5977725016542584
+M15	0.629349014200771
+M15	0.6161307815009858
+M15	0.6512777267197704
+M15	0.6757019028444642
+M15	0.5073127730280965
+M15	0.701420155609996
+M15	0.59032001945968
+M15	0.4515865101708609
+M15	0.5773426594921637
+M15	0.5636089845552104
+M15	0.6728627657325726
+M15	0.48378321802695073
+M15	0.5952043990800492
+M15	0.6120920113934105
+M15	0.6065136432993757
+M15	0.46968773115454343
+M15	0.5011802469013702
+M15	0.7090052094389492
+M15	0.5386784213735233
+M15	0.6351150739769508
+M15	0.5278189131871804
+M15	0.5486701962310538
+M15	0.2616492308184752
+M15	0.6660238823833338
+M15	0.6146599583580176
+M15	0.5915895830453084
+M15	0.6189928512724466
+M15	0.5579075328673592
+M15	0.6544829438914662
+M15	0.5940710081787676
+M15	0.6363699706569073
+M15	0.7051477392376565
+M15	0.5795545038027418
+M15	0.49204446265857416
+M15	0.5015854103784112
+M15	0.47172335690811623
+M15	0.4413032663541667
+M15	0.5793319807301409
+M15	0.6588296249355411
+M15	0.5382940662944947
+M15	0.5439412625865185
+M15	0.5684695339307637
+M15	0.5308218448926687
+M15	0.5900893899648365
+M15	0.5616197648560598
+M15	0.584027956315291
+M15	0.5172246914562418
+M15	0.6376512954420126
+M15	0.6117681808008505
+M15	0.5787028876204487
+M15	0.6527648794056277
+M15	0.6443523521163131
+M15	0.50145625297954
+M15	0.59654285976351
+M15	0.7004814919782812
+M15	0.6216927982185027
+M15	0.638786275123919
+M15	0.5562163558853656
+M15	0.7061247791239731
+M15	0.5539562162325219
+M15	0.6280606271525463
+M15	0.43041173599942195
+M15	0.47148910422114393
+M15	0.6071126916100861
+M15	0.6539295062099657
+M15	0.6416060730436576
+M15	0.6725099961550771
+M15	0.6677485205101742
+M15	0.5749558067320197
+M15	0.6749283162769464
+M15	0.6208306770032408
+M15	0.2637961654714103
+M15	0.5253241117313231
+M15	0.44148415129063723
+M15	0.5754435108288752
+M15	0.5624178225524279
+M15	0.5856977067102119
+M15	0.5173837169352071
+M15	0.6119388850920333
+M15	0.5109764674918406
+M15	0.5141603133583066
+M15	0.5808241633686064
+M15	0.5276763126744993
+M15	0.4972258357322155
+M15	0.676118686717477
+M15	0.4772982930892211
+M15	0.37484289723507036
+M15	0.4928694389799105
+M15	0.4489078138906407
+M15	0.48901520426643197
+M15	0.6697979822514981
+M15	0.553255139468469
+M15	0.3671028425594883
+M15	0.6670228377999886
+M15	0.6427622284769898
+M15	0.6439533549522957
+M15	0.529401033189278
+M15	0.537507578057667
+M15	0.38816498927001186
+M15	0.5190710096914704
+M15	0.486686253178059
+M15	0.5435763265218628
+M15	0.49975764625301994
+M15	0.7225045299660459
+M15	0.6273994921937596
+M15	0.6344878171147251
+M15	0.5695908776046457
+M15	0.6224861410581533
+M15	0.5215323883548539
+M15	0.5501384195427494
+M15	0.6501445033163186
+M15	0.7153418446811175
+M15	0.6117020115606546
+M15	0.6466393966030647
+M15	0.5841426467348708
+M15	0.5712458223660157
+M15	0.5432081896415871
+M15	0.6728138724573464
+M15	0.630181287242738
+M15	0.504164354763837
+M15	0.48508216375914187
+M15	0.6070718948871788
+M15	0.6141247656837832
+M15	0.5231543423872629
+M15	0.6552229174849585
+M15	0.4087497293708998
+M15	0.44798624039825513
+M15	0.6115593434398483
+M15	0.5373857310067874
+M15	0.5857701699955894
+M15	0.5821215730938438
+M15	0.6569106504590517
+M15	0.5870658611138444
+M15	0.5541721031486009
+M15	0.6597146336805682
+M15	0.6721809036228862
+M15	0.546062399842123
+M15	0.6361509773913117
+M15	0.6450008611260942
+M15	0.4661719675630544
+M15	0.5121210579563059
+M15	0.5582555135840419
+M15	0.6037349656608905
+M15	0.7034224750466197
+M15	0.6422763413361847
+M15	0.605920010996879
+M15	0.5369830590792387
+M15	0.48412837429263095
+M15	0.6093736868643395
+M15	0.6354391354855028
+M15	0.6629859545911199
+M15	0.6557568782051858
+M15	0.590830345767698
+M15	0.5592188591218027
+M15	0.4944552065209698
+M15	0.6371086644577931
+M15	0.5765886072982149
+M15	0.5126968207040126
+M15	0.6728319518321707
+M15	0.5654276329509539
+M15	0.6179784053552518
+M15	0.6565614959464945
+M15	0.4265052406379261
+M15	0.6099725042753549
+M15	0.4531987395916378
+M15	0.4500972732097148
+M15	0.6593174177070376
+M15	0.6168917091514472
+M15	0.6173354614969553
+M15	0.565893328943389
+M15	0.6376569161386926
+M15	0.6071161327683156
+M15	0.5335639805304815
+M15	0.6146672730521034
+M15	0.6820948719696
+M15	0.6929446492416504
+M15	0.5486541299371601
+M15	0.5899146671025675
+M15	0.6125258218160546
+M15	0.5318333228760254
+M15	0.41243567026567146
+M15	0.6135315562297795
+M15	0.5301168453668734
+M15	0.5677262805054649
+M15	0.5612066307581127
+M15	0.6158278724056022
+M15	0.6659657547323801
+M15	0.44368881308358665
+M15	0.4951341170430751
+M15	0.6404149284096576
+M15	0.3788551383863476
+M15	0.5457853367862321
+M15	0.31759972056164365
+M15	0.6588934086740501
+M15	0.5554859930170545
+M15	0.7287804650712898
+M15	0.5247716933830943
+M15	0.5830910547853417
+M15	0.5580272567356428
+M15	0.6400207620026811
+M15	0.5625533200655897
+M15	0.5678232056943635
Index: src/com/model/2VS2Test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/2VS2Test.py b/src/com/model/2VS2Test.py
new file mode 100644
--- /dev/null	(date 1674801167000)
+++ b/src/com/model/2VS2Test.py	(date 1674801167000)
@@ -0,0 +1,263 @@
+from scipy.spatial.distance import cosine
+import os
+
+# from torch import nn
+
+# cherry 的 GPU跑不动 死心吧
+# Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "."))  # TODO script
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "../../../"))  # TODO local
+from src.com.model.run_auto_encoder import Autoencoder, config  # TODO local
+# from run_auto_encoder_shell import Autoencoder, config  # TODO script
+import torch
+import numpy as np
+import pandas as pd
+import time
+from transformers import AlbertTokenizer, AlbertModel
+
+from tqdm import tqdm, trange
+import transformers
+from transformers import BertModel
+from sentence_transformers import SentenceTransformer
+from simcse import SimCSE
+
+
+# print(Proj_dir)
+
+def count_word(str):
+    # str = input("请您输入一串字符串：")
+    str1 = str.strip()  # 去掉头尾空格
+    index = 0
+    count = 0
+    while index < len(str1):
+        while str1[index] != " ":  # 有空格时结束当前循环
+            index += 1
+            if index == len(str1):  # 下标与字符串长度相等结束当前循环
+                break
+        count += 1  # 计算单词的个数
+        if index == len(str1):  # 下标与字符串长度相等结束当前循环
+            break
+        while str1[index] == " ":  # 单词之间多个空格时，下标加1
+            index += 1
+    # print("输入的字符串中一共有count = %d个单词" % count)
+    return count
+
+def get_albert_embedding_tensor(sentence, tokenizer, model):
+    encoded_input = tokenizer(sentence, return_tensors='pt')
+    output = model(**encoded_input)
+    return output[-1].detach().squeeze(0)
+
+def two_vs_two(y_test, preds):
+    """
+    1. Each pair of words is compared only once.
+    """
+    points = 0
+    total_points = 0
+    for i in trange(preds.shape[0] - 1):
+        s_i = y_test[i]
+        s_i_pred = preds[i]
+        for j in range(i + 1, preds.shape[0]):
+            s_j = y_test[j]
+            s_j_pred = preds[j]
+
+            # Compute cosine distance.
+            dsii = cosine(s_i, s_i_pred.cpu().detach().numpy().tolist())
+            dsjj = cosine(s_j, s_j_pred.cpu().detach().numpy().tolist())
+            dsij = cosine(s_i, s_j_pred.cpu().detach().numpy().tolist())
+            dsji = cosine(s_j, s_i_pred.cpu().detach().numpy().tolist())
+
+            if dsii + dsjj <= dsij + dsji:
+                points += 1
+            total_points += 1
+
+    return points, total_points, points * 1.0 / total_points
+
+
+def dataloader_pereira(pre_trained_model, language_model_type):
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/'  # laplace
+    files = os.listdir(brain_path)
+    i = 0
+    y_test = []
+    label_list = []
+    brain_arr = []
+    for file in tqdm(files, total=len(files)):  # 遍历文件夹
+        # print(file.replace('.npy', '').split('_'))
+        file_spilt = file.replace('.npy', '').split('_')
+        index = int(file_spilt[3])
+        # user = file_spilt[1]
+
+        exp_index = file_spilt[2]
+        brain_data = np.load(brain_path + file)
+        if exp_index == 'exp1':
+            # 180 ->144 train; ->36 val
+
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp1_text.tsv', sep='\t', header=0)
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp1_text.tsv', sep='\t', header=0)
+            group_boundary = 144
+        elif exp_index == 'exp2':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp2_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp2_text.tsv', sep='\t', header=0)
+            # 384 ->308 train; ->76 val
+            group_boundary = 308
+        elif exp_index == 'exp3':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp3_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp3_text.tsv', sep='\t', header=0)
+            # 243 ->195 train; ->48 val
+            group_boundary = 195
+        if index < group_boundary:
+            continue
+            # train_data.append({
+            #     'index': i,
+            #     'participant': user,
+            #     'brain': brain_data[:46840],
+            #     'label': sentence_df['text'][index]})
+            i = i + 1
+        else:
+            brain_data = brain_data[:46840]
+            label = sentence_df['text'][index]
+            # print(count_word(label))
+
+            if count_word(label) > 1:
+                brain_arr.append(brain_data)
+                label_list.append(label)
+
+            # y_test.append({
+            #     'index': i,
+            #     'participant': user,
+            #     'data': brain_data,
+            #     'label': label
+            # })
+            # preds.append({
+            #     'index': i,
+            #     'participant': user,
+            #     'data': brain_data,
+            #     'label': label
+            # })
+            i = i + 1
+    print(len(label_list))
+    brain_tensor = torch.tensor(brain_arr)
+    brain_tensor = brain_tensor.to(device, dtype=torch.float)
+    y, preds = pre_trained_model(brain_tensor)
+    if language_model_type == 'bert-large-uncased':
+        tokenizer = transformers.AutoTokenizer.from_pretrained(language_model_type)
+        text_model = BertModel.from_pretrained(language_model_type, output_hidden_states=True)
+        for label in label_list:
+            input_ids = torch.tensor(tokenizer.encode(label, add_special_tokens=False)).unsqueeze(0) # Batch size 1
+            outputs = text_model(input_ids)
+            all_layers_output = outputs[2]
+            sent_embeddings = all_layers_output[-1]  # last layer
+            sent_embeddings = torch.squeeze(sent_embeddings, dim=0)
+            sentence_embedding_avg = torch.mean(sent_embeddings, dim=0)
+            y_test.append(sentence_embedding_avg.cpu().detach().numpy().tolist())
+    elif language_model_type == 'sentence-camembert-large':
+        text_model = SentenceTransformer("dangvantuan/sentence-camembert-large")
+        y_test = np.array([text_model.encode(label) for label in label_list])
+    elif language_model_type == 'sup-simcse-bert-base-uncased':
+        text_model = SimCSE("princeton-nlp/sup-simcse-bert-base-uncased")
+
+        y_test = np.array([text_model.encode(label, return_numpy=True, device='cpu', normalize_to_unit=True,
+                                             keepdim=False, batch_size=64,
+                                             max_length=128) for label in label_list])
+
+    elif language_model_type == 'sup-simcse-bert-large-uncased':
+
+        text_model = SimCSE("princeton-nlp/sup-simcse-bert-large-uncased")
+        y_test = np.array([text_model.encode(label, return_numpy=True, device='cpu', normalize_to_unit=True,
+                                             keepdim=False, batch_size=64,
+                                             max_length=128) for label in label_list])
+
+    elif language_model_type == 'sup-simcse-roberta-large':
+
+        text_model = SimCSE("princeton-nlp/sup-simcse-roberta-large")
+        y_test = np.array([text_model.encode(label, return_numpy=True, device='cpu', normalize_to_unit=True,
+                                             keepdim=False, batch_size=64,
+                                             max_length=128) for label in label_list])
+
+    elif language_model_type == 'unsup-simcse-roberta-large':
+
+        text_model = SimCSE("princeton-nlp/unsup-simcse-roberta-large")
+        y_test = np.array([text_model.encode(label, return_numpy=True, device='cpu', normalize_to_unit=True,
+                                             keepdim=False, batch_size=64,
+                                             max_length=128) for label in label_list])
+    elif language_model_type == 'unsup-simcse-bert-large-uncased':
+
+        text_model = SimCSE("princeton-nlp/unsup-simcse-bert-large-uncased")
+        y_test = np.array([text_model.encode(label, return_numpy=True, device='cpu', normalize_to_unit=True,
+                                             keepdim=False, batch_size=64,
+                                             max_length=128) for label in label_list])
+    elif language_model_type in ['albert-xlarge-v1','albert-xlarge-v2']:
+        tokenizer = AlbertTokenizer.from_pretrained(language_model_type)
+        text_model = AlbertModel.from_pretrained(language_model_type)
+        y_test = np.array([get_albert_embedding_tensor(label, tokenizer, text_model) for label in label_list])
+
+    return y_test, preds
+
+
+def make_print_to_file(path='.'):
+    '''
+    path， it is a path for save your log about fuction print
+    example:
+    use  make_print_to_file()   and the   all the information of funtion print , will be write in to a log file
+    :return:
+    '''
+    import os
+    # import config_file as cfg_file
+    import sys
+    import datetime
+
+    class Logger(object):
+        def __init__(self, filename="Default.log", path="./"):
+            self.terminal = sys.stdout
+            self.log = open(os.path.join(path, filename), "a", encoding='utf8', )
+
+        def write(self, message):
+            self.terminal.write(message)
+            self.log.write(message)
+
+        def flush(self):
+            pass
+
+    fileName = datetime.datetime.now().strftime('day and time:' + '%Y_%m_%d')
+    sys.stdout = Logger(fileName + '.out', path=path)
+
+    #############################################################
+    # print -> log
+    #############################################################
+    print(fileName.center(60, '*'))
+
+
+if __name__ == "__main__":
+    start = time.perf_counter()
+    make_print_to_file('.')
+    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+    _config = config()
+    type_dict = {
+        # "bert-large-uncased": "model_1024_vanilla_0.08932987973093987.bin", #bert-large-uncased_1024_0.061.bin /Storage/ying/project/brainAE/benchmark/model1024_nol1_0.036462158693567566.bin
+        "albert-xlarge-v1": "albert-xlarge-v1_2048_vanilla-AE_0.06558057738711005.bin", #bert-large-uncased_1024_0.061.bin /Storage/ying/project/brainAE/benchmark/model1024_nol1_0.036462158693567566.bin
+        "albert-xlarge-v2": "albert-xlarge-v2_2048_vanilla-AE_0.0663215643422597.bin", #bert-large-uncased_1024_0.061.bin /Storage/ying/project/brainAE/benchmark/model1024_nol1_0.036462158693567566.bin
+        # "sentence-camembert-large": "sentence-camembert-large_1024_vanilla-AE_0.1528281674760839.bin",
+        # "unsup-simcse-roberta-large": "unsup-SimCSE_roberta_large_1024_0.072.bin",
+        # "sup-simcse-roberta-large": "SimCSE_roberta_large_sup_1024_0.078.bin",
+        # "sup-simcse-bert-base-uncased": "sup-SimCSE-bert-base_768_0.076.bin",
+        # "unsup-simcse-bert-large-uncased": "SimCSE_bert_large_unsup_1024_0.10.bin",
+        # "sup-simcse-bert-large-uncased": "sup-SimCSE-bert_large_1024_0.09.bin",
+    }
+    for k, v in type_dict.items():
+        # print(k)
+        if k in ['sup-simcse-bert-base-uncased']:
+            _config.LATENT_SIZE = 768
+        elif k in ['albert-xlarge-v1','albert-xlarge-v2']:
+            _config.LATENT_SIZE = 2048
+        # else:
+        #     _config.LATENT_SIZE = 1024
+        AE_model_file = '/Storage/ying/project/brainAE/output/' + v
+        pre_trained_model = Autoencoder()
+        pre_trained_model.load_state_dict(
+            {k.replace('module.', ''): v for k, v in torch.load(os.path.join(AE_model_file)).items()})
+        pre_trained_model.to(device)
+        y_test, y_preds = dataloader_pereira(pre_trained_model, k)
+        print(k, two_vs_two(y_test, y_preds))
+    end = time.perf_counter()
+    time_cost = str((end - start) / 60)
+    print("time-cost:", time_cost)
Index: src/com/model/coco_feature_extraction.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/coco_feature_extraction.py b/src/com/model/coco_feature_extraction.py
new file mode 100644
--- /dev/null	(date 1673241317000)
+++ b/src/com/model/coco_feature_extraction.py	(date 1673241317000)
@@ -0,0 +1,164 @@
+import os
+
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "../../../"))
+import sys
+os.environ["CUDA_VISIBLE_DEVICES"] = "4,5,6,7"  # GPU
+
+sys.path.append(Proj_dir)
+# print(sys.path)
+import json
+import torch
+# import scipy.io as scio
+import numpy as np
+from src.com.util.data_format import normalization
+from transformers import BertModel, BertTokenizer
+from src.com.model.run_auto_encoder_coco import Autoencoder
+from torch import nn
+
+tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')
+bert_model = BertModel.from_pretrained('bert-large-uncased', output_hidden_states=True)
+PROJ_DIR = os.path.abspath(os.path.join(os.getcwd(), "../../../"))
+# /Storage/ying/project/brainAE/output/is_1024_vanilla_0.013152188140832419.bin
+# /Storage/ying/project/brainAE/output/is_1024_vanilla_2.332835287281445.bin /Storage/ying/project/brainAE/output/is_1024_vanilla_2.332835287281445.bin
+model_file = ''
+
+# 这里调整模型
+dataset_name = "COCO2014_2023"
+
+
+def get_sentence_embedding(sentence, option):
+    # if YOU NEED [cls] and [seq] PRESENTATION：True
+    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)  # Batch size 1
+    outputs = bert_model(input_ids)
+
+    all_layers_output = outputs[2]
+    # list of torch.FloatTensor (one for the output of each layer + the output of the embeddings) of shape (batch_size, sequence_length, hidden_size): Hidden-states of the model at the output of each layer plus the initial embedding outputs.
+
+    if option == "last_layer":
+        sent_embeddings = all_layers_output[-1]  # last layer
+    elif option == "second_to_last_layer":
+        sent_embeddings = all_layers_output[-2]  # second to last layer
+    else:
+        sent_embeddings = all_layers_output[-1]  # last layer
+
+    sent_embeddings = torch.squeeze(sent_embeddings, dim=0)
+    # print(sent_embeddings.shape)
+
+    # Calculate the average of all token vectors.
+    sentence_embedding_avg = torch.mean(sent_embeddings, dim=0)
+    # print(sentence_embedding_avg.shape)
+
+    return sent_embeddings.detach(), sentence_embedding_avg.detach()
+
+
+def load_brain_data():
+    coco_brain_ROI = json.loads(
+        open("/Storage/ying/project/ridgeRegression/BOLD5000/ROIs/coco_brain_ROI.json", 'r', encoding='utf-8').read())
+    return coco_brain_ROI
+
+
+def calculate_corrcoef(dataset):
+    participants = ['CSI1', 'CSI2', 'CSI3', 'CSI4']
+    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+    # sentence1_tsv_path = '../../../resource/text_807.tsv'
+    # sentence2_tsv_path = '../../../resource/text_564.tsv'
+    # sentence3_tsv_path = '../../../resource/text_423.tsv'
+    # sentence4_tsv_path = '../../../resource/text_180.tsv'
+    # # join exp1, 2and 3
+    # type1_participants = ['P01', 'M02', 'M04', 'M07', 'M15']
+    # # join exp1 and 3
+    # type2_participants = ['M08', 'M09', 'M14']
+    # # join exp1 and 3
+    # type3_participants = ['M03']
+    # # only join exp1
+    # type4_participants = ['M01', 'M05', 'M06', 'M10', 'M13', 'M16', 'M17']
+    pre_trained_model = Autoencoder()
+    # pre_trained_model.load_state_dict(
+    #     {k.replace('module.', ''): v for k, v in torch.load(os.path.join(model_file)).items()})
+
+    pre_trained_model.to(device)
+
+    corr_user = {}
+    # norm_path = '/Storage/ying/resources/BrainBertTorch/dataset/' + dataset + '/norm/'
+
+    brain_data = load_brain_data()
+    for user in participants:
+        if user == 'CSI1':
+            key = 'CSI01'
+        if user == 'CSI2':
+            key = 'CSI02'
+        if user == 'CSI3':
+            key = 'CSI03'
+        if user == 'CSI4':
+            key = 'CSI04'
+        label_list = open("/Storage/ying/pyCortexProj/ridgeRegression/BOLD5000/ROIs/caption/" + key + "_captioning.txt",
+                          'r').readlines()
+        # sentence_df_path = '/Storage/ying/project/ridgeRegression/BOLD5000/ROIs/caption/' +key +'_captioning.txt'
+        brain_original = np.zeros((np.array(brain_data[user]).shape[0], 3566))
+        brain_original[:, :np.array(brain_data[user]).shape[1]] = np.array(brain_data[user])
+        train_X = np.array(brain_original)
+        train_X, _, _ = normalization(train_X)
+        train_X = torch.Tensor(train_X)
+        train_X = train_X.to(device, dtype=torch.float)
+        y, z = pre_trained_model(train_X)
+        corr_list = []
+        # feature_shape = z[0].shape[0]
+
+        # sentence_df = pd.read_csv(sentence_df_path, sep='\t', header=None)
+        # sentence_df.columns = ['text', 'type']
+        for index in range((z.shape[0])):
+            sentence = label_list[index]
+            sent_embeddings, t = get_sentence_embedding(sentence, "last_layer")
+            # z[index, :].cpu().detach().numpy(), t.cpu().detach().numpy()
+            corr = np.corrcoef(z[index, :].cpu().detach().numpy(), t.cpu().detach().numpy())[0, 1]
+            corr_list.append(corr)
+        corr_user[user] = corr_list
+    with open(dataset + f'_corr_user.json', 'w') as f:
+        json.dump(corr_user, f)
+        f.close()
+
+
+def create_brain_npz(dataset):
+    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+
+    pre_trained_model = Autoencoder()
+    pre_trained_model = nn.DataParallel(pre_trained_model, device_ids=[0, 1, 2, 3])  # multi-GPU
+
+    # checkpoint = torch.load(os.path.join(model_file))
+    # pre_trained_model.load_state_dict(checkpoint)
+
+    pre_trained_model.to(device)
+
+    norm_path = '/Storage/ying/resources/BrainBertTorch/dataset/' + dataset + '/norm/'
+    feature_path = '/Storage/ying/resources/BrainBertTorch/dataset/' + dataset + '/features/'
+    brain_data = load_brain_data()
+    for user in brain_data.keys():
+        brain_original = np.zeros((np.array(brain_data[user]).shape[0], 3566))
+        brain_original[:, :np.array(brain_data[user]).shape[1]] = np.array(brain_data[user])
+        train_X = np.array(brain_original)
+        train_X, _, _ = normalization(train_X)
+        train_X = torch.Tensor(train_X)
+        train_X = train_X.to(device, dtype=torch.float)
+        y, z = pre_trained_model(train_X)
+
+        for index in range(brain_original.shape[0]):
+            if user == 'CSI1':
+                user = 'CSI01'
+            if user == 'CSI2':
+                user = 'CSI02'
+            if user == 'CSI3':
+                user = 'CSI03'
+            if user == 'CSI4':
+                user = 'CSI04'
+            npz_filename = dataset_name + '_' + user + '_' + str(index) + '.npz'
+            print(npz_filename)
+            np.savez(norm_path + npz_filename, features=brain_original[index, :])
+            np.savez(feature_path + npz_filename, features=z[index].cpu().data.numpy().tolist())
+
+
+if __name__ == "__main__":
+    # dataset = 'pereira'
+    # create_brain_npz(dataset_name)
+
+    # print(features['data'])
+    calculate_corrcoef('coco')
Index: src/com/model/apply_brain_mask.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/apply_brain_mask.py b/src/com/model/apply_brain_mask.py
new file mode 100644
--- /dev/null	(date 1620001788000)
+++ b/src/com/model/apply_brain_mask.py	(date 1620001788000)
@@ -0,0 +1,115 @@
+import scipy.io as scio
+import os
+import numpy as np
+
+def load_brain_alice():
+    import nibabel as nib
+    participants = {'18', '22', '23', '24', '26', '28', '30', '31', '35', '36', '37',
+                    '39', '41', '42', '43', '44', '45', '47', '48', '49', '50', '51', '53'}
+    ROI_path = '../../../resource/roi.mat'
+
+    data = scio.loadmat(ROI_path)
+    # read roi index
+    roi = data['index']
+    for user in participants:
+        func_filename = '/Storage/ying/resources/AliceDataset/fMRI/sub-' + str(user) + \
+                        '/derivatives/sub-' + str(user) + '_task-alice_bold_preprocessed.nii.gz'
+        nii = nib.load(func_filename)
+        img_np = nii.get_fdata().T
+        img_np = img_np.reshape(img_np.shape[0],-1)
+
+        for i in range(10,img_np.shape[0]):
+            save_path = '/Storage/ying/resources/BrainBertTorch/brain/alice/ae_npy/' + \
+                             'alice_' + str(user)  + '_' + str(i-10) + '.npy'
+            a = []
+            print('alice_' + str(user)  + '_' + str(i-10) + '.npy')
+            for index in roi[0]:
+                a.append(img_np[i][index])
+            np.save(save_path, a)
+
+
+
+
+def load_brain_pereira():
+    paticipants_1 = ['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07',
+                     'M08', 'M09', 'M10', 'M13', 'M14', 'M15', 'M16', 'M17', 'P01']
+    paticipants_2 = ['M02', 'M04', 'M07', 'M08', 'M09', 'M14', 'M15', 'P01']
+    paticipants_3 = ['M02', 'M03', 'M04', 'M07', 'M15', 'P01']
+    # dataset_path = "/Storage/ying/resources/pereira2018/'+user+'/data_180concepts_wordclouds.mat"
+    for user in paticipants_1:
+        # 用于训练AE
+        exp1_path = '/Storage/ying/resources/pereira2018/' + user + '/data_180concepts_sentences.mat'
+        # 其他提取特征量
+        # exp1_path = '/Storage/ying/resources/pereira2018/' + user + '/data_180concepts_wordclouds.mat'
+
+        exp1_data = scio.loadmat(exp1_path)
+        examples = exp1_data['examples']
+        print(user, examples.shape)
+        # ROI_path = '../../../resource/' + user + '_roi.mat'
+        ROI_path = '../../../resource/'+user+'_roi.mat'
+
+        data = scio.loadmat(ROI_path)
+        # read roi index
+        roi = data['index']
+        for i in range((examples.shape[0])):
+            exp1_save_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/AE_training/' + \
+                             'pereira_' + user + '_exp1_' + str(i) + '.npy'
+            a = []
+            for index in roi[0]:
+                # roi 文件的坐标值 需要在
+                if index < len(examples[i]):
+                    a.append(examples[i][index])
+                # else:
+                    # print(i,index)
+            np.save(exp1_save_path, a)
+
+        print(len(a))
+        # if user in paticipants_2:
+        #     exp2_path = '/Storage/ying/resources/pereira2018/' + user + '/data_384sentences.mat'
+        #     exp2_data = scio.loadmat(exp2_path)
+        #     # print(exp2_data.keys())
+        #     examples = exp2_data['examples_passagesentences']
+        #     for i in range((examples.shape[0])):
+        #         exp2_save_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/' + \
+        #                          'pereira_' + user + '_exp2_' + str(i) + '.npy'
+        #         # print(exp2_save_path)
+        #         a = []
+        #         for index in roi[0]:
+        #             a.append(examples[i][index])
+        #         # print(len(a))
+        #         np.save(exp2_save_path, a)
+        #
+        # if user in paticipants_3:
+        #     exp3_path = '/Storage/ying/resources/pereira2018/' + user + '/data_243sentences.mat'
+        #     exp3_data = scio.loadmat(exp3_path)
+        #     # print(exp3_data.keys())
+        #     examples = exp3_data['examples_passagesentences']
+        #     for i in range((examples.shape[0])):
+        #         print(i)
+        #         exp3_save_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/' + \
+        #                          'pereira_' + user + '_exp3_' + str(i) + '.npy'
+        #         # print(exp3_save_path)
+        #         a = []
+        #         for index in roi[0]:
+        #             a.append(examples[i][index])
+        #         # print(len(a))
+        #         np.save(exp3_save_path, a)
+
+# pereira
+# paticipants_1 = ['M09']
+
+
+# alice
+
+
+# save the new file for brain
+
+
+if __name__ == "__main__":
+    load_brain_pereira()
+    # ROI_path = '../../../resource/roi.mat'
+    #
+    # data = scio.loadmat(ROI_path)
+    # # read roi index
+    # roi = data['index']
+    # print(roi)
\ No newline at end of file
Index: src/com/model/test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/test.py b/src/com/model/test.py
new file mode 100644
--- /dev/null	(date 1695637548000)
+++ b/src/com/model/test.py	(date 1695637548000)
@@ -0,0 +1,14 @@
+# :/Storage2/ying/project/brainLMProj/dataset/prince/bert-large-uncased/features
+import os
+
+# 指定文件夹路径
+folder_path = "/Storage2/ying/project/brainLMProj/dataset/prince/bert-large-uncased/features"
+
+# 获取文件夹中的所有文件
+all_files = os.listdir(folder_path)
+
+# 使用列表推导式筛选包含"EN059"的文件名
+filtered_files = [file for file in all_files if "EN059" in file]
+
+# 输出符合条件的文件数量
+print(f"在路径 {folder_path} 下找到包含 'EN059' 的文件数量为: {len(filtered_files)}")
Index: src/com/model/alice_sentence.tsv
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/alice_sentence.tsv b/src/com/model/alice_sentence.tsv
new file mode 100644
--- /dev/null	(date 1616247278000)
+++ b/src/com/model/alice_sentence.tsv	(date 1616247278000)
@@ -0,0 +1,84 @@
+	id	type	onset	offset	sentences
+0		train	0	8	alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do:  once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it,  and what is the use of a book,  thought alice  without pictures or conversation? 
+1		train	9	18	so she was considering in her own mind as well as she could, for the hot day made her feel very sleepy and stupid , whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a white rabbit with pink eyes ran close by her.
+2		train	19	23	there was nothing so very remarkable in that; nor did alice think it so very much out of the way to hear the rabbit say to itself,  oh dear!
+3		train	23	23	oh dear!
+4		train	24	24	i shall be late! 
+5		train	25	42	when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural ; but when the rabbit actually took a watch out of its waistcoat- pocket, and looked at it, and then hurried on, alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.
+6		train	43	46	in another moment down went alice after it, never once considering how in the world she was to get out again.
+7		train	47	53	the rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that alice had not a moment to think about stopping herself before she found herself falling down a very deep well.
+8		train	53	58	either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next.
+9		train	59	67	first, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs.
+10		train	68	76	she took down a jar from one of the shelves as she passed; it was labelled  orange marmalade , but to her great disappointment it was empty:  she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it.
+11		train	77	77	 well! 
+12		train	77	79	thought alice to herself,  after such a fall as this, i shall think nothing of tumbling down stairs!
+13		train	80	81	how brave they ll all think me at home!
+14		train	81	83	why, i would nt say anything about it, even if i fell off the top of the house! 
+15		train	84	84	which was very likely true. 
+16		train	85	85	down, down, down.
+17		train	86	88	would the fall never come to an end!
+18		train	88	90	 i wonder how many miles i ve fallen by this time? 
+19		train	90	90	she said aloud.
+20		train	90	92	 i must be getting somewhere near the centre of the earth.
+21		train	92	103	let me see:  that would be four thousand miles down, i think--  for, you see, alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a very good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over   --yes, that s about the right distance--but then i wonder what latitude or longitude i ve got to? 
+22		train	104	107	alice had no idea what latitude was, or longitude either, but thought they were nice grand words to say. 
+23		train	108	108	presently she began again.
+24		train	109	110	 i wonder if i shall fall right through the earth!
+25		train	111	113	how funny it ll seem to come out among the people that walk with their heads downward!
+26		train	113	119	the antipathies, i think--  she was rather glad there was no one listening, this time, as it did nt sound at all the right word   --but i shall have to ask them what the name of the country is, you know.
+27		train	120	121	please, mama, is this new zealand or australia? 
+28		train	122	124	and she tried to curtsey as she spoke--fancy curtseying as you re falling through the air!
+29		train	124	125	do you think you could manage it? 
+30		train	126	127	 and what an ignorant little girl she ll think me for asking!
+31		train	127	129	no, it ll never do to ask:  perhaps i shall see it written up somewhere. 
+32		train	130	130	down, down, down.
+33		train	131	133	there was nothing else to do, so alice soon began talking again.
+34		train	134	135	 dinah ll miss me very much to-night, i should think! 
+35		train	136	136	dinah was the cat. 
+36		train	137	138	 i hope they ll remember her saucer of milk at tea time.
+37		train	139	139	dinah my dear!
+38		train	139	140	i wish you were down here with me!
+39		train	140	143	there are no mice in the air, i m afraid, but you might catch a bat, and that s very like a mouse, you know.
+40		train	144	144	but do cats eat bats, i wonder? 
+41		train	145	149	and here alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way,  do cats eat bats?
+42		train	149	150	do cats eat bats? 
+43		train	150	151	and sometimes,  do bats eat cats? 
+44		train	151	154	for, you see, as she could nt answer either question, it did nt much matter which way she put it.
+45		train	154	160	she felt that she was dozing off, and had just begun to dream that she was walking hand in hand with dinah, and saying to her very earnestly,  now, dinah, tell me the truth:  did you ever eat a bat? 
+46		train	161	162	when suddenly, thump!
+47		train	162	162	thump!
+48		train	162	164	down she came upon a heap of sticks and dry leaves, and the fall was over.
+49		train	165	172	alice was not a bit hurt, and she jumped up on to her feet in a moment:  she looked up, but it was all dark overhead; before her was another long passage, and the white rabbit was still in sight, hurrying down it.
+50		train	172	177	there was not a moment to be lost: away went alice like the wind, and was just in time to hear it say, as it turned a corner,  oh my ears and whiskers, how late it s getting! 
+51		train	177	183	she was close behind it when she turned the corner, but the rabbit was no longer to be seen:  she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof.
+52		train	183	190	there were doors all round the hall, but they were all locked; and when alice had been all the way down one side and up the other, trying every door, she walked sadly down the middle, wondering how she was ever to get out again.
+53		train	191	198	suddenly she came upon a little three-legged table, all made of solid glass; there was nothing on it except a tiny golden key, and alice s first thought was that it might belong to one of the doors of the hall; but, alas!
+54		train	198	201	either the locks were too large, or the key was too small, but at any rate it would not open any of them.
+55		train	202	209	however, on the second time round, she came upon a low curtain she had not noticed before, and behind it was a little door about fifteen inches high:  she tried the little golden key in the lock, and to her great delight it fitted!
+56		train	210	216	alice opened the door and found that it led into a small passage, not much larger than a rat-hole:  she knelt down and looked along the passage into the loveliest garden you ever saw.
+57		train	216	225	how she longed to get out of that dark hall, and wander about among those beds of bright flowers and those cool fountains, but she could not even get her head through the doorway;  and even if my head would go through,  thought poor alice,  it would be of very little use without my shoulders.
+58		train	226	226	oh, how i wish i could shut up like a telescope!
+59		train	227	228	i think i could, if i only know how to begin. 
+60		train	229	233	for, you see, so many out-of-the-way things had happened lately, that alice had begun to think that very few things indeed were really impossible.
+61		train	234	247	there seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes:  this time she found a little bottle on it,  which certainly was not here before,  said alice,  and round the neck of the bottle was a paper label, with the words  drink me  beautifully printed on it in large letters.
+62		train	247	250	it was all very well to say  drink me,  but the wise little alice was not going to do that in a hurry.
+63		train	251	268	" no, i ll look first,  she said,  and see whether it s marked ""poison"" or not ; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they would not remember the simple rules their friends had taught them:  such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger very deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked  poison,  it is almost certain to disagree with you, sooner or later."
+64		train	269	278	however, this bottle was not marked  poison,  so alice ventured to taste it, and finding it very nice, it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot buttered toast,  she very soon finished it off.
+65		train	280	280	 what a curious feeling! 
+66		train	281	282	said alice;  i must be shutting up like a telescope. 
+67		test	282	287	and so it was indeed:  she was now only ten inches high, and her face brightened up at the thought that she was now the right size for going through the little door into that lovely garden.
+68		test	288	295	first, however, she waited for a few minutes to see if she was going to shrink any further:  she felt a little nervous about this;  for it might end, you know,  said alice to herself,  in my going out altogether, like a candle.
+69		test	295	296	i wonder what i should be like then? 
+70		test	296	300	and she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing.
+71		test	301	305	after a while, finding that nothing more happened, she decided on going into the garden at once; but, alas for poor alice!
+72		test	305	317	when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it:  she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried.
+73		test	318	319	 come, there s no use in crying like that! 
+74		test	319	322	said alice to herself, rather sharply;  i advise you to leave off this minute! 
+75		val	322	333	she generally gave herself very good advice, though she very seldom followed it , and sometimes she scolded herself so severely as to bring tears into her eyes; she once remembered trying to box her own ears for having cheated herself in a game of croquet she was playing against herself, for this curious child was very fond of pretending to be two people.
+76		val	334	335	 but it s no use now,  thought poor alice,  to pretend to be two people!
+77		val	336	337	why, there s hardly enough of me left to make one respectable person! 
+78		val	338	344	soon her eye fell on a little glass box that was lying under the table:  she opened it, and found in it a very small cake, on which the words  eat me  were beautifully marked in currants.
+79		val	345	351	 well, i ll eat it,  said alice,  and if it makes me grow larger, i can reach the key; and if it makes me grow smaller, i can creep under the door; so either way i ll get into the garden, and i do nt care which happens! 
+80		val	352	354	she ate a little bit, and said anxiously to herself,  which way?
+81		val	355	355	which way?
+82		val	356	361	 , holding her hand on the top of her head to feel which way it was growing, and she was quite surprised to find that she remained the same size:  to be sure, this generally happens when one eats cake
Index: src/com/model/run_auto_encoder_coco.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/run_auto_encoder_coco.py b/src/com/model/run_auto_encoder_coco.py
new file mode 100644
--- /dev/null	(date 1689249492000)
+++ b/src/com/model/run_auto_encoder_coco.py	(date 1689249492000)
@@ -0,0 +1,630 @@
+import os
+
+# Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "src/com/model/"))
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "."))
+# print(Proj_dir)
+# p = os.path.abspath(os.path.join(os.getcwd(), "."))
+# print(p)
+import sys
+os.environ["CUDA_VISIBLE_DEVICES"] = "4,5,6,7"  # GPU
+
+sys.path.append(Proj_dir)
+import json
+import time
+import torch
+import pandas as pd
+from torch import nn
+import torch.nn.functional as F
+import numpy as np
+from transformers import BertModel
+from src.com.util.data_format import normalization, standardization, make_print_to_file
+import transformers
+from transformers import AdamW
+from tqdm.notebook import tqdm
+
+bert_model = BertModel.from_pretrained('bert-large-uncased', output_hidden_states=True)
+# os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"
+
+lr = 1e-5
+criterion_l2 = nn.MSELoss()
+criterion_l1 = nn.L1Loss()
+corr_list = []
+
+
+def get_sentence_embedding(sentence, tokenizer, option):
+    sentence = sentence.replace(",", '').replace(",", '')
+    # print(sentence)
+    # if YOU NEED [cls] and [seq] PRESENTATION：True
+    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=False)).unsqueeze(0)  # Batch size 1
+    outputs = bert_model(input_ids)
+
+    all_layers_output = outputs[2]
+    # list of torch.FloatTensor
+    # (one for the output of each layer + the output of the embeddings)
+    # of shape (batch_size, sequence_length, hidden_size):
+    # Hidden-states of the model at the output of each layer
+    # plus the initial embedding outputs.
+
+    if option == "last_layer":
+        sent_embeddings = all_layers_output[-1]  # last layer
+    elif option == "second_to_last_layer":
+        sent_embeddings = all_layers_output[-2]  # second to last layer
+    else:
+        sent_embeddings = all_layers_output[-1]  # last layer
+
+    sent_embeddings = torch.squeeze(sent_embeddings, dim=0)
+    # print(sent_embeddings.shape)
+
+    # Calculate the average of all token vectors.
+    sentence_embedding_avg = torch.mean(sent_embeddings, dim=0)
+    # print(sentence_embedding_avg.shape)
+
+    return sent_embeddings.detach(), sentence_embedding_avg.detach()
+
+
+class Autoencoder(nn.Module):
+    def __init__(self):
+        super(Autoencoder, self).__init__()
+        self.dense_enc1 = nn.Linear(3566, 1552)  # [batch*size]->[batch*size]
+        self.bn1 = nn.BatchNorm1d(1552)
+        self.dense_enc2 = nn.Linear(1552, 1024)
+        self.bn2 = nn.BatchNorm1d(1024)
+        # 3l
+        # self.dense_enc3 = nn.Linear(4096, 1024)
+        # self.dense_enc3 = nn.Linear(8192, 1024)
+        # vanilla
+        # self.dense_enc4 = nn.Linear(8192, 1024)
+
+        self.dense_dec0 = nn.Linear(1024, 1552)
+
+        # self.dense_dec1 = nn.Linear(1024, 4096)
+        self.bn4 = nn.BatchNorm1d(1552)
+        self.drop1 = nn.Dropout(p=0.2)
+        self.dense_dec2 = nn.Linear(1552, 3566)
+        # self.bn5 = nn.BatchNorm1d(8192)
+        # self.dense_dec3 = nn.Linear(8192, 46840)
+
+    def encoder(self, x):
+        x = F.relu(self.dense_enc1(x))
+        x = self.bn1(x)
+        # vanilla
+        x = F.relu(self.dense_enc2(x))
+        x = self.bn2(x)
+
+        # x = F.relu(self.dense_enc4(x))
+        # 3 layer
+        # x = F.relu(self.dense_enc3(x))
+        return x
+
+    def decoder(self, x):
+        # 3 layer
+        # x = F.relu(self.dense_dec1(x))
+        # x = self.bn4(x)
+        # x = F.relu(self.dense_dec2(x))
+        # vanilla
+        x = F.relu(self.dense_dec0(x))
+        x = self.bn4(x)
+        x = self.drop1(x)
+        x = F.relu(self.dense_dec2(x))
+        return x
+
+    def forward(self, x):
+        z = self.encoder(x)
+        x = self.decoder(z)
+        return x, z
+
+
+class config:
+    import random
+    SEED = random.randint(0, 100)
+    print("seed:", SEED)
+    _type = "1024_vanilla"
+    # KFOLD = 5
+    SAVE_DIR = '/Storage/ying/project/brainAE/output'
+    # TRAIN_FILE = 'train.tsv'
+    # VAL_FILE = 'valid.tsv'
+    # TEST_FILE = 'test.tsv'
+    # OOF_FILE = os.path.join(SAVE_DIR, 'oof.csv')
+    MAX_LEN = 2048
+    MODEL = 'bert-large-uncased'
+    TOKENIZER = transformers.AutoTokenizer.from_pretrained(MODEL)
+    EPOCHS = 75
+    TRAIN_BATCH_SIZE = 32
+    VALID_BATCH_SIZE = 32
+    DEVICE = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+
+    @property
+    def type(self):
+        return self._type
+
+
+def seed_all(seed=42):
+    """
+  Fix seed for reproducibility
+  """
+    # python RNG
+    import random
+    random.seed(seed)
+
+    # pytorch RNGs
+
+    torch.manual_seed(seed)
+    torch.backends.cudnn.deterministic = True
+    if torch.cuda.is_available():
+        torch.cuda.manual_seed_all(seed)
+    # numpy RNG
+
+    np.random.seed(seed)
+
+
+def preprocess(text):
+    # text = html.unescape(text)
+    # text = text.translate(transl_table)
+    # text = text.replace('…', '...')
+    # text = re.sub(control_char_regex, ' ', text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')
+    text = ' '.join(text.split())
+    text = text.lower()
+    text = text.strip()
+
+    # text = text.replace('HTTPURL', 'URL')
+    # text = emoji.demojize(text)
+
+    # text = unidecode.unidecode(text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'So')
+
+    return text
+
+
+def process_data(data, tokenizer, max_len):
+    text = preprocess(data['label'])
+    embeding, embeding_avg = get_sentence_embedding(text, tokenizer, "last_layer")
+    # input_ids = torch.tensor(tokenizer.encode(text, add_special_tokens=False, pad_to_max_length=True)).unsqueeze(
+    #     0)  # Batch size 1
+    # model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)
+
+    # token_ids = tokenizer.encode(text, add_special_tokens=False,pad_to_max_length=True), dim=0)
+    # # mask = [1] * len(token_ids)
+    #
+    # padding = max_len - len(token_ids)
+    #
+    # if padding >= 0:
+    #     token_ids = token_ids + ([0] * padding)
+    #     # mask = mask + ([0] * padding)
+    # else:
+    #     token_ids = token_ids[0:max_len]
+    #     # mask = mask[0:max_len]
+    #
+    # # label = 1 if label == 'INFORMATIVE' else 0
+    #
+    # assert len(token_ids) == max_len
+    # # assert len(mask) == max_len
+
+    return {
+        'ids': data['index'],
+        'brain': data['brain'],
+        # 'mask': mask,
+        'label': embeding_avg
+    }
+
+
+class Dataset:
+    def __init__(self, dataList):
+        self.dataList = dataList
+        # self.label = label
+        self.tokenizer = config.TOKENIZER
+        self.max_len = config.MAX_LEN
+
+    def __len__(self):
+        return len(self.dataList)
+
+    def __getitem__(self, item):
+        data = process_data(
+            self.dataList[item],
+            self.tokenizer,
+            self.max_len,
+            # self.label[item],
+        )
+
+        return {
+            'ids': torch.tensor(data["ids"], dtype=torch.long),
+            # 'mask': torch.tensor(data["mask"], dtype=torch.long),
+            'brain': data['brain'],
+            'label': data['label'],
+        }
+
+
+class EarlyStopping:
+    """
+    Early stopping utility
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self, patience=7, mode="max", delta=0.001, optimizer=None):
+        self.patience = patience
+        self.counter = 0
+        self.mode = mode
+        self.best_score = None
+        self.early_stop = False
+        self.delta = delta
+        self.optimizer = optimizer
+        if self.mode == "min":
+            self.val_score = np.Inf
+        else:
+            self.val_score = -np.Inf
+
+    def __call__(self, epoch_score, model, model_path):
+        if self.mode == "min":
+            score = -1.0 * epoch_score
+            self.delta = -1.0 * self.delta
+        else:
+            score = np.copy(epoch_score)
+        if self.best_score is None:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+        elif score < self.best_score + self.delta:
+            self.counter += 1
+            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))
+            if self.counter >= self.patience:
+                self.early_stop = True
+        else:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+            self.counter = 0
+
+    def save_checkpoint(self, epoch_score, model, model_path):
+        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:
+            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))
+            torch.save(model.state_dict(), model_path)
+            # torch.save({'state_dict': model.state_dict(),
+            #             'optimizer_state_dict': self.optimizer.state_dict()},
+            #            model_path)
+        self.val_score = epoch_score
+
+
+class AverageMeter:
+    """
+    Computes and stores the average and current value
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self):
+        self.reset()
+
+    def reset(self):
+        self.val = 0
+        self.avg = 0
+        self.sum = 0
+        self.count = 0
+
+    def update(self, val, n=1):
+        self.val = val
+        self.sum += val * n
+        self.count += n
+        self.avg = self.sum / self.count
+
+
+def train_fn(data_loader, model, optimizer, device):
+    model.train()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    # optimizer.zero_grad()
+
+    for bi, d in enumerate(tk0):
+        optimizer.zero_grad()
+        x = d['brain']
+        t = d['label']
+
+        x = standardization(x, 'train')
+        t = standardization(t, 'train')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+
+        x = x.to(device, dtype=torch.float)
+        t = t.to(device, dtype=torch.float)
+        # model.zero_grad()
+        # with torch.no_grad():
+        y, z = model(x)
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        # corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        # corr_list.append(corr)
+        # loss.requres_grad = True
+        loss.backward()
+        optimizer.step()
+        tk0.set_postfix(loss=losses.avg)
+
+
+# %%
+def eval_fn(data_loader, model, device):
+    model.eval()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    x_list = []
+    y_list = []
+    for bi, d in enumerate(tk0):
+        x = d['brain']
+        t = d['label']
+        x = standardization(x, 'valid')
+        t = standardization(t, 'valid')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+        x = x.to(device, dtype=torch.float)
+        t = t.to(device, dtype=torch.float)
+        # model.zero_grad()
+        y, z = model(x.float())
+        # loss = criterion(y.float(), x.float())
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        corr_list.append(corr)
+        # print(loss)
+        loss.backward()
+        tk0.set_postfix(loss=losses.avg)
+        x_list.append(x)
+        y_list.append(y)
+
+        losses.update(loss.item(), d['ids'].size(0))
+        # tk0.set_postfix(loss=losses.avg)
+    return losses.avg
+    # return mean_squared_error(x_list, y_list)
+
+
+def run(train, val, fold=None):
+    train_dataset = Dataset(
+        dataList=train
+        # brain=train['brain'],
+        # label='',
+    )
+
+    valid_dataset = Dataset(
+        dataList=val
+        # brain=val['brain'],
+        # label='',
+    )
+
+    train_data_loader = torch.utils.data.DataLoader(
+        train_dataset,
+        batch_size=config.TRAIN_BATCH_SIZE,
+        num_workers=4,
+        drop_last=True,
+        shuffle=True
+    )
+
+    valid_data_loader = torch.utils.data.DataLoader(
+        valid_dataset,
+        batch_size=config.VALID_BATCH_SIZE,
+        num_workers=4,
+        drop_last=True,
+        shuffle=True
+    )
+    # with torch.no_grad():
+    model = Autoencoder()
+    # /Storage/ying/project/brainAE/output/is_1024_vanilla_0.17201072940868992.bin
+    # /Storage/ying/project/brainAE/output/is_1024_vanilla_0.1694207403409694.bin
+    # /Storage/ying/project/brainAE/output/is_1024_vanilla_0.14328230675309897.bin
+    # /Storage/ying/project/brainAE/output/is_1024_vanilla_0.08393220180379493.bin
+    # is_1024_vanilla_0.013152188140832419.bin os.path.join(config.SAVE_DIR, 'is_' + config._type + '_0.013152188140832419.bin')
+    # checkpoint_file = ''
+    # checkpoint = torch.load(checkpoint_file)
+    # model.load_state_dict(checkpoint, False)
+
+    model = nn.DataParallel(model, device_ids=[0, 1, 2, 3])  # multi-GPU
+    # cudnn.benchmark = True
+    # model = transformers.RobertaForSequenceClassification.from_pretrained(config.MODEL, num_labels=2)
+    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+    model.to(device)
+    # criterion = nn.MSELoss()2
+    param_optimizer = list(model.named_parameters())
+    no_decay = ['bias', 'gamma', 'beta']
+    optimizer_grouped_parameters = [
+        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.01},
+        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.0}
+    ]
+    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)
+    # scheduler = ReduceLROnPlateau(optimizer, 'min')  # set up scheduler
+
+    es = EarlyStopping(patience=10, mode="min", optimizer=optimizer)
+    # es = EarlyStopping(patience=3, mode="max")
+
+    print('Starting training....')
+    losses = []
+    for epoch in range(config.EPOCHS):
+        print(epoch)
+        train_fn(train_data_loader, model, optimizer, device)
+        valid_loss = eval_fn(valid_data_loader, model, device)
+        losses.append(valid_loss)
+        # scheduler.step(valid_loss, epoch)  # update lr if needed
+        print(f'Epoch :{epoch + 1} | Validation Loss :{valid_loss}')
+        if fold is None:
+            es(valid_loss, model,
+               model_path=os.path.join(config.SAVE_DIR, f'is_' + config._type + '_' + str(valid_loss) + '.bin'))
+        else:
+            es(valid_loss, model, model_path=os.path.join(config.SAVE_DIR, f'model_{fold}.bin'))
+        if es.early_stop:
+            print('Early stopping')
+            break
+
+    print('Predicting for OOF')
+    print("losses:", losses)
+
+
+def dataloader_alice():
+    brain2txt = json.load(open(f'/Storage/ying/project/brainAE/src/com/model/brain2txt.json', 'r'))
+    sentence_df = pd.read_csv(f'/Storage/ying/project/brainAE/src/com/model/alice_sentence.tsv', sep='\t', header=0)
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/alice/ae_npy/'
+    files = os.listdir(brain_path)
+    # i = 0
+    train_data = []
+    val_data = []
+    # min_size = 10000000
+    for file in files:  # 遍历文件夹
+        file_spilt = file.replace('.npy', '').split('_')
+        index = int(file_spilt[2])
+        user = file_spilt[1]
+        brain_data = np.load(brain_path + file)
+        name = 'alice_' + str(user) + '_' + str(index) + '.npz'
+        sentence_id = int(brain2txt[name].split('-')[2])
+        if index < 362 * 0.8:
+            train_data.append({
+                'index': index,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['sentences'][sentence_id]
+            })
+        else:
+            val_data.append({
+                'index': index,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['sentences'][sentence_id]
+            })
+
+        # (372, 199662)
+    # print("min_size:", min_size)
+    return train_data, val_data
+
+
+def dataloader_pereira():
+    train_data = []
+    val_data = []
+    # brain_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/AE_training/'
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/'
+    files = os.listdir(brain_path)
+    i = 0
+    for file in files:  # 遍历文件夹
+        # print(file.replace('.npy', '').split('_'))
+        file_spilt = file.replace('.npy', '').split('_')
+        index = int(file_spilt[3])
+        user = file_spilt[1]
+        exp_index = file_spilt[2]
+        brain_data = np.load(brain_path + file)
+        if exp_index == 'exp1':
+            # 180 ->144 train; ->36 val
+
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp1_text.tsv', sep='\t', header=0)
+            sentence_df = pd.read_csv('/Storage/ying/project/brainAE/resource/exp1_text.tsv', sep='\t', header=0)
+            group_boundary = 144
+        elif exp_index == 'exp2':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp2_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv('/Storage/ying/project/brainAE/resource/exp2_text.tsv', sep='\t', header=0)
+            # 384 ->308 train; ->76 val
+            group_boundary = 308
+        elif exp_index == 'exp3':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp3_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv('/Storage/ying/project/brainAE/resource/exp3_text.tsv', sep='\t', header=0)
+            # 243 ->195 train; ->48 val
+            group_boundary = 195
+        if index < group_boundary:
+            train_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['text'][index]})
+            i = i + 1
+        else:
+            val_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['text'][index]
+            })
+            i = i + 1
+
+    # print("min_size:", min_size)
+    return train_data, val_data
+
+
+def dataloader_is():
+    train_data = []
+    val_data = []
+    # brain_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/AE_training/'
+    # brain_val_path = '/Storage/ying/resources/BrainBertTorch/brain/coco/npy/'
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/ImageNet_Scene/npy/'
+    files = os.listdir(brain_path)
+    i = 0
+    for file in files:  # 遍历文件夹
+        # print(file.replace('.npy', '').split('_'))
+        file_spilt = file.replace('.npz', '').split('_')
+        index = int(file_spilt[3])
+        user = file_spilt[2]
+        if user == 'CSI1':
+            user = 'CSI01'
+        elif user == 'CSI2':
+            user = 'CSI02'
+        elif user == 'CSI3':
+            user = 'CSI03'
+        elif user == 'CSI4':
+            user = 'CSI04'
+        # exp_idex = file_spilt[2]
+        # 8:2
+        # (3119, 1685)
+        # (3119, 2270)
+        # (3121, 3104)
+        # (1834, 2787)
+        brain_data = np.load(brain_path + file, allow_pickle=True)
+        label_list = open("/Storage/ying/project/ridgeRegression/BOLD5000/ROIs/caption/" + user + "_is_captioning.txt",
+                          'r').readlines()
+
+        if user == 'CSI01':
+            group_boundary = 2495
+        elif user == 'CSI02':
+            group_boundary = 2495
+        elif user == 'CSI03':
+            group_boundary = 2495
+        elif user == 'CSI04':
+            group_boundary = 1467
+        if index < group_boundary:
+            train_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data['arr_0'],
+                'label': label_list[0]})
+            i = i + 1
+        else:
+            val_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data['arr_0'],
+                'label': label_list[0]
+            })
+            i = i + 1
+
+    # print("min_size:", min_size)
+    return train_data, val_data
+
+
+def dataloader_switch(type):
+    if type == 'alice':
+        train_, val_ = dataloader_alice()
+    elif type == 'pereira':
+        train_, val_ = dataloader_pereira()
+    elif type == 'is':
+        train_, val_ = dataloader_is()
+    return train_, val_
+
+
+def run_fold(type, fold_idx=None):
+    """
+      Perform k-fold cross-validation
+    """
+    seed_all(seed=config.SEED)
+    train_, val_ = dataloader_switch(type=type)
+
+    run(train_, val_, fold_idx)
+
+
+if __name__ == "__main__":
+    start = time.perf_counter()
+    make_print_to_file('.')
+    run_fold(type='is', fold_idx=None)
+    print("corr_list:", corr_list)
+    end = time.perf_counter()
+    time_cost = str((end - start) / 60)
+    print("time-cost:", time_cost)
Index: src/com/model/run_auto_encoder.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/run_auto_encoder.py b/src/com/model/run_auto_encoder.py
new file mode 100644
--- /dev/null	(date 1695459107000)
+++ b/src/com/model/run_auto_encoder.py	(date 1695459107000)
@@ -0,0 +1,664 @@
+import os
+import random
+from transformers import AlbertTokenizer, AlbertModel
+
+# cherry 的 GPU跑不动 死心吧
+# Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "."))  # TODO script
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "../../../"))  # TODO local
+# print(Proj_dir)
+import sys
+
+sys.path.append(Proj_dir)
+import json
+import time
+import torch
+import pandas as pd
+from torch import nn
+import torch.nn.functional as F
+import numpy as np
+from transformers import BertModel
+from sentence_transformers import SentenceTransformer
+from simcse import SimCSE
+from src.com.util.data_format import normalization, standardization
+import transformers
+from transformers import AdamW
+from tqdm import tqdm
+
+os.environ["CUDA_VISIBLE_DEVICES"] = "0,1"  # GPU
+
+lr = 1e-5
+
+corr_list = []
+
+
+def get_albert_embedding_tensor(sentence, tokenizer, model):
+    encoded_input = tokenizer(sentence, return_tensors='pt')
+    output = model(**encoded_input)
+    return output[-1].detach().squeeze(0)
+
+
+def get_sentence_embedding(sentence, tokenizer, option):
+    # if YOU NEED [cls] and [seq] PRESENTATION：True
+    # print(_config.MODEL)
+    if _config.MODEL == 'bert-large-uncased':
+        input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=False)).unsqueeze(0)  # Batch size 1
+        text_model = BertModel.from_pretrained(_config.MODEL, output_hidden_states=True)
+        outputs = text_model(input_ids)
+        all_layers_output = outputs[2]
+        if option == "last_layer":
+            sent_embeddings = all_layers_output[-1]  # last layer
+        elif option == "second_to_last_layer":
+            sent_embeddings = all_layers_output[-2]  # second to last layer
+        else:
+            sent_embeddings = all_layers_output[-1]  # last layer
+
+        sent_embeddings = torch.squeeze(sent_embeddings, dim=0)
+        # print(sent_embeddings.shape)
+
+        # Calculate the average of all token vectors.
+        sentence_embedding_avg = torch.mean(sent_embeddings, dim=0)
+        # print(sentence_embedding_avg.shape)
+
+        return sentence_embedding_avg
+
+    elif _config.MODEL == 'sentence-camembert-large':
+        text_model = SentenceTransformer("dangvantuan/sentence-camembert-large")
+        embeddings = text_model.encode(sentence)
+        return embeddings
+    elif _config.MODEL == 'SimCSE':
+
+        text_model = SimCSE("princeton-nlp/sup-simcse-bert-base-uncased")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_large':
+
+        text_model = SimCSE("princeton-nlp/sup-simcse-bert-large-uncased")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_roberta_large':
+        text_model = SimCSE("princeton-nlp/sup-simcse-roberta-large")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_roberta_large_sup':
+        text_model = SimCSE("princeton-nlp/unsup-simcse-roberta-large")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL == 'SimCSE_bert_large_unsup':
+        text_model = SimCSE("princeton-nlp/unsup-simcse-bert-large-uncased")
+        embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+                                       batch_size=64,
+                                       max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+    elif _config.MODEL in ['albert-xlarge-v1', 'albert-xlarge-v2']:
+        text_model = AlbertModel.from_pretrained(_config.MODEL)
+        tokenizer = AlbertTokenizer.from_pretrained(_config.MODEL)
+        # text_model = AlbertModel("princeton-nlp/unsup-simcse-bert-large-uncased")
+        embeddings = get_albert_embedding_tensor(sentence, tokenizer, text_model)
+        # embeddings = get_albert_embedding_tensor(sentence, tokenizer, text_model)
+        # embeddings = text_model.encode(sentence, return_numpy=True, device='cpu', normalize_to_unit=True, keepdim=False,
+        #                                batch_size=64,
+        #                                max_length=128)  # 768 https://github.com/princeton-nlp/SimCSE#use-simcse-with-huggingface　
+        return embeddings
+
+
+# SimCSE_bert_large_unsup
+class config:
+    SEED = random.randint(0, 100)
+    # print("seed:", SEED)
+    _type = "vanilla"
+    # KFOLD = 5
+    SAVE_DIR = Proj_dir + '/output'  # laplace
+    # TRAIN_FILE = 'train.tsv'
+    # VAL_FILE = 'valid.tsv'
+    # TEST_FILE = 'test.tsv'
+    # OOF_FILE = os.path.join(SAVE_DIR, 'oof.csv')
+    MAX_LEN = 2048
+
+    MODEL = 'albert-xlarge-v1'  # default
+    TOKENIZER = ''  # default
+    LATENT_SIZE = 2048  # default
+
+    EPOCHS = 75
+    TRAIN_BATCH_SIZE = 32
+    VALID_BATCH_SIZE = 32
+    DEVICE = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+
+    @property
+    def type(self):
+        return self._type
+
+
+class Autoencoder(nn.Module):
+    def __init__(self):
+        super(Autoencoder, self).__init__()
+        self.dense_enc1 = nn.Linear(46840, 8192)  # [batch*size]->[batch*size]
+        self.bn1 = nn.BatchNorm1d(8192)
+        self.dense_enc2 = nn.Linear(8192, 4096)
+        self.bn2 = nn.BatchNorm1d(4096)
+        # 3l
+        self.dense_enc3 = nn.Linear(4096, _config.LATENT_SIZE)
+        # self.dense_enc3 = nn.Linear(8192, 1024)
+        # vanilla
+        self.dense_enc4 = nn.Linear(8192, _config.LATENT_SIZE)
+
+        self.dense_dec0 = nn.Linear(_config.LATENT_SIZE, 8192)
+
+        self.dense_dec1 = nn.Linear(_config.LATENT_SIZE, 4096)
+        self.bn4 = nn.BatchNorm1d(4096)
+        self.dense_dec2 = nn.Linear(4096, 8192)
+        self.bn5 = nn.BatchNorm1d(8192)
+        self.drop1 = nn.Dropout(p=0.2)
+        self.dense_dec3 = nn.Linear(8192, 46840)
+
+    def encoder(self, x):
+        x = F.relu(self.dense_enc1(x))
+        x = self.bn1(x)
+        # vanilla
+        x = F.relu(self.dense_enc4(x))
+        # 3 layer
+        # x = F.relu(self.dense_enc2(x))
+        # x = self.bn2(x)
+        # x = F.relu(self.dense_enc3(x))
+        return x
+
+    def decoder(self, x):
+        # 3 layer
+        # x = F.relu(self.dense_dec1(x))
+        # x = self.bn4(x)
+        # x = F.relu(self.dense_dec2(x))
+        # vanilla
+        x = F.relu(self.dense_dec0(x))
+        x = self.bn5(x)
+        x = self.drop1(x)
+        x = F.relu(self.dense_dec3(x))
+        return x
+
+    def forward(self, x):
+        z = self.encoder(x)
+        x = self.decoder(z)
+        return x, z
+
+
+def seed_all(seed=42):
+    """
+  Fix seed for reproducibility
+  """
+    # python RNG
+    import random
+    random.seed(seed)
+
+    # pytorch RNGs
+    torch.manual_seed(seed)
+    torch.backends.cudnn.deterministic = True
+    if torch.cuda.is_available():
+        torch.cuda.manual_seed_all(seed)
+    np.random.seed(seed)
+
+
+def preprocess(text):
+    # text = html.unescape(text)
+    # text = text.translate(transl_table)
+    # text = text.replace('…', '...')
+    # text = re.sub(control_char_regex, ' ', text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'C')
+    text = ' '.join(text.split())
+    text = text.lower()
+    text = text.strip()
+
+    # text = text.replace('HTTPURL', 'URL')
+    # text = emoji.demojize(text)
+
+    # text = unidecode.unidecode(text)
+    # text = ''.join(ch for ch in text if unicodedata.category(ch)[0] != 'So')
+
+    return text
+
+
+def process_data(data, tokenizer, max_len):
+    # text = preprocess(data['label'])
+    # embeding = get_sentence_embedding(sentence=text, tokenizer=tokenizer, option="last_layer")
+
+    return {
+        'ids': data['index'],
+        'brain': data['brain'],
+        # 'mask': mask,
+        'label': embeding
+    }
+
+
+class Dataset:
+    def __init__(self, dataList):
+        self.dataList = dataList
+        # self.label = label
+        # self.tokenizer = _config.TOKENIZER
+        # self.max_len = _config.MAX_LEN
+
+    def __len__(self):
+        return len(self.dataList)
+
+    def __getitem__(self, item):
+        data = process_data(
+            self.dataList[item],
+            # self.tokenizer,
+            # self.max_len,
+            # self.label[item],
+        )
+
+        return {
+            'ids': torch.tensor(data["ids"], dtype=torch.long),
+            # 'mask': torch.tensor(data["mask"], dtype=torch.long),
+            'brain': data['brain'],
+            'label': torch.tensor(data["label"], dtype=torch.long)  # data['label'],
+        }
+
+
+class EarlyStopping:
+    """
+    Early stopping utility
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self, patience=7, mode="max", delta=0.001, optimizer=None):
+        self.patience = patience
+        self.counter = 0
+        self.mode = mode
+        self.best_score = None
+        self.early_stop = False
+        self.delta = delta
+        self.optimizer = optimizer
+        if self.mode == "min":
+            self.val_score = np.Inf
+        else:
+            self.val_score = -np.Inf
+
+    def __call__(self, epoch_score, model, model_path):
+        if self.mode == "min":
+            score = -1.0 * epoch_score
+            self.delta = -1.0 * self.delta
+        else:
+            score = np.copy(epoch_score)
+        if self.best_score is None:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+        elif score < self.best_score + self.delta:
+            self.counter += 1
+            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))
+            if self.counter >= self.patience:
+                self.early_stop = True
+        else:
+            self.best_score = score
+            self.save_checkpoint(epoch_score, model, model_path)
+            self.counter = 0
+
+    def save_checkpoint(self, epoch_score, model, model_path):
+        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:
+            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))
+            torch.save(model.state_dict(), model_path)
+            # torch.save({'state_dict': model.state_dict(),
+            #             'optimizer_state_dict': self.optimizer.state_dict()},
+            #            model_path)
+        self.val_score = epoch_score
+
+
+class AverageMeter:
+    """
+    Computes and stores the average and current value
+    Source : https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch/
+    """
+
+    def __init__(self):
+        self.reset()
+
+    def reset(self):
+        self.val = 0
+        self.avg = 0
+        self.sum = 0
+        self.count = 0
+
+    def update(self, val, n=1):
+        self.val = val
+        self.sum += val * n
+        self.count += n
+        self.avg = self.sum / self.count
+
+
+def train_fn(data_loader, model, optimizer):
+    model.train()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    # optimizer.zero_grad()
+
+    for bi, d in enumerate(tk0):
+        optimizer.zero_grad()
+        x = d['brain']
+        t = d['label']
+
+        x = standardization(x, 'train')
+        t = standardization(t, 'train')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+
+        # model.zero_grad()
+        # with torch.no_grad():
+        x = torch.autograd.Variable(x).to(_config.DEVICE, dtype=torch.float)
+        t = torch.autograd.Variable(t).to(_config.DEVICE, dtype=torch.float)
+        # x = x.to(_config.DEVICE, dtype=torch.float)
+        # t = t.to(_config.DEVICE, dtype=torch.float)
+        y, z = model(x)
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        # corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        # corr_list.append(corr)
+        # loss.requres_grad = True
+        loss.backward()
+        optimizer.step()
+        tk0.set_postfix(loss=losses.avg)
+
+
+# %%
+def eval_fn(data_loader, model):
+    model.eval()
+    losses = AverageMeter()
+    tk0 = tqdm(data_loader, total=len(data_loader))
+    x_list = []
+    y_list = []
+    for bi, d in enumerate(tk0):
+        x = d['brain']
+        t = d['label']
+        x = standardization(x, 'valid')
+        t = standardization(t, 'valid')
+        x, _, _ = normalization(x)
+        t, _, _ = normalization(t)
+        x = torch.Tensor(x).float()
+        t = torch.Tensor(t).float()
+        x = x.to(_config.DEVICE, dtype=torch.float)
+        t = t.to(_config.DEVICE, dtype=torch.float)
+        # model.zero_grad()
+        y, z = model(x.float())
+        # loss = criterion(y.float(), x.float())
+        loss = criterion_l2(y.float(), x.float()) + criterion_l1(z.float(), t.float())
+        # corr = np.corrcoef(t.cpu().detach().numpy(), z.cpu().detach().numpy())[0, 1]
+        # corr_list.append(corr)
+        print(loss)
+        loss.backward()
+        tk0.set_postfix(loss=losses.avg)
+        x_list.append(x)
+        y_list.append(y)
+
+        losses.update(loss.item(), d['ids'].size(0))
+        tk0.set_postfix(loss=losses.avg)
+    return losses.avg
+    # return mean_squared_error(x_list, y_list)
+
+
+def run(train, val, fold=None):
+    train_dataset = Dataset(
+        dataList=train
+        # brain=train['brain'],
+        # label='',
+    )
+
+    valid_dataset = Dataset(
+        dataList=val
+        # brain=val['brain'],
+        # label='',
+    )
+
+    train_data_loader = torch.utils.data.DataLoader(
+        train_dataset,
+        batch_size=_config.TRAIN_BATCH_SIZE,
+        num_workers=8,
+        drop_last=True,
+        shuffle=True
+    )
+
+    valid_data_loader = torch.utils.data.DataLoader(
+        valid_dataset,
+        batch_size=_config.VALID_BATCH_SIZE,
+        num_workers=8,
+        drop_last=True,
+        shuffle=True
+    )
+    # with torch.no_grad():
+    model = Autoencoder()
+    # checkpoint_file = os.path.join(_config.SAVE_DIR, 'model_sentenceBERT_' + _config._type + '.bin')
+    # checkpoint = torch.load(checkpoint_file)
+    # model.load_state_dict(checkpoint,False)
+    # laplace 0~7
+    model = nn.DataParallel(model, device_ids=[0, 1])  # multi- GPU
+    model = model.module.to(_config.DEVICE)
+
+    # cudnn.benchmark = True
+
+    # model.to(device)
+    # criterion = nn.MSELoss()2
+    param_optimizer = list(model.named_parameters())
+    no_decay = ['bias', 'gamma', 'beta']
+    optimizer_grouped_parameters = [
+        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.01},
+        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],
+         'weight_decay_rate': 0.0}
+    ]
+    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)
+    # scheduler = ReduceLROnPlateau(optimizer, 'min')  # set up scheduler
+
+    es = EarlyStopping(patience=10, mode="min", optimizer=optimizer)
+    # es = EarlyStopping(patience=3, mode="max")
+
+    print('Starting training....')
+    losses = []
+    for epoch in range(_config.EPOCHS):
+        print(epoch)
+        train_fn(train_data_loader, model, optimizer)
+        valid_loss = eval_fn(valid_data_loader, model)
+        losses.append(valid_loss)
+        # scheduler.step(valid_loss, epoch)  # update lr if needed
+        print(f'Epoch :{epoch + 1} | Validation Loss :{valid_loss}')
+        if fold is None:
+            es(valid_loss, model, model_path=os.path.join(_config.SAVE_DIR,
+                                                          _config.MODEL + '_' + str(
+                                                              _config.LATENT_SIZE) + '_' + _config._type + '-AE_' + str(
+                                                              valid_loss) + '.bin'))
+        else:
+            es(valid_loss, model, model_path=os.path.join(_config.SAVE_DIR,
+                                                          _config.MODEL + '_' + str(
+                                                              _config.LATENT_SIZE) + f'-AE_{fold}.bin'))
+        if es.early_stop:
+            print('Early stopping')
+            break
+
+    print('Predicting for OOF')
+    print(losses)
+
+
+def dataloader_alice():
+    brain2txt = json.load(open(Proj_dir + f'/src/com/model/brain2txt.json', 'r'))
+    sentence_df = pd.read_csv(Proj_dir + f'/src/com/model/alice_sentence.tsv', sep='\t', header=0)
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/alice/ae_npy/'  # laplace
+    files = os.listdir(brain_path)
+    # i = 0
+    train_data = []
+    val_data = []
+    # min_size = 10000000
+    for file in files:  # 遍历文件夹
+        file_spilt = file.replace('.npy', '').split('_')
+        index = int(file_spilt[2])
+        user = file_spilt[1]
+        brain_data = np.load(brain_path + file)
+        name = 'alice_' + str(user) + '_' + str(index) + '.npz'
+        sentence_id = int(brain2txt[name].split('-')[2])
+        if index < 362 * 0.8:
+            train_data.append({
+                'index': index,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['sentences'][sentence_id]
+            })
+        else:
+            val_data.append({
+                'index': index,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['sentences'][sentence_id]
+            })
+
+        # (372, 199662)
+    # print("min_size:", min_size)
+    return train_data, val_data
+
+
+def dataloader_pereira():
+    train_data = []
+    val_data = []
+    brain_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/'  # laplace
+    files = os.listdir(brain_path)
+    i = 0
+    for file in files:  # 遍历文件夹
+        # print(file.replace('.npy', '').split('_'))
+        file_spilt = file.replace('.npy', '').split('_')
+        index = int(file_spilt[3])
+        user = file_spilt[1]
+        exp_index = file_spilt[2]
+        brain_data = np.load(brain_path + file)
+        if exp_index == 'exp1':
+            # 180 ->144 train; ->36 val
+
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp1_text.tsv', sep='\t', header=0)
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp1_text.tsv', sep='\t', header=0)
+            group_boundary = 144
+        elif exp_index == 'exp2':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp2_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp2_text.tsv', sep='\t', header=0)
+            # 384 ->308 train; ->76 val
+            group_boundary = 308
+        elif exp_index == 'exp3':
+            # sentence_df = pd.read_csv(Proj_dir+'/resource/exp3_text.tsv', sep='\t', header=0)
+
+            sentence_df = pd.read_csv(Proj_dir + '/resource/exp3_text.tsv', sep='\t', header=0)
+            # 243 ->195 train; ->48 val
+            group_boundary = 195
+        if index < group_boundary:
+            train_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['text'][index]})
+            i = i + 1
+        else:
+            val_data.append({
+                'index': i,
+                'participant': user,
+                'brain': brain_data[:46840],
+                'label': sentence_df['text'][index]
+            })
+            i = i + 1
+
+    # print("min_size:", min_size)
+    return train_data, val_data
+
+
+def dataloader_switch(type):
+    if type == 'alice':
+        train_, val_ = dataloader_alice()
+    elif type == 'pereira':
+        train_, val_ = dataloader_pereira()
+    return train_, val_
+
+
+def run_fold(type, fold_idx=None):
+    """
+      Perform k-fold cross-validation
+    """
+    seed_all(seed=_config.SEED)
+    train_, val_ = dataloader_switch(type=type)
+
+    run(train_, val_, fold_idx)
+
+
+def make_print_to_file(path='.'):
+    '''
+    path， it is a path for save your log about fuction print
+    example:
+    use  make_print_to_file()   and the   all the information of funtion print , will be write in to a log file
+    :return:
+    '''
+    import os
+    # import config_file as cfg_file
+    import sys
+    import datetime
+
+    class Logger(object):
+        def __init__(self, filename="Default.log", path="./"):
+            self.terminal = sys.stdout
+            self.log = open(os.path.join(path, filename), "a", encoding='utf8', )
+
+        def write(self, message):
+            self.terminal.write(message)
+            self.log.write(message)
+
+        def flush(self):
+            pass
+
+    fileName = datetime.datetime.now().strftime('day and time:' + '%Y_%m_%d')
+    sys.stdout = Logger(fileName + '.log', path=path)
+
+    #############################################################
+    # print -> log
+    #############################################################
+    print(fileName.center(60, '*'))
+
+_config = config()
+if __name__ == "__main__":
+    torch.multiprocessing.set_start_method('spawn')
+    start = time.perf_counter()
+    make_print_to_file('.')
+
+    criterion_l2 = nn.MSELoss().to(_config.DEVICE)
+    criterion_l1 = nn.L1Loss().to(_config.DEVICE)
+    _config.MODEL = 'albert-xlarge-v1'  # local running
+    # print(sys.argv)
+    # _config.MODEL = sys.argv[2]  # TODO shell
+    # local
+    # if _config.MODEL == 'bert-large-uncased':
+    #     _config.TOKENIZER = transformers.AutoTokenizer.from_pretrained(_config.MODEL)
+    #     _config.LATENT_SIZE = 1024
+    # elif _config.MODEL == 'sentence-camembert-large':
+    #     _config.TOKENIZER = SentenceTransformer("dangvantuan/sentence-camembert-large")
+    #     _config.LATENT_SIZE = 1024
+    # elif _config.MODEL == 'SimCSE_large':
+    #     _config.TOKENIZER = SimCSE("princeton-nlp/sup-simcse-bert-large-uncased")
+    #     _config.LATENT_SIZE = 1024
+    # elif _config.MODEL == 'SimCSE':
+    #     _config.TOKENIZER = SimCSE("princeton-nlp/sup-simcse-bert-base-uncased")
+    #     _config.LATENT_SIZE = 768
+    # elif _config.MODEL == 'SimCSE_roberta_large':
+    #     _config.TOKENIZER = SimCSE("princeton-nlp/unsup-simcse-roberta-large")
+    #     _config.LATENT_SIZE = 1024
+    # elif _config.MODEL == 'SimCSE_bert_large_unsup':
+    #     _config.TOKENIZER = SimCSE("princeton-nlp/unsup-simcse-bert-large-uncased")
+    #     _config.LATENT_SIZE = 1024
+    # elif _config.MODEL == 'albert-xlarge-v1':
+    #     _config.TOKENIZER = AlbertTokenizer.from_pretrained(_config.MODEL)
+    #     _config.LATENT_SIZE = 2048
+    # elif _config.MODEL == 'albert-xlarge-v2':
+    #     _config.TOKENIZER = AlbertTokenizer.from_pretrained(_config.MODEL)
+    #     _config.LATENT_SIZE = 2048
+    # # elif _config.MODEL == 'SimCSE_roberta_large_sup':
+    # #     _config.TOKENIZER = SimCSE("princeton-nlp/sup-simcse-roberta-large")
+    # #     _config.LATENT_SIZE = 1024
+    run_fold(type='pereira', fold_idx=None)
+    print(corr_list)
+    end = time.perf_counter()
+    time_cost = str((end - start) / 60)
+    print("time-cost:", time_cost)
Index: src/com/model/brain2txt.json
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/brain2txt.json b/src/com/model/brain2txt.json
new file mode 100644
--- /dev/null	(date 1616247277000)
+++ b/src/com/model/brain2txt.json	(date 1616247277000)
@@ -0,0 +1,16636 @@
+{
+
+  "alice_18_0.npz": "train-18-0-0",
+
+  "alice_18_1.npz": "train-18-0-1",
+
+  "alice_18_2.npz": "train-18-0-2",
+
+  "alice_18_3.npz": "train-18-0-3",
+
+  "alice_18_4.npz": "train-18-0-4",
+
+  "alice_18_5.npz": "train-18-0-5",
+
+  "alice_18_6.npz": "train-18-0-6",
+
+  "alice_18_7.npz": "train-18-0-7",
+
+  "alice_18_8.npz": "train-18-0-8",
+
+  "alice_18_9.npz": "train-18-1-0",
+
+  "alice_18_10.npz": "train-18-1-1",
+
+  "alice_18_11.npz": "train-18-1-2",
+
+  "alice_18_12.npz": "train-18-1-3",
+
+  "alice_18_13.npz": "train-18-1-4",
+
+  "alice_18_14.npz": "train-18-1-5",
+
+  "alice_18_15.npz": "train-18-1-6",
+
+  "alice_18_16.npz": "train-18-1-7",
+
+  "alice_18_17.npz": "train-18-1-8",
+
+  "alice_18_18.npz": "train-18-1-9",
+
+  "alice_18_19.npz": "train-18-2-0",
+
+  "alice_18_20.npz": "train-18-2-1",
+
+  "alice_18_21.npz": "train-18-2-2",
+
+  "alice_18_22.npz": "train-18-2-3",
+
+  "alice_18_23.npz": "train-18-3-0",
+
+  "alice_18_24.npz": "train-18-4-0",
+
+  "alice_18_25.npz": "train-18-5-0",
+
+  "alice_18_26.npz": "train-18-5-1",
+
+  "alice_18_27.npz": "train-18-5-2",
+
+  "alice_18_28.npz": "train-18-5-3",
+
+  "alice_18_29.npz": "train-18-5-4",
+
+  "alice_18_30.npz": "train-18-5-5",
+
+  "alice_18_31.npz": "train-18-5-6",
+
+  "alice_18_32.npz": "train-18-5-7",
+
+  "alice_18_33.npz": "train-18-5-8",
+
+  "alice_18_34.npz": "train-18-5-9",
+
+  "alice_18_35.npz": "train-18-5-10",
+
+  "alice_18_36.npz": "train-18-5-11",
+
+  "alice_18_37.npz": "train-18-5-12",
+
+  "alice_18_38.npz": "train-18-5-13",
+
+  "alice_18_39.npz": "train-18-5-14",
+
+  "alice_18_40.npz": "train-18-5-15",
+
+  "alice_18_41.npz": "train-18-5-16",
+
+  "alice_18_42.npz": "train-18-5-17",
+
+  "alice_18_43.npz": "train-18-6-0",
+
+  "alice_18_44.npz": "train-18-6-1",
+
+  "alice_18_45.npz": "train-18-6-2",
+
+  "alice_18_46.npz": "train-18-6-3",
+
+  "alice_18_47.npz": "train-18-7-0",
+
+  "alice_18_48.npz": "train-18-7-1",
+
+  "alice_18_49.npz": "train-18-7-2",
+
+  "alice_18_50.npz": "train-18-7-3",
+
+  "alice_18_51.npz": "train-18-7-4",
+
+  "alice_18_52.npz": "train-18-7-5",
+
+  "alice_18_53.npz": "train-18-8-0",
+
+  "alice_18_54.npz": "train-18-8-1",
+
+  "alice_18_55.npz": "train-18-8-2",
+
+  "alice_18_56.npz": "train-18-8-3",
+
+  "alice_18_57.npz": "train-18-8-4",
+
+  "alice_18_58.npz": "train-18-8-5",
+
+  "alice_18_59.npz": "train-18-9-0",
+
+  "alice_18_60.npz": "train-18-9-1",
+
+  "alice_18_61.npz": "train-18-9-2",
+
+  "alice_18_62.npz": "train-18-9-3",
+
+  "alice_18_63.npz": "train-18-9-4",
+
+  "alice_18_64.npz": "train-18-9-5",
+
+  "alice_18_65.npz": "train-18-9-6",
+
+  "alice_18_66.npz": "train-18-9-7",
+
+  "alice_18_67.npz": "train-18-9-8",
+
+  "alice_18_68.npz": "train-18-10-0",
+
+  "alice_18_69.npz": "train-18-10-1",
+
+  "alice_18_70.npz": "train-18-10-2",
+
+  "alice_18_71.npz": "train-18-10-3",
+
+  "alice_18_72.npz": "train-18-10-4",
+
+  "alice_18_73.npz": "train-18-10-5",
+
+  "alice_18_74.npz": "train-18-10-6",
+
+  "alice_18_75.npz": "train-18-10-7",
+
+  "alice_18_76.npz": "train-18-10-8",
+
+  "alice_18_77.npz": "train-18-12-0",
+
+  "alice_18_78.npz": "train-18-12-1",
+
+  "alice_18_79.npz": "train-18-12-2",
+
+  "alice_18_80.npz": "train-18-13-0",
+
+  "alice_18_81.npz": "train-18-14-0",
+
+  "alice_18_82.npz": "train-18-14-1",
+
+  "alice_18_83.npz": "train-18-14-2",
+
+  "alice_18_84.npz": "train-18-15-0",
+
+  "alice_18_85.npz": "train-18-16-0",
+
+  "alice_18_86.npz": "train-18-17-0",
+
+  "alice_18_87.npz": "train-18-17-1",
+
+  "alice_18_88.npz": "train-18-18-0",
+
+  "alice_18_89.npz": "train-18-18-1",
+
+  "alice_18_90.npz": "train-18-20-0",
+
+  "alice_18_91.npz": "train-18-20-1",
+
+  "alice_18_92.npz": "train-18-21-0",
+
+  "alice_18_93.npz": "train-18-21-1",
+
+  "alice_18_94.npz": "train-18-21-2",
+
+  "alice_18_95.npz": "train-18-21-3",
+
+  "alice_18_96.npz": "train-18-21-4",
+
+  "alice_18_97.npz": "train-18-21-5",
+
+  "alice_18_98.npz": "train-18-21-6",
+
+  "alice_18_99.npz": "train-18-21-7",
+
+  "alice_18_100.npz": "train-18-21-8",
+
+  "alice_18_101.npz": "train-18-21-9",
+
+  "alice_18_102.npz": "train-18-21-10",
+
+  "alice_18_103.npz": "train-18-21-11",
+
+  "alice_18_104.npz": "train-18-22-0",
+
+  "alice_18_105.npz": "train-18-22-1",
+
+  "alice_18_106.npz": "train-18-22-2",
+
+  "alice_18_107.npz": "train-18-22-3",
+
+  "alice_18_108.npz": "train-18-23-0",
+
+  "alice_18_109.npz": "train-18-24-0",
+
+  "alice_18_110.npz": "train-18-24-1",
+
+  "alice_18_111.npz": "train-18-25-0",
+
+  "alice_18_112.npz": "train-18-25-1",
+
+  "alice_18_113.npz": "train-18-26-0",
+
+  "alice_18_114.npz": "train-18-26-1",
+
+  "alice_18_115.npz": "train-18-26-2",
+
+  "alice_18_116.npz": "train-18-26-3",
+
+  "alice_18_117.npz": "train-18-26-4",
+
+  "alice_18_118.npz": "train-18-26-5",
+
+  "alice_18_119.npz": "train-18-26-6",
+
+  "alice_18_120.npz": "train-18-27-0",
+
+  "alice_18_121.npz": "train-18-27-1",
+
+  "alice_18_122.npz": "train-18-28-0",
+
+  "alice_18_123.npz": "train-18-28-1",
+
+  "alice_18_124.npz": "train-18-29-0",
+
+  "alice_18_125.npz": "train-18-29-1",
+
+  "alice_18_126.npz": "train-18-30-0",
+
+  "alice_18_127.npz": "train-18-31-0",
+
+  "alice_18_128.npz": "train-18-31-1",
+
+  "alice_18_129.npz": "train-18-31-2",
+
+  "alice_18_130.npz": "train-18-32-0",
+
+  "alice_18_131.npz": "train-18-33-0",
+
+  "alice_18_132.npz": "train-18-33-1",
+
+  "alice_18_133.npz": "train-18-33-2",
+
+  "alice_18_134.npz": "train-18-34-0",
+
+  "alice_18_135.npz": "train-18-34-1",
+
+  "alice_18_136.npz": "train-18-35-0",
+
+  "alice_18_137.npz": "train-18-36-0",
+
+  "alice_18_138.npz": "train-18-36-1",
+
+  "alice_18_139.npz": "train-18-38-0",
+
+  "alice_18_140.npz": "train-18-39-0",
+
+  "alice_18_141.npz": "train-18-39-1",
+
+  "alice_18_142.npz": "train-18-39-2",
+
+  "alice_18_143.npz": "train-18-39-3",
+
+  "alice_18_144.npz": "train-18-40-0",
+
+  "alice_18_145.npz": "train-18-41-0",
+
+  "alice_18_146.npz": "train-18-41-1",
+
+  "alice_18_147.npz": "train-18-41-2",
+
+  "alice_18_148.npz": "train-18-41-3",
+
+  "alice_18_149.npz": "train-18-42-0",
+
+  "alice_18_150.npz": "train-18-43-0",
+
+  "alice_18_151.npz": "train-18-44-0",
+
+  "alice_18_152.npz": "train-18-44-1",
+
+  "alice_18_153.npz": "train-18-44-2",
+
+  "alice_18_154.npz": "train-18-45-0",
+
+  "alice_18_155.npz": "train-18-45-1",
+
+  "alice_18_156.npz": "train-18-45-2",
+
+  "alice_18_157.npz": "train-18-45-3",
+
+  "alice_18_158.npz": "train-18-45-4",
+
+  "alice_18_159.npz": "train-18-45-5",
+
+  "alice_18_160.npz": "train-18-45-6",
+
+  "alice_18_161.npz": "train-18-46-0",
+
+  "alice_18_162.npz": "train-18-48-0",
+
+  "alice_18_163.npz": "train-18-48-1",
+
+  "alice_18_164.npz": "train-18-48-2",
+
+  "alice_18_165.npz": "train-18-49-0",
+
+  "alice_18_166.npz": "train-18-49-1",
+
+  "alice_18_167.npz": "train-18-49-2",
+
+  "alice_18_168.npz": "train-18-49-3",
+
+  "alice_18_169.npz": "train-18-49-4",
+
+  "alice_18_170.npz": "train-18-49-5",
+
+  "alice_18_171.npz": "train-18-49-6",
+
+  "alice_18_172.npz": "train-18-50-0",
+
+  "alice_18_173.npz": "train-18-50-1",
+
+  "alice_18_174.npz": "train-18-50-2",
+
+  "alice_18_175.npz": "train-18-50-3",
+
+  "alice_18_176.npz": "train-18-50-4",
+
+  "alice_18_177.npz": "train-18-51-0",
+
+  "alice_18_178.npz": "train-18-51-1",
+
+  "alice_18_179.npz": "train-18-51-2",
+
+  "alice_18_180.npz": "train-18-51-3",
+
+  "alice_18_181.npz": "train-18-51-4",
+
+  "alice_18_182.npz": "train-18-51-5",
+
+  "alice_18_183.npz": "train-18-52-0",
+
+  "alice_18_184.npz": "train-18-52-1",
+
+  "alice_18_185.npz": "train-18-52-2",
+
+  "alice_18_186.npz": "train-18-52-3",
+
+  "alice_18_187.npz": "train-18-52-4",
+
+  "alice_18_188.npz": "train-18-52-5",
+
+  "alice_18_189.npz": "train-18-52-6",
+
+  "alice_18_190.npz": "train-18-52-7",
+
+  "alice_18_191.npz": "train-18-53-0",
+
+  "alice_18_192.npz": "train-18-53-1",
+
+  "alice_18_193.npz": "train-18-53-2",
+
+  "alice_18_194.npz": "train-18-53-3",
+
+  "alice_18_195.npz": "train-18-53-4",
+
+  "alice_18_196.npz": "train-18-53-5",
+
+  "alice_18_197.npz": "train-18-53-6",
+
+  "alice_18_198.npz": "train-18-54-0",
+
+  "alice_18_199.npz": "train-18-54-1",
+
+  "alice_18_200.npz": "train-18-54-2",
+
+  "alice_18_201.npz": "train-18-54-3",
+
+  "alice_18_202.npz": "train-18-55-0",
+
+  "alice_18_203.npz": "train-18-55-1",
+
+  "alice_18_204.npz": "train-18-55-2",
+
+  "alice_18_205.npz": "train-18-55-3",
+
+  "alice_18_206.npz": "train-18-55-4",
+
+  "alice_18_207.npz": "train-18-55-5",
+
+  "alice_18_208.npz": "train-18-55-6",
+
+  "alice_18_209.npz": "train-18-55-7",
+
+  "alice_18_210.npz": "train-18-56-0",
+
+  "alice_18_211.npz": "train-18-56-1",
+
+  "alice_18_212.npz": "train-18-56-2",
+
+  "alice_18_213.npz": "train-18-56-3",
+
+  "alice_18_214.npz": "train-18-56-4",
+
+  "alice_18_215.npz": "train-18-56-5",
+
+  "alice_18_216.npz": "train-18-57-0",
+
+  "alice_18_217.npz": "train-18-57-1",
+
+  "alice_18_218.npz": "train-18-57-2",
+
+  "alice_18_219.npz": "train-18-57-3",
+
+  "alice_18_220.npz": "train-18-57-4",
+
+  "alice_18_221.npz": "train-18-57-5",
+
+  "alice_18_222.npz": "train-18-57-6",
+
+  "alice_18_223.npz": "train-18-57-7",
+
+  "alice_18_224.npz": "train-18-57-8",
+
+  "alice_18_225.npz": "train-18-57-9",
+
+  "alice_18_226.npz": "train-18-58-0",
+
+  "alice_18_227.npz": "train-18-59-0",
+
+  "alice_18_228.npz": "train-18-59-1",
+
+  "alice_18_229.npz": "train-18-60-0",
+
+  "alice_18_230.npz": "train-18-60-1",
+
+  "alice_18_231.npz": "train-18-60-2",
+
+  "alice_18_232.npz": "train-18-60-3",
+
+  "alice_18_233.npz": "train-18-60-4",
+
+  "alice_18_234.npz": "train-18-61-0",
+
+  "alice_18_235.npz": "train-18-61-1",
+
+  "alice_18_236.npz": "train-18-61-2",
+
+  "alice_18_237.npz": "train-18-61-3",
+
+  "alice_18_238.npz": "train-18-61-4",
+
+  "alice_18_239.npz": "train-18-61-5",
+
+  "alice_18_240.npz": "train-18-61-6",
+
+  "alice_18_241.npz": "train-18-61-7",
+
+  "alice_18_242.npz": "train-18-61-8",
+
+  "alice_18_243.npz": "train-18-61-9",
+
+  "alice_18_244.npz": "train-18-61-10",
+
+  "alice_18_245.npz": "train-18-61-11",
+
+  "alice_18_246.npz": "train-18-61-12",
+
+  "alice_18_247.npz": "train-18-62-0",
+
+  "alice_18_248.npz": "train-18-62-1",
+
+  "alice_18_249.npz": "train-18-62-2",
+
+  "alice_18_250.npz": "train-18-62-3",
+
+  "alice_18_251.npz": "train-18-63-0",
+
+  "alice_18_252.npz": "train-18-63-1",
+
+  "alice_18_253.npz": "train-18-63-2",
+
+  "alice_18_254.npz": "train-18-63-3",
+
+  "alice_18_255.npz": "train-18-63-4",
+
+  "alice_18_256.npz": "train-18-63-5",
+
+  "alice_18_257.npz": "train-18-63-6",
+
+  "alice_18_258.npz": "train-18-63-7",
+
+  "alice_18_259.npz": "train-18-63-8",
+
+  "alice_18_260.npz": "train-18-63-9",
+
+  "alice_18_261.npz": "train-18-63-10",
+
+  "alice_18_262.npz": "train-18-63-11",
+
+  "alice_18_263.npz": "train-18-63-12",
+
+  "alice_18_264.npz": "train-18-63-13",
+
+  "alice_18_265.npz": "train-18-63-14",
+
+  "alice_18_266.npz": "train-18-63-15",
+
+  "alice_18_267.npz": "train-18-63-16",
+
+  "alice_18_268.npz": "train-18-63-17",
+
+  "alice_18_269.npz": "train-18-64-0",
+
+  "alice_18_270.npz": "train-18-64-1",
+
+  "alice_18_271.npz": "train-18-64-2",
+
+  "alice_18_272.npz": "train-18-64-3",
+
+  "alice_18_273.npz": "train-18-64-4",
+
+  "alice_18_274.npz": "train-18-64-5",
+
+  "alice_18_275.npz": "train-18-64-6",
+
+  "alice_18_276.npz": "train-18-64-7",
+
+  "alice_18_277.npz": "train-18-64-8",
+
+  "alice_18_278.npz": "train-18-64-9",
+  "alice_18_279.npz": "train-18-64-9",
+
+  "alice_18_280.npz": "train-18-65-0",
+
+  "alice_18_281.npz": "train-18-66-0",
+
+  "alice_48_0.npz": "train-48-0-0",
+
+  "alice_48_1.npz": "train-48-0-1",
+
+  "alice_48_2.npz": "train-48-0-2",
+
+  "alice_48_3.npz": "train-48-0-3",
+
+  "alice_48_4.npz": "train-48-0-4",
+
+  "alice_48_5.npz": "train-48-0-5",
+
+  "alice_48_6.npz": "train-48-0-6",
+
+  "alice_48_7.npz": "train-48-0-7",
+
+  "alice_48_8.npz": "train-48-0-8",
+
+  "alice_48_9.npz": "train-48-1-0",
+
+  "alice_48_10.npz": "train-48-1-1",
+
+  "alice_48_11.npz": "train-48-1-2",
+
+  "alice_48_12.npz": "train-48-1-3",
+
+  "alice_48_13.npz": "train-48-1-4",
+
+  "alice_48_14.npz": "train-48-1-5",
+
+  "alice_48_15.npz": "train-48-1-6",
+
+  "alice_48_16.npz": "train-48-1-7",
+
+  "alice_48_17.npz": "train-48-1-8",
+
+  "alice_48_18.npz": "train-48-1-9",
+
+  "alice_48_19.npz": "train-48-2-0",
+
+  "alice_48_20.npz": "train-48-2-1",
+
+  "alice_48_21.npz": "train-48-2-2",
+
+  "alice_48_22.npz": "train-48-2-3",
+
+  "alice_48_23.npz": "train-48-3-0",
+
+  "alice_48_24.npz": "train-48-4-0",
+
+  "alice_48_25.npz": "train-48-5-0",
+
+  "alice_48_26.npz": "train-48-5-1",
+
+  "alice_48_27.npz": "train-48-5-2",
+
+  "alice_48_28.npz": "train-48-5-3",
+
+  "alice_48_29.npz": "train-48-5-4",
+
+  "alice_48_30.npz": "train-48-5-5",
+
+  "alice_48_31.npz": "train-48-5-6",
+
+  "alice_48_32.npz": "train-48-5-7",
+
+  "alice_48_33.npz": "train-48-5-8",
+
+  "alice_48_34.npz": "train-48-5-9",
+
+  "alice_48_35.npz": "train-48-5-10",
+
+  "alice_48_36.npz": "train-48-5-11",
+
+  "alice_48_37.npz": "train-48-5-12",
+
+  "alice_48_38.npz": "train-48-5-13",
+
+  "alice_48_39.npz": "train-48-5-14",
+
+  "alice_48_40.npz": "train-48-5-15",
+
+  "alice_48_41.npz": "train-48-5-16",
+
+  "alice_48_42.npz": "train-48-5-17",
+
+  "alice_48_43.npz": "train-48-6-0",
+
+  "alice_48_44.npz": "train-48-6-1",
+
+  "alice_48_45.npz": "train-48-6-2",
+
+  "alice_48_46.npz": "train-48-6-3",
+
+  "alice_48_47.npz": "train-48-7-0",
+
+  "alice_48_48.npz": "train-48-7-1",
+
+  "alice_48_49.npz": "train-48-7-2",
+
+  "alice_48_50.npz": "train-48-7-3",
+
+  "alice_48_51.npz": "train-48-7-4",
+
+  "alice_48_52.npz": "train-48-7-5",
+
+  "alice_48_53.npz": "train-48-8-0",
+
+  "alice_48_54.npz": "train-48-8-1",
+
+  "alice_48_55.npz": "train-48-8-2",
+
+  "alice_48_56.npz": "train-48-8-3",
+
+  "alice_48_57.npz": "train-48-8-4",
+
+  "alice_48_58.npz": "train-48-8-5",
+
+  "alice_48_59.npz": "train-48-9-0",
+
+  "alice_48_60.npz": "train-48-9-1",
+
+  "alice_48_61.npz": "train-48-9-2",
+
+  "alice_48_62.npz": "train-48-9-3",
+
+  "alice_48_63.npz": "train-48-9-4",
+
+  "alice_48_64.npz": "train-48-9-5",
+
+  "alice_48_65.npz": "train-48-9-6",
+
+  "alice_48_66.npz": "train-48-9-7",
+
+  "alice_48_67.npz": "train-48-9-8",
+
+  "alice_48_68.npz": "train-48-10-0",
+
+  "alice_48_69.npz": "train-48-10-1",
+
+  "alice_48_70.npz": "train-48-10-2",
+
+  "alice_48_71.npz": "train-48-10-3",
+
+  "alice_48_72.npz": "train-48-10-4",
+
+  "alice_48_73.npz": "train-48-10-5",
+
+  "alice_48_74.npz": "train-48-10-6",
+
+  "alice_48_75.npz": "train-48-10-7",
+
+  "alice_48_76.npz": "train-48-10-8",
+
+  "alice_48_77.npz": "train-48-12-0",
+
+  "alice_48_78.npz": "train-48-12-1",
+
+  "alice_48_79.npz": "train-48-12-2",
+
+  "alice_48_80.npz": "train-48-13-0",
+
+  "alice_48_81.npz": "train-48-14-0",
+
+  "alice_48_82.npz": "train-48-14-1",
+
+  "alice_48_83.npz": "train-48-14-2",
+
+  "alice_48_84.npz": "train-48-15-0",
+
+  "alice_48_85.npz": "train-48-16-0",
+
+  "alice_48_86.npz": "train-48-17-0",
+
+  "alice_48_87.npz": "train-48-17-1",
+
+  "alice_48_88.npz": "train-48-18-0",
+
+  "alice_48_89.npz": "train-48-18-1",
+
+  "alice_48_90.npz": "train-48-20-0",
+
+  "alice_48_91.npz": "train-48-20-1",
+
+  "alice_48_92.npz": "train-48-21-0",
+
+  "alice_48_93.npz": "train-48-21-1",
+
+  "alice_48_94.npz": "train-48-21-2",
+
+  "alice_48_95.npz": "train-48-21-3",
+
+  "alice_48_96.npz": "train-48-21-4",
+
+  "alice_48_97.npz": "train-48-21-5",
+
+  "alice_48_98.npz": "train-48-21-6",
+
+  "alice_48_99.npz": "train-48-21-7",
+
+  "alice_48_100.npz": "train-48-21-8",
+
+  "alice_48_101.npz": "train-48-21-9",
+
+  "alice_48_102.npz": "train-48-21-10",
+
+  "alice_48_103.npz": "train-48-21-11",
+
+  "alice_48_104.npz": "train-48-22-0",
+
+  "alice_48_105.npz": "train-48-22-1",
+
+  "alice_48_106.npz": "train-48-22-2",
+
+  "alice_48_107.npz": "train-48-22-3",
+
+  "alice_48_108.npz": "train-48-23-0",
+
+  "alice_48_109.npz": "train-48-24-0",
+
+  "alice_48_110.npz": "train-48-24-1",
+
+  "alice_48_111.npz": "train-48-25-0",
+
+  "alice_48_112.npz": "train-48-25-1",
+
+  "alice_48_113.npz": "train-48-26-0",
+
+  "alice_48_114.npz": "train-48-26-1",
+
+  "alice_48_115.npz": "train-48-26-2",
+
+  "alice_48_116.npz": "train-48-26-3",
+
+  "alice_48_117.npz": "train-48-26-4",
+
+  "alice_48_118.npz": "train-48-26-5",
+
+  "alice_48_119.npz": "train-48-26-6",
+
+  "alice_48_120.npz": "train-48-27-0",
+
+  "alice_48_121.npz": "train-48-27-1",
+
+  "alice_48_122.npz": "train-48-28-0",
+
+  "alice_48_123.npz": "train-48-28-1",
+
+  "alice_48_124.npz": "train-48-29-0",
+
+  "alice_48_125.npz": "train-48-29-1",
+
+  "alice_48_126.npz": "train-48-30-0",
+
+  "alice_48_127.npz": "train-48-31-0",
+
+  "alice_48_128.npz": "train-48-31-1",
+
+  "alice_48_129.npz": "train-48-31-2",
+
+  "alice_48_130.npz": "train-48-32-0",
+
+  "alice_48_131.npz": "train-48-33-0",
+
+  "alice_48_132.npz": "train-48-33-1",
+
+  "alice_48_133.npz": "train-48-33-2",
+
+  "alice_48_134.npz": "train-48-34-0",
+
+  "alice_48_135.npz": "train-48-34-1",
+
+  "alice_48_136.npz": "train-48-35-0",
+
+  "alice_48_137.npz": "train-48-36-0",
+
+  "alice_48_138.npz": "train-48-36-1",
+
+  "alice_48_139.npz": "train-48-38-0",
+
+  "alice_48_140.npz": "train-48-39-0",
+
+  "alice_48_141.npz": "train-48-39-1",
+
+  "alice_48_142.npz": "train-48-39-2",
+
+  "alice_48_143.npz": "train-48-39-3",
+
+  "alice_48_144.npz": "train-48-40-0",
+
+  "alice_48_145.npz": "train-48-41-0",
+
+  "alice_48_146.npz": "train-48-41-1",
+
+  "alice_48_147.npz": "train-48-41-2",
+
+  "alice_48_148.npz": "train-48-41-3",
+
+  "alice_48_149.npz": "train-48-42-0",
+
+  "alice_48_150.npz": "train-48-43-0",
+
+  "alice_48_151.npz": "train-48-44-0",
+
+  "alice_48_152.npz": "train-48-44-1",
+
+  "alice_48_153.npz": "train-48-44-2",
+
+  "alice_48_154.npz": "train-48-45-0",
+
+  "alice_48_155.npz": "train-48-45-1",
+
+  "alice_48_156.npz": "train-48-45-2",
+
+  "alice_48_157.npz": "train-48-45-3",
+
+  "alice_48_158.npz": "train-48-45-4",
+
+  "alice_48_159.npz": "train-48-45-5",
+
+  "alice_48_160.npz": "train-48-45-6",
+
+  "alice_48_161.npz": "train-48-46-0",
+
+  "alice_48_162.npz": "train-48-48-0",
+
+  "alice_48_163.npz": "train-48-48-1",
+
+  "alice_48_164.npz": "train-48-48-2",
+
+  "alice_48_165.npz": "train-48-49-0",
+
+  "alice_48_166.npz": "train-48-49-1",
+
+  "alice_48_167.npz": "train-48-49-2",
+
+  "alice_48_168.npz": "train-48-49-3",
+
+  "alice_48_169.npz": "train-48-49-4",
+
+  "alice_48_170.npz": "train-48-49-5",
+
+  "alice_48_171.npz": "train-48-49-6",
+
+  "alice_48_172.npz": "train-48-50-0",
+
+  "alice_48_173.npz": "train-48-50-1",
+
+  "alice_48_174.npz": "train-48-50-2",
+
+  "alice_48_175.npz": "train-48-50-3",
+
+  "alice_48_176.npz": "train-48-50-4",
+
+  "alice_48_177.npz": "train-48-51-0",
+
+  "alice_48_178.npz": "train-48-51-1",
+
+  "alice_48_179.npz": "train-48-51-2",
+
+  "alice_48_180.npz": "train-48-51-3",
+
+  "alice_48_181.npz": "train-48-51-4",
+
+  "alice_48_182.npz": "train-48-51-5",
+
+  "alice_48_183.npz": "train-48-52-0",
+
+  "alice_48_184.npz": "train-48-52-1",
+
+  "alice_48_185.npz": "train-48-52-2",
+
+  "alice_48_186.npz": "train-48-52-3",
+
+  "alice_48_187.npz": "train-48-52-4",
+
+  "alice_48_188.npz": "train-48-52-5",
+
+  "alice_48_189.npz": "train-48-52-6",
+
+  "alice_48_190.npz": "train-48-52-7",
+
+  "alice_48_191.npz": "train-48-53-0",
+
+  "alice_48_192.npz": "train-48-53-1",
+
+  "alice_48_193.npz": "train-48-53-2",
+
+  "alice_48_194.npz": "train-48-53-3",
+
+  "alice_48_195.npz": "train-48-53-4",
+
+  "alice_48_196.npz": "train-48-53-5",
+
+  "alice_48_197.npz": "train-48-53-6",
+
+  "alice_48_198.npz": "train-48-54-0",
+
+  "alice_48_199.npz": "train-48-54-1",
+
+  "alice_48_200.npz": "train-48-54-2",
+
+  "alice_48_201.npz": "train-48-54-3",
+
+  "alice_48_202.npz": "train-48-55-0",
+
+  "alice_48_203.npz": "train-48-55-1",
+
+  "alice_48_204.npz": "train-48-55-2",
+
+  "alice_48_205.npz": "train-48-55-3",
+
+  "alice_48_206.npz": "train-48-55-4",
+
+  "alice_48_207.npz": "train-48-55-5",
+
+  "alice_48_208.npz": "train-48-55-6",
+
+  "alice_48_209.npz": "train-48-55-7",
+
+  "alice_48_210.npz": "train-48-56-0",
+
+  "alice_48_211.npz": "train-48-56-1",
+
+  "alice_48_212.npz": "train-48-56-2",
+
+  "alice_48_213.npz": "train-48-56-3",
+
+  "alice_48_214.npz": "train-48-56-4",
+
+  "alice_48_215.npz": "train-48-56-5",
+
+  "alice_48_216.npz": "train-48-57-0",
+
+  "alice_48_217.npz": "train-48-57-1",
+
+  "alice_48_218.npz": "train-48-57-2",
+
+  "alice_48_219.npz": "train-48-57-3",
+
+  "alice_48_220.npz": "train-48-57-4",
+
+  "alice_48_221.npz": "train-48-57-5",
+
+  "alice_48_222.npz": "train-48-57-6",
+
+  "alice_48_223.npz": "train-48-57-7",
+
+  "alice_48_224.npz": "train-48-57-8",
+
+  "alice_48_225.npz": "train-48-57-9",
+
+  "alice_48_226.npz": "train-48-58-0",
+
+  "alice_48_227.npz": "train-48-59-0",
+
+  "alice_48_228.npz": "train-48-59-1",
+
+  "alice_48_229.npz": "train-48-60-0",
+
+  "alice_48_230.npz": "train-48-60-1",
+
+  "alice_48_231.npz": "train-48-60-2",
+
+  "alice_48_232.npz": "train-48-60-3",
+
+  "alice_48_233.npz": "train-48-60-4",
+
+  "alice_48_234.npz": "train-48-61-0",
+
+  "alice_48_235.npz": "train-48-61-1",
+
+  "alice_48_236.npz": "train-48-61-2",
+
+  "alice_48_237.npz": "train-48-61-3",
+
+  "alice_48_238.npz": "train-48-61-4",
+
+  "alice_48_239.npz": "train-48-61-5",
+
+  "alice_48_240.npz": "train-48-61-6",
+
+  "alice_48_241.npz": "train-48-61-7",
+
+  "alice_48_242.npz": "train-48-61-8",
+
+  "alice_48_243.npz": "train-48-61-9",
+
+  "alice_48_244.npz": "train-48-61-10",
+
+  "alice_48_245.npz": "train-48-61-11",
+
+  "alice_48_246.npz": "train-48-61-12",
+
+  "alice_48_247.npz": "train-48-62-0",
+
+  "alice_48_248.npz": "train-48-62-1",
+
+  "alice_48_249.npz": "train-48-62-2",
+
+  "alice_48_250.npz": "train-48-62-3",
+
+  "alice_48_251.npz": "train-48-63-0",
+
+  "alice_48_252.npz": "train-48-63-1",
+
+  "alice_48_253.npz": "train-48-63-2",
+
+  "alice_48_254.npz": "train-48-63-3",
+
+  "alice_48_255.npz": "train-48-63-4",
+
+  "alice_48_256.npz": "train-48-63-5",
+
+  "alice_48_257.npz": "train-48-63-6",
+
+  "alice_48_258.npz": "train-48-63-7",
+
+  "alice_48_259.npz": "train-48-63-8",
+
+  "alice_48_260.npz": "train-48-63-9",
+
+  "alice_48_261.npz": "train-48-63-10",
+
+  "alice_48_262.npz": "train-48-63-11",
+
+  "alice_48_263.npz": "train-48-63-12",
+
+  "alice_48_264.npz": "train-48-63-13",
+
+  "alice_48_265.npz": "train-48-63-14",
+
+  "alice_48_266.npz": "train-48-63-15",
+
+  "alice_48_267.npz": "train-48-63-16",
+
+  "alice_48_268.npz": "train-48-63-17",
+
+  "alice_48_269.npz": "train-48-64-0",
+
+  "alice_48_270.npz": "train-48-64-1",
+
+  "alice_48_271.npz": "train-48-64-2",
+
+  "alice_48_272.npz": "train-48-64-3",
+
+  "alice_48_273.npz": "train-48-64-4",
+
+  "alice_48_274.npz": "train-48-64-5",
+
+  "alice_48_275.npz": "train-48-64-6",
+
+  "alice_48_276.npz": "train-48-64-7",
+
+  "alice_48_277.npz": "train-48-64-8",
+
+  "alice_48_278.npz": "train-48-64-9",
+  "alice_48_279.npz": "train-48-64-9",
+
+  "alice_48_280.npz": "train-48-65-0",
+
+  "alice_48_281.npz": "train-48-66-0",
+
+  "alice_31_0.npz": "train-31-0-0",
+
+  "alice_31_1.npz": "train-31-0-1",
+
+  "alice_31_2.npz": "train-31-0-2",
+
+  "alice_31_3.npz": "train-31-0-3",
+
+  "alice_31_4.npz": "train-31-0-4",
+
+  "alice_31_5.npz": "train-31-0-5",
+
+  "alice_31_6.npz": "train-31-0-6",
+
+  "alice_31_7.npz": "train-31-0-7",
+
+  "alice_31_8.npz": "train-31-0-8",
+
+  "alice_31_9.npz": "train-31-1-0",
+
+  "alice_31_10.npz": "train-31-1-1",
+
+  "alice_31_11.npz": "train-31-1-2",
+
+  "alice_31_12.npz": "train-31-1-3",
+
+  "alice_31_13.npz": "train-31-1-4",
+
+  "alice_31_14.npz": "train-31-1-5",
+
+  "alice_31_15.npz": "train-31-1-6",
+
+  "alice_31_16.npz": "train-31-1-7",
+
+  "alice_31_17.npz": "train-31-1-8",
+
+  "alice_31_18.npz": "train-31-1-9",
+
+  "alice_31_19.npz": "train-31-2-0",
+
+  "alice_31_20.npz": "train-31-2-1",
+
+  "alice_31_21.npz": "train-31-2-2",
+
+  "alice_31_22.npz": "train-31-2-3",
+
+  "alice_31_23.npz": "train-31-3-0",
+
+  "alice_31_24.npz": "train-31-4-0",
+
+  "alice_31_25.npz": "train-31-5-0",
+
+  "alice_31_26.npz": "train-31-5-1",
+
+  "alice_31_27.npz": "train-31-5-2",
+
+  "alice_31_28.npz": "train-31-5-3",
+
+  "alice_31_29.npz": "train-31-5-4",
+
+  "alice_31_30.npz": "train-31-5-5",
+
+  "alice_31_31.npz": "train-31-5-6",
+
+  "alice_31_32.npz": "train-31-5-7",
+
+  "alice_31_33.npz": "train-31-5-8",
+
+  "alice_31_34.npz": "train-31-5-9",
+
+  "alice_31_35.npz": "train-31-5-10",
+
+  "alice_31_36.npz": "train-31-5-11",
+
+  "alice_31_37.npz": "train-31-5-12",
+
+  "alice_31_38.npz": "train-31-5-13",
+
+  "alice_31_39.npz": "train-31-5-14",
+
+  "alice_31_40.npz": "train-31-5-15",
+
+  "alice_31_41.npz": "train-31-5-16",
+
+  "alice_31_42.npz": "train-31-5-17",
+
+  "alice_31_43.npz": "train-31-6-0",
+
+  "alice_31_44.npz": "train-31-6-1",
+
+  "alice_31_45.npz": "train-31-6-2",
+
+  "alice_31_46.npz": "train-31-6-3",
+
+  "alice_31_47.npz": "train-31-7-0",
+
+  "alice_31_48.npz": "train-31-7-1",
+
+  "alice_31_49.npz": "train-31-7-2",
+
+  "alice_31_50.npz": "train-31-7-3",
+
+  "alice_31_51.npz": "train-31-7-4",
+
+  "alice_31_52.npz": "train-31-7-5",
+
+  "alice_31_53.npz": "train-31-8-0",
+
+  "alice_31_54.npz": "train-31-8-1",
+
+  "alice_31_55.npz": "train-31-8-2",
+
+  "alice_31_56.npz": "train-31-8-3",
+
+  "alice_31_57.npz": "train-31-8-4",
+
+  "alice_31_58.npz": "train-31-8-5",
+
+  "alice_31_59.npz": "train-31-9-0",
+
+  "alice_31_60.npz": "train-31-9-1",
+
+  "alice_31_61.npz": "train-31-9-2",
+
+  "alice_31_62.npz": "train-31-9-3",
+
+  "alice_31_63.npz": "train-31-9-4",
+
+  "alice_31_64.npz": "train-31-9-5",
+
+  "alice_31_65.npz": "train-31-9-6",
+
+  "alice_31_66.npz": "train-31-9-7",
+
+  "alice_31_67.npz": "train-31-9-8",
+
+  "alice_31_68.npz": "train-31-10-0",
+
+  "alice_31_69.npz": "train-31-10-1",
+
+  "alice_31_70.npz": "train-31-10-2",
+
+  "alice_31_71.npz": "train-31-10-3",
+
+  "alice_31_72.npz": "train-31-10-4",
+
+  "alice_31_73.npz": "train-31-10-5",
+
+  "alice_31_74.npz": "train-31-10-6",
+
+  "alice_31_75.npz": "train-31-10-7",
+
+  "alice_31_76.npz": "train-31-10-8",
+
+  "alice_31_77.npz": "train-31-12-0",
+
+  "alice_31_78.npz": "train-31-12-1",
+
+  "alice_31_79.npz": "train-31-12-2",
+
+  "alice_31_80.npz": "train-31-13-0",
+
+  "alice_31_81.npz": "train-31-14-0",
+
+  "alice_31_82.npz": "train-31-14-1",
+
+  "alice_31_83.npz": "train-31-14-2",
+
+  "alice_31_84.npz": "train-31-15-0",
+
+  "alice_31_85.npz": "train-31-16-0",
+
+  "alice_31_86.npz": "train-31-17-0",
+
+  "alice_31_87.npz": "train-31-17-1",
+
+  "alice_31_88.npz": "train-31-18-0",
+
+  "alice_31_89.npz": "train-31-18-1",
+
+  "alice_31_90.npz": "train-31-20-0",
+
+  "alice_31_91.npz": "train-31-20-1",
+
+  "alice_31_92.npz": "train-31-21-0",
+
+  "alice_31_93.npz": "train-31-21-1",
+
+  "alice_31_94.npz": "train-31-21-2",
+
+  "alice_31_95.npz": "train-31-21-3",
+
+  "alice_31_96.npz": "train-31-21-4",
+
+  "alice_31_97.npz": "train-31-21-5",
+
+  "alice_31_98.npz": "train-31-21-6",
+
+  "alice_31_99.npz": "train-31-21-7",
+
+  "alice_31_100.npz": "train-31-21-8",
+
+  "alice_31_101.npz": "train-31-21-9",
+
+  "alice_31_102.npz": "train-31-21-10",
+
+  "alice_31_103.npz": "train-31-21-11",
+
+  "alice_31_104.npz": "train-31-22-0",
+
+  "alice_31_105.npz": "train-31-22-1",
+
+  "alice_31_106.npz": "train-31-22-2",
+
+  "alice_31_107.npz": "train-31-22-3",
+
+  "alice_31_108.npz": "train-31-23-0",
+
+  "alice_31_109.npz": "train-31-24-0",
+
+  "alice_31_110.npz": "train-31-24-1",
+
+  "alice_31_111.npz": "train-31-25-0",
+
+  "alice_31_112.npz": "train-31-25-1",
+
+  "alice_31_113.npz": "train-31-26-0",
+
+  "alice_31_114.npz": "train-31-26-1",
+
+  "alice_31_115.npz": "train-31-26-2",
+
+  "alice_31_116.npz": "train-31-26-3",
+
+  "alice_31_117.npz": "train-31-26-4",
+
+  "alice_31_118.npz": "train-31-26-5",
+
+  "alice_31_119.npz": "train-31-26-6",
+
+  "alice_31_120.npz": "train-31-27-0",
+
+  "alice_31_121.npz": "train-31-27-1",
+
+  "alice_31_122.npz": "train-31-28-0",
+
+  "alice_31_123.npz": "train-31-28-1",
+
+  "alice_31_124.npz": "train-31-29-0",
+
+  "alice_31_125.npz": "train-31-29-1",
+
+  "alice_31_126.npz": "train-31-30-0",
+
+  "alice_31_127.npz": "train-31-31-0",
+
+  "alice_31_128.npz": "train-31-31-1",
+
+  "alice_31_129.npz": "train-31-31-2",
+
+  "alice_31_130.npz": "train-31-32-0",
+
+  "alice_31_131.npz": "train-31-33-0",
+
+  "alice_31_132.npz": "train-31-33-1",
+
+  "alice_31_133.npz": "train-31-33-2",
+
+  "alice_31_134.npz": "train-31-34-0",
+
+  "alice_31_135.npz": "train-31-34-1",
+
+  "alice_31_136.npz": "train-31-35-0",
+
+  "alice_31_137.npz": "train-31-36-0",
+
+  "alice_31_138.npz": "train-31-36-1",
+
+  "alice_31_139.npz": "train-31-38-0",
+
+  "alice_31_140.npz": "train-31-39-0",
+
+  "alice_31_141.npz": "train-31-39-1",
+
+  "alice_31_142.npz": "train-31-39-2",
+
+  "alice_31_143.npz": "train-31-39-3",
+
+  "alice_31_144.npz": "train-31-40-0",
+
+  "alice_31_145.npz": "train-31-41-0",
+
+  "alice_31_146.npz": "train-31-41-1",
+
+  "alice_31_147.npz": "train-31-41-2",
+
+  "alice_31_148.npz": "train-31-41-3",
+
+  "alice_31_149.npz": "train-31-42-0",
+
+  "alice_31_150.npz": "train-31-43-0",
+
+  "alice_31_151.npz": "train-31-44-0",
+
+  "alice_31_152.npz": "train-31-44-1",
+
+  "alice_31_153.npz": "train-31-44-2",
+
+  "alice_31_154.npz": "train-31-45-0",
+
+  "alice_31_155.npz": "train-31-45-1",
+
+  "alice_31_156.npz": "train-31-45-2",
+
+  "alice_31_157.npz": "train-31-45-3",
+
+  "alice_31_158.npz": "train-31-45-4",
+
+  "alice_31_159.npz": "train-31-45-5",
+
+  "alice_31_160.npz": "train-31-45-6",
+
+  "alice_31_161.npz": "train-31-46-0",
+
+  "alice_31_162.npz": "train-31-48-0",
+
+  "alice_31_163.npz": "train-31-48-1",
+
+  "alice_31_164.npz": "train-31-48-2",
+
+  "alice_31_165.npz": "train-31-49-0",
+
+  "alice_31_166.npz": "train-31-49-1",
+
+  "alice_31_167.npz": "train-31-49-2",
+
+  "alice_31_168.npz": "train-31-49-3",
+
+  "alice_31_169.npz": "train-31-49-4",
+
+  "alice_31_170.npz": "train-31-49-5",
+
+  "alice_31_171.npz": "train-31-49-6",
+
+  "alice_31_172.npz": "train-31-50-0",
+
+  "alice_31_173.npz": "train-31-50-1",
+
+  "alice_31_174.npz": "train-31-50-2",
+
+  "alice_31_175.npz": "train-31-50-3",
+
+  "alice_31_176.npz": "train-31-50-4",
+
+  "alice_31_177.npz": "train-31-51-0",
+
+  "alice_31_178.npz": "train-31-51-1",
+
+  "alice_31_179.npz": "train-31-51-2",
+
+  "alice_31_180.npz": "train-31-51-3",
+
+  "alice_31_181.npz": "train-31-51-4",
+
+  "alice_31_182.npz": "train-31-51-5",
+
+  "alice_31_183.npz": "train-31-52-0",
+
+  "alice_31_184.npz": "train-31-52-1",
+
+  "alice_31_185.npz": "train-31-52-2",
+
+  "alice_31_186.npz": "train-31-52-3",
+
+  "alice_31_187.npz": "train-31-52-4",
+
+  "alice_31_188.npz": "train-31-52-5",
+
+  "alice_31_189.npz": "train-31-52-6",
+
+  "alice_31_190.npz": "train-31-52-7",
+
+  "alice_31_191.npz": "train-31-53-0",
+
+  "alice_31_192.npz": "train-31-53-1",
+
+  "alice_31_193.npz": "train-31-53-2",
+
+  "alice_31_194.npz": "train-31-53-3",
+
+  "alice_31_195.npz": "train-31-53-4",
+
+  "alice_31_196.npz": "train-31-53-5",
+
+  "alice_31_197.npz": "train-31-53-6",
+
+  "alice_31_198.npz": "train-31-54-0",
+
+  "alice_31_199.npz": "train-31-54-1",
+
+  "alice_31_200.npz": "train-31-54-2",
+
+  "alice_31_201.npz": "train-31-54-3",
+
+  "alice_31_202.npz": "train-31-55-0",
+
+  "alice_31_203.npz": "train-31-55-1",
+
+  "alice_31_204.npz": "train-31-55-2",
+
+  "alice_31_205.npz": "train-31-55-3",
+
+  "alice_31_206.npz": "train-31-55-4",
+
+  "alice_31_207.npz": "train-31-55-5",
+
+  "alice_31_208.npz": "train-31-55-6",
+
+  "alice_31_209.npz": "train-31-55-7",
+
+  "alice_31_210.npz": "train-31-56-0",
+
+  "alice_31_211.npz": "train-31-56-1",
+
+  "alice_31_212.npz": "train-31-56-2",
+
+  "alice_31_213.npz": "train-31-56-3",
+
+  "alice_31_214.npz": "train-31-56-4",
+
+  "alice_31_215.npz": "train-31-56-5",
+
+  "alice_31_216.npz": "train-31-57-0",
+
+  "alice_31_217.npz": "train-31-57-1",
+
+  "alice_31_218.npz": "train-31-57-2",
+
+  "alice_31_219.npz": "train-31-57-3",
+
+  "alice_31_220.npz": "train-31-57-4",
+
+  "alice_31_221.npz": "train-31-57-5",
+
+  "alice_31_222.npz": "train-31-57-6",
+
+  "alice_31_223.npz": "train-31-57-7",
+
+  "alice_31_224.npz": "train-31-57-8",
+
+  "alice_31_225.npz": "train-31-57-9",
+
+  "alice_31_226.npz": "train-31-58-0",
+
+  "alice_31_227.npz": "train-31-59-0",
+
+  "alice_31_228.npz": "train-31-59-1",
+
+  "alice_31_229.npz": "train-31-60-0",
+
+  "alice_31_230.npz": "train-31-60-1",
+
+  "alice_31_231.npz": "train-31-60-2",
+
+  "alice_31_232.npz": "train-31-60-3",
+
+  "alice_31_233.npz": "train-31-60-4",
+
+  "alice_31_234.npz": "train-31-61-0",
+
+  "alice_31_235.npz": "train-31-61-1",
+
+  "alice_31_236.npz": "train-31-61-2",
+
+  "alice_31_237.npz": "train-31-61-3",
+
+  "alice_31_238.npz": "train-31-61-4",
+
+  "alice_31_239.npz": "train-31-61-5",
+
+  "alice_31_240.npz": "train-31-61-6",
+
+  "alice_31_241.npz": "train-31-61-7",
+
+  "alice_31_242.npz": "train-31-61-8",
+
+  "alice_31_243.npz": "train-31-61-9",
+
+  "alice_31_244.npz": "train-31-61-10",
+
+  "alice_31_245.npz": "train-31-61-11",
+
+  "alice_31_246.npz": "train-31-61-12",
+
+  "alice_31_247.npz": "train-31-62-0",
+
+  "alice_31_248.npz": "train-31-62-1",
+
+  "alice_31_249.npz": "train-31-62-2",
+
+  "alice_31_250.npz": "train-31-62-3",
+
+  "alice_31_251.npz": "train-31-63-0",
+
+  "alice_31_252.npz": "train-31-63-1",
+
+  "alice_31_253.npz": "train-31-63-2",
+
+  "alice_31_254.npz": "train-31-63-3",
+
+  "alice_31_255.npz": "train-31-63-4",
+
+  "alice_31_256.npz": "train-31-63-5",
+
+  "alice_31_257.npz": "train-31-63-6",
+
+  "alice_31_258.npz": "train-31-63-7",
+
+  "alice_31_259.npz": "train-31-63-8",
+
+  "alice_31_260.npz": "train-31-63-9",
+
+  "alice_31_261.npz": "train-31-63-10",
+
+  "alice_31_262.npz": "train-31-63-11",
+
+  "alice_31_263.npz": "train-31-63-12",
+
+  "alice_31_264.npz": "train-31-63-13",
+
+  "alice_31_265.npz": "train-31-63-14",
+
+  "alice_31_266.npz": "train-31-63-15",
+
+  "alice_31_267.npz": "train-31-63-16",
+
+  "alice_31_268.npz": "train-31-63-17",
+
+  "alice_31_269.npz": "train-31-64-0",
+
+  "alice_31_270.npz": "train-31-64-1",
+
+  "alice_31_271.npz": "train-31-64-2",
+
+  "alice_31_272.npz": "train-31-64-3",
+
+  "alice_31_273.npz": "train-31-64-4",
+
+  "alice_31_274.npz": "train-31-64-5",
+
+  "alice_31_275.npz": "train-31-64-6",
+
+  "alice_31_276.npz": "train-31-64-7",
+
+  "alice_31_277.npz": "train-31-64-8",
+
+  "alice_31_278.npz": "train-31-64-9",
+  "alice_31_279.npz": "train-31-64-9",
+
+  "alice_31_280.npz": "train-31-65-0",
+
+  "alice_31_281.npz": "train-31-66-0",
+
+  "alice_47_0.npz": "train-47-0-0",
+
+  "alice_47_1.npz": "train-47-0-1",
+
+  "alice_47_2.npz": "train-47-0-2",
+
+  "alice_47_3.npz": "train-47-0-3",
+
+  "alice_47_4.npz": "train-47-0-4",
+
+  "alice_47_5.npz": "train-47-0-5",
+
+  "alice_47_6.npz": "train-47-0-6",
+
+  "alice_47_7.npz": "train-47-0-7",
+
+  "alice_47_8.npz": "train-47-0-8",
+
+  "alice_47_9.npz": "train-47-1-0",
+
+  "alice_47_10.npz": "train-47-1-1",
+
+  "alice_47_11.npz": "train-47-1-2",
+
+  "alice_47_12.npz": "train-47-1-3",
+
+  "alice_47_13.npz": "train-47-1-4",
+
+  "alice_47_14.npz": "train-47-1-5",
+
+  "alice_47_15.npz": "train-47-1-6",
+
+  "alice_47_16.npz": "train-47-1-7",
+
+  "alice_47_17.npz": "train-47-1-8",
+
+  "alice_47_18.npz": "train-47-1-9",
+
+  "alice_47_19.npz": "train-47-2-0",
+
+  "alice_47_20.npz": "train-47-2-1",
+
+  "alice_47_21.npz": "train-47-2-2",
+
+  "alice_47_22.npz": "train-47-2-3",
+
+  "alice_47_23.npz": "train-47-3-0",
+
+  "alice_47_24.npz": "train-47-4-0",
+
+  "alice_47_25.npz": "train-47-5-0",
+
+  "alice_47_26.npz": "train-47-5-1",
+
+  "alice_47_27.npz": "train-47-5-2",
+
+  "alice_47_28.npz": "train-47-5-3",
+
+  "alice_47_29.npz": "train-47-5-4",
+
+  "alice_47_30.npz": "train-47-5-5",
+
+  "alice_47_31.npz": "train-47-5-6",
+
+  "alice_47_32.npz": "train-47-5-7",
+
+  "alice_47_33.npz": "train-47-5-8",
+
+  "alice_47_34.npz": "train-47-5-9",
+
+  "alice_47_35.npz": "train-47-5-10",
+
+  "alice_47_36.npz": "train-47-5-11",
+
+  "alice_47_37.npz": "train-47-5-12",
+
+  "alice_47_38.npz": "train-47-5-13",
+
+  "alice_47_39.npz": "train-47-5-14",
+
+  "alice_47_40.npz": "train-47-5-15",
+
+  "alice_47_41.npz": "train-47-5-16",
+
+  "alice_47_42.npz": "train-47-5-17",
+
+  "alice_47_43.npz": "train-47-6-0",
+
+  "alice_47_44.npz": "train-47-6-1",
+
+  "alice_47_45.npz": "train-47-6-2",
+
+  "alice_47_46.npz": "train-47-6-3",
+
+  "alice_47_47.npz": "train-47-7-0",
+
+  "alice_47_48.npz": "train-47-7-1",
+
+  "alice_47_49.npz": "train-47-7-2",
+
+  "alice_47_50.npz": "train-47-7-3",
+
+  "alice_47_51.npz": "train-47-7-4",
+
+  "alice_47_52.npz": "train-47-7-5",
+
+  "alice_47_53.npz": "train-47-8-0",
+
+  "alice_47_54.npz": "train-47-8-1",
+
+  "alice_47_55.npz": "train-47-8-2",
+
+  "alice_47_56.npz": "train-47-8-3",
+
+  "alice_47_57.npz": "train-47-8-4",
+
+  "alice_47_58.npz": "train-47-8-5",
+
+  "alice_47_59.npz": "train-47-9-0",
+
+  "alice_47_60.npz": "train-47-9-1",
+
+  "alice_47_61.npz": "train-47-9-2",
+
+  "alice_47_62.npz": "train-47-9-3",
+
+  "alice_47_63.npz": "train-47-9-4",
+
+  "alice_47_64.npz": "train-47-9-5",
+
+  "alice_47_65.npz": "train-47-9-6",
+
+  "alice_47_66.npz": "train-47-9-7",
+
+  "alice_47_67.npz": "train-47-9-8",
+
+  "alice_47_68.npz": "train-47-10-0",
+
+  "alice_47_69.npz": "train-47-10-1",
+
+  "alice_47_70.npz": "train-47-10-2",
+
+  "alice_47_71.npz": "train-47-10-3",
+
+  "alice_47_72.npz": "train-47-10-4",
+
+  "alice_47_73.npz": "train-47-10-5",
+
+  "alice_47_74.npz": "train-47-10-6",
+
+  "alice_47_75.npz": "train-47-10-7",
+
+  "alice_47_76.npz": "train-47-10-8",
+
+  "alice_47_77.npz": "train-47-12-0",
+
+  "alice_47_78.npz": "train-47-12-1",
+
+  "alice_47_79.npz": "train-47-12-2",
+
+  "alice_47_80.npz": "train-47-13-0",
+
+  "alice_47_81.npz": "train-47-14-0",
+
+  "alice_47_82.npz": "train-47-14-1",
+
+  "alice_47_83.npz": "train-47-14-2",
+
+  "alice_47_84.npz": "train-47-15-0",
+
+  "alice_47_85.npz": "train-47-16-0",
+
+  "alice_47_86.npz": "train-47-17-0",
+
+  "alice_47_87.npz": "train-47-17-1",
+
+  "alice_47_88.npz": "train-47-18-0",
+
+  "alice_47_89.npz": "train-47-18-1",
+
+  "alice_47_90.npz": "train-47-20-0",
+
+  "alice_47_91.npz": "train-47-20-1",
+
+  "alice_47_92.npz": "train-47-21-0",
+
+  "alice_47_93.npz": "train-47-21-1",
+
+  "alice_47_94.npz": "train-47-21-2",
+
+  "alice_47_95.npz": "train-47-21-3",
+
+  "alice_47_96.npz": "train-47-21-4",
+
+  "alice_47_97.npz": "train-47-21-5",
+
+  "alice_47_98.npz": "train-47-21-6",
+
+  "alice_47_99.npz": "train-47-21-7",
+
+  "alice_47_100.npz": "train-47-21-8",
+
+  "alice_47_101.npz": "train-47-21-9",
+
+  "alice_47_102.npz": "train-47-21-10",
+
+  "alice_47_103.npz": "train-47-21-11",
+
+  "alice_47_104.npz": "train-47-22-0",
+
+  "alice_47_105.npz": "train-47-22-1",
+
+  "alice_47_106.npz": "train-47-22-2",
+
+  "alice_47_107.npz": "train-47-22-3",
+
+  "alice_47_108.npz": "train-47-23-0",
+
+  "alice_47_109.npz": "train-47-24-0",
+
+  "alice_47_110.npz": "train-47-24-1",
+
+  "alice_47_111.npz": "train-47-25-0",
+
+  "alice_47_112.npz": "train-47-25-1",
+
+  "alice_47_113.npz": "train-47-26-0",
+
+  "alice_47_114.npz": "train-47-26-1",
+
+  "alice_47_115.npz": "train-47-26-2",
+
+  "alice_47_116.npz": "train-47-26-3",
+
+  "alice_47_117.npz": "train-47-26-4",
+
+  "alice_47_118.npz": "train-47-26-5",
+
+  "alice_47_119.npz": "train-47-26-6",
+
+  "alice_47_120.npz": "train-47-27-0",
+
+  "alice_47_121.npz": "train-47-27-1",
+
+  "alice_47_122.npz": "train-47-28-0",
+
+  "alice_47_123.npz": "train-47-28-1",
+
+  "alice_47_124.npz": "train-47-29-0",
+
+  "alice_47_125.npz": "train-47-29-1",
+
+  "alice_47_126.npz": "train-47-30-0",
+
+  "alice_47_127.npz": "train-47-31-0",
+
+  "alice_47_128.npz": "train-47-31-1",
+
+  "alice_47_129.npz": "train-47-31-2",
+
+  "alice_47_130.npz": "train-47-32-0",
+
+  "alice_47_131.npz": "train-47-33-0",
+
+  "alice_47_132.npz": "train-47-33-1",
+
+  "alice_47_133.npz": "train-47-33-2",
+
+  "alice_47_134.npz": "train-47-34-0",
+
+  "alice_47_135.npz": "train-47-34-1",
+
+  "alice_47_136.npz": "train-47-35-0",
+
+  "alice_47_137.npz": "train-47-36-0",
+
+  "alice_47_138.npz": "train-47-36-1",
+
+  "alice_47_139.npz": "train-47-38-0",
+
+  "alice_47_140.npz": "train-47-39-0",
+
+  "alice_47_141.npz": "train-47-39-1",
+
+  "alice_47_142.npz": "train-47-39-2",
+
+  "alice_47_143.npz": "train-47-39-3",
+
+  "alice_47_144.npz": "train-47-40-0",
+
+  "alice_47_145.npz": "train-47-41-0",
+
+  "alice_47_146.npz": "train-47-41-1",
+
+  "alice_47_147.npz": "train-47-41-2",
+
+  "alice_47_148.npz": "train-47-41-3",
+
+  "alice_47_149.npz": "train-47-42-0",
+
+  "alice_47_150.npz": "train-47-43-0",
+
+  "alice_47_151.npz": "train-47-44-0",
+
+  "alice_47_152.npz": "train-47-44-1",
+
+  "alice_47_153.npz": "train-47-44-2",
+
+  "alice_47_154.npz": "train-47-45-0",
+
+  "alice_47_155.npz": "train-47-45-1",
+
+  "alice_47_156.npz": "train-47-45-2",
+
+  "alice_47_157.npz": "train-47-45-3",
+
+  "alice_47_158.npz": "train-47-45-4",
+
+  "alice_47_159.npz": "train-47-45-5",
+
+  "alice_47_160.npz": "train-47-45-6",
+
+  "alice_47_161.npz": "train-47-46-0",
+
+  "alice_47_162.npz": "train-47-48-0",
+
+  "alice_47_163.npz": "train-47-48-1",
+
+  "alice_47_164.npz": "train-47-48-2",
+
+  "alice_47_165.npz": "train-47-49-0",
+
+  "alice_47_166.npz": "train-47-49-1",
+
+  "alice_47_167.npz": "train-47-49-2",
+
+  "alice_47_168.npz": "train-47-49-3",
+
+  "alice_47_169.npz": "train-47-49-4",
+
+  "alice_47_170.npz": "train-47-49-5",
+
+  "alice_47_171.npz": "train-47-49-6",
+
+  "alice_47_172.npz": "train-47-50-0",
+
+  "alice_47_173.npz": "train-47-50-1",
+
+  "alice_47_174.npz": "train-47-50-2",
+
+  "alice_47_175.npz": "train-47-50-3",
+
+  "alice_47_176.npz": "train-47-50-4",
+
+  "alice_47_177.npz": "train-47-51-0",
+
+  "alice_47_178.npz": "train-47-51-1",
+
+  "alice_47_179.npz": "train-47-51-2",
+
+  "alice_47_180.npz": "train-47-51-3",
+
+  "alice_47_181.npz": "train-47-51-4",
+
+  "alice_47_182.npz": "train-47-51-5",
+
+  "alice_47_183.npz": "train-47-52-0",
+
+  "alice_47_184.npz": "train-47-52-1",
+
+  "alice_47_185.npz": "train-47-52-2",
+
+  "alice_47_186.npz": "train-47-52-3",
+
+  "alice_47_187.npz": "train-47-52-4",
+
+  "alice_47_188.npz": "train-47-52-5",
+
+  "alice_47_189.npz": "train-47-52-6",
+
+  "alice_47_190.npz": "train-47-52-7",
+
+  "alice_47_191.npz": "train-47-53-0",
+
+  "alice_47_192.npz": "train-47-53-1",
+
+  "alice_47_193.npz": "train-47-53-2",
+
+  "alice_47_194.npz": "train-47-53-3",
+
+  "alice_47_195.npz": "train-47-53-4",
+
+  "alice_47_196.npz": "train-47-53-5",
+
+  "alice_47_197.npz": "train-47-53-6",
+
+  "alice_47_198.npz": "train-47-54-0",
+
+  "alice_47_199.npz": "train-47-54-1",
+
+  "alice_47_200.npz": "train-47-54-2",
+
+  "alice_47_201.npz": "train-47-54-3",
+
+  "alice_47_202.npz": "train-47-55-0",
+
+  "alice_47_203.npz": "train-47-55-1",
+
+  "alice_47_204.npz": "train-47-55-2",
+
+  "alice_47_205.npz": "train-47-55-3",
+
+  "alice_47_206.npz": "train-47-55-4",
+
+  "alice_47_207.npz": "train-47-55-5",
+
+  "alice_47_208.npz": "train-47-55-6",
+
+  "alice_47_209.npz": "train-47-55-7",
+
+  "alice_47_210.npz": "train-47-56-0",
+
+  "alice_47_211.npz": "train-47-56-1",
+
+  "alice_47_212.npz": "train-47-56-2",
+
+  "alice_47_213.npz": "train-47-56-3",
+
+  "alice_47_214.npz": "train-47-56-4",
+
+  "alice_47_215.npz": "train-47-56-5",
+
+  "alice_47_216.npz": "train-47-57-0",
+
+  "alice_47_217.npz": "train-47-57-1",
+
+  "alice_47_218.npz": "train-47-57-2",
+
+  "alice_47_219.npz": "train-47-57-3",
+
+  "alice_47_220.npz": "train-47-57-4",
+
+  "alice_47_221.npz": "train-47-57-5",
+
+  "alice_47_222.npz": "train-47-57-6",
+
+  "alice_47_223.npz": "train-47-57-7",
+
+  "alice_47_224.npz": "train-47-57-8",
+
+  "alice_47_225.npz": "train-47-57-9",
+
+  "alice_47_226.npz": "train-47-58-0",
+
+  "alice_47_227.npz": "train-47-59-0",
+
+  "alice_47_228.npz": "train-47-59-1",
+
+  "alice_47_229.npz": "train-47-60-0",
+
+  "alice_47_230.npz": "train-47-60-1",
+
+  "alice_47_231.npz": "train-47-60-2",
+
+  "alice_47_232.npz": "train-47-60-3",
+
+  "alice_47_233.npz": "train-47-60-4",
+
+  "alice_47_234.npz": "train-47-61-0",
+
+  "alice_47_235.npz": "train-47-61-1",
+
+  "alice_47_236.npz": "train-47-61-2",
+
+  "alice_47_237.npz": "train-47-61-3",
+
+  "alice_47_238.npz": "train-47-61-4",
+
+  "alice_47_239.npz": "train-47-61-5",
+
+  "alice_47_240.npz": "train-47-61-6",
+
+  "alice_47_241.npz": "train-47-61-7",
+
+  "alice_47_242.npz": "train-47-61-8",
+
+  "alice_47_243.npz": "train-47-61-9",
+
+  "alice_47_244.npz": "train-47-61-10",
+
+  "alice_47_245.npz": "train-47-61-11",
+
+  "alice_47_246.npz": "train-47-61-12",
+
+  "alice_47_247.npz": "train-47-62-0",
+
+  "alice_47_248.npz": "train-47-62-1",
+
+  "alice_47_249.npz": "train-47-62-2",
+
+  "alice_47_250.npz": "train-47-62-3",
+
+  "alice_47_251.npz": "train-47-63-0",
+
+  "alice_47_252.npz": "train-47-63-1",
+
+  "alice_47_253.npz": "train-47-63-2",
+
+  "alice_47_254.npz": "train-47-63-3",
+
+  "alice_47_255.npz": "train-47-63-4",
+
+  "alice_47_256.npz": "train-47-63-5",
+
+  "alice_47_257.npz": "train-47-63-6",
+
+  "alice_47_258.npz": "train-47-63-7",
+
+  "alice_47_259.npz": "train-47-63-8",
+
+  "alice_47_260.npz": "train-47-63-9",
+
+  "alice_47_261.npz": "train-47-63-10",
+
+  "alice_47_262.npz": "train-47-63-11",
+
+  "alice_47_263.npz": "train-47-63-12",
+
+  "alice_47_264.npz": "train-47-63-13",
+
+  "alice_47_265.npz": "train-47-63-14",
+
+  "alice_47_266.npz": "train-47-63-15",
+
+  "alice_47_267.npz": "train-47-63-16",
+
+  "alice_47_268.npz": "train-47-63-17",
+
+  "alice_47_269.npz": "train-47-64-0",
+
+  "alice_47_270.npz": "train-47-64-1",
+
+  "alice_47_271.npz": "train-47-64-2",
+
+  "alice_47_272.npz": "train-47-64-3",
+
+  "alice_47_273.npz": "train-47-64-4",
+
+  "alice_47_274.npz": "train-47-64-5",
+
+  "alice_47_275.npz": "train-47-64-6",
+
+  "alice_47_276.npz": "train-47-64-7",
+
+  "alice_47_277.npz": "train-47-64-8",
+
+  "alice_47_278.npz": "train-47-64-9",
+  "alice_47_279.npz": "train-47-64-9",
+
+  "alice_47_280.npz": "train-47-65-0",
+
+  "alice_47_281.npz": "train-47-66-0",
+
+  "alice_51_0.npz": "train-51-0-0",
+
+  "alice_51_1.npz": "train-51-0-1",
+
+  "alice_51_2.npz": "train-51-0-2",
+
+  "alice_51_3.npz": "train-51-0-3",
+
+  "alice_51_4.npz": "train-51-0-4",
+
+  "alice_51_5.npz": "train-51-0-5",
+
+  "alice_51_6.npz": "train-51-0-6",
+
+  "alice_51_7.npz": "train-51-0-7",
+
+  "alice_51_8.npz": "train-51-0-8",
+
+  "alice_51_9.npz": "train-51-1-0",
+
+  "alice_51_10.npz": "train-51-1-1",
+
+  "alice_51_11.npz": "train-51-1-2",
+
+  "alice_51_12.npz": "train-51-1-3",
+
+  "alice_51_13.npz": "train-51-1-4",
+
+  "alice_51_14.npz": "train-51-1-5",
+
+  "alice_51_15.npz": "train-51-1-6",
+
+  "alice_51_16.npz": "train-51-1-7",
+
+  "alice_51_17.npz": "train-51-1-8",
+
+  "alice_51_18.npz": "train-51-1-9",
+
+  "alice_51_19.npz": "train-51-2-0",
+
+  "alice_51_20.npz": "train-51-2-1",
+
+  "alice_51_21.npz": "train-51-2-2",
+
+  "alice_51_22.npz": "train-51-2-3",
+
+  "alice_51_23.npz": "train-51-3-0",
+
+  "alice_51_24.npz": "train-51-4-0",
+
+  "alice_51_25.npz": "train-51-5-0",
+
+  "alice_51_26.npz": "train-51-5-1",
+
+  "alice_51_27.npz": "train-51-5-2",
+
+  "alice_51_28.npz": "train-51-5-3",
+
+  "alice_51_29.npz": "train-51-5-4",
+
+  "alice_51_30.npz": "train-51-5-5",
+
+  "alice_51_31.npz": "train-51-5-6",
+
+  "alice_51_32.npz": "train-51-5-7",
+
+  "alice_51_33.npz": "train-51-5-8",
+
+  "alice_51_34.npz": "train-51-5-9",
+
+  "alice_51_35.npz": "train-51-5-10",
+
+  "alice_51_36.npz": "train-51-5-11",
+
+  "alice_51_37.npz": "train-51-5-12",
+
+  "alice_51_38.npz": "train-51-5-13",
+
+  "alice_51_39.npz": "train-51-5-14",
+
+  "alice_51_40.npz": "train-51-5-15",
+
+  "alice_51_41.npz": "train-51-5-16",
+
+  "alice_51_42.npz": "train-51-5-17",
+
+  "alice_51_43.npz": "train-51-6-0",
+
+  "alice_51_44.npz": "train-51-6-1",
+
+  "alice_51_45.npz": "train-51-6-2",
+
+  "alice_51_46.npz": "train-51-6-3",
+
+  "alice_51_47.npz": "train-51-7-0",
+
+  "alice_51_48.npz": "train-51-7-1",
+
+  "alice_51_49.npz": "train-51-7-2",
+
+  "alice_51_50.npz": "train-51-7-3",
+
+  "alice_51_51.npz": "train-51-7-4",
+
+  "alice_51_52.npz": "train-51-7-5",
+
+  "alice_51_53.npz": "train-51-8-0",
+
+  "alice_51_54.npz": "train-51-8-1",
+
+  "alice_51_55.npz": "train-51-8-2",
+
+  "alice_51_56.npz": "train-51-8-3",
+
+  "alice_51_57.npz": "train-51-8-4",
+
+  "alice_51_58.npz": "train-51-8-5",
+
+  "alice_51_59.npz": "train-51-9-0",
+
+  "alice_51_60.npz": "train-51-9-1",
+
+  "alice_51_61.npz": "train-51-9-2",
+
+  "alice_51_62.npz": "train-51-9-3",
+
+  "alice_51_63.npz": "train-51-9-4",
+
+  "alice_51_64.npz": "train-51-9-5",
+
+  "alice_51_65.npz": "train-51-9-6",
+
+  "alice_51_66.npz": "train-51-9-7",
+
+  "alice_51_67.npz": "train-51-9-8",
+
+  "alice_51_68.npz": "train-51-10-0",
+
+  "alice_51_69.npz": "train-51-10-1",
+
+  "alice_51_70.npz": "train-51-10-2",
+
+  "alice_51_71.npz": "train-51-10-3",
+
+  "alice_51_72.npz": "train-51-10-4",
+
+  "alice_51_73.npz": "train-51-10-5",
+
+  "alice_51_74.npz": "train-51-10-6",
+
+  "alice_51_75.npz": "train-51-10-7",
+
+  "alice_51_76.npz": "train-51-10-8",
+
+  "alice_51_77.npz": "train-51-12-0",
+
+  "alice_51_78.npz": "train-51-12-1",
+
+  "alice_51_79.npz": "train-51-12-2",
+
+  "alice_51_80.npz": "train-51-13-0",
+
+  "alice_51_81.npz": "train-51-14-0",
+
+  "alice_51_82.npz": "train-51-14-1",
+
+  "alice_51_83.npz": "train-51-14-2",
+
+  "alice_51_84.npz": "train-51-15-0",
+
+  "alice_51_85.npz": "train-51-16-0",
+
+  "alice_51_86.npz": "train-51-17-0",
+
+  "alice_51_87.npz": "train-51-17-1",
+
+  "alice_51_88.npz": "train-51-18-0",
+
+  "alice_51_89.npz": "train-51-18-1",
+
+  "alice_51_90.npz": "train-51-20-0",
+
+  "alice_51_91.npz": "train-51-20-1",
+
+  "alice_51_92.npz": "train-51-21-0",
+
+  "alice_51_93.npz": "train-51-21-1",
+
+  "alice_51_94.npz": "train-51-21-2",
+
+  "alice_51_95.npz": "train-51-21-3",
+
+  "alice_51_96.npz": "train-51-21-4",
+
+  "alice_51_97.npz": "train-51-21-5",
+
+  "alice_51_98.npz": "train-51-21-6",
+
+  "alice_51_99.npz": "train-51-21-7",
+
+  "alice_51_100.npz": "train-51-21-8",
+
+  "alice_51_101.npz": "train-51-21-9",
+
+  "alice_51_102.npz": "train-51-21-10",
+
+  "alice_51_103.npz": "train-51-21-11",
+
+  "alice_51_104.npz": "train-51-22-0",
+
+  "alice_51_105.npz": "train-51-22-1",
+
+  "alice_51_106.npz": "train-51-22-2",
+
+  "alice_51_107.npz": "train-51-22-3",
+
+  "alice_51_108.npz": "train-51-23-0",
+
+  "alice_51_109.npz": "train-51-24-0",
+
+  "alice_51_110.npz": "train-51-24-1",
+
+  "alice_51_111.npz": "train-51-25-0",
+
+  "alice_51_112.npz": "train-51-25-1",
+
+  "alice_51_113.npz": "train-51-26-0",
+
+  "alice_51_114.npz": "train-51-26-1",
+
+  "alice_51_115.npz": "train-51-26-2",
+
+  "alice_51_116.npz": "train-51-26-3",
+
+  "alice_51_117.npz": "train-51-26-4",
+
+  "alice_51_118.npz": "train-51-26-5",
+
+  "alice_51_119.npz": "train-51-26-6",
+
+  "alice_51_120.npz": "train-51-27-0",
+
+  "alice_51_121.npz": "train-51-27-1",
+
+  "alice_51_122.npz": "train-51-28-0",
+
+  "alice_51_123.npz": "train-51-28-1",
+
+  "alice_51_124.npz": "train-51-29-0",
+
+  "alice_51_125.npz": "train-51-29-1",
+
+  "alice_51_126.npz": "train-51-30-0",
+
+  "alice_51_127.npz": "train-51-31-0",
+
+  "alice_51_128.npz": "train-51-31-1",
+
+  "alice_51_129.npz": "train-51-31-2",
+
+  "alice_51_130.npz": "train-51-32-0",
+
+  "alice_51_131.npz": "train-51-33-0",
+
+  "alice_51_132.npz": "train-51-33-1",
+
+  "alice_51_133.npz": "train-51-33-2",
+
+  "alice_51_134.npz": "train-51-34-0",
+
+  "alice_51_135.npz": "train-51-34-1",
+
+  "alice_51_136.npz": "train-51-35-0",
+
+  "alice_51_137.npz": "train-51-36-0",
+
+  "alice_51_138.npz": "train-51-36-1",
+
+  "alice_51_139.npz": "train-51-38-0",
+
+  "alice_51_140.npz": "train-51-39-0",
+
+  "alice_51_141.npz": "train-51-39-1",
+
+  "alice_51_142.npz": "train-51-39-2",
+
+  "alice_51_143.npz": "train-51-39-3",
+
+  "alice_51_144.npz": "train-51-40-0",
+
+  "alice_51_145.npz": "train-51-41-0",
+
+  "alice_51_146.npz": "train-51-41-1",
+
+  "alice_51_147.npz": "train-51-41-2",
+
+  "alice_51_148.npz": "train-51-41-3",
+
+  "alice_51_149.npz": "train-51-42-0",
+
+  "alice_51_150.npz": "train-51-43-0",
+
+  "alice_51_151.npz": "train-51-44-0",
+
+  "alice_51_152.npz": "train-51-44-1",
+
+  "alice_51_153.npz": "train-51-44-2",
+
+  "alice_51_154.npz": "train-51-45-0",
+
+  "alice_51_155.npz": "train-51-45-1",
+
+  "alice_51_156.npz": "train-51-45-2",
+
+  "alice_51_157.npz": "train-51-45-3",
+
+  "alice_51_158.npz": "train-51-45-4",
+
+  "alice_51_159.npz": "train-51-45-5",
+
+  "alice_51_160.npz": "train-51-45-6",
+
+  "alice_51_161.npz": "train-51-46-0",
+
+  "alice_51_162.npz": "train-51-48-0",
+
+  "alice_51_163.npz": "train-51-48-1",
+
+  "alice_51_164.npz": "train-51-48-2",
+
+  "alice_51_165.npz": "train-51-49-0",
+
+  "alice_51_166.npz": "train-51-49-1",
+
+  "alice_51_167.npz": "train-51-49-2",
+
+  "alice_51_168.npz": "train-51-49-3",
+
+  "alice_51_169.npz": "train-51-49-4",
+
+  "alice_51_170.npz": "train-51-49-5",
+
+  "alice_51_171.npz": "train-51-49-6",
+
+  "alice_51_172.npz": "train-51-50-0",
+
+  "alice_51_173.npz": "train-51-50-1",
+
+  "alice_51_174.npz": "train-51-50-2",
+
+  "alice_51_175.npz": "train-51-50-3",
+
+  "alice_51_176.npz": "train-51-50-4",
+
+  "alice_51_177.npz": "train-51-51-0",
+
+  "alice_51_178.npz": "train-51-51-1",
+
+  "alice_51_179.npz": "train-51-51-2",
+
+  "alice_51_180.npz": "train-51-51-3",
+
+  "alice_51_181.npz": "train-51-51-4",
+
+  "alice_51_182.npz": "train-51-51-5",
+
+  "alice_51_183.npz": "train-51-52-0",
+
+  "alice_51_184.npz": "train-51-52-1",
+
+  "alice_51_185.npz": "train-51-52-2",
+
+  "alice_51_186.npz": "train-51-52-3",
+
+  "alice_51_187.npz": "train-51-52-4",
+
+  "alice_51_188.npz": "train-51-52-5",
+
+  "alice_51_189.npz": "train-51-52-6",
+
+  "alice_51_190.npz": "train-51-52-7",
+
+  "alice_51_191.npz": "train-51-53-0",
+
+  "alice_51_192.npz": "train-51-53-1",
+
+  "alice_51_193.npz": "train-51-53-2",
+
+  "alice_51_194.npz": "train-51-53-3",
+
+  "alice_51_195.npz": "train-51-53-4",
+
+  "alice_51_196.npz": "train-51-53-5",
+
+  "alice_51_197.npz": "train-51-53-6",
+
+  "alice_51_198.npz": "train-51-54-0",
+
+  "alice_51_199.npz": "train-51-54-1",
+
+  "alice_51_200.npz": "train-51-54-2",
+
+  "alice_51_201.npz": "train-51-54-3",
+
+  "alice_51_202.npz": "train-51-55-0",
+
+  "alice_51_203.npz": "train-51-55-1",
+
+  "alice_51_204.npz": "train-51-55-2",
+
+  "alice_51_205.npz": "train-51-55-3",
+
+  "alice_51_206.npz": "train-51-55-4",
+
+  "alice_51_207.npz": "train-51-55-5",
+
+  "alice_51_208.npz": "train-51-55-6",
+
+  "alice_51_209.npz": "train-51-55-7",
+
+  "alice_51_210.npz": "train-51-56-0",
+
+  "alice_51_211.npz": "train-51-56-1",
+
+  "alice_51_212.npz": "train-51-56-2",
+
+  "alice_51_213.npz": "train-51-56-3",
+
+  "alice_51_214.npz": "train-51-56-4",
+
+  "alice_51_215.npz": "train-51-56-5",
+
+  "alice_51_216.npz": "train-51-57-0",
+
+  "alice_51_217.npz": "train-51-57-1",
+
+  "alice_51_218.npz": "train-51-57-2",
+
+  "alice_51_219.npz": "train-51-57-3",
+
+  "alice_51_220.npz": "train-51-57-4",
+
+  "alice_51_221.npz": "train-51-57-5",
+
+  "alice_51_222.npz": "train-51-57-6",
+
+  "alice_51_223.npz": "train-51-57-7",
+
+  "alice_51_224.npz": "train-51-57-8",
+
+  "alice_51_225.npz": "train-51-57-9",
+
+  "alice_51_226.npz": "train-51-58-0",
+
+  "alice_51_227.npz": "train-51-59-0",
+
+  "alice_51_228.npz": "train-51-59-1",
+
+  "alice_51_229.npz": "train-51-60-0",
+
+  "alice_51_230.npz": "train-51-60-1",
+
+  "alice_51_231.npz": "train-51-60-2",
+
+  "alice_51_232.npz": "train-51-60-3",
+
+  "alice_51_233.npz": "train-51-60-4",
+
+  "alice_51_234.npz": "train-51-61-0",
+
+  "alice_51_235.npz": "train-51-61-1",
+
+  "alice_51_236.npz": "train-51-61-2",
+
+  "alice_51_237.npz": "train-51-61-3",
+
+  "alice_51_238.npz": "train-51-61-4",
+
+  "alice_51_239.npz": "train-51-61-5",
+
+  "alice_51_240.npz": "train-51-61-6",
+
+  "alice_51_241.npz": "train-51-61-7",
+
+  "alice_51_242.npz": "train-51-61-8",
+
+  "alice_51_243.npz": "train-51-61-9",
+
+  "alice_51_244.npz": "train-51-61-10",
+
+  "alice_51_245.npz": "train-51-61-11",
+
+  "alice_51_246.npz": "train-51-61-12",
+
+  "alice_51_247.npz": "train-51-62-0",
+
+  "alice_51_248.npz": "train-51-62-1",
+
+  "alice_51_249.npz": "train-51-62-2",
+
+  "alice_51_250.npz": "train-51-62-3",
+
+  "alice_51_251.npz": "train-51-63-0",
+
+  "alice_51_252.npz": "train-51-63-1",
+
+  "alice_51_253.npz": "train-51-63-2",
+
+  "alice_51_254.npz": "train-51-63-3",
+
+  "alice_51_255.npz": "train-51-63-4",
+
+  "alice_51_256.npz": "train-51-63-5",
+
+  "alice_51_257.npz": "train-51-63-6",
+
+  "alice_51_258.npz": "train-51-63-7",
+
+  "alice_51_259.npz": "train-51-63-8",
+
+  "alice_51_260.npz": "train-51-63-9",
+
+  "alice_51_261.npz": "train-51-63-10",
+
+  "alice_51_262.npz": "train-51-63-11",
+
+  "alice_51_263.npz": "train-51-63-12",
+
+  "alice_51_264.npz": "train-51-63-13",
+
+  "alice_51_265.npz": "train-51-63-14",
+
+  "alice_51_266.npz": "train-51-63-15",
+
+  "alice_51_267.npz": "train-51-63-16",
+
+  "alice_51_268.npz": "train-51-63-17",
+
+  "alice_51_269.npz": "train-51-64-0",
+
+  "alice_51_270.npz": "train-51-64-1",
+
+  "alice_51_271.npz": "train-51-64-2",
+
+  "alice_51_272.npz": "train-51-64-3",
+
+  "alice_51_273.npz": "train-51-64-4",
+
+  "alice_51_274.npz": "train-51-64-5",
+
+  "alice_51_275.npz": "train-51-64-6",
+
+  "alice_51_276.npz": "train-51-64-7",
+
+  "alice_51_277.npz": "train-51-64-8",
+
+  "alice_51_278.npz": "train-51-64-9",
+  "alice_51_279.npz": "train-51-64-9",
+
+  "alice_51_280.npz": "train-51-65-0",
+
+  "alice_51_281.npz": "train-51-66-0",
+
+  "alice_24_0.npz": "train-24-0-0",
+
+  "alice_24_1.npz": "train-24-0-1",
+
+  "alice_24_2.npz": "train-24-0-2",
+
+  "alice_24_3.npz": "train-24-0-3",
+
+  "alice_24_4.npz": "train-24-0-4",
+
+  "alice_24_5.npz": "train-24-0-5",
+
+  "alice_24_6.npz": "train-24-0-6",
+
+  "alice_24_7.npz": "train-24-0-7",
+
+  "alice_24_8.npz": "train-24-0-8",
+
+  "alice_24_9.npz": "train-24-1-0",
+
+  "alice_24_10.npz": "train-24-1-1",
+
+  "alice_24_11.npz": "train-24-1-2",
+
+  "alice_24_12.npz": "train-24-1-3",
+
+  "alice_24_13.npz": "train-24-1-4",
+
+  "alice_24_14.npz": "train-24-1-5",
+
+  "alice_24_15.npz": "train-24-1-6",
+
+  "alice_24_16.npz": "train-24-1-7",
+
+  "alice_24_17.npz": "train-24-1-8",
+
+  "alice_24_18.npz": "train-24-1-9",
+
+  "alice_24_19.npz": "train-24-2-0",
+
+  "alice_24_20.npz": "train-24-2-1",
+
+  "alice_24_21.npz": "train-24-2-2",
+
+  "alice_24_22.npz": "train-24-2-3",
+
+  "alice_24_23.npz": "train-24-3-0",
+
+  "alice_24_24.npz": "train-24-4-0",
+
+  "alice_24_25.npz": "train-24-5-0",
+
+  "alice_24_26.npz": "train-24-5-1",
+
+  "alice_24_27.npz": "train-24-5-2",
+
+  "alice_24_28.npz": "train-24-5-3",
+
+  "alice_24_29.npz": "train-24-5-4",
+
+  "alice_24_30.npz": "train-24-5-5",
+
+  "alice_24_31.npz": "train-24-5-6",
+
+  "alice_24_32.npz": "train-24-5-7",
+
+  "alice_24_33.npz": "train-24-5-8",
+
+  "alice_24_34.npz": "train-24-5-9",
+
+  "alice_24_35.npz": "train-24-5-10",
+
+  "alice_24_36.npz": "train-24-5-11",
+
+  "alice_24_37.npz": "train-24-5-12",
+
+  "alice_24_38.npz": "train-24-5-13",
+
+  "alice_24_39.npz": "train-24-5-14",
+
+  "alice_24_40.npz": "train-24-5-15",
+
+  "alice_24_41.npz": "train-24-5-16",
+
+  "alice_24_42.npz": "train-24-5-17",
+
+  "alice_24_43.npz": "train-24-6-0",
+
+  "alice_24_44.npz": "train-24-6-1",
+
+  "alice_24_45.npz": "train-24-6-2",
+
+  "alice_24_46.npz": "train-24-6-3",
+
+  "alice_24_47.npz": "train-24-7-0",
+
+  "alice_24_48.npz": "train-24-7-1",
+
+  "alice_24_49.npz": "train-24-7-2",
+
+  "alice_24_50.npz": "train-24-7-3",
+
+  "alice_24_51.npz": "train-24-7-4",
+
+  "alice_24_52.npz": "train-24-7-5",
+
+  "alice_24_53.npz": "train-24-8-0",
+
+  "alice_24_54.npz": "train-24-8-1",
+
+  "alice_24_55.npz": "train-24-8-2",
+
+  "alice_24_56.npz": "train-24-8-3",
+
+  "alice_24_57.npz": "train-24-8-4",
+
+  "alice_24_58.npz": "train-24-8-5",
+
+  "alice_24_59.npz": "train-24-9-0",
+
+  "alice_24_60.npz": "train-24-9-1",
+
+  "alice_24_61.npz": "train-24-9-2",
+
+  "alice_24_62.npz": "train-24-9-3",
+
+  "alice_24_63.npz": "train-24-9-4",
+
+  "alice_24_64.npz": "train-24-9-5",
+
+  "alice_24_65.npz": "train-24-9-6",
+
+  "alice_24_66.npz": "train-24-9-7",
+
+  "alice_24_67.npz": "train-24-9-8",
+
+  "alice_24_68.npz": "train-24-10-0",
+
+  "alice_24_69.npz": "train-24-10-1",
+
+  "alice_24_70.npz": "train-24-10-2",
+
+  "alice_24_71.npz": "train-24-10-3",
+
+  "alice_24_72.npz": "train-24-10-4",
+
+  "alice_24_73.npz": "train-24-10-5",
+
+  "alice_24_74.npz": "train-24-10-6",
+
+  "alice_24_75.npz": "train-24-10-7",
+
+  "alice_24_76.npz": "train-24-10-8",
+
+  "alice_24_77.npz": "train-24-12-0",
+
+  "alice_24_78.npz": "train-24-12-1",
+
+  "alice_24_79.npz": "train-24-12-2",
+
+  "alice_24_80.npz": "train-24-13-0",
+
+  "alice_24_81.npz": "train-24-14-0",
+
+  "alice_24_82.npz": "train-24-14-1",
+
+  "alice_24_83.npz": "train-24-14-2",
+
+  "alice_24_84.npz": "train-24-15-0",
+
+  "alice_24_85.npz": "train-24-16-0",
+
+  "alice_24_86.npz": "train-24-17-0",
+
+  "alice_24_87.npz": "train-24-17-1",
+
+  "alice_24_88.npz": "train-24-18-0",
+
+  "alice_24_89.npz": "train-24-18-1",
+
+  "alice_24_90.npz": "train-24-20-0",
+
+  "alice_24_91.npz": "train-24-20-1",
+
+  "alice_24_92.npz": "train-24-21-0",
+
+  "alice_24_93.npz": "train-24-21-1",
+
+  "alice_24_94.npz": "train-24-21-2",
+
+  "alice_24_95.npz": "train-24-21-3",
+
+  "alice_24_96.npz": "train-24-21-4",
+
+  "alice_24_97.npz": "train-24-21-5",
+
+  "alice_24_98.npz": "train-24-21-6",
+
+  "alice_24_99.npz": "train-24-21-7",
+
+  "alice_24_100.npz": "train-24-21-8",
+
+  "alice_24_101.npz": "train-24-21-9",
+
+  "alice_24_102.npz": "train-24-21-10",
+
+  "alice_24_103.npz": "train-24-21-11",
+
+  "alice_24_104.npz": "train-24-22-0",
+
+  "alice_24_105.npz": "train-24-22-1",
+
+  "alice_24_106.npz": "train-24-22-2",
+
+  "alice_24_107.npz": "train-24-22-3",
+
+  "alice_24_108.npz": "train-24-23-0",
+
+  "alice_24_109.npz": "train-24-24-0",
+
+  "alice_24_110.npz": "train-24-24-1",
+
+  "alice_24_111.npz": "train-24-25-0",
+
+  "alice_24_112.npz": "train-24-25-1",
+
+  "alice_24_113.npz": "train-24-26-0",
+
+  "alice_24_114.npz": "train-24-26-1",
+
+  "alice_24_115.npz": "train-24-26-2",
+
+  "alice_24_116.npz": "train-24-26-3",
+
+  "alice_24_117.npz": "train-24-26-4",
+
+  "alice_24_118.npz": "train-24-26-5",
+
+  "alice_24_119.npz": "train-24-26-6",
+
+  "alice_24_120.npz": "train-24-27-0",
+
+  "alice_24_121.npz": "train-24-27-1",
+
+  "alice_24_122.npz": "train-24-28-0",
+
+  "alice_24_123.npz": "train-24-28-1",
+
+  "alice_24_124.npz": "train-24-29-0",
+
+  "alice_24_125.npz": "train-24-29-1",
+
+  "alice_24_126.npz": "train-24-30-0",
+
+  "alice_24_127.npz": "train-24-31-0",
+
+  "alice_24_128.npz": "train-24-31-1",
+
+  "alice_24_129.npz": "train-24-31-2",
+
+  "alice_24_130.npz": "train-24-32-0",
+
+  "alice_24_131.npz": "train-24-33-0",
+
+  "alice_24_132.npz": "train-24-33-1",
+
+  "alice_24_133.npz": "train-24-33-2",
+
+  "alice_24_134.npz": "train-24-34-0",
+
+  "alice_24_135.npz": "train-24-34-1",
+
+  "alice_24_136.npz": "train-24-35-0",
+
+  "alice_24_137.npz": "train-24-36-0",
+
+  "alice_24_138.npz": "train-24-36-1",
+
+  "alice_24_139.npz": "train-24-38-0",
+
+  "alice_24_140.npz": "train-24-39-0",
+
+  "alice_24_141.npz": "train-24-39-1",
+
+  "alice_24_142.npz": "train-24-39-2",
+
+  "alice_24_143.npz": "train-24-39-3",
+
+  "alice_24_144.npz": "train-24-40-0",
+
+  "alice_24_145.npz": "train-24-41-0",
+
+  "alice_24_146.npz": "train-24-41-1",
+
+  "alice_24_147.npz": "train-24-41-2",
+
+  "alice_24_148.npz": "train-24-41-3",
+
+  "alice_24_149.npz": "train-24-42-0",
+
+  "alice_24_150.npz": "train-24-43-0",
+
+  "alice_24_151.npz": "train-24-44-0",
+
+  "alice_24_152.npz": "train-24-44-1",
+
+  "alice_24_153.npz": "train-24-44-2",
+
+  "alice_24_154.npz": "train-24-45-0",
+
+  "alice_24_155.npz": "train-24-45-1",
+
+  "alice_24_156.npz": "train-24-45-2",
+
+  "alice_24_157.npz": "train-24-45-3",
+
+  "alice_24_158.npz": "train-24-45-4",
+
+  "alice_24_159.npz": "train-24-45-5",
+
+  "alice_24_160.npz": "train-24-45-6",
+
+  "alice_24_161.npz": "train-24-46-0",
+
+  "alice_24_162.npz": "train-24-48-0",
+
+  "alice_24_163.npz": "train-24-48-1",
+
+  "alice_24_164.npz": "train-24-48-2",
+
+  "alice_24_165.npz": "train-24-49-0",
+
+  "alice_24_166.npz": "train-24-49-1",
+
+  "alice_24_167.npz": "train-24-49-2",
+
+  "alice_24_168.npz": "train-24-49-3",
+
+  "alice_24_169.npz": "train-24-49-4",
+
+  "alice_24_170.npz": "train-24-49-5",
+
+  "alice_24_171.npz": "train-24-49-6",
+
+  "alice_24_172.npz": "train-24-50-0",
+
+  "alice_24_173.npz": "train-24-50-1",
+
+  "alice_24_174.npz": "train-24-50-2",
+
+  "alice_24_175.npz": "train-24-50-3",
+
+  "alice_24_176.npz": "train-24-50-4",
+
+  "alice_24_177.npz": "train-24-51-0",
+
+  "alice_24_178.npz": "train-24-51-1",
+
+  "alice_24_179.npz": "train-24-51-2",
+
+  "alice_24_180.npz": "train-24-51-3",
+
+  "alice_24_181.npz": "train-24-51-4",
+
+  "alice_24_182.npz": "train-24-51-5",
+
+  "alice_24_183.npz": "train-24-52-0",
+
+  "alice_24_184.npz": "train-24-52-1",
+
+  "alice_24_185.npz": "train-24-52-2",
+
+  "alice_24_186.npz": "train-24-52-3",
+
+  "alice_24_187.npz": "train-24-52-4",
+
+  "alice_24_188.npz": "train-24-52-5",
+
+  "alice_24_189.npz": "train-24-52-6",
+
+  "alice_24_190.npz": "train-24-52-7",
+
+  "alice_24_191.npz": "train-24-53-0",
+
+  "alice_24_192.npz": "train-24-53-1",
+
+  "alice_24_193.npz": "train-24-53-2",
+
+  "alice_24_194.npz": "train-24-53-3",
+
+  "alice_24_195.npz": "train-24-53-4",
+
+  "alice_24_196.npz": "train-24-53-5",
+
+  "alice_24_197.npz": "train-24-53-6",
+
+  "alice_24_198.npz": "train-24-54-0",
+
+  "alice_24_199.npz": "train-24-54-1",
+
+  "alice_24_200.npz": "train-24-54-2",
+
+  "alice_24_201.npz": "train-24-54-3",
+
+  "alice_24_202.npz": "train-24-55-0",
+
+  "alice_24_203.npz": "train-24-55-1",
+
+  "alice_24_204.npz": "train-24-55-2",
+
+  "alice_24_205.npz": "train-24-55-3",
+
+  "alice_24_206.npz": "train-24-55-4",
+
+  "alice_24_207.npz": "train-24-55-5",
+
+  "alice_24_208.npz": "train-24-55-6",
+
+  "alice_24_209.npz": "train-24-55-7",
+
+  "alice_24_210.npz": "train-24-56-0",
+
+  "alice_24_211.npz": "train-24-56-1",
+
+  "alice_24_212.npz": "train-24-56-2",
+
+  "alice_24_213.npz": "train-24-56-3",
+
+  "alice_24_214.npz": "train-24-56-4",
+
+  "alice_24_215.npz": "train-24-56-5",
+
+  "alice_24_216.npz": "train-24-57-0",
+
+  "alice_24_217.npz": "train-24-57-1",
+
+  "alice_24_218.npz": "train-24-57-2",
+
+  "alice_24_219.npz": "train-24-57-3",
+
+  "alice_24_220.npz": "train-24-57-4",
+
+  "alice_24_221.npz": "train-24-57-5",
+
+  "alice_24_222.npz": "train-24-57-6",
+
+  "alice_24_223.npz": "train-24-57-7",
+
+  "alice_24_224.npz": "train-24-57-8",
+
+  "alice_24_225.npz": "train-24-57-9",
+
+  "alice_24_226.npz": "train-24-58-0",
+
+  "alice_24_227.npz": "train-24-59-0",
+
+  "alice_24_228.npz": "train-24-59-1",
+
+  "alice_24_229.npz": "train-24-60-0",
+
+  "alice_24_230.npz": "train-24-60-1",
+
+  "alice_24_231.npz": "train-24-60-2",
+
+  "alice_24_232.npz": "train-24-60-3",
+
+  "alice_24_233.npz": "train-24-60-4",
+
+  "alice_24_234.npz": "train-24-61-0",
+
+  "alice_24_235.npz": "train-24-61-1",
+
+  "alice_24_236.npz": "train-24-61-2",
+
+  "alice_24_237.npz": "train-24-61-3",
+
+  "alice_24_238.npz": "train-24-61-4",
+
+  "alice_24_239.npz": "train-24-61-5",
+
+  "alice_24_240.npz": "train-24-61-6",
+
+  "alice_24_241.npz": "train-24-61-7",
+
+  "alice_24_242.npz": "train-24-61-8",
+
+  "alice_24_243.npz": "train-24-61-9",
+
+  "alice_24_244.npz": "train-24-61-10",
+
+  "alice_24_245.npz": "train-24-61-11",
+
+  "alice_24_246.npz": "train-24-61-12",
+
+  "alice_24_247.npz": "train-24-62-0",
+
+  "alice_24_248.npz": "train-24-62-1",
+
+  "alice_24_249.npz": "train-24-62-2",
+
+  "alice_24_250.npz": "train-24-62-3",
+
+  "alice_24_251.npz": "train-24-63-0",
+
+  "alice_24_252.npz": "train-24-63-1",
+
+  "alice_24_253.npz": "train-24-63-2",
+
+  "alice_24_254.npz": "train-24-63-3",
+
+  "alice_24_255.npz": "train-24-63-4",
+
+  "alice_24_256.npz": "train-24-63-5",
+
+  "alice_24_257.npz": "train-24-63-6",
+
+  "alice_24_258.npz": "train-24-63-7",
+
+  "alice_24_259.npz": "train-24-63-8",
+
+  "alice_24_260.npz": "train-24-63-9",
+
+  "alice_24_261.npz": "train-24-63-10",
+
+  "alice_24_262.npz": "train-24-63-11",
+
+  "alice_24_263.npz": "train-24-63-12",
+
+  "alice_24_264.npz": "train-24-63-13",
+
+  "alice_24_265.npz": "train-24-63-14",
+
+  "alice_24_266.npz": "train-24-63-15",
+
+  "alice_24_267.npz": "train-24-63-16",
+
+  "alice_24_268.npz": "train-24-63-17",
+
+  "alice_24_269.npz": "train-24-64-0",
+
+  "alice_24_270.npz": "train-24-64-1",
+
+  "alice_24_271.npz": "train-24-64-2",
+
+  "alice_24_272.npz": "train-24-64-3",
+
+  "alice_24_273.npz": "train-24-64-4",
+
+  "alice_24_274.npz": "train-24-64-5",
+
+  "alice_24_275.npz": "train-24-64-6",
+
+  "alice_24_276.npz": "train-24-64-7",
+
+  "alice_24_277.npz": "train-24-64-8",
+
+  "alice_24_278.npz": "train-24-64-9",
+  "alice_24_279.npz": "train-24-64-9",
+
+  "alice_24_280.npz": "train-24-65-0",
+
+  "alice_24_281.npz": "train-24-66-0",
+
+  "alice_35_0.npz": "train-35-0-0",
+
+  "alice_35_1.npz": "train-35-0-1",
+
+  "alice_35_2.npz": "train-35-0-2",
+
+  "alice_35_3.npz": "train-35-0-3",
+
+  "alice_35_4.npz": "train-35-0-4",
+
+  "alice_35_5.npz": "train-35-0-5",
+
+  "alice_35_6.npz": "train-35-0-6",
+
+  "alice_35_7.npz": "train-35-0-7",
+
+  "alice_35_8.npz": "train-35-0-8",
+
+  "alice_35_9.npz": "train-35-1-0",
+
+  "alice_35_10.npz": "train-35-1-1",
+
+  "alice_35_11.npz": "train-35-1-2",
+
+  "alice_35_12.npz": "train-35-1-3",
+
+  "alice_35_13.npz": "train-35-1-4",
+
+  "alice_35_14.npz": "train-35-1-5",
+
+  "alice_35_15.npz": "train-35-1-6",
+
+  "alice_35_16.npz": "train-35-1-7",
+
+  "alice_35_17.npz": "train-35-1-8",
+
+  "alice_35_18.npz": "train-35-1-9",
+
+  "alice_35_19.npz": "train-35-2-0",
+
+  "alice_35_20.npz": "train-35-2-1",
+
+  "alice_35_21.npz": "train-35-2-2",
+
+  "alice_35_22.npz": "train-35-2-3",
+
+  "alice_35_23.npz": "train-35-3-0",
+
+  "alice_35_24.npz": "train-35-4-0",
+
+  "alice_35_25.npz": "train-35-5-0",
+
+  "alice_35_26.npz": "train-35-5-1",
+
+  "alice_35_27.npz": "train-35-5-2",
+
+  "alice_35_28.npz": "train-35-5-3",
+
+  "alice_35_29.npz": "train-35-5-4",
+
+  "alice_35_30.npz": "train-35-5-5",
+
+  "alice_35_31.npz": "train-35-5-6",
+
+  "alice_35_32.npz": "train-35-5-7",
+
+  "alice_35_33.npz": "train-35-5-8",
+
+  "alice_35_34.npz": "train-35-5-9",
+
+  "alice_35_35.npz": "train-35-5-10",
+
+  "alice_35_36.npz": "train-35-5-11",
+
+  "alice_35_37.npz": "train-35-5-12",
+
+  "alice_35_38.npz": "train-35-5-13",
+
+  "alice_35_39.npz": "train-35-5-14",
+
+  "alice_35_40.npz": "train-35-5-15",
+
+  "alice_35_41.npz": "train-35-5-16",
+
+  "alice_35_42.npz": "train-35-5-17",
+
+  "alice_35_43.npz": "train-35-6-0",
+
+  "alice_35_44.npz": "train-35-6-1",
+
+  "alice_35_45.npz": "train-35-6-2",
+
+  "alice_35_46.npz": "train-35-6-3",
+
+  "alice_35_47.npz": "train-35-7-0",
+
+  "alice_35_48.npz": "train-35-7-1",
+
+  "alice_35_49.npz": "train-35-7-2",
+
+  "alice_35_50.npz": "train-35-7-3",
+
+  "alice_35_51.npz": "train-35-7-4",
+
+  "alice_35_52.npz": "train-35-7-5",
+
+  "alice_35_53.npz": "train-35-8-0",
+
+  "alice_35_54.npz": "train-35-8-1",
+
+  "alice_35_55.npz": "train-35-8-2",
+
+  "alice_35_56.npz": "train-35-8-3",
+
+  "alice_35_57.npz": "train-35-8-4",
+
+  "alice_35_58.npz": "train-35-8-5",
+
+  "alice_35_59.npz": "train-35-9-0",
+
+  "alice_35_60.npz": "train-35-9-1",
+
+  "alice_35_61.npz": "train-35-9-2",
+
+  "alice_35_62.npz": "train-35-9-3",
+
+  "alice_35_63.npz": "train-35-9-4",
+
+  "alice_35_64.npz": "train-35-9-5",
+
+  "alice_35_65.npz": "train-35-9-6",
+
+  "alice_35_66.npz": "train-35-9-7",
+
+  "alice_35_67.npz": "train-35-9-8",
+
+  "alice_35_68.npz": "train-35-10-0",
+
+  "alice_35_69.npz": "train-35-10-1",
+
+  "alice_35_70.npz": "train-35-10-2",
+
+  "alice_35_71.npz": "train-35-10-3",
+
+  "alice_35_72.npz": "train-35-10-4",
+
+  "alice_35_73.npz": "train-35-10-5",
+
+  "alice_35_74.npz": "train-35-10-6",
+
+  "alice_35_75.npz": "train-35-10-7",
+
+  "alice_35_76.npz": "train-35-10-8",
+
+  "alice_35_77.npz": "train-35-12-0",
+
+  "alice_35_78.npz": "train-35-12-1",
+
+  "alice_35_79.npz": "train-35-12-2",
+
+  "alice_35_80.npz": "train-35-13-0",
+
+  "alice_35_81.npz": "train-35-14-0",
+
+  "alice_35_82.npz": "train-35-14-1",
+
+  "alice_35_83.npz": "train-35-14-2",
+
+  "alice_35_84.npz": "train-35-15-0",
+
+  "alice_35_85.npz": "train-35-16-0",
+
+  "alice_35_86.npz": "train-35-17-0",
+
+  "alice_35_87.npz": "train-35-17-1",
+
+  "alice_35_88.npz": "train-35-18-0",
+
+  "alice_35_89.npz": "train-35-18-1",
+
+  "alice_35_90.npz": "train-35-20-0",
+
+  "alice_35_91.npz": "train-35-20-1",
+
+  "alice_35_92.npz": "train-35-21-0",
+
+  "alice_35_93.npz": "train-35-21-1",
+
+  "alice_35_94.npz": "train-35-21-2",
+
+  "alice_35_95.npz": "train-35-21-3",
+
+  "alice_35_96.npz": "train-35-21-4",
+
+  "alice_35_97.npz": "train-35-21-5",
+
+  "alice_35_98.npz": "train-35-21-6",
+
+  "alice_35_99.npz": "train-35-21-7",
+
+  "alice_35_100.npz": "train-35-21-8",
+
+  "alice_35_101.npz": "train-35-21-9",
+
+  "alice_35_102.npz": "train-35-21-10",
+
+  "alice_35_103.npz": "train-35-21-11",
+
+  "alice_35_104.npz": "train-35-22-0",
+
+  "alice_35_105.npz": "train-35-22-1",
+
+  "alice_35_106.npz": "train-35-22-2",
+
+  "alice_35_107.npz": "train-35-22-3",
+
+  "alice_35_108.npz": "train-35-23-0",
+
+  "alice_35_109.npz": "train-35-24-0",
+
+  "alice_35_110.npz": "train-35-24-1",
+
+  "alice_35_111.npz": "train-35-25-0",
+
+  "alice_35_112.npz": "train-35-25-1",
+
+  "alice_35_113.npz": "train-35-26-0",
+
+  "alice_35_114.npz": "train-35-26-1",
+
+  "alice_35_115.npz": "train-35-26-2",
+
+  "alice_35_116.npz": "train-35-26-3",
+
+  "alice_35_117.npz": "train-35-26-4",
+
+  "alice_35_118.npz": "train-35-26-5",
+
+  "alice_35_119.npz": "train-35-26-6",
+
+  "alice_35_120.npz": "train-35-27-0",
+
+  "alice_35_121.npz": "train-35-27-1",
+
+  "alice_35_122.npz": "train-35-28-0",
+
+  "alice_35_123.npz": "train-35-28-1",
+
+  "alice_35_124.npz": "train-35-29-0",
+
+  "alice_35_125.npz": "train-35-29-1",
+
+  "alice_35_126.npz": "train-35-30-0",
+
+  "alice_35_127.npz": "train-35-31-0",
+
+  "alice_35_128.npz": "train-35-31-1",
+
+  "alice_35_129.npz": "train-35-31-2",
+
+  "alice_35_130.npz": "train-35-32-0",
+
+  "alice_35_131.npz": "train-35-33-0",
+
+  "alice_35_132.npz": "train-35-33-1",
+
+  "alice_35_133.npz": "train-35-33-2",
+
+  "alice_35_134.npz": "train-35-34-0",
+
+  "alice_35_135.npz": "train-35-34-1",
+
+  "alice_35_136.npz": "train-35-35-0",
+
+  "alice_35_137.npz": "train-35-36-0",
+
+  "alice_35_138.npz": "train-35-36-1",
+
+  "alice_35_139.npz": "train-35-38-0",
+
+  "alice_35_140.npz": "train-35-39-0",
+
+  "alice_35_141.npz": "train-35-39-1",
+
+  "alice_35_142.npz": "train-35-39-2",
+
+  "alice_35_143.npz": "train-35-39-3",
+
+  "alice_35_144.npz": "train-35-40-0",
+
+  "alice_35_145.npz": "train-35-41-0",
+
+  "alice_35_146.npz": "train-35-41-1",
+
+  "alice_35_147.npz": "train-35-41-2",
+
+  "alice_35_148.npz": "train-35-41-3",
+
+  "alice_35_149.npz": "train-35-42-0",
+
+  "alice_35_150.npz": "train-35-43-0",
+
+  "alice_35_151.npz": "train-35-44-0",
+
+  "alice_35_152.npz": "train-35-44-1",
+
+  "alice_35_153.npz": "train-35-44-2",
+
+  "alice_35_154.npz": "train-35-45-0",
+
+  "alice_35_155.npz": "train-35-45-1",
+
+  "alice_35_156.npz": "train-35-45-2",
+
+  "alice_35_157.npz": "train-35-45-3",
+
+  "alice_35_158.npz": "train-35-45-4",
+
+  "alice_35_159.npz": "train-35-45-5",
+
+  "alice_35_160.npz": "train-35-45-6",
+
+  "alice_35_161.npz": "train-35-46-0",
+
+  "alice_35_162.npz": "train-35-48-0",
+
+  "alice_35_163.npz": "train-35-48-1",
+
+  "alice_35_164.npz": "train-35-48-2",
+
+  "alice_35_165.npz": "train-35-49-0",
+
+  "alice_35_166.npz": "train-35-49-1",
+
+  "alice_35_167.npz": "train-35-49-2",
+
+  "alice_35_168.npz": "train-35-49-3",
+
+  "alice_35_169.npz": "train-35-49-4",
+
+  "alice_35_170.npz": "train-35-49-5",
+
+  "alice_35_171.npz": "train-35-49-6",
+
+  "alice_35_172.npz": "train-35-50-0",
+
+  "alice_35_173.npz": "train-35-50-1",
+
+  "alice_35_174.npz": "train-35-50-2",
+
+  "alice_35_175.npz": "train-35-50-3",
+
+  "alice_35_176.npz": "train-35-50-4",
+
+  "alice_35_177.npz": "train-35-51-0",
+
+  "alice_35_178.npz": "train-35-51-1",
+
+  "alice_35_179.npz": "train-35-51-2",
+
+  "alice_35_180.npz": "train-35-51-3",
+
+  "alice_35_181.npz": "train-35-51-4",
+
+  "alice_35_182.npz": "train-35-51-5",
+
+  "alice_35_183.npz": "train-35-52-0",
+
+  "alice_35_184.npz": "train-35-52-1",
+
+  "alice_35_185.npz": "train-35-52-2",
+
+  "alice_35_186.npz": "train-35-52-3",
+
+  "alice_35_187.npz": "train-35-52-4",
+
+  "alice_35_188.npz": "train-35-52-5",
+
+  "alice_35_189.npz": "train-35-52-6",
+
+  "alice_35_190.npz": "train-35-52-7",
+
+  "alice_35_191.npz": "train-35-53-0",
+
+  "alice_35_192.npz": "train-35-53-1",
+
+  "alice_35_193.npz": "train-35-53-2",
+
+  "alice_35_194.npz": "train-35-53-3",
+
+  "alice_35_195.npz": "train-35-53-4",
+
+  "alice_35_196.npz": "train-35-53-5",
+
+  "alice_35_197.npz": "train-35-53-6",
+
+  "alice_35_198.npz": "train-35-54-0",
+
+  "alice_35_199.npz": "train-35-54-1",
+
+  "alice_35_200.npz": "train-35-54-2",
+
+  "alice_35_201.npz": "train-35-54-3",
+
+  "alice_35_202.npz": "train-35-55-0",
+
+  "alice_35_203.npz": "train-35-55-1",
+
+  "alice_35_204.npz": "train-35-55-2",
+
+  "alice_35_205.npz": "train-35-55-3",
+
+  "alice_35_206.npz": "train-35-55-4",
+
+  "alice_35_207.npz": "train-35-55-5",
+
+  "alice_35_208.npz": "train-35-55-6",
+
+  "alice_35_209.npz": "train-35-55-7",
+
+  "alice_35_210.npz": "train-35-56-0",
+
+  "alice_35_211.npz": "train-35-56-1",
+
+  "alice_35_212.npz": "train-35-56-2",
+
+  "alice_35_213.npz": "train-35-56-3",
+
+  "alice_35_214.npz": "train-35-56-4",
+
+  "alice_35_215.npz": "train-35-56-5",
+
+  "alice_35_216.npz": "train-35-57-0",
+
+  "alice_35_217.npz": "train-35-57-1",
+
+  "alice_35_218.npz": "train-35-57-2",
+
+  "alice_35_219.npz": "train-35-57-3",
+
+  "alice_35_220.npz": "train-35-57-4",
+
+  "alice_35_221.npz": "train-35-57-5",
+
+  "alice_35_222.npz": "train-35-57-6",
+
+  "alice_35_223.npz": "train-35-57-7",
+
+  "alice_35_224.npz": "train-35-57-8",
+
+  "alice_35_225.npz": "train-35-57-9",
+
+  "alice_35_226.npz": "train-35-58-0",
+
+  "alice_35_227.npz": "train-35-59-0",
+
+  "alice_35_228.npz": "train-35-59-1",
+
+  "alice_35_229.npz": "train-35-60-0",
+
+  "alice_35_230.npz": "train-35-60-1",
+
+  "alice_35_231.npz": "train-35-60-2",
+
+  "alice_35_232.npz": "train-35-60-3",
+
+  "alice_35_233.npz": "train-35-60-4",
+
+  "alice_35_234.npz": "train-35-61-0",
+
+  "alice_35_235.npz": "train-35-61-1",
+
+  "alice_35_236.npz": "train-35-61-2",
+
+  "alice_35_237.npz": "train-35-61-3",
+
+  "alice_35_238.npz": "train-35-61-4",
+
+  "alice_35_239.npz": "train-35-61-5",
+
+  "alice_35_240.npz": "train-35-61-6",
+
+  "alice_35_241.npz": "train-35-61-7",
+
+  "alice_35_242.npz": "train-35-61-8",
+
+  "alice_35_243.npz": "train-35-61-9",
+
+  "alice_35_244.npz": "train-35-61-10",
+
+  "alice_35_245.npz": "train-35-61-11",
+
+  "alice_35_246.npz": "train-35-61-12",
+
+  "alice_35_247.npz": "train-35-62-0",
+
+  "alice_35_248.npz": "train-35-62-1",
+
+  "alice_35_249.npz": "train-35-62-2",
+
+  "alice_35_250.npz": "train-35-62-3",
+
+  "alice_35_251.npz": "train-35-63-0",
+
+  "alice_35_252.npz": "train-35-63-1",
+
+  "alice_35_253.npz": "train-35-63-2",
+
+  "alice_35_254.npz": "train-35-63-3",
+
+  "alice_35_255.npz": "train-35-63-4",
+
+  "alice_35_256.npz": "train-35-63-5",
+
+  "alice_35_257.npz": "train-35-63-6",
+
+  "alice_35_258.npz": "train-35-63-7",
+
+  "alice_35_259.npz": "train-35-63-8",
+
+  "alice_35_260.npz": "train-35-63-9",
+
+  "alice_35_261.npz": "train-35-63-10",
+
+  "alice_35_262.npz": "train-35-63-11",
+
+  "alice_35_263.npz": "train-35-63-12",
+
+  "alice_35_264.npz": "train-35-63-13",
+
+  "alice_35_265.npz": "train-35-63-14",
+
+  "alice_35_266.npz": "train-35-63-15",
+
+  "alice_35_267.npz": "train-35-63-16",
+
+  "alice_35_268.npz": "train-35-63-17",
+
+  "alice_35_269.npz": "train-35-64-0",
+
+  "alice_35_270.npz": "train-35-64-1",
+
+  "alice_35_271.npz": "train-35-64-2",
+
+  "alice_35_272.npz": "train-35-64-3",
+
+  "alice_35_273.npz": "train-35-64-4",
+
+  "alice_35_274.npz": "train-35-64-5",
+
+  "alice_35_275.npz": "train-35-64-6",
+
+  "alice_35_276.npz": "train-35-64-7",
+
+  "alice_35_277.npz": "train-35-64-8",
+
+  "alice_35_278.npz": "train-35-64-9",
+  "alice_35_279.npz": "train-35-64-9",
+
+  "alice_35_280.npz": "train-35-65-0",
+
+  "alice_35_281.npz": "train-35-66-0",
+
+  "alice_28_0.npz": "train-28-0-0",
+
+  "alice_28_1.npz": "train-28-0-1",
+
+  "alice_28_2.npz": "train-28-0-2",
+
+  "alice_28_3.npz": "train-28-0-3",
+
+  "alice_28_4.npz": "train-28-0-4",
+
+  "alice_28_5.npz": "train-28-0-5",
+
+  "alice_28_6.npz": "train-28-0-6",
+
+  "alice_28_7.npz": "train-28-0-7",
+
+  "alice_28_8.npz": "train-28-0-8",
+
+  "alice_28_9.npz": "train-28-1-0",
+
+  "alice_28_10.npz": "train-28-1-1",
+
+  "alice_28_11.npz": "train-28-1-2",
+
+  "alice_28_12.npz": "train-28-1-3",
+
+  "alice_28_13.npz": "train-28-1-4",
+
+  "alice_28_14.npz": "train-28-1-5",
+
+  "alice_28_15.npz": "train-28-1-6",
+
+  "alice_28_16.npz": "train-28-1-7",
+
+  "alice_28_17.npz": "train-28-1-8",
+
+  "alice_28_18.npz": "train-28-1-9",
+
+  "alice_28_19.npz": "train-28-2-0",
+
+  "alice_28_20.npz": "train-28-2-1",
+
+  "alice_28_21.npz": "train-28-2-2",
+
+  "alice_28_22.npz": "train-28-2-3",
+
+  "alice_28_23.npz": "train-28-3-0",
+
+  "alice_28_24.npz": "train-28-4-0",
+
+  "alice_28_25.npz": "train-28-5-0",
+
+  "alice_28_26.npz": "train-28-5-1",
+
+  "alice_28_27.npz": "train-28-5-2",
+
+  "alice_28_28.npz": "train-28-5-3",
+
+  "alice_28_29.npz": "train-28-5-4",
+
+  "alice_28_30.npz": "train-28-5-5",
+
+  "alice_28_31.npz": "train-28-5-6",
+
+  "alice_28_32.npz": "train-28-5-7",
+
+  "alice_28_33.npz": "train-28-5-8",
+
+  "alice_28_34.npz": "train-28-5-9",
+
+  "alice_28_35.npz": "train-28-5-10",
+
+  "alice_28_36.npz": "train-28-5-11",
+
+  "alice_28_37.npz": "train-28-5-12",
+
+  "alice_28_38.npz": "train-28-5-13",
+
+  "alice_28_39.npz": "train-28-5-14",
+
+  "alice_28_40.npz": "train-28-5-15",
+
+  "alice_28_41.npz": "train-28-5-16",
+
+  "alice_28_42.npz": "train-28-5-17",
+
+  "alice_28_43.npz": "train-28-6-0",
+
+  "alice_28_44.npz": "train-28-6-1",
+
+  "alice_28_45.npz": "train-28-6-2",
+
+  "alice_28_46.npz": "train-28-6-3",
+
+  "alice_28_47.npz": "train-28-7-0",
+
+  "alice_28_48.npz": "train-28-7-1",
+
+  "alice_28_49.npz": "train-28-7-2",
+
+  "alice_28_50.npz": "train-28-7-3",
+
+  "alice_28_51.npz": "train-28-7-4",
+
+  "alice_28_52.npz": "train-28-7-5",
+
+  "alice_28_53.npz": "train-28-8-0",
+
+  "alice_28_54.npz": "train-28-8-1",
+
+  "alice_28_55.npz": "train-28-8-2",
+
+  "alice_28_56.npz": "train-28-8-3",
+
+  "alice_28_57.npz": "train-28-8-4",
+
+  "alice_28_58.npz": "train-28-8-5",
+
+  "alice_28_59.npz": "train-28-9-0",
+
+  "alice_28_60.npz": "train-28-9-1",
+
+  "alice_28_61.npz": "train-28-9-2",
+
+  "alice_28_62.npz": "train-28-9-3",
+
+  "alice_28_63.npz": "train-28-9-4",
+
+  "alice_28_64.npz": "train-28-9-5",
+
+  "alice_28_65.npz": "train-28-9-6",
+
+  "alice_28_66.npz": "train-28-9-7",
+
+  "alice_28_67.npz": "train-28-9-8",
+
+  "alice_28_68.npz": "train-28-10-0",
+
+  "alice_28_69.npz": "train-28-10-1",
+
+  "alice_28_70.npz": "train-28-10-2",
+
+  "alice_28_71.npz": "train-28-10-3",
+
+  "alice_28_72.npz": "train-28-10-4",
+
+  "alice_28_73.npz": "train-28-10-5",
+
+  "alice_28_74.npz": "train-28-10-6",
+
+  "alice_28_75.npz": "train-28-10-7",
+
+  "alice_28_76.npz": "train-28-10-8",
+
+  "alice_28_77.npz": "train-28-12-0",
+
+  "alice_28_78.npz": "train-28-12-1",
+
+  "alice_28_79.npz": "train-28-12-2",
+
+  "alice_28_80.npz": "train-28-13-0",
+
+  "alice_28_81.npz": "train-28-14-0",
+
+  "alice_28_82.npz": "train-28-14-1",
+
+  "alice_28_83.npz": "train-28-14-2",
+
+  "alice_28_84.npz": "train-28-15-0",
+
+  "alice_28_85.npz": "train-28-16-0",
+
+  "alice_28_86.npz": "train-28-17-0",
+
+  "alice_28_87.npz": "train-28-17-1",
+
+  "alice_28_88.npz": "train-28-18-0",
+
+  "alice_28_89.npz": "train-28-18-1",
+
+  "alice_28_90.npz": "train-28-20-0",
+
+  "alice_28_91.npz": "train-28-20-1",
+
+  "alice_28_92.npz": "train-28-21-0",
+
+  "alice_28_93.npz": "train-28-21-1",
+
+  "alice_28_94.npz": "train-28-21-2",
+
+  "alice_28_95.npz": "train-28-21-3",
+
+  "alice_28_96.npz": "train-28-21-4",
+
+  "alice_28_97.npz": "train-28-21-5",
+
+  "alice_28_98.npz": "train-28-21-6",
+
+  "alice_28_99.npz": "train-28-21-7",
+
+  "alice_28_100.npz": "train-28-21-8",
+
+  "alice_28_101.npz": "train-28-21-9",
+
+  "alice_28_102.npz": "train-28-21-10",
+
+  "alice_28_103.npz": "train-28-21-11",
+
+  "alice_28_104.npz": "train-28-22-0",
+
+  "alice_28_105.npz": "train-28-22-1",
+
+  "alice_28_106.npz": "train-28-22-2",
+
+  "alice_28_107.npz": "train-28-22-3",
+
+  "alice_28_108.npz": "train-28-23-0",
+
+  "alice_28_109.npz": "train-28-24-0",
+
+  "alice_28_110.npz": "train-28-24-1",
+
+  "alice_28_111.npz": "train-28-25-0",
+
+  "alice_28_112.npz": "train-28-25-1",
+
+  "alice_28_113.npz": "train-28-26-0",
+
+  "alice_28_114.npz": "train-28-26-1",
+
+  "alice_28_115.npz": "train-28-26-2",
+
+  "alice_28_116.npz": "train-28-26-3",
+
+  "alice_28_117.npz": "train-28-26-4",
+
+  "alice_28_118.npz": "train-28-26-5",
+
+  "alice_28_119.npz": "train-28-26-6",
+
+  "alice_28_120.npz": "train-28-27-0",
+
+  "alice_28_121.npz": "train-28-27-1",
+
+  "alice_28_122.npz": "train-28-28-0",
+
+  "alice_28_123.npz": "train-28-28-1",
+
+  "alice_28_124.npz": "train-28-29-0",
+
+  "alice_28_125.npz": "train-28-29-1",
+
+  "alice_28_126.npz": "train-28-30-0",
+
+  "alice_28_127.npz": "train-28-31-0",
+
+  "alice_28_128.npz": "train-28-31-1",
+
+  "alice_28_129.npz": "train-28-31-2",
+
+  "alice_28_130.npz": "train-28-32-0",
+
+  "alice_28_131.npz": "train-28-33-0",
+
+  "alice_28_132.npz": "train-28-33-1",
+
+  "alice_28_133.npz": "train-28-33-2",
+
+  "alice_28_134.npz": "train-28-34-0",
+
+  "alice_28_135.npz": "train-28-34-1",
+
+  "alice_28_136.npz": "train-28-35-0",
+
+  "alice_28_137.npz": "train-28-36-0",
+
+  "alice_28_138.npz": "train-28-36-1",
+
+  "alice_28_139.npz": "train-28-38-0",
+
+  "alice_28_140.npz": "train-28-39-0",
+
+  "alice_28_141.npz": "train-28-39-1",
+
+  "alice_28_142.npz": "train-28-39-2",
+
+  "alice_28_143.npz": "train-28-39-3",
+
+  "alice_28_144.npz": "train-28-40-0",
+
+  "alice_28_145.npz": "train-28-41-0",
+
+  "alice_28_146.npz": "train-28-41-1",
+
+  "alice_28_147.npz": "train-28-41-2",
+
+  "alice_28_148.npz": "train-28-41-3",
+
+  "alice_28_149.npz": "train-28-42-0",
+
+  "alice_28_150.npz": "train-28-43-0",
+
+  "alice_28_151.npz": "train-28-44-0",
+
+  "alice_28_152.npz": "train-28-44-1",
+
+  "alice_28_153.npz": "train-28-44-2",
+
+  "alice_28_154.npz": "train-28-45-0",
+
+  "alice_28_155.npz": "train-28-45-1",
+
+  "alice_28_156.npz": "train-28-45-2",
+
+  "alice_28_157.npz": "train-28-45-3",
+
+  "alice_28_158.npz": "train-28-45-4",
+
+  "alice_28_159.npz": "train-28-45-5",
+
+  "alice_28_160.npz": "train-28-45-6",
+
+  "alice_28_161.npz": "train-28-46-0",
+
+  "alice_28_162.npz": "train-28-48-0",
+
+  "alice_28_163.npz": "train-28-48-1",
+
+  "alice_28_164.npz": "train-28-48-2",
+
+  "alice_28_165.npz": "train-28-49-0",
+
+  "alice_28_166.npz": "train-28-49-1",
+
+  "alice_28_167.npz": "train-28-49-2",
+
+  "alice_28_168.npz": "train-28-49-3",
+
+  "alice_28_169.npz": "train-28-49-4",
+
+  "alice_28_170.npz": "train-28-49-5",
+
+  "alice_28_171.npz": "train-28-49-6",
+
+  "alice_28_172.npz": "train-28-50-0",
+
+  "alice_28_173.npz": "train-28-50-1",
+
+  "alice_28_174.npz": "train-28-50-2",
+
+  "alice_28_175.npz": "train-28-50-3",
+
+  "alice_28_176.npz": "train-28-50-4",
+
+  "alice_28_177.npz": "train-28-51-0",
+
+  "alice_28_178.npz": "train-28-51-1",
+
+  "alice_28_179.npz": "train-28-51-2",
+
+  "alice_28_180.npz": "train-28-51-3",
+
+  "alice_28_181.npz": "train-28-51-4",
+
+  "alice_28_182.npz": "train-28-51-5",
+
+  "alice_28_183.npz": "train-28-52-0",
+
+  "alice_28_184.npz": "train-28-52-1",
+
+  "alice_28_185.npz": "train-28-52-2",
+
+  "alice_28_186.npz": "train-28-52-3",
+
+  "alice_28_187.npz": "train-28-52-4",
+
+  "alice_28_188.npz": "train-28-52-5",
+
+  "alice_28_189.npz": "train-28-52-6",
+
+  "alice_28_190.npz": "train-28-52-7",
+
+  "alice_28_191.npz": "train-28-53-0",
+
+  "alice_28_192.npz": "train-28-53-1",
+
+  "alice_28_193.npz": "train-28-53-2",
+
+  "alice_28_194.npz": "train-28-53-3",
+
+  "alice_28_195.npz": "train-28-53-4",
+
+  "alice_28_196.npz": "train-28-53-5",
+
+  "alice_28_197.npz": "train-28-53-6",
+
+  "alice_28_198.npz": "train-28-54-0",
+
+  "alice_28_199.npz": "train-28-54-1",
+
+  "alice_28_200.npz": "train-28-54-2",
+
+  "alice_28_201.npz": "train-28-54-3",
+
+  "alice_28_202.npz": "train-28-55-0",
+
+  "alice_28_203.npz": "train-28-55-1",
+
+  "alice_28_204.npz": "train-28-55-2",
+
+  "alice_28_205.npz": "train-28-55-3",
+
+  "alice_28_206.npz": "train-28-55-4",
+
+  "alice_28_207.npz": "train-28-55-5",
+
+  "alice_28_208.npz": "train-28-55-6",
+
+  "alice_28_209.npz": "train-28-55-7",
+
+  "alice_28_210.npz": "train-28-56-0",
+
+  "alice_28_211.npz": "train-28-56-1",
+
+  "alice_28_212.npz": "train-28-56-2",
+
+  "alice_28_213.npz": "train-28-56-3",
+
+  "alice_28_214.npz": "train-28-56-4",
+
+  "alice_28_215.npz": "train-28-56-5",
+
+  "alice_28_216.npz": "train-28-57-0",
+
+  "alice_28_217.npz": "train-28-57-1",
+
+  "alice_28_218.npz": "train-28-57-2",
+
+  "alice_28_219.npz": "train-28-57-3",
+
+  "alice_28_220.npz": "train-28-57-4",
+
+  "alice_28_221.npz": "train-28-57-5",
+
+  "alice_28_222.npz": "train-28-57-6",
+
+  "alice_28_223.npz": "train-28-57-7",
+
+  "alice_28_224.npz": "train-28-57-8",
+
+  "alice_28_225.npz": "train-28-57-9",
+
+  "alice_28_226.npz": "train-28-58-0",
+
+  "alice_28_227.npz": "train-28-59-0",
+
+  "alice_28_228.npz": "train-28-59-1",
+
+  "alice_28_229.npz": "train-28-60-0",
+
+  "alice_28_230.npz": "train-28-60-1",
+
+  "alice_28_231.npz": "train-28-60-2",
+
+  "alice_28_232.npz": "train-28-60-3",
+
+  "alice_28_233.npz": "train-28-60-4",
+
+  "alice_28_234.npz": "train-28-61-0",
+
+  "alice_28_235.npz": "train-28-61-1",
+
+  "alice_28_236.npz": "train-28-61-2",
+
+  "alice_28_237.npz": "train-28-61-3",
+
+  "alice_28_238.npz": "train-28-61-4",
+
+  "alice_28_239.npz": "train-28-61-5",
+
+  "alice_28_240.npz": "train-28-61-6",
+
+  "alice_28_241.npz": "train-28-61-7",
+
+  "alice_28_242.npz": "train-28-61-8",
+
+  "alice_28_243.npz": "train-28-61-9",
+
+  "alice_28_244.npz": "train-28-61-10",
+
+  "alice_28_245.npz": "train-28-61-11",
+
+  "alice_28_246.npz": "train-28-61-12",
+
+  "alice_28_247.npz": "train-28-62-0",
+
+  "alice_28_248.npz": "train-28-62-1",
+
+  "alice_28_249.npz": "train-28-62-2",
+
+  "alice_28_250.npz": "train-28-62-3",
+
+  "alice_28_251.npz": "train-28-63-0",
+
+  "alice_28_252.npz": "train-28-63-1",
+
+  "alice_28_253.npz": "train-28-63-2",
+
+  "alice_28_254.npz": "train-28-63-3",
+
+  "alice_28_255.npz": "train-28-63-4",
+
+  "alice_28_256.npz": "train-28-63-5",
+
+  "alice_28_257.npz": "train-28-63-6",
+
+  "alice_28_258.npz": "train-28-63-7",
+
+  "alice_28_259.npz": "train-28-63-8",
+
+  "alice_28_260.npz": "train-28-63-9",
+
+  "alice_28_261.npz": "train-28-63-10",
+
+  "alice_28_262.npz": "train-28-63-11",
+
+  "alice_28_263.npz": "train-28-63-12",
+
+  "alice_28_264.npz": "train-28-63-13",
+
+  "alice_28_265.npz": "train-28-63-14",
+
+  "alice_28_266.npz": "train-28-63-15",
+
+  "alice_28_267.npz": "train-28-63-16",
+
+  "alice_28_268.npz": "train-28-63-17",
+
+  "alice_28_269.npz": "train-28-64-0",
+
+  "alice_28_270.npz": "train-28-64-1",
+
+  "alice_28_271.npz": "train-28-64-2",
+
+  "alice_28_272.npz": "train-28-64-3",
+
+  "alice_28_273.npz": "train-28-64-4",
+
+  "alice_28_274.npz": "train-28-64-5",
+
+  "alice_28_275.npz": "train-28-64-6",
+
+  "alice_28_276.npz": "train-28-64-7",
+
+  "alice_28_277.npz": "train-28-64-8",
+
+  "alice_28_278.npz": "train-28-64-9",
+  "alice_28_279.npz": "train-28-64-9",
+
+  "alice_28_280.npz": "train-28-65-0",
+
+  "alice_28_281.npz": "train-28-66-0",
+
+  "alice_53_0.npz": "train-53-0-0",
+
+  "alice_53_1.npz": "train-53-0-1",
+
+  "alice_53_2.npz": "train-53-0-2",
+
+  "alice_53_3.npz": "train-53-0-3",
+
+  "alice_53_4.npz": "train-53-0-4",
+
+  "alice_53_5.npz": "train-53-0-5",
+
+  "alice_53_6.npz": "train-53-0-6",
+
+  "alice_53_7.npz": "train-53-0-7",
+
+  "alice_53_8.npz": "train-53-0-8",
+
+  "alice_53_9.npz": "train-53-1-0",
+
+  "alice_53_10.npz": "train-53-1-1",
+
+  "alice_53_11.npz": "train-53-1-2",
+
+  "alice_53_12.npz": "train-53-1-3",
+
+  "alice_53_13.npz": "train-53-1-4",
+
+  "alice_53_14.npz": "train-53-1-5",
+
+  "alice_53_15.npz": "train-53-1-6",
+
+  "alice_53_16.npz": "train-53-1-7",
+
+  "alice_53_17.npz": "train-53-1-8",
+
+  "alice_53_18.npz": "train-53-1-9",
+
+  "alice_53_19.npz": "train-53-2-0",
+
+  "alice_53_20.npz": "train-53-2-1",
+
+  "alice_53_21.npz": "train-53-2-2",
+
+  "alice_53_22.npz": "train-53-2-3",
+
+  "alice_53_23.npz": "train-53-3-0",
+
+  "alice_53_24.npz": "train-53-4-0",
+
+  "alice_53_25.npz": "train-53-5-0",
+
+  "alice_53_26.npz": "train-53-5-1",
+
+  "alice_53_27.npz": "train-53-5-2",
+
+  "alice_53_28.npz": "train-53-5-3",
+
+  "alice_53_29.npz": "train-53-5-4",
+
+  "alice_53_30.npz": "train-53-5-5",
+
+  "alice_53_31.npz": "train-53-5-6",
+
+  "alice_53_32.npz": "train-53-5-7",
+
+  "alice_53_33.npz": "train-53-5-8",
+
+  "alice_53_34.npz": "train-53-5-9",
+
+  "alice_53_35.npz": "train-53-5-10",
+
+  "alice_53_36.npz": "train-53-5-11",
+
+  "alice_53_37.npz": "train-53-5-12",
+
+  "alice_53_38.npz": "train-53-5-13",
+
+  "alice_53_39.npz": "train-53-5-14",
+
+  "alice_53_40.npz": "train-53-5-15",
+
+  "alice_53_41.npz": "train-53-5-16",
+
+  "alice_53_42.npz": "train-53-5-17",
+
+  "alice_53_43.npz": "train-53-6-0",
+
+  "alice_53_44.npz": "train-53-6-1",
+
+  "alice_53_45.npz": "train-53-6-2",
+
+  "alice_53_46.npz": "train-53-6-3",
+
+  "alice_53_47.npz": "train-53-7-0",
+
+  "alice_53_48.npz": "train-53-7-1",
+
+  "alice_53_49.npz": "train-53-7-2",
+
+  "alice_53_50.npz": "train-53-7-3",
+
+  "alice_53_51.npz": "train-53-7-4",
+
+  "alice_53_52.npz": "train-53-7-5",
+
+  "alice_53_53.npz": "train-53-8-0",
+
+  "alice_53_54.npz": "train-53-8-1",
+
+  "alice_53_55.npz": "train-53-8-2",
+
+  "alice_53_56.npz": "train-53-8-3",
+
+  "alice_53_57.npz": "train-53-8-4",
+
+  "alice_53_58.npz": "train-53-8-5",
+
+  "alice_53_59.npz": "train-53-9-0",
+
+  "alice_53_60.npz": "train-53-9-1",
+
+  "alice_53_61.npz": "train-53-9-2",
+
+  "alice_53_62.npz": "train-53-9-3",
+
+  "alice_53_63.npz": "train-53-9-4",
+
+  "alice_53_64.npz": "train-53-9-5",
+
+  "alice_53_65.npz": "train-53-9-6",
+
+  "alice_53_66.npz": "train-53-9-7",
+
+  "alice_53_67.npz": "train-53-9-8",
+
+  "alice_53_68.npz": "train-53-10-0",
+
+  "alice_53_69.npz": "train-53-10-1",
+
+  "alice_53_70.npz": "train-53-10-2",
+
+  "alice_53_71.npz": "train-53-10-3",
+
+  "alice_53_72.npz": "train-53-10-4",
+
+  "alice_53_73.npz": "train-53-10-5",
+
+  "alice_53_74.npz": "train-53-10-6",
+
+  "alice_53_75.npz": "train-53-10-7",
+
+  "alice_53_76.npz": "train-53-10-8",
+
+  "alice_53_77.npz": "train-53-12-0",
+
+  "alice_53_78.npz": "train-53-12-1",
+
+  "alice_53_79.npz": "train-53-12-2",
+
+  "alice_53_80.npz": "train-53-13-0",
+
+  "alice_53_81.npz": "train-53-14-0",
+
+  "alice_53_82.npz": "train-53-14-1",
+
+  "alice_53_83.npz": "train-53-14-2",
+
+  "alice_53_84.npz": "train-53-15-0",
+
+  "alice_53_85.npz": "train-53-16-0",
+
+  "alice_53_86.npz": "train-53-17-0",
+
+  "alice_53_87.npz": "train-53-17-1",
+
+  "alice_53_88.npz": "train-53-18-0",
+
+  "alice_53_89.npz": "train-53-18-1",
+
+  "alice_53_90.npz": "train-53-20-0",
+
+  "alice_53_91.npz": "train-53-20-1",
+
+  "alice_53_92.npz": "train-53-21-0",
+
+  "alice_53_93.npz": "train-53-21-1",
+
+  "alice_53_94.npz": "train-53-21-2",
+
+  "alice_53_95.npz": "train-53-21-3",
+
+  "alice_53_96.npz": "train-53-21-4",
+
+  "alice_53_97.npz": "train-53-21-5",
+
+  "alice_53_98.npz": "train-53-21-6",
+
+  "alice_53_99.npz": "train-53-21-7",
+
+  "alice_53_100.npz": "train-53-21-8",
+
+  "alice_53_101.npz": "train-53-21-9",
+
+  "alice_53_102.npz": "train-53-21-10",
+
+  "alice_53_103.npz": "train-53-21-11",
+
+  "alice_53_104.npz": "train-53-22-0",
+
+  "alice_53_105.npz": "train-53-22-1",
+
+  "alice_53_106.npz": "train-53-22-2",
+
+  "alice_53_107.npz": "train-53-22-3",
+
+  "alice_53_108.npz": "train-53-23-0",
+
+  "alice_53_109.npz": "train-53-24-0",
+
+  "alice_53_110.npz": "train-53-24-1",
+
+  "alice_53_111.npz": "train-53-25-0",
+
+  "alice_53_112.npz": "train-53-25-1",
+
+  "alice_53_113.npz": "train-53-26-0",
+
+  "alice_53_114.npz": "train-53-26-1",
+
+  "alice_53_115.npz": "train-53-26-2",
+
+  "alice_53_116.npz": "train-53-26-3",
+
+  "alice_53_117.npz": "train-53-26-4",
+
+  "alice_53_118.npz": "train-53-26-5",
+
+  "alice_53_119.npz": "train-53-26-6",
+
+  "alice_53_120.npz": "train-53-27-0",
+
+  "alice_53_121.npz": "train-53-27-1",
+
+  "alice_53_122.npz": "train-53-28-0",
+
+  "alice_53_123.npz": "train-53-28-1",
+
+  "alice_53_124.npz": "train-53-29-0",
+
+  "alice_53_125.npz": "train-53-29-1",
+
+  "alice_53_126.npz": "train-53-30-0",
+
+  "alice_53_127.npz": "train-53-31-0",
+
+  "alice_53_128.npz": "train-53-31-1",
+
+  "alice_53_129.npz": "train-53-31-2",
+
+  "alice_53_130.npz": "train-53-32-0",
+
+  "alice_53_131.npz": "train-53-33-0",
+
+  "alice_53_132.npz": "train-53-33-1",
+
+  "alice_53_133.npz": "train-53-33-2",
+
+  "alice_53_134.npz": "train-53-34-0",
+
+  "alice_53_135.npz": "train-53-34-1",
+
+  "alice_53_136.npz": "train-53-35-0",
+
+  "alice_53_137.npz": "train-53-36-0",
+
+  "alice_53_138.npz": "train-53-36-1",
+
+  "alice_53_139.npz": "train-53-38-0",
+
+  "alice_53_140.npz": "train-53-39-0",
+
+  "alice_53_141.npz": "train-53-39-1",
+
+  "alice_53_142.npz": "train-53-39-2",
+
+  "alice_53_143.npz": "train-53-39-3",
+
+  "alice_53_144.npz": "train-53-40-0",
+
+  "alice_53_145.npz": "train-53-41-0",
+
+  "alice_53_146.npz": "train-53-41-1",
+
+  "alice_53_147.npz": "train-53-41-2",
+
+  "alice_53_148.npz": "train-53-41-3",
+
+  "alice_53_149.npz": "train-53-42-0",
+
+  "alice_53_150.npz": "train-53-43-0",
+
+  "alice_53_151.npz": "train-53-44-0",
+
+  "alice_53_152.npz": "train-53-44-1",
+
+  "alice_53_153.npz": "train-53-44-2",
+
+  "alice_53_154.npz": "train-53-45-0",
+
+  "alice_53_155.npz": "train-53-45-1",
+
+  "alice_53_156.npz": "train-53-45-2",
+
+  "alice_53_157.npz": "train-53-45-3",
+
+  "alice_53_158.npz": "train-53-45-4",
+
+  "alice_53_159.npz": "train-53-45-5",
+
+  "alice_53_160.npz": "train-53-45-6",
+
+  "alice_53_161.npz": "train-53-46-0",
+
+  "alice_53_162.npz": "train-53-48-0",
+
+  "alice_53_163.npz": "train-53-48-1",
+
+  "alice_53_164.npz": "train-53-48-2",
+
+  "alice_53_165.npz": "train-53-49-0",
+
+  "alice_53_166.npz": "train-53-49-1",
+
+  "alice_53_167.npz": "train-53-49-2",
+
+  "alice_53_168.npz": "train-53-49-3",
+
+  "alice_53_169.npz": "train-53-49-4",
+
+  "alice_53_170.npz": "train-53-49-5",
+
+  "alice_53_171.npz": "train-53-49-6",
+
+  "alice_53_172.npz": "train-53-50-0",
+
+  "alice_53_173.npz": "train-53-50-1",
+
+  "alice_53_174.npz": "train-53-50-2",
+
+  "alice_53_175.npz": "train-53-50-3",
+
+  "alice_53_176.npz": "train-53-50-4",
+
+  "alice_53_177.npz": "train-53-51-0",
+
+  "alice_53_178.npz": "train-53-51-1",
+
+  "alice_53_179.npz": "train-53-51-2",
+
+  "alice_53_180.npz": "train-53-51-3",
+
+  "alice_53_181.npz": "train-53-51-4",
+
+  "alice_53_182.npz": "train-53-51-5",
+
+  "alice_53_183.npz": "train-53-52-0",
+
+  "alice_53_184.npz": "train-53-52-1",
+
+  "alice_53_185.npz": "train-53-52-2",
+
+  "alice_53_186.npz": "train-53-52-3",
+
+  "alice_53_187.npz": "train-53-52-4",
+
+  "alice_53_188.npz": "train-53-52-5",
+
+  "alice_53_189.npz": "train-53-52-6",
+
+  "alice_53_190.npz": "train-53-52-7",
+
+  "alice_53_191.npz": "train-53-53-0",
+
+  "alice_53_192.npz": "train-53-53-1",
+
+  "alice_53_193.npz": "train-53-53-2",
+
+  "alice_53_194.npz": "train-53-53-3",
+
+  "alice_53_195.npz": "train-53-53-4",
+
+  "alice_53_196.npz": "train-53-53-5",
+
+  "alice_53_197.npz": "train-53-53-6",
+
+  "alice_53_198.npz": "train-53-54-0",
+
+  "alice_53_199.npz": "train-53-54-1",
+
+  "alice_53_200.npz": "train-53-54-2",
+
+  "alice_53_201.npz": "train-53-54-3",
+
+  "alice_53_202.npz": "train-53-55-0",
+
+  "alice_53_203.npz": "train-53-55-1",
+
+  "alice_53_204.npz": "train-53-55-2",
+
+  "alice_53_205.npz": "train-53-55-3",
+
+  "alice_53_206.npz": "train-53-55-4",
+
+  "alice_53_207.npz": "train-53-55-5",
+
+  "alice_53_208.npz": "train-53-55-6",
+
+  "alice_53_209.npz": "train-53-55-7",
+
+  "alice_53_210.npz": "train-53-56-0",
+
+  "alice_53_211.npz": "train-53-56-1",
+
+  "alice_53_212.npz": "train-53-56-2",
+
+  "alice_53_213.npz": "train-53-56-3",
+
+  "alice_53_214.npz": "train-53-56-4",
+
+  "alice_53_215.npz": "train-53-56-5",
+
+  "alice_53_216.npz": "train-53-57-0",
+
+  "alice_53_217.npz": "train-53-57-1",
+
+  "alice_53_218.npz": "train-53-57-2",
+
+  "alice_53_219.npz": "train-53-57-3",
+
+  "alice_53_220.npz": "train-53-57-4",
+
+  "alice_53_221.npz": "train-53-57-5",
+
+  "alice_53_222.npz": "train-53-57-6",
+
+  "alice_53_223.npz": "train-53-57-7",
+
+  "alice_53_224.npz": "train-53-57-8",
+
+  "alice_53_225.npz": "train-53-57-9",
+
+  "alice_53_226.npz": "train-53-58-0",
+
+  "alice_53_227.npz": "train-53-59-0",
+
+  "alice_53_228.npz": "train-53-59-1",
+
+  "alice_53_229.npz": "train-53-60-0",
+
+  "alice_53_230.npz": "train-53-60-1",
+
+  "alice_53_231.npz": "train-53-60-2",
+
+  "alice_53_232.npz": "train-53-60-3",
+
+  "alice_53_233.npz": "train-53-60-4",
+
+  "alice_53_234.npz": "train-53-61-0",
+
+  "alice_53_235.npz": "train-53-61-1",
+
+  "alice_53_236.npz": "train-53-61-2",
+
+  "alice_53_237.npz": "train-53-61-3",
+
+  "alice_53_238.npz": "train-53-61-4",
+
+  "alice_53_239.npz": "train-53-61-5",
+
+  "alice_53_240.npz": "train-53-61-6",
+
+  "alice_53_241.npz": "train-53-61-7",
+
+  "alice_53_242.npz": "train-53-61-8",
+
+  "alice_53_243.npz": "train-53-61-9",
+
+  "alice_53_244.npz": "train-53-61-10",
+
+  "alice_53_245.npz": "train-53-61-11",
+
+  "alice_53_246.npz": "train-53-61-12",
+
+  "alice_53_247.npz": "train-53-62-0",
+
+  "alice_53_248.npz": "train-53-62-1",
+
+  "alice_53_249.npz": "train-53-62-2",
+
+  "alice_53_250.npz": "train-53-62-3",
+
+  "alice_53_251.npz": "train-53-63-0",
+
+  "alice_53_252.npz": "train-53-63-1",
+
+  "alice_53_253.npz": "train-53-63-2",
+
+  "alice_53_254.npz": "train-53-63-3",
+
+  "alice_53_255.npz": "train-53-63-4",
+
+  "alice_53_256.npz": "train-53-63-5",
+
+  "alice_53_257.npz": "train-53-63-6",
+
+  "alice_53_258.npz": "train-53-63-7",
+
+  "alice_53_259.npz": "train-53-63-8",
+
+  "alice_53_260.npz": "train-53-63-9",
+
+  "alice_53_261.npz": "train-53-63-10",
+
+  "alice_53_262.npz": "train-53-63-11",
+
+  "alice_53_263.npz": "train-53-63-12",
+
+  "alice_53_264.npz": "train-53-63-13",
+
+  "alice_53_265.npz": "train-53-63-14",
+
+  "alice_53_266.npz": "train-53-63-15",
+
+  "alice_53_267.npz": "train-53-63-16",
+
+  "alice_53_268.npz": "train-53-63-17",
+
+  "alice_53_269.npz": "train-53-64-0",
+
+  "alice_53_270.npz": "train-53-64-1",
+
+  "alice_53_271.npz": "train-53-64-2",
+
+  "alice_53_272.npz": "train-53-64-3",
+
+  "alice_53_273.npz": "train-53-64-4",
+
+  "alice_53_274.npz": "train-53-64-5",
+
+  "alice_53_275.npz": "train-53-64-6",
+
+  "alice_53_276.npz": "train-53-64-7",
+
+  "alice_53_277.npz": "train-53-64-8",
+
+  "alice_53_278.npz": "train-53-64-9",
+  "alice_53_279.npz": "train-53-64-9",
+
+  "alice_53_280.npz": "train-53-65-0",
+
+  "alice_53_281.npz": "train-53-66-0",
+
+  "alice_23_0.npz": "train-23-0-0",
+
+  "alice_23_1.npz": "train-23-0-1",
+
+  "alice_23_2.npz": "train-23-0-2",
+
+  "alice_23_3.npz": "train-23-0-3",
+
+  "alice_23_4.npz": "train-23-0-4",
+
+  "alice_23_5.npz": "train-23-0-5",
+
+  "alice_23_6.npz": "train-23-0-6",
+
+  "alice_23_7.npz": "train-23-0-7",
+
+  "alice_23_8.npz": "train-23-0-8",
+
+  "alice_23_9.npz": "train-23-1-0",
+
+  "alice_23_10.npz": "train-23-1-1",
+
+  "alice_23_11.npz": "train-23-1-2",
+
+  "alice_23_12.npz": "train-23-1-3",
+
+  "alice_23_13.npz": "train-23-1-4",
+
+  "alice_23_14.npz": "train-23-1-5",
+
+  "alice_23_15.npz": "train-23-1-6",
+
+  "alice_23_16.npz": "train-23-1-7",
+
+  "alice_23_17.npz": "train-23-1-8",
+
+  "alice_23_18.npz": "train-23-1-9",
+
+  "alice_23_19.npz": "train-23-2-0",
+
+  "alice_23_20.npz": "train-23-2-1",
+
+  "alice_23_21.npz": "train-23-2-2",
+
+  "alice_23_22.npz": "train-23-2-3",
+
+  "alice_23_23.npz": "train-23-3-0",
+
+  "alice_23_24.npz": "train-23-4-0",
+
+  "alice_23_25.npz": "train-23-5-0",
+
+  "alice_23_26.npz": "train-23-5-1",
+
+  "alice_23_27.npz": "train-23-5-2",
+
+  "alice_23_28.npz": "train-23-5-3",
+
+  "alice_23_29.npz": "train-23-5-4",
+
+  "alice_23_30.npz": "train-23-5-5",
+
+  "alice_23_31.npz": "train-23-5-6",
+
+  "alice_23_32.npz": "train-23-5-7",
+
+  "alice_23_33.npz": "train-23-5-8",
+
+  "alice_23_34.npz": "train-23-5-9",
+
+  "alice_23_35.npz": "train-23-5-10",
+
+  "alice_23_36.npz": "train-23-5-11",
+
+  "alice_23_37.npz": "train-23-5-12",
+
+  "alice_23_38.npz": "train-23-5-13",
+
+  "alice_23_39.npz": "train-23-5-14",
+
+  "alice_23_40.npz": "train-23-5-15",
+
+  "alice_23_41.npz": "train-23-5-16",
+
+  "alice_23_42.npz": "train-23-5-17",
+
+  "alice_23_43.npz": "train-23-6-0",
+
+  "alice_23_44.npz": "train-23-6-1",
+
+  "alice_23_45.npz": "train-23-6-2",
+
+  "alice_23_46.npz": "train-23-6-3",
+
+  "alice_23_47.npz": "train-23-7-0",
+
+  "alice_23_48.npz": "train-23-7-1",
+
+  "alice_23_49.npz": "train-23-7-2",
+
+  "alice_23_50.npz": "train-23-7-3",
+
+  "alice_23_51.npz": "train-23-7-4",
+
+  "alice_23_52.npz": "train-23-7-5",
+
+  "alice_23_53.npz": "train-23-8-0",
+
+  "alice_23_54.npz": "train-23-8-1",
+
+  "alice_23_55.npz": "train-23-8-2",
+
+  "alice_23_56.npz": "train-23-8-3",
+
+  "alice_23_57.npz": "train-23-8-4",
+
+  "alice_23_58.npz": "train-23-8-5",
+
+  "alice_23_59.npz": "train-23-9-0",
+
+  "alice_23_60.npz": "train-23-9-1",
+
+  "alice_23_61.npz": "train-23-9-2",
+
+  "alice_23_62.npz": "train-23-9-3",
+
+  "alice_23_63.npz": "train-23-9-4",
+
+  "alice_23_64.npz": "train-23-9-5",
+
+  "alice_23_65.npz": "train-23-9-6",
+
+  "alice_23_66.npz": "train-23-9-7",
+
+  "alice_23_67.npz": "train-23-9-8",
+
+  "alice_23_68.npz": "train-23-10-0",
+
+  "alice_23_69.npz": "train-23-10-1",
+
+  "alice_23_70.npz": "train-23-10-2",
+
+  "alice_23_71.npz": "train-23-10-3",
+
+  "alice_23_72.npz": "train-23-10-4",
+
+  "alice_23_73.npz": "train-23-10-5",
+
+  "alice_23_74.npz": "train-23-10-6",
+
+  "alice_23_75.npz": "train-23-10-7",
+
+  "alice_23_76.npz": "train-23-10-8",
+
+  "alice_23_77.npz": "train-23-12-0",
+
+  "alice_23_78.npz": "train-23-12-1",
+
+  "alice_23_79.npz": "train-23-12-2",
+
+  "alice_23_80.npz": "train-23-13-0",
+
+  "alice_23_81.npz": "train-23-14-0",
+
+  "alice_23_82.npz": "train-23-14-1",
+
+  "alice_23_83.npz": "train-23-14-2",
+
+  "alice_23_84.npz": "train-23-15-0",
+
+  "alice_23_85.npz": "train-23-16-0",
+
+  "alice_23_86.npz": "train-23-17-0",
+
+  "alice_23_87.npz": "train-23-17-1",
+
+  "alice_23_88.npz": "train-23-18-0",
+
+  "alice_23_89.npz": "train-23-18-1",
+
+  "alice_23_90.npz": "train-23-20-0",
+
+  "alice_23_91.npz": "train-23-20-1",
+
+  "alice_23_92.npz": "train-23-21-0",
+
+  "alice_23_93.npz": "train-23-21-1",
+
+  "alice_23_94.npz": "train-23-21-2",
+
+  "alice_23_95.npz": "train-23-21-3",
+
+  "alice_23_96.npz": "train-23-21-4",
+
+  "alice_23_97.npz": "train-23-21-5",
+
+  "alice_23_98.npz": "train-23-21-6",
+
+  "alice_23_99.npz": "train-23-21-7",
+
+  "alice_23_100.npz": "train-23-21-8",
+
+  "alice_23_101.npz": "train-23-21-9",
+
+  "alice_23_102.npz": "train-23-21-10",
+
+  "alice_23_103.npz": "train-23-21-11",
+
+  "alice_23_104.npz": "train-23-22-0",
+
+  "alice_23_105.npz": "train-23-22-1",
+
+  "alice_23_106.npz": "train-23-22-2",
+
+  "alice_23_107.npz": "train-23-22-3",
+
+  "alice_23_108.npz": "train-23-23-0",
+
+  "alice_23_109.npz": "train-23-24-0",
+
+  "alice_23_110.npz": "train-23-24-1",
+
+  "alice_23_111.npz": "train-23-25-0",
+
+  "alice_23_112.npz": "train-23-25-1",
+
+  "alice_23_113.npz": "train-23-26-0",
+
+  "alice_23_114.npz": "train-23-26-1",
+
+  "alice_23_115.npz": "train-23-26-2",
+
+  "alice_23_116.npz": "train-23-26-3",
+
+  "alice_23_117.npz": "train-23-26-4",
+
+  "alice_23_118.npz": "train-23-26-5",
+
+  "alice_23_119.npz": "train-23-26-6",
+
+  "alice_23_120.npz": "train-23-27-0",
+
+  "alice_23_121.npz": "train-23-27-1",
+
+  "alice_23_122.npz": "train-23-28-0",
+
+  "alice_23_123.npz": "train-23-28-1",
+
+  "alice_23_124.npz": "train-23-29-0",
+
+  "alice_23_125.npz": "train-23-29-1",
+
+  "alice_23_126.npz": "train-23-30-0",
+
+  "alice_23_127.npz": "train-23-31-0",
+
+  "alice_23_128.npz": "train-23-31-1",
+
+  "alice_23_129.npz": "train-23-31-2",
+
+  "alice_23_130.npz": "train-23-32-0",
+
+  "alice_23_131.npz": "train-23-33-0",
+
+  "alice_23_132.npz": "train-23-33-1",
+
+  "alice_23_133.npz": "train-23-33-2",
+
+  "alice_23_134.npz": "train-23-34-0",
+
+  "alice_23_135.npz": "train-23-34-1",
+
+  "alice_23_136.npz": "train-23-35-0",
+
+  "alice_23_137.npz": "train-23-36-0",
+
+  "alice_23_138.npz": "train-23-36-1",
+
+  "alice_23_139.npz": "train-23-38-0",
+
+  "alice_23_140.npz": "train-23-39-0",
+
+  "alice_23_141.npz": "train-23-39-1",
+
+  "alice_23_142.npz": "train-23-39-2",
+
+  "alice_23_143.npz": "train-23-39-3",
+
+  "alice_23_144.npz": "train-23-40-0",
+
+  "alice_23_145.npz": "train-23-41-0",
+
+  "alice_23_146.npz": "train-23-41-1",
+
+  "alice_23_147.npz": "train-23-41-2",
+
+  "alice_23_148.npz": "train-23-41-3",
+
+  "alice_23_149.npz": "train-23-42-0",
+
+  "alice_23_150.npz": "train-23-43-0",
+
+  "alice_23_151.npz": "train-23-44-0",
+
+  "alice_23_152.npz": "train-23-44-1",
+
+  "alice_23_153.npz": "train-23-44-2",
+
+  "alice_23_154.npz": "train-23-45-0",
+
+  "alice_23_155.npz": "train-23-45-1",
+
+  "alice_23_156.npz": "train-23-45-2",
+
+  "alice_23_157.npz": "train-23-45-3",
+
+  "alice_23_158.npz": "train-23-45-4",
+
+  "alice_23_159.npz": "train-23-45-5",
+
+  "alice_23_160.npz": "train-23-45-6",
+
+  "alice_23_161.npz": "train-23-46-0",
+
+  "alice_23_162.npz": "train-23-48-0",
+
+  "alice_23_163.npz": "train-23-48-1",
+
+  "alice_23_164.npz": "train-23-48-2",
+
+  "alice_23_165.npz": "train-23-49-0",
+
+  "alice_23_166.npz": "train-23-49-1",
+
+  "alice_23_167.npz": "train-23-49-2",
+
+  "alice_23_168.npz": "train-23-49-3",
+
+  "alice_23_169.npz": "train-23-49-4",
+
+  "alice_23_170.npz": "train-23-49-5",
+
+  "alice_23_171.npz": "train-23-49-6",
+
+  "alice_23_172.npz": "train-23-50-0",
+
+  "alice_23_173.npz": "train-23-50-1",
+
+  "alice_23_174.npz": "train-23-50-2",
+
+  "alice_23_175.npz": "train-23-50-3",
+
+  "alice_23_176.npz": "train-23-50-4",
+
+  "alice_23_177.npz": "train-23-51-0",
+
+  "alice_23_178.npz": "train-23-51-1",
+
+  "alice_23_179.npz": "train-23-51-2",
+
+  "alice_23_180.npz": "train-23-51-3",
+
+  "alice_23_181.npz": "train-23-51-4",
+
+  "alice_23_182.npz": "train-23-51-5",
+
+  "alice_23_183.npz": "train-23-52-0",
+
+  "alice_23_184.npz": "train-23-52-1",
+
+  "alice_23_185.npz": "train-23-52-2",
+
+  "alice_23_186.npz": "train-23-52-3",
+
+  "alice_23_187.npz": "train-23-52-4",
+
+  "alice_23_188.npz": "train-23-52-5",
+
+  "alice_23_189.npz": "train-23-52-6",
+
+  "alice_23_190.npz": "train-23-52-7",
+
+  "alice_23_191.npz": "train-23-53-0",
+
+  "alice_23_192.npz": "train-23-53-1",
+
+  "alice_23_193.npz": "train-23-53-2",
+
+  "alice_23_194.npz": "train-23-53-3",
+
+  "alice_23_195.npz": "train-23-53-4",
+
+  "alice_23_196.npz": "train-23-53-5",
+
+  "alice_23_197.npz": "train-23-53-6",
+
+  "alice_23_198.npz": "train-23-54-0",
+
+  "alice_23_199.npz": "train-23-54-1",
+
+  "alice_23_200.npz": "train-23-54-2",
+
+  "alice_23_201.npz": "train-23-54-3",
+
+  "alice_23_202.npz": "train-23-55-0",
+
+  "alice_23_203.npz": "train-23-55-1",
+
+  "alice_23_204.npz": "train-23-55-2",
+
+  "alice_23_205.npz": "train-23-55-3",
+
+  "alice_23_206.npz": "train-23-55-4",
+
+  "alice_23_207.npz": "train-23-55-5",
+
+  "alice_23_208.npz": "train-23-55-6",
+
+  "alice_23_209.npz": "train-23-55-7",
+
+  "alice_23_210.npz": "train-23-56-0",
+
+  "alice_23_211.npz": "train-23-56-1",
+
+  "alice_23_212.npz": "train-23-56-2",
+
+  "alice_23_213.npz": "train-23-56-3",
+
+  "alice_23_214.npz": "train-23-56-4",
+
+  "alice_23_215.npz": "train-23-56-5",
+
+  "alice_23_216.npz": "train-23-57-0",
+
+  "alice_23_217.npz": "train-23-57-1",
+
+  "alice_23_218.npz": "train-23-57-2",
+
+  "alice_23_219.npz": "train-23-57-3",
+
+  "alice_23_220.npz": "train-23-57-4",
+
+  "alice_23_221.npz": "train-23-57-5",
+
+  "alice_23_222.npz": "train-23-57-6",
+
+  "alice_23_223.npz": "train-23-57-7",
+
+  "alice_23_224.npz": "train-23-57-8",
+
+  "alice_23_225.npz": "train-23-57-9",
+
+  "alice_23_226.npz": "train-23-58-0",
+
+  "alice_23_227.npz": "train-23-59-0",
+
+  "alice_23_228.npz": "train-23-59-1",
+
+  "alice_23_229.npz": "train-23-60-0",
+
+  "alice_23_230.npz": "train-23-60-1",
+
+  "alice_23_231.npz": "train-23-60-2",
+
+  "alice_23_232.npz": "train-23-60-3",
+
+  "alice_23_233.npz": "train-23-60-4",
+
+  "alice_23_234.npz": "train-23-61-0",
+
+  "alice_23_235.npz": "train-23-61-1",
+
+  "alice_23_236.npz": "train-23-61-2",
+
+  "alice_23_237.npz": "train-23-61-3",
+
+  "alice_23_238.npz": "train-23-61-4",
+
+  "alice_23_239.npz": "train-23-61-5",
+
+  "alice_23_240.npz": "train-23-61-6",
+
+  "alice_23_241.npz": "train-23-61-7",
+
+  "alice_23_242.npz": "train-23-61-8",
+
+  "alice_23_243.npz": "train-23-61-9",
+
+  "alice_23_244.npz": "train-23-61-10",
+
+  "alice_23_245.npz": "train-23-61-11",
+
+  "alice_23_246.npz": "train-23-61-12",
+
+  "alice_23_247.npz": "train-23-62-0",
+
+  "alice_23_248.npz": "train-23-62-1",
+
+  "alice_23_249.npz": "train-23-62-2",
+
+  "alice_23_250.npz": "train-23-62-3",
+
+  "alice_23_251.npz": "train-23-63-0",
+
+  "alice_23_252.npz": "train-23-63-1",
+
+  "alice_23_253.npz": "train-23-63-2",
+
+  "alice_23_254.npz": "train-23-63-3",
+
+  "alice_23_255.npz": "train-23-63-4",
+
+  "alice_23_256.npz": "train-23-63-5",
+
+  "alice_23_257.npz": "train-23-63-6",
+
+  "alice_23_258.npz": "train-23-63-7",
+
+  "alice_23_259.npz": "train-23-63-8",
+
+  "alice_23_260.npz": "train-23-63-9",
+
+  "alice_23_261.npz": "train-23-63-10",
+
+  "alice_23_262.npz": "train-23-63-11",
+
+  "alice_23_263.npz": "train-23-63-12",
+
+  "alice_23_264.npz": "train-23-63-13",
+
+  "alice_23_265.npz": "train-23-63-14",
+
+  "alice_23_266.npz": "train-23-63-15",
+
+  "alice_23_267.npz": "train-23-63-16",
+
+  "alice_23_268.npz": "train-23-63-17",
+
+  "alice_23_269.npz": "train-23-64-0",
+
+  "alice_23_270.npz": "train-23-64-1",
+
+  "alice_23_271.npz": "train-23-64-2",
+
+  "alice_23_272.npz": "train-23-64-3",
+
+  "alice_23_273.npz": "train-23-64-4",
+
+  "alice_23_274.npz": "train-23-64-5",
+
+  "alice_23_275.npz": "train-23-64-6",
+
+  "alice_23_276.npz": "train-23-64-7",
+
+  "alice_23_277.npz": "train-23-64-8",
+
+  "alice_23_278.npz": "train-23-64-9",
+  "alice_23_279.npz": "train-23-64-9",
+
+  "alice_23_280.npz": "train-23-65-0",
+
+  "alice_23_281.npz": "train-23-66-0",
+
+  "alice_36_0.npz": "train-36-0-0",
+
+  "alice_36_1.npz": "train-36-0-1",
+
+  "alice_36_2.npz": "train-36-0-2",
+
+  "alice_36_3.npz": "train-36-0-3",
+
+  "alice_36_4.npz": "train-36-0-4",
+
+  "alice_36_5.npz": "train-36-0-5",
+
+  "alice_36_6.npz": "train-36-0-6",
+
+  "alice_36_7.npz": "train-36-0-7",
+
+  "alice_36_8.npz": "train-36-0-8",
+
+  "alice_36_9.npz": "train-36-1-0",
+
+  "alice_36_10.npz": "train-36-1-1",
+
+  "alice_36_11.npz": "train-36-1-2",
+
+  "alice_36_12.npz": "train-36-1-3",
+
+  "alice_36_13.npz": "train-36-1-4",
+
+  "alice_36_14.npz": "train-36-1-5",
+
+  "alice_36_15.npz": "train-36-1-6",
+
+  "alice_36_16.npz": "train-36-1-7",
+
+  "alice_36_17.npz": "train-36-1-8",
+
+  "alice_36_18.npz": "train-36-1-9",
+
+  "alice_36_19.npz": "train-36-2-0",
+
+  "alice_36_20.npz": "train-36-2-1",
+
+  "alice_36_21.npz": "train-36-2-2",
+
+  "alice_36_22.npz": "train-36-2-3",
+
+  "alice_36_23.npz": "train-36-3-0",
+
+  "alice_36_24.npz": "train-36-4-0",
+
+  "alice_36_25.npz": "train-36-5-0",
+
+  "alice_36_26.npz": "train-36-5-1",
+
+  "alice_36_27.npz": "train-36-5-2",
+
+  "alice_36_28.npz": "train-36-5-3",
+
+  "alice_36_29.npz": "train-36-5-4",
+
+  "alice_36_30.npz": "train-36-5-5",
+
+  "alice_36_31.npz": "train-36-5-6",
+
+  "alice_36_32.npz": "train-36-5-7",
+
+  "alice_36_33.npz": "train-36-5-8",
+
+  "alice_36_34.npz": "train-36-5-9",
+
+  "alice_36_35.npz": "train-36-5-10",
+
+  "alice_36_36.npz": "train-36-5-11",
+
+  "alice_36_37.npz": "train-36-5-12",
+
+  "alice_36_38.npz": "train-36-5-13",
+
+  "alice_36_39.npz": "train-36-5-14",
+
+  "alice_36_40.npz": "train-36-5-15",
+
+  "alice_36_41.npz": "train-36-5-16",
+
+  "alice_36_42.npz": "train-36-5-17",
+
+  "alice_36_43.npz": "train-36-6-0",
+
+  "alice_36_44.npz": "train-36-6-1",
+
+  "alice_36_45.npz": "train-36-6-2",
+
+  "alice_36_46.npz": "train-36-6-3",
+
+  "alice_36_47.npz": "train-36-7-0",
+
+  "alice_36_48.npz": "train-36-7-1",
+
+  "alice_36_49.npz": "train-36-7-2",
+
+  "alice_36_50.npz": "train-36-7-3",
+
+  "alice_36_51.npz": "train-36-7-4",
+
+  "alice_36_52.npz": "train-36-7-5",
+
+  "alice_36_53.npz": "train-36-8-0",
+
+  "alice_36_54.npz": "train-36-8-1",
+
+  "alice_36_55.npz": "train-36-8-2",
+
+  "alice_36_56.npz": "train-36-8-3",
+
+  "alice_36_57.npz": "train-36-8-4",
+
+  "alice_36_58.npz": "train-36-8-5",
+
+  "alice_36_59.npz": "train-36-9-0",
+
+  "alice_36_60.npz": "train-36-9-1",
+
+  "alice_36_61.npz": "train-36-9-2",
+
+  "alice_36_62.npz": "train-36-9-3",
+
+  "alice_36_63.npz": "train-36-9-4",
+
+  "alice_36_64.npz": "train-36-9-5",
+
+  "alice_36_65.npz": "train-36-9-6",
+
+  "alice_36_66.npz": "train-36-9-7",
+
+  "alice_36_67.npz": "train-36-9-8",
+
+  "alice_36_68.npz": "train-36-10-0",
+
+  "alice_36_69.npz": "train-36-10-1",
+
+  "alice_36_70.npz": "train-36-10-2",
+
+  "alice_36_71.npz": "train-36-10-3",
+
+  "alice_36_72.npz": "train-36-10-4",
+
+  "alice_36_73.npz": "train-36-10-5",
+
+  "alice_36_74.npz": "train-36-10-6",
+
+  "alice_36_75.npz": "train-36-10-7",
+
+  "alice_36_76.npz": "train-36-10-8",
+
+  "alice_36_77.npz": "train-36-12-0",
+
+  "alice_36_78.npz": "train-36-12-1",
+
+  "alice_36_79.npz": "train-36-12-2",
+
+  "alice_36_80.npz": "train-36-13-0",
+
+  "alice_36_81.npz": "train-36-14-0",
+
+  "alice_36_82.npz": "train-36-14-1",
+
+  "alice_36_83.npz": "train-36-14-2",
+
+  "alice_36_84.npz": "train-36-15-0",
+
+  "alice_36_85.npz": "train-36-16-0",
+
+  "alice_36_86.npz": "train-36-17-0",
+
+  "alice_36_87.npz": "train-36-17-1",
+
+  "alice_36_88.npz": "train-36-18-0",
+
+  "alice_36_89.npz": "train-36-18-1",
+
+  "alice_36_90.npz": "train-36-20-0",
+
+  "alice_36_91.npz": "train-36-20-1",
+
+  "alice_36_92.npz": "train-36-21-0",
+
+  "alice_36_93.npz": "train-36-21-1",
+
+  "alice_36_94.npz": "train-36-21-2",
+
+  "alice_36_95.npz": "train-36-21-3",
+
+  "alice_36_96.npz": "train-36-21-4",
+
+  "alice_36_97.npz": "train-36-21-5",
+
+  "alice_36_98.npz": "train-36-21-6",
+
+  "alice_36_99.npz": "train-36-21-7",
+
+  "alice_36_100.npz": "train-36-21-8",
+
+  "alice_36_101.npz": "train-36-21-9",
+
+  "alice_36_102.npz": "train-36-21-10",
+
+  "alice_36_103.npz": "train-36-21-11",
+
+  "alice_36_104.npz": "train-36-22-0",
+
+  "alice_36_105.npz": "train-36-22-1",
+
+  "alice_36_106.npz": "train-36-22-2",
+
+  "alice_36_107.npz": "train-36-22-3",
+
+  "alice_36_108.npz": "train-36-23-0",
+
+  "alice_36_109.npz": "train-36-24-0",
+
+  "alice_36_110.npz": "train-36-24-1",
+
+  "alice_36_111.npz": "train-36-25-0",
+
+  "alice_36_112.npz": "train-36-25-1",
+
+  "alice_36_113.npz": "train-36-26-0",
+
+  "alice_36_114.npz": "train-36-26-1",
+
+  "alice_36_115.npz": "train-36-26-2",
+
+  "alice_36_116.npz": "train-36-26-3",
+
+  "alice_36_117.npz": "train-36-26-4",
+
+  "alice_36_118.npz": "train-36-26-5",
+
+  "alice_36_119.npz": "train-36-26-6",
+
+  "alice_36_120.npz": "train-36-27-0",
+
+  "alice_36_121.npz": "train-36-27-1",
+
+  "alice_36_122.npz": "train-36-28-0",
+
+  "alice_36_123.npz": "train-36-28-1",
+
+  "alice_36_124.npz": "train-36-29-0",
+
+  "alice_36_125.npz": "train-36-29-1",
+
+  "alice_36_126.npz": "train-36-30-0",
+
+  "alice_36_127.npz": "train-36-31-0",
+
+  "alice_36_128.npz": "train-36-31-1",
+
+  "alice_36_129.npz": "train-36-31-2",
+
+  "alice_36_130.npz": "train-36-32-0",
+
+  "alice_36_131.npz": "train-36-33-0",
+
+  "alice_36_132.npz": "train-36-33-1",
+
+  "alice_36_133.npz": "train-36-33-2",
+
+  "alice_36_134.npz": "train-36-34-0",
+
+  "alice_36_135.npz": "train-36-34-1",
+
+  "alice_36_136.npz": "train-36-35-0",
+
+  "alice_36_137.npz": "train-36-36-0",
+
+  "alice_36_138.npz": "train-36-36-1",
+
+  "alice_36_139.npz": "train-36-38-0",
+
+  "alice_36_140.npz": "train-36-39-0",
+
+  "alice_36_141.npz": "train-36-39-1",
+
+  "alice_36_142.npz": "train-36-39-2",
+
+  "alice_36_143.npz": "train-36-39-3",
+
+  "alice_36_144.npz": "train-36-40-0",
+
+  "alice_36_145.npz": "train-36-41-0",
+
+  "alice_36_146.npz": "train-36-41-1",
+
+  "alice_36_147.npz": "train-36-41-2",
+
+  "alice_36_148.npz": "train-36-41-3",
+
+  "alice_36_149.npz": "train-36-42-0",
+
+  "alice_36_150.npz": "train-36-43-0",
+
+  "alice_36_151.npz": "train-36-44-0",
+
+  "alice_36_152.npz": "train-36-44-1",
+
+  "alice_36_153.npz": "train-36-44-2",
+
+  "alice_36_154.npz": "train-36-45-0",
+
+  "alice_36_155.npz": "train-36-45-1",
+
+  "alice_36_156.npz": "train-36-45-2",
+
+  "alice_36_157.npz": "train-36-45-3",
+
+  "alice_36_158.npz": "train-36-45-4",
+
+  "alice_36_159.npz": "train-36-45-5",
+
+  "alice_36_160.npz": "train-36-45-6",
+
+  "alice_36_161.npz": "train-36-46-0",
+
+  "alice_36_162.npz": "train-36-48-0",
+
+  "alice_36_163.npz": "train-36-48-1",
+
+  "alice_36_164.npz": "train-36-48-2",
+
+  "alice_36_165.npz": "train-36-49-0",
+
+  "alice_36_166.npz": "train-36-49-1",
+
+  "alice_36_167.npz": "train-36-49-2",
+
+  "alice_36_168.npz": "train-36-49-3",
+
+  "alice_36_169.npz": "train-36-49-4",
+
+  "alice_36_170.npz": "train-36-49-5",
+
+  "alice_36_171.npz": "train-36-49-6",
+
+  "alice_36_172.npz": "train-36-50-0",
+
+  "alice_36_173.npz": "train-36-50-1",
+
+  "alice_36_174.npz": "train-36-50-2",
+
+  "alice_36_175.npz": "train-36-50-3",
+
+  "alice_36_176.npz": "train-36-50-4",
+
+  "alice_36_177.npz": "train-36-51-0",
+
+  "alice_36_178.npz": "train-36-51-1",
+
+  "alice_36_179.npz": "train-36-51-2",
+
+  "alice_36_180.npz": "train-36-51-3",
+
+  "alice_36_181.npz": "train-36-51-4",
+
+  "alice_36_182.npz": "train-36-51-5",
+
+  "alice_36_183.npz": "train-36-52-0",
+
+  "alice_36_184.npz": "train-36-52-1",
+
+  "alice_36_185.npz": "train-36-52-2",
+
+  "alice_36_186.npz": "train-36-52-3",
+
+  "alice_36_187.npz": "train-36-52-4",
+
+  "alice_36_188.npz": "train-36-52-5",
+
+  "alice_36_189.npz": "train-36-52-6",
+
+  "alice_36_190.npz": "train-36-52-7",
+
+  "alice_36_191.npz": "train-36-53-0",
+
+  "alice_36_192.npz": "train-36-53-1",
+
+  "alice_36_193.npz": "train-36-53-2",
+
+  "alice_36_194.npz": "train-36-53-3",
+
+  "alice_36_195.npz": "train-36-53-4",
+
+  "alice_36_196.npz": "train-36-53-5",
+
+  "alice_36_197.npz": "train-36-53-6",
+
+  "alice_36_198.npz": "train-36-54-0",
+
+  "alice_36_199.npz": "train-36-54-1",
+
+  "alice_36_200.npz": "train-36-54-2",
+
+  "alice_36_201.npz": "train-36-54-3",
+
+  "alice_36_202.npz": "train-36-55-0",
+
+  "alice_36_203.npz": "train-36-55-1",
+
+  "alice_36_204.npz": "train-36-55-2",
+
+  "alice_36_205.npz": "train-36-55-3",
+
+  "alice_36_206.npz": "train-36-55-4",
+
+  "alice_36_207.npz": "train-36-55-5",
+
+  "alice_36_208.npz": "train-36-55-6",
+
+  "alice_36_209.npz": "train-36-55-7",
+
+  "alice_36_210.npz": "train-36-56-0",
+
+  "alice_36_211.npz": "train-36-56-1",
+
+  "alice_36_212.npz": "train-36-56-2",
+
+  "alice_36_213.npz": "train-36-56-3",
+
+  "alice_36_214.npz": "train-36-56-4",
+
+  "alice_36_215.npz": "train-36-56-5",
+
+  "alice_36_216.npz": "train-36-57-0",
+
+  "alice_36_217.npz": "train-36-57-1",
+
+  "alice_36_218.npz": "train-36-57-2",
+
+  "alice_36_219.npz": "train-36-57-3",
+
+  "alice_36_220.npz": "train-36-57-4",
+
+  "alice_36_221.npz": "train-36-57-5",
+
+  "alice_36_222.npz": "train-36-57-6",
+
+  "alice_36_223.npz": "train-36-57-7",
+
+  "alice_36_224.npz": "train-36-57-8",
+
+  "alice_36_225.npz": "train-36-57-9",
+
+  "alice_36_226.npz": "train-36-58-0",
+
+  "alice_36_227.npz": "train-36-59-0",
+
+  "alice_36_228.npz": "train-36-59-1",
+
+  "alice_36_229.npz": "train-36-60-0",
+
+  "alice_36_230.npz": "train-36-60-1",
+
+  "alice_36_231.npz": "train-36-60-2",
+
+  "alice_36_232.npz": "train-36-60-3",
+
+  "alice_36_233.npz": "train-36-60-4",
+
+  "alice_36_234.npz": "train-36-61-0",
+
+  "alice_36_235.npz": "train-36-61-1",
+
+  "alice_36_236.npz": "train-36-61-2",
+
+  "alice_36_237.npz": "train-36-61-3",
+
+  "alice_36_238.npz": "train-36-61-4",
+
+  "alice_36_239.npz": "train-36-61-5",
+
+  "alice_36_240.npz": "train-36-61-6",
+
+  "alice_36_241.npz": "train-36-61-7",
+
+  "alice_36_242.npz": "train-36-61-8",
+
+  "alice_36_243.npz": "train-36-61-9",
+
+  "alice_36_244.npz": "train-36-61-10",
+
+  "alice_36_245.npz": "train-36-61-11",
+
+  "alice_36_246.npz": "train-36-61-12",
+
+  "alice_36_247.npz": "train-36-62-0",
+
+  "alice_36_248.npz": "train-36-62-1",
+
+  "alice_36_249.npz": "train-36-62-2",
+
+  "alice_36_250.npz": "train-36-62-3",
+
+  "alice_36_251.npz": "train-36-63-0",
+
+  "alice_36_252.npz": "train-36-63-1",
+
+  "alice_36_253.npz": "train-36-63-2",
+
+  "alice_36_254.npz": "train-36-63-3",
+
+  "alice_36_255.npz": "train-36-63-4",
+
+  "alice_36_256.npz": "train-36-63-5",
+
+  "alice_36_257.npz": "train-36-63-6",
+
+  "alice_36_258.npz": "train-36-63-7",
+
+  "alice_36_259.npz": "train-36-63-8",
+
+  "alice_36_260.npz": "train-36-63-9",
+
+  "alice_36_261.npz": "train-36-63-10",
+
+  "alice_36_262.npz": "train-36-63-11",
+
+  "alice_36_263.npz": "train-36-63-12",
+
+  "alice_36_264.npz": "train-36-63-13",
+
+  "alice_36_265.npz": "train-36-63-14",
+
+  "alice_36_266.npz": "train-36-63-15",
+
+  "alice_36_267.npz": "train-36-63-16",
+
+  "alice_36_268.npz": "train-36-63-17",
+
+  "alice_36_269.npz": "train-36-64-0",
+
+  "alice_36_270.npz": "train-36-64-1",
+
+  "alice_36_271.npz": "train-36-64-2",
+
+  "alice_36_272.npz": "train-36-64-3",
+
+  "alice_36_273.npz": "train-36-64-4",
+
+  "alice_36_274.npz": "train-36-64-5",
+
+  "alice_36_275.npz": "train-36-64-6",
+
+  "alice_36_276.npz": "train-36-64-7",
+
+  "alice_36_277.npz": "train-36-64-8",
+
+  "alice_36_278.npz": "train-36-64-9",
+  "alice_36_279.npz": "train-36-64-9",
+
+  "alice_36_280.npz": "train-36-65-0",
+
+  "alice_36_281.npz": "train-36-66-0",
+
+  "alice_42_0.npz": "train-42-0-0",
+
+  "alice_42_1.npz": "train-42-0-1",
+
+  "alice_42_2.npz": "train-42-0-2",
+
+  "alice_42_3.npz": "train-42-0-3",
+
+  "alice_42_4.npz": "train-42-0-4",
+
+  "alice_42_5.npz": "train-42-0-5",
+
+  "alice_42_6.npz": "train-42-0-6",
+
+  "alice_42_7.npz": "train-42-0-7",
+
+  "alice_42_8.npz": "train-42-0-8",
+
+  "alice_42_9.npz": "train-42-1-0",
+
+  "alice_42_10.npz": "train-42-1-1",
+
+  "alice_42_11.npz": "train-42-1-2",
+
+  "alice_42_12.npz": "train-42-1-3",
+
+  "alice_42_13.npz": "train-42-1-4",
+
+  "alice_42_14.npz": "train-42-1-5",
+
+  "alice_42_15.npz": "train-42-1-6",
+
+  "alice_42_16.npz": "train-42-1-7",
+
+  "alice_42_17.npz": "train-42-1-8",
+
+  "alice_42_18.npz": "train-42-1-9",
+
+  "alice_42_19.npz": "train-42-2-0",
+
+  "alice_42_20.npz": "train-42-2-1",
+
+  "alice_42_21.npz": "train-42-2-2",
+
+  "alice_42_22.npz": "train-42-2-3",
+
+  "alice_42_23.npz": "train-42-3-0",
+
+  "alice_42_24.npz": "train-42-4-0",
+
+  "alice_42_25.npz": "train-42-5-0",
+
+  "alice_42_26.npz": "train-42-5-1",
+
+  "alice_42_27.npz": "train-42-5-2",
+
+  "alice_42_28.npz": "train-42-5-3",
+
+  "alice_42_29.npz": "train-42-5-4",
+
+  "alice_42_30.npz": "train-42-5-5",
+
+  "alice_42_31.npz": "train-42-5-6",
+
+  "alice_42_32.npz": "train-42-5-7",
+
+  "alice_42_33.npz": "train-42-5-8",
+
+  "alice_42_34.npz": "train-42-5-9",
+
+  "alice_42_35.npz": "train-42-5-10",
+
+  "alice_42_36.npz": "train-42-5-11",
+
+  "alice_42_37.npz": "train-42-5-12",
+
+  "alice_42_38.npz": "train-42-5-13",
+
+  "alice_42_39.npz": "train-42-5-14",
+
+  "alice_42_40.npz": "train-42-5-15",
+
+  "alice_42_41.npz": "train-42-5-16",
+
+  "alice_42_42.npz": "train-42-5-17",
+
+  "alice_42_43.npz": "train-42-6-0",
+
+  "alice_42_44.npz": "train-42-6-1",
+
+  "alice_42_45.npz": "train-42-6-2",
+
+  "alice_42_46.npz": "train-42-6-3",
+
+  "alice_42_47.npz": "train-42-7-0",
+
+  "alice_42_48.npz": "train-42-7-1",
+
+  "alice_42_49.npz": "train-42-7-2",
+
+  "alice_42_50.npz": "train-42-7-3",
+
+  "alice_42_51.npz": "train-42-7-4",
+
+  "alice_42_52.npz": "train-42-7-5",
+
+  "alice_42_53.npz": "train-42-8-0",
+
+  "alice_42_54.npz": "train-42-8-1",
+
+  "alice_42_55.npz": "train-42-8-2",
+
+  "alice_42_56.npz": "train-42-8-3",
+
+  "alice_42_57.npz": "train-42-8-4",
+
+  "alice_42_58.npz": "train-42-8-5",
+
+  "alice_42_59.npz": "train-42-9-0",
+
+  "alice_42_60.npz": "train-42-9-1",
+
+  "alice_42_61.npz": "train-42-9-2",
+
+  "alice_42_62.npz": "train-42-9-3",
+
+  "alice_42_63.npz": "train-42-9-4",
+
+  "alice_42_64.npz": "train-42-9-5",
+
+  "alice_42_65.npz": "train-42-9-6",
+
+  "alice_42_66.npz": "train-42-9-7",
+
+  "alice_42_67.npz": "train-42-9-8",
+
+  "alice_42_68.npz": "train-42-10-0",
+
+  "alice_42_69.npz": "train-42-10-1",
+
+  "alice_42_70.npz": "train-42-10-2",
+
+  "alice_42_71.npz": "train-42-10-3",
+
+  "alice_42_72.npz": "train-42-10-4",
+
+  "alice_42_73.npz": "train-42-10-5",
+
+  "alice_42_74.npz": "train-42-10-6",
+
+  "alice_42_75.npz": "train-42-10-7",
+
+  "alice_42_76.npz": "train-42-10-8",
+
+  "alice_42_77.npz": "train-42-12-0",
+
+  "alice_42_78.npz": "train-42-12-1",
+
+  "alice_42_79.npz": "train-42-12-2",
+
+  "alice_42_80.npz": "train-42-13-0",
+
+  "alice_42_81.npz": "train-42-14-0",
+
+  "alice_42_82.npz": "train-42-14-1",
+
+  "alice_42_83.npz": "train-42-14-2",
+
+  "alice_42_84.npz": "train-42-15-0",
+
+  "alice_42_85.npz": "train-42-16-0",
+
+  "alice_42_86.npz": "train-42-17-0",
+
+  "alice_42_87.npz": "train-42-17-1",
+
+  "alice_42_88.npz": "train-42-18-0",
+
+  "alice_42_89.npz": "train-42-18-1",
+
+  "alice_42_90.npz": "train-42-20-0",
+
+  "alice_42_91.npz": "train-42-20-1",
+
+  "alice_42_92.npz": "train-42-21-0",
+
+  "alice_42_93.npz": "train-42-21-1",
+
+  "alice_42_94.npz": "train-42-21-2",
+
+  "alice_42_95.npz": "train-42-21-3",
+
+  "alice_42_96.npz": "train-42-21-4",
+
+  "alice_42_97.npz": "train-42-21-5",
+
+  "alice_42_98.npz": "train-42-21-6",
+
+  "alice_42_99.npz": "train-42-21-7",
+
+  "alice_42_100.npz": "train-42-21-8",
+
+  "alice_42_101.npz": "train-42-21-9",
+
+  "alice_42_102.npz": "train-42-21-10",
+
+  "alice_42_103.npz": "train-42-21-11",
+
+  "alice_42_104.npz": "train-42-22-0",
+
+  "alice_42_105.npz": "train-42-22-1",
+
+  "alice_42_106.npz": "train-42-22-2",
+
+  "alice_42_107.npz": "train-42-22-3",
+
+  "alice_42_108.npz": "train-42-23-0",
+
+  "alice_42_109.npz": "train-42-24-0",
+
+  "alice_42_110.npz": "train-42-24-1",
+
+  "alice_42_111.npz": "train-42-25-0",
+
+  "alice_42_112.npz": "train-42-25-1",
+
+  "alice_42_113.npz": "train-42-26-0",
+
+  "alice_42_114.npz": "train-42-26-1",
+
+  "alice_42_115.npz": "train-42-26-2",
+
+  "alice_42_116.npz": "train-42-26-3",
+
+  "alice_42_117.npz": "train-42-26-4",
+
+  "alice_42_118.npz": "train-42-26-5",
+
+  "alice_42_119.npz": "train-42-26-6",
+
+  "alice_42_120.npz": "train-42-27-0",
+
+  "alice_42_121.npz": "train-42-27-1",
+
+  "alice_42_122.npz": "train-42-28-0",
+
+  "alice_42_123.npz": "train-42-28-1",
+
+  "alice_42_124.npz": "train-42-29-0",
+
+  "alice_42_125.npz": "train-42-29-1",
+
+  "alice_42_126.npz": "train-42-30-0",
+
+  "alice_42_127.npz": "train-42-31-0",
+
+  "alice_42_128.npz": "train-42-31-1",
+
+  "alice_42_129.npz": "train-42-31-2",
+
+  "alice_42_130.npz": "train-42-32-0",
+
+  "alice_42_131.npz": "train-42-33-0",
+
+  "alice_42_132.npz": "train-42-33-1",
+
+  "alice_42_133.npz": "train-42-33-2",
+
+  "alice_42_134.npz": "train-42-34-0",
+
+  "alice_42_135.npz": "train-42-34-1",
+
+  "alice_42_136.npz": "train-42-35-0",
+
+  "alice_42_137.npz": "train-42-36-0",
+
+  "alice_42_138.npz": "train-42-36-1",
+
+  "alice_42_139.npz": "train-42-38-0",
+
+  "alice_42_140.npz": "train-42-39-0",
+
+  "alice_42_141.npz": "train-42-39-1",
+
+  "alice_42_142.npz": "train-42-39-2",
+
+  "alice_42_143.npz": "train-42-39-3",
+
+  "alice_42_144.npz": "train-42-40-0",
+
+  "alice_42_145.npz": "train-42-41-0",
+
+  "alice_42_146.npz": "train-42-41-1",
+
+  "alice_42_147.npz": "train-42-41-2",
+
+  "alice_42_148.npz": "train-42-41-3",
+
+  "alice_42_149.npz": "train-42-42-0",
+
+  "alice_42_150.npz": "train-42-43-0",
+
+  "alice_42_151.npz": "train-42-44-0",
+
+  "alice_42_152.npz": "train-42-44-1",
+
+  "alice_42_153.npz": "train-42-44-2",
+
+  "alice_42_154.npz": "train-42-45-0",
+
+  "alice_42_155.npz": "train-42-45-1",
+
+  "alice_42_156.npz": "train-42-45-2",
+
+  "alice_42_157.npz": "train-42-45-3",
+
+  "alice_42_158.npz": "train-42-45-4",
+
+  "alice_42_159.npz": "train-42-45-5",
+
+  "alice_42_160.npz": "train-42-45-6",
+
+  "alice_42_161.npz": "train-42-46-0",
+
+  "alice_42_162.npz": "train-42-48-0",
+
+  "alice_42_163.npz": "train-42-48-1",
+
+  "alice_42_164.npz": "train-42-48-2",
+
+  "alice_42_165.npz": "train-42-49-0",
+
+  "alice_42_166.npz": "train-42-49-1",
+
+  "alice_42_167.npz": "train-42-49-2",
+
+  "alice_42_168.npz": "train-42-49-3",
+
+  "alice_42_169.npz": "train-42-49-4",
+
+  "alice_42_170.npz": "train-42-49-5",
+
+  "alice_42_171.npz": "train-42-49-6",
+
+  "alice_42_172.npz": "train-42-50-0",
+
+  "alice_42_173.npz": "train-42-50-1",
+
+  "alice_42_174.npz": "train-42-50-2",
+
+  "alice_42_175.npz": "train-42-50-3",
+
+  "alice_42_176.npz": "train-42-50-4",
+
+  "alice_42_177.npz": "train-42-51-0",
+
+  "alice_42_178.npz": "train-42-51-1",
+
+  "alice_42_179.npz": "train-42-51-2",
+
+  "alice_42_180.npz": "train-42-51-3",
+
+  "alice_42_181.npz": "train-42-51-4",
+
+  "alice_42_182.npz": "train-42-51-5",
+
+  "alice_42_183.npz": "train-42-52-0",
+
+  "alice_42_184.npz": "train-42-52-1",
+
+  "alice_42_185.npz": "train-42-52-2",
+
+  "alice_42_186.npz": "train-42-52-3",
+
+  "alice_42_187.npz": "train-42-52-4",
+
+  "alice_42_188.npz": "train-42-52-5",
+
+  "alice_42_189.npz": "train-42-52-6",
+
+  "alice_42_190.npz": "train-42-52-7",
+
+  "alice_42_191.npz": "train-42-53-0",
+
+  "alice_42_192.npz": "train-42-53-1",
+
+  "alice_42_193.npz": "train-42-53-2",
+
+  "alice_42_194.npz": "train-42-53-3",
+
+  "alice_42_195.npz": "train-42-53-4",
+
+  "alice_42_196.npz": "train-42-53-5",
+
+  "alice_42_197.npz": "train-42-53-6",
+
+  "alice_42_198.npz": "train-42-54-0",
+
+  "alice_42_199.npz": "train-42-54-1",
+
+  "alice_42_200.npz": "train-42-54-2",
+
+  "alice_42_201.npz": "train-42-54-3",
+
+  "alice_42_202.npz": "train-42-55-0",
+
+  "alice_42_203.npz": "train-42-55-1",
+
+  "alice_42_204.npz": "train-42-55-2",
+
+  "alice_42_205.npz": "train-42-55-3",
+
+  "alice_42_206.npz": "train-42-55-4",
+
+  "alice_42_207.npz": "train-42-55-5",
+
+  "alice_42_208.npz": "train-42-55-6",
+
+  "alice_42_209.npz": "train-42-55-7",
+
+  "alice_42_210.npz": "train-42-56-0",
+
+  "alice_42_211.npz": "train-42-56-1",
+
+  "alice_42_212.npz": "train-42-56-2",
+
+  "alice_42_213.npz": "train-42-56-3",
+
+  "alice_42_214.npz": "train-42-56-4",
+
+  "alice_42_215.npz": "train-42-56-5",
+
+  "alice_42_216.npz": "train-42-57-0",
+
+  "alice_42_217.npz": "train-42-57-1",
+
+  "alice_42_218.npz": "train-42-57-2",
+
+  "alice_42_219.npz": "train-42-57-3",
+
+  "alice_42_220.npz": "train-42-57-4",
+
+  "alice_42_221.npz": "train-42-57-5",
+
+  "alice_42_222.npz": "train-42-57-6",
+
+  "alice_42_223.npz": "train-42-57-7",
+
+  "alice_42_224.npz": "train-42-57-8",
+
+  "alice_42_225.npz": "train-42-57-9",
+
+  "alice_42_226.npz": "train-42-58-0",
+
+  "alice_42_227.npz": "train-42-59-0",
+
+  "alice_42_228.npz": "train-42-59-1",
+
+  "alice_42_229.npz": "train-42-60-0",
+
+  "alice_42_230.npz": "train-42-60-1",
+
+  "alice_42_231.npz": "train-42-60-2",
+
+  "alice_42_232.npz": "train-42-60-3",
+
+  "alice_42_233.npz": "train-42-60-4",
+
+  "alice_42_234.npz": "train-42-61-0",
+
+  "alice_42_235.npz": "train-42-61-1",
+
+  "alice_42_236.npz": "train-42-61-2",
+
+  "alice_42_237.npz": "train-42-61-3",
+
+  "alice_42_238.npz": "train-42-61-4",
+
+  "alice_42_239.npz": "train-42-61-5",
+
+  "alice_42_240.npz": "train-42-61-6",
+
+  "alice_42_241.npz": "train-42-61-7",
+
+  "alice_42_242.npz": "train-42-61-8",
+
+  "alice_42_243.npz": "train-42-61-9",
+
+  "alice_42_244.npz": "train-42-61-10",
+
+  "alice_42_245.npz": "train-42-61-11",
+
+  "alice_42_246.npz": "train-42-61-12",
+
+  "alice_42_247.npz": "train-42-62-0",
+
+  "alice_42_248.npz": "train-42-62-1",
+
+  "alice_42_249.npz": "train-42-62-2",
+
+  "alice_42_250.npz": "train-42-62-3",
+
+  "alice_42_251.npz": "train-42-63-0",
+
+  "alice_42_252.npz": "train-42-63-1",
+
+  "alice_42_253.npz": "train-42-63-2",
+
+  "alice_42_254.npz": "train-42-63-3",
+
+  "alice_42_255.npz": "train-42-63-4",
+
+  "alice_42_256.npz": "train-42-63-5",
+
+  "alice_42_257.npz": "train-42-63-6",
+
+  "alice_42_258.npz": "train-42-63-7",
+
+  "alice_42_259.npz": "train-42-63-8",
+
+  "alice_42_260.npz": "train-42-63-9",
+
+  "alice_42_261.npz": "train-42-63-10",
+
+  "alice_42_262.npz": "train-42-63-11",
+
+  "alice_42_263.npz": "train-42-63-12",
+
+  "alice_42_264.npz": "train-42-63-13",
+
+  "alice_42_265.npz": "train-42-63-14",
+
+  "alice_42_266.npz": "train-42-63-15",
+
+  "alice_42_267.npz": "train-42-63-16",
+
+  "alice_42_268.npz": "train-42-63-17",
+
+  "alice_42_269.npz": "train-42-64-0",
+
+  "alice_42_270.npz": "train-42-64-1",
+
+  "alice_42_271.npz": "train-42-64-2",
+
+  "alice_42_272.npz": "train-42-64-3",
+
+  "alice_42_273.npz": "train-42-64-4",
+
+  "alice_42_274.npz": "train-42-64-5",
+
+  "alice_42_275.npz": "train-42-64-6",
+
+  "alice_42_276.npz": "train-42-64-7",
+
+  "alice_42_277.npz": "train-42-64-8",
+
+  "alice_42_278.npz": "train-42-64-9",
+  "alice_42_279.npz": "train-42-64-9",
+
+  "alice_42_280.npz": "train-42-65-0",
+
+  "alice_42_281.npz": "train-42-66-0",
+
+  "alice_44_0.npz": "train-44-0-0",
+
+  "alice_44_1.npz": "train-44-0-1",
+
+  "alice_44_2.npz": "train-44-0-2",
+
+  "alice_44_3.npz": "train-44-0-3",
+
+  "alice_44_4.npz": "train-44-0-4",
+
+  "alice_44_5.npz": "train-44-0-5",
+
+  "alice_44_6.npz": "train-44-0-6",
+
+  "alice_44_7.npz": "train-44-0-7",
+
+  "alice_44_8.npz": "train-44-0-8",
+
+  "alice_44_9.npz": "train-44-1-0",
+
+  "alice_44_10.npz": "train-44-1-1",
+
+  "alice_44_11.npz": "train-44-1-2",
+
+  "alice_44_12.npz": "train-44-1-3",
+
+  "alice_44_13.npz": "train-44-1-4",
+
+  "alice_44_14.npz": "train-44-1-5",
+
+  "alice_44_15.npz": "train-44-1-6",
+
+  "alice_44_16.npz": "train-44-1-7",
+
+  "alice_44_17.npz": "train-44-1-8",
+
+  "alice_44_18.npz": "train-44-1-9",
+
+  "alice_44_19.npz": "train-44-2-0",
+
+  "alice_44_20.npz": "train-44-2-1",
+
+  "alice_44_21.npz": "train-44-2-2",
+
+  "alice_44_22.npz": "train-44-2-3",
+
+  "alice_44_23.npz": "train-44-3-0",
+
+  "alice_44_24.npz": "train-44-4-0",
+
+  "alice_44_25.npz": "train-44-5-0",
+
+  "alice_44_26.npz": "train-44-5-1",
+
+  "alice_44_27.npz": "train-44-5-2",
+
+  "alice_44_28.npz": "train-44-5-3",
+
+  "alice_44_29.npz": "train-44-5-4",
+
+  "alice_44_30.npz": "train-44-5-5",
+
+  "alice_44_31.npz": "train-44-5-6",
+
+  "alice_44_32.npz": "train-44-5-7",
+
+  "alice_44_33.npz": "train-44-5-8",
+
+  "alice_44_34.npz": "train-44-5-9",
+
+  "alice_44_35.npz": "train-44-5-10",
+
+  "alice_44_36.npz": "train-44-5-11",
+
+  "alice_44_37.npz": "train-44-5-12",
+
+  "alice_44_38.npz": "train-44-5-13",
+
+  "alice_44_39.npz": "train-44-5-14",
+
+  "alice_44_40.npz": "train-44-5-15",
+
+  "alice_44_41.npz": "train-44-5-16",
+
+  "alice_44_42.npz": "train-44-5-17",
+
+  "alice_44_43.npz": "train-44-6-0",
+
+  "alice_44_44.npz": "train-44-6-1",
+
+  "alice_44_45.npz": "train-44-6-2",
+
+  "alice_44_46.npz": "train-44-6-3",
+
+  "alice_44_47.npz": "train-44-7-0",
+
+  "alice_44_48.npz": "train-44-7-1",
+
+  "alice_44_49.npz": "train-44-7-2",
+
+  "alice_44_50.npz": "train-44-7-3",
+
+  "alice_44_51.npz": "train-44-7-4",
+
+  "alice_44_52.npz": "train-44-7-5",
+
+  "alice_44_53.npz": "train-44-8-0",
+
+  "alice_44_54.npz": "train-44-8-1",
+
+  "alice_44_55.npz": "train-44-8-2",
+
+  "alice_44_56.npz": "train-44-8-3",
+
+  "alice_44_57.npz": "train-44-8-4",
+
+  "alice_44_58.npz": "train-44-8-5",
+
+  "alice_44_59.npz": "train-44-9-0",
+
+  "alice_44_60.npz": "train-44-9-1",
+
+  "alice_44_61.npz": "train-44-9-2",
+
+  "alice_44_62.npz": "train-44-9-3",
+
+  "alice_44_63.npz": "train-44-9-4",
+
+  "alice_44_64.npz": "train-44-9-5",
+
+  "alice_44_65.npz": "train-44-9-6",
+
+  "alice_44_66.npz": "train-44-9-7",
+
+  "alice_44_67.npz": "train-44-9-8",
+
+  "alice_44_68.npz": "train-44-10-0",
+
+  "alice_44_69.npz": "train-44-10-1",
+
+  "alice_44_70.npz": "train-44-10-2",
+
+  "alice_44_71.npz": "train-44-10-3",
+
+  "alice_44_72.npz": "train-44-10-4",
+
+  "alice_44_73.npz": "train-44-10-5",
+
+  "alice_44_74.npz": "train-44-10-6",
+
+  "alice_44_75.npz": "train-44-10-7",
+
+  "alice_44_76.npz": "train-44-10-8",
+
+  "alice_44_77.npz": "train-44-12-0",
+
+  "alice_44_78.npz": "train-44-12-1",
+
+  "alice_44_79.npz": "train-44-12-2",
+
+  "alice_44_80.npz": "train-44-13-0",
+
+  "alice_44_81.npz": "train-44-14-0",
+
+  "alice_44_82.npz": "train-44-14-1",
+
+  "alice_44_83.npz": "train-44-14-2",
+
+  "alice_44_84.npz": "train-44-15-0",
+
+  "alice_44_85.npz": "train-44-16-0",
+
+  "alice_44_86.npz": "train-44-17-0",
+
+  "alice_44_87.npz": "train-44-17-1",
+
+  "alice_44_88.npz": "train-44-18-0",
+
+  "alice_44_89.npz": "train-44-18-1",
+
+  "alice_44_90.npz": "train-44-20-0",
+
+  "alice_44_91.npz": "train-44-20-1",
+
+  "alice_44_92.npz": "train-44-21-0",
+
+  "alice_44_93.npz": "train-44-21-1",
+
+  "alice_44_94.npz": "train-44-21-2",
+
+  "alice_44_95.npz": "train-44-21-3",
+
+  "alice_44_96.npz": "train-44-21-4",
+
+  "alice_44_97.npz": "train-44-21-5",
+
+  "alice_44_98.npz": "train-44-21-6",
+
+  "alice_44_99.npz": "train-44-21-7",
+
+  "alice_44_100.npz": "train-44-21-8",
+
+  "alice_44_101.npz": "train-44-21-9",
+
+  "alice_44_102.npz": "train-44-21-10",
+
+  "alice_44_103.npz": "train-44-21-11",
+
+  "alice_44_104.npz": "train-44-22-0",
+
+  "alice_44_105.npz": "train-44-22-1",
+
+  "alice_44_106.npz": "train-44-22-2",
+
+  "alice_44_107.npz": "train-44-22-3",
+
+  "alice_44_108.npz": "train-44-23-0",
+
+  "alice_44_109.npz": "train-44-24-0",
+
+  "alice_44_110.npz": "train-44-24-1",
+
+  "alice_44_111.npz": "train-44-25-0",
+
+  "alice_44_112.npz": "train-44-25-1",
+
+  "alice_44_113.npz": "train-44-26-0",
+
+  "alice_44_114.npz": "train-44-26-1",
+
+  "alice_44_115.npz": "train-44-26-2",
+
+  "alice_44_116.npz": "train-44-26-3",
+
+  "alice_44_117.npz": "train-44-26-4",
+
+  "alice_44_118.npz": "train-44-26-5",
+
+  "alice_44_119.npz": "train-44-26-6",
+
+  "alice_44_120.npz": "train-44-27-0",
+
+  "alice_44_121.npz": "train-44-27-1",
+
+  "alice_44_122.npz": "train-44-28-0",
+
+  "alice_44_123.npz": "train-44-28-1",
+
+  "alice_44_124.npz": "train-44-29-0",
+
+  "alice_44_125.npz": "train-44-29-1",
+
+  "alice_44_126.npz": "train-44-30-0",
+
+  "alice_44_127.npz": "train-44-31-0",
+
+  "alice_44_128.npz": "train-44-31-1",
+
+  "alice_44_129.npz": "train-44-31-2",
+
+  "alice_44_130.npz": "train-44-32-0",
+
+  "alice_44_131.npz": "train-44-33-0",
+
+  "alice_44_132.npz": "train-44-33-1",
+
+  "alice_44_133.npz": "train-44-33-2",
+
+  "alice_44_134.npz": "train-44-34-0",
+
+  "alice_44_135.npz": "train-44-34-1",
+
+  "alice_44_136.npz": "train-44-35-0",
+
+  "alice_44_137.npz": "train-44-36-0",
+
+  "alice_44_138.npz": "train-44-36-1",
+
+  "alice_44_139.npz": "train-44-38-0",
+
+  "alice_44_140.npz": "train-44-39-0",
+
+  "alice_44_141.npz": "train-44-39-1",
+
+  "alice_44_142.npz": "train-44-39-2",
+
+  "alice_44_143.npz": "train-44-39-3",
+
+  "alice_44_144.npz": "train-44-40-0",
+
+  "alice_44_145.npz": "train-44-41-0",
+
+  "alice_44_146.npz": "train-44-41-1",
+
+  "alice_44_147.npz": "train-44-41-2",
+
+  "alice_44_148.npz": "train-44-41-3",
+
+  "alice_44_149.npz": "train-44-42-0",
+
+  "alice_44_150.npz": "train-44-43-0",
+
+  "alice_44_151.npz": "train-44-44-0",
+
+  "alice_44_152.npz": "train-44-44-1",
+
+  "alice_44_153.npz": "train-44-44-2",
+
+  "alice_44_154.npz": "train-44-45-0",
+
+  "alice_44_155.npz": "train-44-45-1",
+
+  "alice_44_156.npz": "train-44-45-2",
+
+  "alice_44_157.npz": "train-44-45-3",
+
+  "alice_44_158.npz": "train-44-45-4",
+
+  "alice_44_159.npz": "train-44-45-5",
+
+  "alice_44_160.npz": "train-44-45-6",
+
+  "alice_44_161.npz": "train-44-46-0",
+
+  "alice_44_162.npz": "train-44-48-0",
+
+  "alice_44_163.npz": "train-44-48-1",
+
+  "alice_44_164.npz": "train-44-48-2",
+
+  "alice_44_165.npz": "train-44-49-0",
+
+  "alice_44_166.npz": "train-44-49-1",
+
+  "alice_44_167.npz": "train-44-49-2",
+
+  "alice_44_168.npz": "train-44-49-3",
+
+  "alice_44_169.npz": "train-44-49-4",
+
+  "alice_44_170.npz": "train-44-49-5",
+
+  "alice_44_171.npz": "train-44-49-6",
+
+  "alice_44_172.npz": "train-44-50-0",
+
+  "alice_44_173.npz": "train-44-50-1",
+
+  "alice_44_174.npz": "train-44-50-2",
+
+  "alice_44_175.npz": "train-44-50-3",
+
+  "alice_44_176.npz": "train-44-50-4",
+
+  "alice_44_177.npz": "train-44-51-0",
+
+  "alice_44_178.npz": "train-44-51-1",
+
+  "alice_44_179.npz": "train-44-51-2",
+
+  "alice_44_180.npz": "train-44-51-3",
+
+  "alice_44_181.npz": "train-44-51-4",
+
+  "alice_44_182.npz": "train-44-51-5",
+
+  "alice_44_183.npz": "train-44-52-0",
+
+  "alice_44_184.npz": "train-44-52-1",
+
+  "alice_44_185.npz": "train-44-52-2",
+
+  "alice_44_186.npz": "train-44-52-3",
+
+  "alice_44_187.npz": "train-44-52-4",
+
+  "alice_44_188.npz": "train-44-52-5",
+
+  "alice_44_189.npz": "train-44-52-6",
+
+  "alice_44_190.npz": "train-44-52-7",
+
+  "alice_44_191.npz": "train-44-53-0",
+
+  "alice_44_192.npz": "train-44-53-1",
+
+  "alice_44_193.npz": "train-44-53-2",
+
+  "alice_44_194.npz": "train-44-53-3",
+
+  "alice_44_195.npz": "train-44-53-4",
+
+  "alice_44_196.npz": "train-44-53-5",
+
+  "alice_44_197.npz": "train-44-53-6",
+
+  "alice_44_198.npz": "train-44-54-0",
+
+  "alice_44_199.npz": "train-44-54-1",
+
+  "alice_44_200.npz": "train-44-54-2",
+
+  "alice_44_201.npz": "train-44-54-3",
+
+  "alice_44_202.npz": "train-44-55-0",
+
+  "alice_44_203.npz": "train-44-55-1",
+
+  "alice_44_204.npz": "train-44-55-2",
+
+  "alice_44_205.npz": "train-44-55-3",
+
+  "alice_44_206.npz": "train-44-55-4",
+
+  "alice_44_207.npz": "train-44-55-5",
+
+  "alice_44_208.npz": "train-44-55-6",
+
+  "alice_44_209.npz": "train-44-55-7",
+
+  "alice_44_210.npz": "train-44-56-0",
+
+  "alice_44_211.npz": "train-44-56-1",
+
+  "alice_44_212.npz": "train-44-56-2",
+
+  "alice_44_213.npz": "train-44-56-3",
+
+  "alice_44_214.npz": "train-44-56-4",
+
+  "alice_44_215.npz": "train-44-56-5",
+
+  "alice_44_216.npz": "train-44-57-0",
+
+  "alice_44_217.npz": "train-44-57-1",
+
+  "alice_44_218.npz": "train-44-57-2",
+
+  "alice_44_219.npz": "train-44-57-3",
+
+  "alice_44_220.npz": "train-44-57-4",
+
+  "alice_44_221.npz": "train-44-57-5",
+
+  "alice_44_222.npz": "train-44-57-6",
+
+  "alice_44_223.npz": "train-44-57-7",
+
+  "alice_44_224.npz": "train-44-57-8",
+
+  "alice_44_225.npz": "train-44-57-9",
+
+  "alice_44_226.npz": "train-44-58-0",
+
+  "alice_44_227.npz": "train-44-59-0",
+
+  "alice_44_228.npz": "train-44-59-1",
+
+  "alice_44_229.npz": "train-44-60-0",
+
+  "alice_44_230.npz": "train-44-60-1",
+
+  "alice_44_231.npz": "train-44-60-2",
+
+  "alice_44_232.npz": "train-44-60-3",
+
+  "alice_44_233.npz": "train-44-60-4",
+
+  "alice_44_234.npz": "train-44-61-0",
+
+  "alice_44_235.npz": "train-44-61-1",
+
+  "alice_44_236.npz": "train-44-61-2",
+
+  "alice_44_237.npz": "train-44-61-3",
+
+  "alice_44_238.npz": "train-44-61-4",
+
+  "alice_44_239.npz": "train-44-61-5",
+
+  "alice_44_240.npz": "train-44-61-6",
+
+  "alice_44_241.npz": "train-44-61-7",
+
+  "alice_44_242.npz": "train-44-61-8",
+
+  "alice_44_243.npz": "train-44-61-9",
+
+  "alice_44_244.npz": "train-44-61-10",
+
+  "alice_44_245.npz": "train-44-61-11",
+
+  "alice_44_246.npz": "train-44-61-12",
+
+  "alice_44_247.npz": "train-44-62-0",
+
+  "alice_44_248.npz": "train-44-62-1",
+
+  "alice_44_249.npz": "train-44-62-2",
+
+  "alice_44_250.npz": "train-44-62-3",
+
+  "alice_44_251.npz": "train-44-63-0",
+
+  "alice_44_252.npz": "train-44-63-1",
+
+  "alice_44_253.npz": "train-44-63-2",
+
+  "alice_44_254.npz": "train-44-63-3",
+
+  "alice_44_255.npz": "train-44-63-4",
+
+  "alice_44_256.npz": "train-44-63-5",
+
+  "alice_44_257.npz": "train-44-63-6",
+
+  "alice_44_258.npz": "train-44-63-7",
+
+  "alice_44_259.npz": "train-44-63-8",
+
+  "alice_44_260.npz": "train-44-63-9",
+
+  "alice_44_261.npz": "train-44-63-10",
+
+  "alice_44_262.npz": "train-44-63-11",
+
+  "alice_44_263.npz": "train-44-63-12",
+
+  "alice_44_264.npz": "train-44-63-13",
+
+  "alice_44_265.npz": "train-44-63-14",
+
+  "alice_44_266.npz": "train-44-63-15",
+
+  "alice_44_267.npz": "train-44-63-16",
+
+  "alice_44_268.npz": "train-44-63-17",
+
+  "alice_44_269.npz": "train-44-64-0",
+
+  "alice_44_270.npz": "train-44-64-1",
+
+  "alice_44_271.npz": "train-44-64-2",
+
+  "alice_44_272.npz": "train-44-64-3",
+
+  "alice_44_273.npz": "train-44-64-4",
+
+  "alice_44_274.npz": "train-44-64-5",
+
+  "alice_44_275.npz": "train-44-64-6",
+
+  "alice_44_276.npz": "train-44-64-7",
+
+  "alice_44_277.npz": "train-44-64-8",
+
+  "alice_44_278.npz": "train-44-64-9",
+  "alice_44_279.npz": "train-44-64-9",
+
+  "alice_44_280.npz": "train-44-65-0",
+
+  "alice_44_281.npz": "train-44-66-0",
+
+  "alice_39_0.npz": "train-39-0-0",
+
+  "alice_39_1.npz": "train-39-0-1",
+
+  "alice_39_2.npz": "train-39-0-2",
+
+  "alice_39_3.npz": "train-39-0-3",
+
+  "alice_39_4.npz": "train-39-0-4",
+
+  "alice_39_5.npz": "train-39-0-5",
+
+  "alice_39_6.npz": "train-39-0-6",
+
+  "alice_39_7.npz": "train-39-0-7",
+
+  "alice_39_8.npz": "train-39-0-8",
+
+  "alice_39_9.npz": "train-39-1-0",
+
+  "alice_39_10.npz": "train-39-1-1",
+
+  "alice_39_11.npz": "train-39-1-2",
+
+  "alice_39_12.npz": "train-39-1-3",
+
+  "alice_39_13.npz": "train-39-1-4",
+
+  "alice_39_14.npz": "train-39-1-5",
+
+  "alice_39_15.npz": "train-39-1-6",
+
+  "alice_39_16.npz": "train-39-1-7",
+
+  "alice_39_17.npz": "train-39-1-8",
+
+  "alice_39_18.npz": "train-39-1-9",
+
+  "alice_39_19.npz": "train-39-2-0",
+
+  "alice_39_20.npz": "train-39-2-1",
+
+  "alice_39_21.npz": "train-39-2-2",
+
+  "alice_39_22.npz": "train-39-2-3",
+
+  "alice_39_23.npz": "train-39-3-0",
+
+  "alice_39_24.npz": "train-39-4-0",
+
+  "alice_39_25.npz": "train-39-5-0",
+
+  "alice_39_26.npz": "train-39-5-1",
+
+  "alice_39_27.npz": "train-39-5-2",
+
+  "alice_39_28.npz": "train-39-5-3",
+
+  "alice_39_29.npz": "train-39-5-4",
+
+  "alice_39_30.npz": "train-39-5-5",
+
+  "alice_39_31.npz": "train-39-5-6",
+
+  "alice_39_32.npz": "train-39-5-7",
+
+  "alice_39_33.npz": "train-39-5-8",
+
+  "alice_39_34.npz": "train-39-5-9",
+
+  "alice_39_35.npz": "train-39-5-10",
+
+  "alice_39_36.npz": "train-39-5-11",
+
+  "alice_39_37.npz": "train-39-5-12",
+
+  "alice_39_38.npz": "train-39-5-13",
+
+  "alice_39_39.npz": "train-39-5-14",
+
+  "alice_39_40.npz": "train-39-5-15",
+
+  "alice_39_41.npz": "train-39-5-16",
+
+  "alice_39_42.npz": "train-39-5-17",
+
+  "alice_39_43.npz": "train-39-6-0",
+
+  "alice_39_44.npz": "train-39-6-1",
+
+  "alice_39_45.npz": "train-39-6-2",
+
+  "alice_39_46.npz": "train-39-6-3",
+
+  "alice_39_47.npz": "train-39-7-0",
+
+  "alice_39_48.npz": "train-39-7-1",
+
+  "alice_39_49.npz": "train-39-7-2",
+
+  "alice_39_50.npz": "train-39-7-3",
+
+  "alice_39_51.npz": "train-39-7-4",
+
+  "alice_39_52.npz": "train-39-7-5",
+
+  "alice_39_53.npz": "train-39-8-0",
+
+  "alice_39_54.npz": "train-39-8-1",
+
+  "alice_39_55.npz": "train-39-8-2",
+
+  "alice_39_56.npz": "train-39-8-3",
+
+  "alice_39_57.npz": "train-39-8-4",
+
+  "alice_39_58.npz": "train-39-8-5",
+
+  "alice_39_59.npz": "train-39-9-0",
+
+  "alice_39_60.npz": "train-39-9-1",
+
+  "alice_39_61.npz": "train-39-9-2",
+
+  "alice_39_62.npz": "train-39-9-3",
+
+  "alice_39_63.npz": "train-39-9-4",
+
+  "alice_39_64.npz": "train-39-9-5",
+
+  "alice_39_65.npz": "train-39-9-6",
+
+  "alice_39_66.npz": "train-39-9-7",
+
+  "alice_39_67.npz": "train-39-9-8",
+
+  "alice_39_68.npz": "train-39-10-0",
+
+  "alice_39_69.npz": "train-39-10-1",
+
+  "alice_39_70.npz": "train-39-10-2",
+
+  "alice_39_71.npz": "train-39-10-3",
+
+  "alice_39_72.npz": "train-39-10-4",
+
+  "alice_39_73.npz": "train-39-10-5",
+
+  "alice_39_74.npz": "train-39-10-6",
+
+  "alice_39_75.npz": "train-39-10-7",
+
+  "alice_39_76.npz": "train-39-10-8",
+
+  "alice_39_77.npz": "train-39-12-0",
+
+  "alice_39_78.npz": "train-39-12-1",
+
+  "alice_39_79.npz": "train-39-12-2",
+
+  "alice_39_80.npz": "train-39-13-0",
+
+  "alice_39_81.npz": "train-39-14-0",
+
+  "alice_39_82.npz": "train-39-14-1",
+
+  "alice_39_83.npz": "train-39-14-2",
+
+  "alice_39_84.npz": "train-39-15-0",
+
+  "alice_39_85.npz": "train-39-16-0",
+
+  "alice_39_86.npz": "train-39-17-0",
+
+  "alice_39_87.npz": "train-39-17-1",
+
+  "alice_39_88.npz": "train-39-18-0",
+
+  "alice_39_89.npz": "train-39-18-1",
+
+  "alice_39_90.npz": "train-39-20-0",
+
+  "alice_39_91.npz": "train-39-20-1",
+
+  "alice_39_92.npz": "train-39-21-0",
+
+  "alice_39_93.npz": "train-39-21-1",
+
+  "alice_39_94.npz": "train-39-21-2",
+
+  "alice_39_95.npz": "train-39-21-3",
+
+  "alice_39_96.npz": "train-39-21-4",
+
+  "alice_39_97.npz": "train-39-21-5",
+
+  "alice_39_98.npz": "train-39-21-6",
+
+  "alice_39_99.npz": "train-39-21-7",
+
+  "alice_39_100.npz": "train-39-21-8",
+
+  "alice_39_101.npz": "train-39-21-9",
+
+  "alice_39_102.npz": "train-39-21-10",
+
+  "alice_39_103.npz": "train-39-21-11",
+
+  "alice_39_104.npz": "train-39-22-0",
+
+  "alice_39_105.npz": "train-39-22-1",
+
+  "alice_39_106.npz": "train-39-22-2",
+
+  "alice_39_107.npz": "train-39-22-3",
+
+  "alice_39_108.npz": "train-39-23-0",
+
+  "alice_39_109.npz": "train-39-24-0",
+
+  "alice_39_110.npz": "train-39-24-1",
+
+  "alice_39_111.npz": "train-39-25-0",
+
+  "alice_39_112.npz": "train-39-25-1",
+
+  "alice_39_113.npz": "train-39-26-0",
+
+  "alice_39_114.npz": "train-39-26-1",
+
+  "alice_39_115.npz": "train-39-26-2",
+
+  "alice_39_116.npz": "train-39-26-3",
+
+  "alice_39_117.npz": "train-39-26-4",
+
+  "alice_39_118.npz": "train-39-26-5",
+
+  "alice_39_119.npz": "train-39-26-6",
+
+  "alice_39_120.npz": "train-39-27-0",
+
+  "alice_39_121.npz": "train-39-27-1",
+
+  "alice_39_122.npz": "train-39-28-0",
+
+  "alice_39_123.npz": "train-39-28-1",
+
+  "alice_39_124.npz": "train-39-29-0",
+
+  "alice_39_125.npz": "train-39-29-1",
+
+  "alice_39_126.npz": "train-39-30-0",
+
+  "alice_39_127.npz": "train-39-31-0",
+
+  "alice_39_128.npz": "train-39-31-1",
+
+  "alice_39_129.npz": "train-39-31-2",
+
+  "alice_39_130.npz": "train-39-32-0",
+
+  "alice_39_131.npz": "train-39-33-0",
+
+  "alice_39_132.npz": "train-39-33-1",
+
+  "alice_39_133.npz": "train-39-33-2",
+
+  "alice_39_134.npz": "train-39-34-0",
+
+  "alice_39_135.npz": "train-39-34-1",
+
+  "alice_39_136.npz": "train-39-35-0",
+
+  "alice_39_137.npz": "train-39-36-0",
+
+  "alice_39_138.npz": "train-39-36-1",
+
+  "alice_39_139.npz": "train-39-38-0",
+
+  "alice_39_140.npz": "train-39-39-0",
+
+  "alice_39_141.npz": "train-39-39-1",
+
+  "alice_39_142.npz": "train-39-39-2",
+
+  "alice_39_143.npz": "train-39-39-3",
+
+  "alice_39_144.npz": "train-39-40-0",
+
+  "alice_39_145.npz": "train-39-41-0",
+
+  "alice_39_146.npz": "train-39-41-1",
+
+  "alice_39_147.npz": "train-39-41-2",
+
+  "alice_39_148.npz": "train-39-41-3",
+
+  "alice_39_149.npz": "train-39-42-0",
+
+  "alice_39_150.npz": "train-39-43-0",
+
+  "alice_39_151.npz": "train-39-44-0",
+
+  "alice_39_152.npz": "train-39-44-1",
+
+  "alice_39_153.npz": "train-39-44-2",
+
+  "alice_39_154.npz": "train-39-45-0",
+
+  "alice_39_155.npz": "train-39-45-1",
+
+  "alice_39_156.npz": "train-39-45-2",
+
+  "alice_39_157.npz": "train-39-45-3",
+
+  "alice_39_158.npz": "train-39-45-4",
+
+  "alice_39_159.npz": "train-39-45-5",
+
+  "alice_39_160.npz": "train-39-45-6",
+
+  "alice_39_161.npz": "train-39-46-0",
+
+  "alice_39_162.npz": "train-39-48-0",
+
+  "alice_39_163.npz": "train-39-48-1",
+
+  "alice_39_164.npz": "train-39-48-2",
+
+  "alice_39_165.npz": "train-39-49-0",
+
+  "alice_39_166.npz": "train-39-49-1",
+
+  "alice_39_167.npz": "train-39-49-2",
+
+  "alice_39_168.npz": "train-39-49-3",
+
+  "alice_39_169.npz": "train-39-49-4",
+
+  "alice_39_170.npz": "train-39-49-5",
+
+  "alice_39_171.npz": "train-39-49-6",
+
+  "alice_39_172.npz": "train-39-50-0",
+
+  "alice_39_173.npz": "train-39-50-1",
+
+  "alice_39_174.npz": "train-39-50-2",
+
+  "alice_39_175.npz": "train-39-50-3",
+
+  "alice_39_176.npz": "train-39-50-4",
+
+  "alice_39_177.npz": "train-39-51-0",
+
+  "alice_39_178.npz": "train-39-51-1",
+
+  "alice_39_179.npz": "train-39-51-2",
+
+  "alice_39_180.npz": "train-39-51-3",
+
+  "alice_39_181.npz": "train-39-51-4",
+
+  "alice_39_182.npz": "train-39-51-5",
+
+  "alice_39_183.npz": "train-39-52-0",
+
+  "alice_39_184.npz": "train-39-52-1",
+
+  "alice_39_185.npz": "train-39-52-2",
+
+  "alice_39_186.npz": "train-39-52-3",
+
+  "alice_39_187.npz": "train-39-52-4",
+
+  "alice_39_188.npz": "train-39-52-5",
+
+  "alice_39_189.npz": "train-39-52-6",
+
+  "alice_39_190.npz": "train-39-52-7",
+
+  "alice_39_191.npz": "train-39-53-0",
+
+  "alice_39_192.npz": "train-39-53-1",
+
+  "alice_39_193.npz": "train-39-53-2",
+
+  "alice_39_194.npz": "train-39-53-3",
+
+  "alice_39_195.npz": "train-39-53-4",
+
+  "alice_39_196.npz": "train-39-53-5",
+
+  "alice_39_197.npz": "train-39-53-6",
+
+  "alice_39_198.npz": "train-39-54-0",
+
+  "alice_39_199.npz": "train-39-54-1",
+
+  "alice_39_200.npz": "train-39-54-2",
+
+  "alice_39_201.npz": "train-39-54-3",
+
+  "alice_39_202.npz": "train-39-55-0",
+
+  "alice_39_203.npz": "train-39-55-1",
+
+  "alice_39_204.npz": "train-39-55-2",
+
+  "alice_39_205.npz": "train-39-55-3",
+
+  "alice_39_206.npz": "train-39-55-4",
+
+  "alice_39_207.npz": "train-39-55-5",
+
+  "alice_39_208.npz": "train-39-55-6",
+
+  "alice_39_209.npz": "train-39-55-7",
+
+  "alice_39_210.npz": "train-39-56-0",
+
+  "alice_39_211.npz": "train-39-56-1",
+
+  "alice_39_212.npz": "train-39-56-2",
+
+  "alice_39_213.npz": "train-39-56-3",
+
+  "alice_39_214.npz": "train-39-56-4",
+
+  "alice_39_215.npz": "train-39-56-5",
+
+  "alice_39_216.npz": "train-39-57-0",
+
+  "alice_39_217.npz": "train-39-57-1",
+
+  "alice_39_218.npz": "train-39-57-2",
+
+  "alice_39_219.npz": "train-39-57-3",
+
+  "alice_39_220.npz": "train-39-57-4",
+
+  "alice_39_221.npz": "train-39-57-5",
+
+  "alice_39_222.npz": "train-39-57-6",
+
+  "alice_39_223.npz": "train-39-57-7",
+
+  "alice_39_224.npz": "train-39-57-8",
+
+  "alice_39_225.npz": "train-39-57-9",
+
+  "alice_39_226.npz": "train-39-58-0",
+
+  "alice_39_227.npz": "train-39-59-0",
+
+  "alice_39_228.npz": "train-39-59-1",
+
+  "alice_39_229.npz": "train-39-60-0",
+
+  "alice_39_230.npz": "train-39-60-1",
+
+  "alice_39_231.npz": "train-39-60-2",
+
+  "alice_39_232.npz": "train-39-60-3",
+
+  "alice_39_233.npz": "train-39-60-4",
+
+  "alice_39_234.npz": "train-39-61-0",
+
+  "alice_39_235.npz": "train-39-61-1",
+
+  "alice_39_236.npz": "train-39-61-2",
+
+  "alice_39_237.npz": "train-39-61-3",
+
+  "alice_39_238.npz": "train-39-61-4",
+
+  "alice_39_239.npz": "train-39-61-5",
+
+  "alice_39_240.npz": "train-39-61-6",
+
+  "alice_39_241.npz": "train-39-61-7",
+
+  "alice_39_242.npz": "train-39-61-8",
+
+  "alice_39_243.npz": "train-39-61-9",
+
+  "alice_39_244.npz": "train-39-61-10",
+
+  "alice_39_245.npz": "train-39-61-11",
+
+  "alice_39_246.npz": "train-39-61-12",
+
+  "alice_39_247.npz": "train-39-62-0",
+
+  "alice_39_248.npz": "train-39-62-1",
+
+  "alice_39_249.npz": "train-39-62-2",
+
+  "alice_39_250.npz": "train-39-62-3",
+
+  "alice_39_251.npz": "train-39-63-0",
+
+  "alice_39_252.npz": "train-39-63-1",
+
+  "alice_39_253.npz": "train-39-63-2",
+
+  "alice_39_254.npz": "train-39-63-3",
+
+  "alice_39_255.npz": "train-39-63-4",
+
+  "alice_39_256.npz": "train-39-63-5",
+
+  "alice_39_257.npz": "train-39-63-6",
+
+  "alice_39_258.npz": "train-39-63-7",
+
+  "alice_39_259.npz": "train-39-63-8",
+
+  "alice_39_260.npz": "train-39-63-9",
+
+  "alice_39_261.npz": "train-39-63-10",
+
+  "alice_39_262.npz": "train-39-63-11",
+
+  "alice_39_263.npz": "train-39-63-12",
+
+  "alice_39_264.npz": "train-39-63-13",
+
+  "alice_39_265.npz": "train-39-63-14",
+
+  "alice_39_266.npz": "train-39-63-15",
+
+  "alice_39_267.npz": "train-39-63-16",
+
+  "alice_39_268.npz": "train-39-63-17",
+
+  "alice_39_269.npz": "train-39-64-0",
+
+  "alice_39_270.npz": "train-39-64-1",
+
+  "alice_39_271.npz": "train-39-64-2",
+
+  "alice_39_272.npz": "train-39-64-3",
+
+  "alice_39_273.npz": "train-39-64-4",
+
+  "alice_39_274.npz": "train-39-64-5",
+
+  "alice_39_275.npz": "train-39-64-6",
+
+  "alice_39_276.npz": "train-39-64-7",
+
+  "alice_39_277.npz": "train-39-64-8",
+
+  "alice_39_278.npz": "train-39-64-9",
+  "alice_39_279.npz": "train-39-64-9",
+
+  "alice_39_280.npz": "train-39-65-0",
+
+  "alice_39_281.npz": "train-39-66-0",
+
+  "alice_41_0.npz": "train-41-0-0",
+
+  "alice_41_1.npz": "train-41-0-1",
+
+  "alice_41_2.npz": "train-41-0-2",
+
+  "alice_41_3.npz": "train-41-0-3",
+
+  "alice_41_4.npz": "train-41-0-4",
+
+  "alice_41_5.npz": "train-41-0-5",
+
+  "alice_41_6.npz": "train-41-0-6",
+
+  "alice_41_7.npz": "train-41-0-7",
+
+  "alice_41_8.npz": "train-41-0-8",
+
+  "alice_41_9.npz": "train-41-1-0",
+
+  "alice_41_10.npz": "train-41-1-1",
+
+  "alice_41_11.npz": "train-41-1-2",
+
+  "alice_41_12.npz": "train-41-1-3",
+
+  "alice_41_13.npz": "train-41-1-4",
+
+  "alice_41_14.npz": "train-41-1-5",
+
+  "alice_41_15.npz": "train-41-1-6",
+
+  "alice_41_16.npz": "train-41-1-7",
+
+  "alice_41_17.npz": "train-41-1-8",
+
+  "alice_41_18.npz": "train-41-1-9",
+
+  "alice_41_19.npz": "train-41-2-0",
+
+  "alice_41_20.npz": "train-41-2-1",
+
+  "alice_41_21.npz": "train-41-2-2",
+
+  "alice_41_22.npz": "train-41-2-3",
+
+  "alice_41_23.npz": "train-41-3-0",
+
+  "alice_41_24.npz": "train-41-4-0",
+
+  "alice_41_25.npz": "train-41-5-0",
+
+  "alice_41_26.npz": "train-41-5-1",
+
+  "alice_41_27.npz": "train-41-5-2",
+
+  "alice_41_28.npz": "train-41-5-3",
+
+  "alice_41_29.npz": "train-41-5-4",
+
+  "alice_41_30.npz": "train-41-5-5",
+
+  "alice_41_31.npz": "train-41-5-6",
+
+  "alice_41_32.npz": "train-41-5-7",
+
+  "alice_41_33.npz": "train-41-5-8",
+
+  "alice_41_34.npz": "train-41-5-9",
+
+  "alice_41_35.npz": "train-41-5-10",
+
+  "alice_41_36.npz": "train-41-5-11",
+
+  "alice_41_37.npz": "train-41-5-12",
+
+  "alice_41_38.npz": "train-41-5-13",
+
+  "alice_41_39.npz": "train-41-5-14",
+
+  "alice_41_40.npz": "train-41-5-15",
+
+  "alice_41_41.npz": "train-41-5-16",
+
+  "alice_41_42.npz": "train-41-5-17",
+
+  "alice_41_43.npz": "train-41-6-0",
+
+  "alice_41_44.npz": "train-41-6-1",
+
+  "alice_41_45.npz": "train-41-6-2",
+
+  "alice_41_46.npz": "train-41-6-3",
+
+  "alice_41_47.npz": "train-41-7-0",
+
+  "alice_41_48.npz": "train-41-7-1",
+
+  "alice_41_49.npz": "train-41-7-2",
+
+  "alice_41_50.npz": "train-41-7-3",
+
+  "alice_41_51.npz": "train-41-7-4",
+
+  "alice_41_52.npz": "train-41-7-5",
+
+  "alice_41_53.npz": "train-41-8-0",
+
+  "alice_41_54.npz": "train-41-8-1",
+
+  "alice_41_55.npz": "train-41-8-2",
+
+  "alice_41_56.npz": "train-41-8-3",
+
+  "alice_41_57.npz": "train-41-8-4",
+
+  "alice_41_58.npz": "train-41-8-5",
+
+  "alice_41_59.npz": "train-41-9-0",
+
+  "alice_41_60.npz": "train-41-9-1",
+
+  "alice_41_61.npz": "train-41-9-2",
+
+  "alice_41_62.npz": "train-41-9-3",
+
+  "alice_41_63.npz": "train-41-9-4",
+
+  "alice_41_64.npz": "train-41-9-5",
+
+  "alice_41_65.npz": "train-41-9-6",
+
+  "alice_41_66.npz": "train-41-9-7",
+
+  "alice_41_67.npz": "train-41-9-8",
+
+  "alice_41_68.npz": "train-41-10-0",
+
+  "alice_41_69.npz": "train-41-10-1",
+
+  "alice_41_70.npz": "train-41-10-2",
+
+  "alice_41_71.npz": "train-41-10-3",
+
+  "alice_41_72.npz": "train-41-10-4",
+
+  "alice_41_73.npz": "train-41-10-5",
+
+  "alice_41_74.npz": "train-41-10-6",
+
+  "alice_41_75.npz": "train-41-10-7",
+
+  "alice_41_76.npz": "train-41-10-8",
+
+  "alice_41_77.npz": "train-41-12-0",
+
+  "alice_41_78.npz": "train-41-12-1",
+
+  "alice_41_79.npz": "train-41-12-2",
+
+  "alice_41_80.npz": "train-41-13-0",
+
+  "alice_41_81.npz": "train-41-14-0",
+
+  "alice_41_82.npz": "train-41-14-1",
+
+  "alice_41_83.npz": "train-41-14-2",
+
+  "alice_41_84.npz": "train-41-15-0",
+
+  "alice_41_85.npz": "train-41-16-0",
+
+  "alice_41_86.npz": "train-41-17-0",
+
+  "alice_41_87.npz": "train-41-17-1",
+
+  "alice_41_88.npz": "train-41-18-0",
+
+  "alice_41_89.npz": "train-41-18-1",
+
+  "alice_41_90.npz": "train-41-20-0",
+
+  "alice_41_91.npz": "train-41-20-1",
+
+  "alice_41_92.npz": "train-41-21-0",
+
+  "alice_41_93.npz": "train-41-21-1",
+
+  "alice_41_94.npz": "train-41-21-2",
+
+  "alice_41_95.npz": "train-41-21-3",
+
+  "alice_41_96.npz": "train-41-21-4",
+
+  "alice_41_97.npz": "train-41-21-5",
+
+  "alice_41_98.npz": "train-41-21-6",
+
+  "alice_41_99.npz": "train-41-21-7",
+
+  "alice_41_100.npz": "train-41-21-8",
+
+  "alice_41_101.npz": "train-41-21-9",
+
+  "alice_41_102.npz": "train-41-21-10",
+
+  "alice_41_103.npz": "train-41-21-11",
+
+  "alice_41_104.npz": "train-41-22-0",
+
+  "alice_41_105.npz": "train-41-22-1",
+
+  "alice_41_106.npz": "train-41-22-2",
+
+  "alice_41_107.npz": "train-41-22-3",
+
+  "alice_41_108.npz": "train-41-23-0",
+
+  "alice_41_109.npz": "train-41-24-0",
+
+  "alice_41_110.npz": "train-41-24-1",
+
+  "alice_41_111.npz": "train-41-25-0",
+
+  "alice_41_112.npz": "train-41-25-1",
+
+  "alice_41_113.npz": "train-41-26-0",
+
+  "alice_41_114.npz": "train-41-26-1",
+
+  "alice_41_115.npz": "train-41-26-2",
+
+  "alice_41_116.npz": "train-41-26-3",
+
+  "alice_41_117.npz": "train-41-26-4",
+
+  "alice_41_118.npz": "train-41-26-5",
+
+  "alice_41_119.npz": "train-41-26-6",
+
+  "alice_41_120.npz": "train-41-27-0",
+
+  "alice_41_121.npz": "train-41-27-1",
+
+  "alice_41_122.npz": "train-41-28-0",
+
+  "alice_41_123.npz": "train-41-28-1",
+
+  "alice_41_124.npz": "train-41-29-0",
+
+  "alice_41_125.npz": "train-41-29-1",
+
+  "alice_41_126.npz": "train-41-30-0",
+
+  "alice_41_127.npz": "train-41-31-0",
+
+  "alice_41_128.npz": "train-41-31-1",
+
+  "alice_41_129.npz": "train-41-31-2",
+
+  "alice_41_130.npz": "train-41-32-0",
+
+  "alice_41_131.npz": "train-41-33-0",
+
+  "alice_41_132.npz": "train-41-33-1",
+
+  "alice_41_133.npz": "train-41-33-2",
+
+  "alice_41_134.npz": "train-41-34-0",
+
+  "alice_41_135.npz": "train-41-34-1",
+
+  "alice_41_136.npz": "train-41-35-0",
+
+  "alice_41_137.npz": "train-41-36-0",
+
+  "alice_41_138.npz": "train-41-36-1",
+
+  "alice_41_139.npz": "train-41-38-0",
+
+  "alice_41_140.npz": "train-41-39-0",
+
+  "alice_41_141.npz": "train-41-39-1",
+
+  "alice_41_142.npz": "train-41-39-2",
+
+  "alice_41_143.npz": "train-41-39-3",
+
+  "alice_41_144.npz": "train-41-40-0",
+
+  "alice_41_145.npz": "train-41-41-0",
+
+  "alice_41_146.npz": "train-41-41-1",
+
+  "alice_41_147.npz": "train-41-41-2",
+
+  "alice_41_148.npz": "train-41-41-3",
+
+  "alice_41_149.npz": "train-41-42-0",
+
+  "alice_41_150.npz": "train-41-43-0",
+
+  "alice_41_151.npz": "train-41-44-0",
+
+  "alice_41_152.npz": "train-41-44-1",
+
+  "alice_41_153.npz": "train-41-44-2",
+
+  "alice_41_154.npz": "train-41-45-0",
+
+  "alice_41_155.npz": "train-41-45-1",
+
+  "alice_41_156.npz": "train-41-45-2",
+
+  "alice_41_157.npz": "train-41-45-3",
+
+  "alice_41_158.npz": "train-41-45-4",
+
+  "alice_41_159.npz": "train-41-45-5",
+
+  "alice_41_160.npz": "train-41-45-6",
+
+  "alice_41_161.npz": "train-41-46-0",
+
+  "alice_41_162.npz": "train-41-48-0",
+
+  "alice_41_163.npz": "train-41-48-1",
+
+  "alice_41_164.npz": "train-41-48-2",
+
+  "alice_41_165.npz": "train-41-49-0",
+
+  "alice_41_166.npz": "train-41-49-1",
+
+  "alice_41_167.npz": "train-41-49-2",
+
+  "alice_41_168.npz": "train-41-49-3",
+
+  "alice_41_169.npz": "train-41-49-4",
+
+  "alice_41_170.npz": "train-41-49-5",
+
+  "alice_41_171.npz": "train-41-49-6",
+
+  "alice_41_172.npz": "train-41-50-0",
+
+  "alice_41_173.npz": "train-41-50-1",
+
+  "alice_41_174.npz": "train-41-50-2",
+
+  "alice_41_175.npz": "train-41-50-3",
+
+  "alice_41_176.npz": "train-41-50-4",
+
+  "alice_41_177.npz": "train-41-51-0",
+
+  "alice_41_178.npz": "train-41-51-1",
+
+  "alice_41_179.npz": "train-41-51-2",
+
+  "alice_41_180.npz": "train-41-51-3",
+
+  "alice_41_181.npz": "train-41-51-4",
+
+  "alice_41_182.npz": "train-41-51-5",
+
+  "alice_41_183.npz": "train-41-52-0",
+
+  "alice_41_184.npz": "train-41-52-1",
+
+  "alice_41_185.npz": "train-41-52-2",
+
+  "alice_41_186.npz": "train-41-52-3",
+
+  "alice_41_187.npz": "train-41-52-4",
+
+  "alice_41_188.npz": "train-41-52-5",
+
+  "alice_41_189.npz": "train-41-52-6",
+
+  "alice_41_190.npz": "train-41-52-7",
+
+  "alice_41_191.npz": "train-41-53-0",
+
+  "alice_41_192.npz": "train-41-53-1",
+
+  "alice_41_193.npz": "train-41-53-2",
+
+  "alice_41_194.npz": "train-41-53-3",
+
+  "alice_41_195.npz": "train-41-53-4",
+
+  "alice_41_196.npz": "train-41-53-5",
+
+  "alice_41_197.npz": "train-41-53-6",
+
+  "alice_41_198.npz": "train-41-54-0",
+
+  "alice_41_199.npz": "train-41-54-1",
+
+  "alice_41_200.npz": "train-41-54-2",
+
+  "alice_41_201.npz": "train-41-54-3",
+
+  "alice_41_202.npz": "train-41-55-0",
+
+  "alice_41_203.npz": "train-41-55-1",
+
+  "alice_41_204.npz": "train-41-55-2",
+
+  "alice_41_205.npz": "train-41-55-3",
+
+  "alice_41_206.npz": "train-41-55-4",
+
+  "alice_41_207.npz": "train-41-55-5",
+
+  "alice_41_208.npz": "train-41-55-6",
+
+  "alice_41_209.npz": "train-41-55-7",
+
+  "alice_41_210.npz": "train-41-56-0",
+
+  "alice_41_211.npz": "train-41-56-1",
+
+  "alice_41_212.npz": "train-41-56-2",
+
+  "alice_41_213.npz": "train-41-56-3",
+
+  "alice_41_214.npz": "train-41-56-4",
+
+  "alice_41_215.npz": "train-41-56-5",
+
+  "alice_41_216.npz": "train-41-57-0",
+
+  "alice_41_217.npz": "train-41-57-1",
+
+  "alice_41_218.npz": "train-41-57-2",
+
+  "alice_41_219.npz": "train-41-57-3",
+
+  "alice_41_220.npz": "train-41-57-4",
+
+  "alice_41_221.npz": "train-41-57-5",
+
+  "alice_41_222.npz": "train-41-57-6",
+
+  "alice_41_223.npz": "train-41-57-7",
+
+  "alice_41_224.npz": "train-41-57-8",
+
+  "alice_41_225.npz": "train-41-57-9",
+
+  "alice_41_226.npz": "train-41-58-0",
+
+  "alice_41_227.npz": "train-41-59-0",
+
+  "alice_41_228.npz": "train-41-59-1",
+
+  "alice_41_229.npz": "train-41-60-0",
+
+  "alice_41_230.npz": "train-41-60-1",
+
+  "alice_41_231.npz": "train-41-60-2",
+
+  "alice_41_232.npz": "train-41-60-3",
+
+  "alice_41_233.npz": "train-41-60-4",
+
+  "alice_41_234.npz": "train-41-61-0",
+
+  "alice_41_235.npz": "train-41-61-1",
+
+  "alice_41_236.npz": "train-41-61-2",
+
+  "alice_41_237.npz": "train-41-61-3",
+
+  "alice_41_238.npz": "train-41-61-4",
+
+  "alice_41_239.npz": "train-41-61-5",
+
+  "alice_41_240.npz": "train-41-61-6",
+
+  "alice_41_241.npz": "train-41-61-7",
+
+  "alice_41_242.npz": "train-41-61-8",
+
+  "alice_41_243.npz": "train-41-61-9",
+
+  "alice_41_244.npz": "train-41-61-10",
+
+  "alice_41_245.npz": "train-41-61-11",
+
+  "alice_41_246.npz": "train-41-61-12",
+
+  "alice_41_247.npz": "train-41-62-0",
+
+  "alice_41_248.npz": "train-41-62-1",
+
+  "alice_41_249.npz": "train-41-62-2",
+
+  "alice_41_250.npz": "train-41-62-3",
+
+  "alice_41_251.npz": "train-41-63-0",
+
+  "alice_41_252.npz": "train-41-63-1",
+
+  "alice_41_253.npz": "train-41-63-2",
+
+  "alice_41_254.npz": "train-41-63-3",
+
+  "alice_41_255.npz": "train-41-63-4",
+
+  "alice_41_256.npz": "train-41-63-5",
+
+  "alice_41_257.npz": "train-41-63-6",
+
+  "alice_41_258.npz": "train-41-63-7",
+
+  "alice_41_259.npz": "train-41-63-8",
+
+  "alice_41_260.npz": "train-41-63-9",
+
+  "alice_41_261.npz": "train-41-63-10",
+
+  "alice_41_262.npz": "train-41-63-11",
+
+  "alice_41_263.npz": "train-41-63-12",
+
+  "alice_41_264.npz": "train-41-63-13",
+
+  "alice_41_265.npz": "train-41-63-14",
+
+  "alice_41_266.npz": "train-41-63-15",
+
+  "alice_41_267.npz": "train-41-63-16",
+
+  "alice_41_268.npz": "train-41-63-17",
+
+  "alice_41_269.npz": "train-41-64-0",
+
+  "alice_41_270.npz": "train-41-64-1",
+
+  "alice_41_271.npz": "train-41-64-2",
+
+  "alice_41_272.npz": "train-41-64-3",
+
+  "alice_41_273.npz": "train-41-64-4",
+
+  "alice_41_274.npz": "train-41-64-5",
+
+  "alice_41_275.npz": "train-41-64-6",
+
+  "alice_41_276.npz": "train-41-64-7",
+
+  "alice_41_277.npz": "train-41-64-8",
+
+  "alice_41_278.npz": "train-41-64-9",
+  "alice_41_279.npz": "train-41-64-9",
+
+  "alice_41_280.npz": "train-41-65-0",
+
+  "alice_41_281.npz": "train-41-66-0",
+
+  "alice_30_0.npz": "train-30-0-0",
+
+  "alice_30_1.npz": "train-30-0-1",
+
+  "alice_30_2.npz": "train-30-0-2",
+
+  "alice_30_3.npz": "train-30-0-3",
+
+  "alice_30_4.npz": "train-30-0-4",
+
+  "alice_30_5.npz": "train-30-0-5",
+
+  "alice_30_6.npz": "train-30-0-6",
+
+  "alice_30_7.npz": "train-30-0-7",
+
+  "alice_30_8.npz": "train-30-0-8",
+
+  "alice_30_9.npz": "train-30-1-0",
+
+  "alice_30_10.npz": "train-30-1-1",
+
+  "alice_30_11.npz": "train-30-1-2",
+
+  "alice_30_12.npz": "train-30-1-3",
+
+  "alice_30_13.npz": "train-30-1-4",
+
+  "alice_30_14.npz": "train-30-1-5",
+
+  "alice_30_15.npz": "train-30-1-6",
+
+  "alice_30_16.npz": "train-30-1-7",
+
+  "alice_30_17.npz": "train-30-1-8",
+
+  "alice_30_18.npz": "train-30-1-9",
+
+  "alice_30_19.npz": "train-30-2-0",
+
+  "alice_30_20.npz": "train-30-2-1",
+
+  "alice_30_21.npz": "train-30-2-2",
+
+  "alice_30_22.npz": "train-30-2-3",
+
+  "alice_30_23.npz": "train-30-3-0",
+
+  "alice_30_24.npz": "train-30-4-0",
+
+  "alice_30_25.npz": "train-30-5-0",
+
+  "alice_30_26.npz": "train-30-5-1",
+
+  "alice_30_27.npz": "train-30-5-2",
+
+  "alice_30_28.npz": "train-30-5-3",
+
+  "alice_30_29.npz": "train-30-5-4",
+
+  "alice_30_30.npz": "train-30-5-5",
+
+  "alice_30_31.npz": "train-30-5-6",
+
+  "alice_30_32.npz": "train-30-5-7",
+
+  "alice_30_33.npz": "train-30-5-8",
+
+  "alice_30_34.npz": "train-30-5-9",
+
+  "alice_30_35.npz": "train-30-5-10",
+
+  "alice_30_36.npz": "train-30-5-11",
+
+  "alice_30_37.npz": "train-30-5-12",
+
+  "alice_30_38.npz": "train-30-5-13",
+
+  "alice_30_39.npz": "train-30-5-14",
+
+  "alice_30_40.npz": "train-30-5-15",
+
+  "alice_30_41.npz": "train-30-5-16",
+
+  "alice_30_42.npz": "train-30-5-17",
+
+  "alice_30_43.npz": "train-30-6-0",
+
+  "alice_30_44.npz": "train-30-6-1",
+
+  "alice_30_45.npz": "train-30-6-2",
+
+  "alice_30_46.npz": "train-30-6-3",
+
+  "alice_30_47.npz": "train-30-7-0",
+
+  "alice_30_48.npz": "train-30-7-1",
+
+  "alice_30_49.npz": "train-30-7-2",
+
+  "alice_30_50.npz": "train-30-7-3",
+
+  "alice_30_51.npz": "train-30-7-4",
+
+  "alice_30_52.npz": "train-30-7-5",
+
+  "alice_30_53.npz": "train-30-8-0",
+
+  "alice_30_54.npz": "train-30-8-1",
+
+  "alice_30_55.npz": "train-30-8-2",
+
+  "alice_30_56.npz": "train-30-8-3",
+
+  "alice_30_57.npz": "train-30-8-4",
+
+  "alice_30_58.npz": "train-30-8-5",
+
+  "alice_30_59.npz": "train-30-9-0",
+
+  "alice_30_60.npz": "train-30-9-1",
+
+  "alice_30_61.npz": "train-30-9-2",
+
+  "alice_30_62.npz": "train-30-9-3",
+
+  "alice_30_63.npz": "train-30-9-4",
+
+  "alice_30_64.npz": "train-30-9-5",
+
+  "alice_30_65.npz": "train-30-9-6",
+
+  "alice_30_66.npz": "train-30-9-7",
+
+  "alice_30_67.npz": "train-30-9-8",
+
+  "alice_30_68.npz": "train-30-10-0",
+
+  "alice_30_69.npz": "train-30-10-1",
+
+  "alice_30_70.npz": "train-30-10-2",
+
+  "alice_30_71.npz": "train-30-10-3",
+
+  "alice_30_72.npz": "train-30-10-4",
+
+  "alice_30_73.npz": "train-30-10-5",
+
+  "alice_30_74.npz": "train-30-10-6",
+
+  "alice_30_75.npz": "train-30-10-7",
+
+  "alice_30_76.npz": "train-30-10-8",
+
+  "alice_30_77.npz": "train-30-12-0",
+
+  "alice_30_78.npz": "train-30-12-1",
+
+  "alice_30_79.npz": "train-30-12-2",
+
+  "alice_30_80.npz": "train-30-13-0",
+
+  "alice_30_81.npz": "train-30-14-0",
+
+  "alice_30_82.npz": "train-30-14-1",
+
+  "alice_30_83.npz": "train-30-14-2",
+
+  "alice_30_84.npz": "train-30-15-0",
+
+  "alice_30_85.npz": "train-30-16-0",
+
+  "alice_30_86.npz": "train-30-17-0",
+
+  "alice_30_87.npz": "train-30-17-1",
+
+  "alice_30_88.npz": "train-30-18-0",
+
+  "alice_30_89.npz": "train-30-18-1",
+
+  "alice_30_90.npz": "train-30-20-0",
+
+  "alice_30_91.npz": "train-30-20-1",
+
+  "alice_30_92.npz": "train-30-21-0",
+
+  "alice_30_93.npz": "train-30-21-1",
+
+  "alice_30_94.npz": "train-30-21-2",
+
+  "alice_30_95.npz": "train-30-21-3",
+
+  "alice_30_96.npz": "train-30-21-4",
+
+  "alice_30_97.npz": "train-30-21-5",
+
+  "alice_30_98.npz": "train-30-21-6",
+
+  "alice_30_99.npz": "train-30-21-7",
+
+  "alice_30_100.npz": "train-30-21-8",
+
+  "alice_30_101.npz": "train-30-21-9",
+
+  "alice_30_102.npz": "train-30-21-10",
+
+  "alice_30_103.npz": "train-30-21-11",
+
+  "alice_30_104.npz": "train-30-22-0",
+
+  "alice_30_105.npz": "train-30-22-1",
+
+  "alice_30_106.npz": "train-30-22-2",
+
+  "alice_30_107.npz": "train-30-22-3",
+
+  "alice_30_108.npz": "train-30-23-0",
+
+  "alice_30_109.npz": "train-30-24-0",
+
+  "alice_30_110.npz": "train-30-24-1",
+
+  "alice_30_111.npz": "train-30-25-0",
+
+  "alice_30_112.npz": "train-30-25-1",
+
+  "alice_30_113.npz": "train-30-26-0",
+
+  "alice_30_114.npz": "train-30-26-1",
+
+  "alice_30_115.npz": "train-30-26-2",
+
+  "alice_30_116.npz": "train-30-26-3",
+
+  "alice_30_117.npz": "train-30-26-4",
+
+  "alice_30_118.npz": "train-30-26-5",
+
+  "alice_30_119.npz": "train-30-26-6",
+
+  "alice_30_120.npz": "train-30-27-0",
+
+  "alice_30_121.npz": "train-30-27-1",
+
+  "alice_30_122.npz": "train-30-28-0",
+
+  "alice_30_123.npz": "train-30-28-1",
+
+  "alice_30_124.npz": "train-30-29-0",
+
+  "alice_30_125.npz": "train-30-29-1",
+
+  "alice_30_126.npz": "train-30-30-0",
+
+  "alice_30_127.npz": "train-30-31-0",
+
+  "alice_30_128.npz": "train-30-31-1",
+
+  "alice_30_129.npz": "train-30-31-2",
+
+  "alice_30_130.npz": "train-30-32-0",
+
+  "alice_30_131.npz": "train-30-33-0",
+
+  "alice_30_132.npz": "train-30-33-1",
+
+  "alice_30_133.npz": "train-30-33-2",
+
+  "alice_30_134.npz": "train-30-34-0",
+
+  "alice_30_135.npz": "train-30-34-1",
+
+  "alice_30_136.npz": "train-30-35-0",
+
+  "alice_30_137.npz": "train-30-36-0",
+
+  "alice_30_138.npz": "train-30-36-1",
+
+  "alice_30_139.npz": "train-30-38-0",
+
+  "alice_30_140.npz": "train-30-39-0",
+
+  "alice_30_141.npz": "train-30-39-1",
+
+  "alice_30_142.npz": "train-30-39-2",
+
+  "alice_30_143.npz": "train-30-39-3",
+
+  "alice_30_144.npz": "train-30-40-0",
+
+  "alice_30_145.npz": "train-30-41-0",
+
+  "alice_30_146.npz": "train-30-41-1",
+
+  "alice_30_147.npz": "train-30-41-2",
+
+  "alice_30_148.npz": "train-30-41-3",
+
+  "alice_30_149.npz": "train-30-42-0",
+
+  "alice_30_150.npz": "train-30-43-0",
+
+  "alice_30_151.npz": "train-30-44-0",
+
+  "alice_30_152.npz": "train-30-44-1",
+
+  "alice_30_153.npz": "train-30-44-2",
+
+  "alice_30_154.npz": "train-30-45-0",
+
+  "alice_30_155.npz": "train-30-45-1",
+
+  "alice_30_156.npz": "train-30-45-2",
+
+  "alice_30_157.npz": "train-30-45-3",
+
+  "alice_30_158.npz": "train-30-45-4",
+
+  "alice_30_159.npz": "train-30-45-5",
+
+  "alice_30_160.npz": "train-30-45-6",
+
+  "alice_30_161.npz": "train-30-46-0",
+
+  "alice_30_162.npz": "train-30-48-0",
+
+  "alice_30_163.npz": "train-30-48-1",
+
+  "alice_30_164.npz": "train-30-48-2",
+
+  "alice_30_165.npz": "train-30-49-0",
+
+  "alice_30_166.npz": "train-30-49-1",
+
+  "alice_30_167.npz": "train-30-49-2",
+
+  "alice_30_168.npz": "train-30-49-3",
+
+  "alice_30_169.npz": "train-30-49-4",
+
+  "alice_30_170.npz": "train-30-49-5",
+
+  "alice_30_171.npz": "train-30-49-6",
+
+  "alice_30_172.npz": "train-30-50-0",
+
+  "alice_30_173.npz": "train-30-50-1",
+
+  "alice_30_174.npz": "train-30-50-2",
+
+  "alice_30_175.npz": "train-30-50-3",
+
+  "alice_30_176.npz": "train-30-50-4",
+
+  "alice_30_177.npz": "train-30-51-0",
+
+  "alice_30_178.npz": "train-30-51-1",
+
+  "alice_30_179.npz": "train-30-51-2",
+
+  "alice_30_180.npz": "train-30-51-3",
+
+  "alice_30_181.npz": "train-30-51-4",
+
+  "alice_30_182.npz": "train-30-51-5",
+
+  "alice_30_183.npz": "train-30-52-0",
+
+  "alice_30_184.npz": "train-30-52-1",
+
+  "alice_30_185.npz": "train-30-52-2",
+
+  "alice_30_186.npz": "train-30-52-3",
+
+  "alice_30_187.npz": "train-30-52-4",
+
+  "alice_30_188.npz": "train-30-52-5",
+
+  "alice_30_189.npz": "train-30-52-6",
+
+  "alice_30_190.npz": "train-30-52-7",
+
+  "alice_30_191.npz": "train-30-53-0",
+
+  "alice_30_192.npz": "train-30-53-1",
+
+  "alice_30_193.npz": "train-30-53-2",
+
+  "alice_30_194.npz": "train-30-53-3",
+
+  "alice_30_195.npz": "train-30-53-4",
+
+  "alice_30_196.npz": "train-30-53-5",
+
+  "alice_30_197.npz": "train-30-53-6",
+
+  "alice_30_198.npz": "train-30-54-0",
+
+  "alice_30_199.npz": "train-30-54-1",
+
+  "alice_30_200.npz": "train-30-54-2",
+
+  "alice_30_201.npz": "train-30-54-3",
+
+  "alice_30_202.npz": "train-30-55-0",
+
+  "alice_30_203.npz": "train-30-55-1",
+
+  "alice_30_204.npz": "train-30-55-2",
+
+  "alice_30_205.npz": "train-30-55-3",
+
+  "alice_30_206.npz": "train-30-55-4",
+
+  "alice_30_207.npz": "train-30-55-5",
+
+  "alice_30_208.npz": "train-30-55-6",
+
+  "alice_30_209.npz": "train-30-55-7",
+
+  "alice_30_210.npz": "train-30-56-0",
+
+  "alice_30_211.npz": "train-30-56-1",
+
+  "alice_30_212.npz": "train-30-56-2",
+
+  "alice_30_213.npz": "train-30-56-3",
+
+  "alice_30_214.npz": "train-30-56-4",
+
+  "alice_30_215.npz": "train-30-56-5",
+
+  "alice_30_216.npz": "train-30-57-0",
+
+  "alice_30_217.npz": "train-30-57-1",
+
+  "alice_30_218.npz": "train-30-57-2",
+
+  "alice_30_219.npz": "train-30-57-3",
+
+  "alice_30_220.npz": "train-30-57-4",
+
+  "alice_30_221.npz": "train-30-57-5",
+
+  "alice_30_222.npz": "train-30-57-6",
+
+  "alice_30_223.npz": "train-30-57-7",
+
+  "alice_30_224.npz": "train-30-57-8",
+
+  "alice_30_225.npz": "train-30-57-9",
+
+  "alice_30_226.npz": "train-30-58-0",
+
+  "alice_30_227.npz": "train-30-59-0",
+
+  "alice_30_228.npz": "train-30-59-1",
+
+  "alice_30_229.npz": "train-30-60-0",
+
+  "alice_30_230.npz": "train-30-60-1",
+
+  "alice_30_231.npz": "train-30-60-2",
+
+  "alice_30_232.npz": "train-30-60-3",
+
+  "alice_30_233.npz": "train-30-60-4",
+
+  "alice_30_234.npz": "train-30-61-0",
+
+  "alice_30_235.npz": "train-30-61-1",
+
+  "alice_30_236.npz": "train-30-61-2",
+
+  "alice_30_237.npz": "train-30-61-3",
+
+  "alice_30_238.npz": "train-30-61-4",
+
+  "alice_30_239.npz": "train-30-61-5",
+
+  "alice_30_240.npz": "train-30-61-6",
+
+  "alice_30_241.npz": "train-30-61-7",
+
+  "alice_30_242.npz": "train-30-61-8",
+
+  "alice_30_243.npz": "train-30-61-9",
+
+  "alice_30_244.npz": "train-30-61-10",
+
+  "alice_30_245.npz": "train-30-61-11",
+
+  "alice_30_246.npz": "train-30-61-12",
+
+  "alice_30_247.npz": "train-30-62-0",
+
+  "alice_30_248.npz": "train-30-62-1",
+
+  "alice_30_249.npz": "train-30-62-2",
+
+  "alice_30_250.npz": "train-30-62-3",
+
+  "alice_30_251.npz": "train-30-63-0",
+
+  "alice_30_252.npz": "train-30-63-1",
+
+  "alice_30_253.npz": "train-30-63-2",
+
+  "alice_30_254.npz": "train-30-63-3",
+
+  "alice_30_255.npz": "train-30-63-4",
+
+  "alice_30_256.npz": "train-30-63-5",
+
+  "alice_30_257.npz": "train-30-63-6",
+
+  "alice_30_258.npz": "train-30-63-7",
+
+  "alice_30_259.npz": "train-30-63-8",
+
+  "alice_30_260.npz": "train-30-63-9",
+
+  "alice_30_261.npz": "train-30-63-10",
+
+  "alice_30_262.npz": "train-30-63-11",
+
+  "alice_30_263.npz": "train-30-63-12",
+
+  "alice_30_264.npz": "train-30-63-13",
+
+  "alice_30_265.npz": "train-30-63-14",
+
+  "alice_30_266.npz": "train-30-63-15",
+
+  "alice_30_267.npz": "train-30-63-16",
+
+  "alice_30_268.npz": "train-30-63-17",
+
+  "alice_30_269.npz": "train-30-64-0",
+
+  "alice_30_270.npz": "train-30-64-1",
+
+  "alice_30_271.npz": "train-30-64-2",
+
+  "alice_30_272.npz": "train-30-64-3",
+
+  "alice_30_273.npz": "train-30-64-4",
+
+  "alice_30_274.npz": "train-30-64-5",
+
+  "alice_30_275.npz": "train-30-64-6",
+
+  "alice_30_276.npz": "train-30-64-7",
+
+  "alice_30_277.npz": "train-30-64-8",
+
+  "alice_30_278.npz": "train-30-64-9",
+
+  "alice_30_279.npz": "train-30-64-9",
+
+  "alice_30_280.npz": "train-30-65-0",
+
+  "alice_30_281.npz": "train-30-66-0",
+
+  "alice_43_0.npz": "train-43-0-0",
+
+  "alice_43_1.npz": "train-43-0-1",
+
+  "alice_43_2.npz": "train-43-0-2",
+
+  "alice_43_3.npz": "train-43-0-3",
+
+  "alice_43_4.npz": "train-43-0-4",
+
+  "alice_43_5.npz": "train-43-0-5",
+
+  "alice_43_6.npz": "train-43-0-6",
+
+  "alice_43_7.npz": "train-43-0-7",
+
+  "alice_43_8.npz": "train-43-0-8",
+
+  "alice_43_9.npz": "train-43-1-0",
+
+  "alice_43_10.npz": "train-43-1-1",
+
+  "alice_43_11.npz": "train-43-1-2",
+
+  "alice_43_12.npz": "train-43-1-3",
+
+  "alice_43_13.npz": "train-43-1-4",
+
+  "alice_43_14.npz": "train-43-1-5",
+
+  "alice_43_15.npz": "train-43-1-6",
+
+  "alice_43_16.npz": "train-43-1-7",
+
+  "alice_43_17.npz": "train-43-1-8",
+
+  "alice_43_18.npz": "train-43-1-9",
+
+  "alice_43_19.npz": "train-43-2-0",
+
+  "alice_43_20.npz": "train-43-2-1",
+
+  "alice_43_21.npz": "train-43-2-2",
+
+  "alice_43_22.npz": "train-43-2-3",
+
+  "alice_43_23.npz": "train-43-3-0",
+
+  "alice_43_24.npz": "train-43-4-0",
+
+  "alice_43_25.npz": "train-43-5-0",
+
+  "alice_43_26.npz": "train-43-5-1",
+
+  "alice_43_27.npz": "train-43-5-2",
+
+  "alice_43_28.npz": "train-43-5-3",
+
+  "alice_43_29.npz": "train-43-5-4",
+
+  "alice_43_30.npz": "train-43-5-5",
+
+  "alice_43_31.npz": "train-43-5-6",
+
+  "alice_43_32.npz": "train-43-5-7",
+
+  "alice_43_33.npz": "train-43-5-8",
+
+  "alice_43_34.npz": "train-43-5-9",
+
+  "alice_43_35.npz": "train-43-5-10",
+
+  "alice_43_36.npz": "train-43-5-11",
+
+  "alice_43_37.npz": "train-43-5-12",
+
+  "alice_43_38.npz": "train-43-5-13",
+
+  "alice_43_39.npz": "train-43-5-14",
+
+  "alice_43_40.npz": "train-43-5-15",
+
+  "alice_43_41.npz": "train-43-5-16",
+
+  "alice_43_42.npz": "train-43-5-17",
+
+  "alice_43_43.npz": "train-43-6-0",
+
+  "alice_43_44.npz": "train-43-6-1",
+
+  "alice_43_45.npz": "train-43-6-2",
+
+  "alice_43_46.npz": "train-43-6-3",
+
+  "alice_43_47.npz": "train-43-7-0",
+
+  "alice_43_48.npz": "train-43-7-1",
+
+  "alice_43_49.npz": "train-43-7-2",
+
+  "alice_43_50.npz": "train-43-7-3",
+
+  "alice_43_51.npz": "train-43-7-4",
+
+  "alice_43_52.npz": "train-43-7-5",
+
+  "alice_43_53.npz": "train-43-8-0",
+
+  "alice_43_54.npz": "train-43-8-1",
+
+  "alice_43_55.npz": "train-43-8-2",
+
+  "alice_43_56.npz": "train-43-8-3",
+
+  "alice_43_57.npz": "train-43-8-4",
+
+  "alice_43_58.npz": "train-43-8-5",
+
+  "alice_43_59.npz": "train-43-9-0",
+
+  "alice_43_60.npz": "train-43-9-1",
+
+  "alice_43_61.npz": "train-43-9-2",
+
+  "alice_43_62.npz": "train-43-9-3",
+
+  "alice_43_63.npz": "train-43-9-4",
+
+  "alice_43_64.npz": "train-43-9-5",
+
+  "alice_43_65.npz": "train-43-9-6",
+
+  "alice_43_66.npz": "train-43-9-7",
+
+  "alice_43_67.npz": "train-43-9-8",
+
+  "alice_43_68.npz": "train-43-10-0",
+
+  "alice_43_69.npz": "train-43-10-1",
+
+  "alice_43_70.npz": "train-43-10-2",
+
+  "alice_43_71.npz": "train-43-10-3",
+
+  "alice_43_72.npz": "train-43-10-4",
+
+  "alice_43_73.npz": "train-43-10-5",
+
+  "alice_43_74.npz": "train-43-10-6",
+
+  "alice_43_75.npz": "train-43-10-7",
+
+  "alice_43_76.npz": "train-43-10-8",
+
+  "alice_43_77.npz": "train-43-12-0",
+
+  "alice_43_78.npz": "train-43-12-1",
+
+  "alice_43_79.npz": "train-43-12-2",
+
+  "alice_43_80.npz": "train-43-13-0",
+
+  "alice_43_81.npz": "train-43-14-0",
+
+  "alice_43_82.npz": "train-43-14-1",
+
+  "alice_43_83.npz": "train-43-14-2",
+
+  "alice_43_84.npz": "train-43-15-0",
+
+  "alice_43_85.npz": "train-43-16-0",
+
+  "alice_43_86.npz": "train-43-17-0",
+
+  "alice_43_87.npz": "train-43-17-1",
+
+  "alice_43_88.npz": "train-43-18-0",
+
+  "alice_43_89.npz": "train-43-18-1",
+
+  "alice_43_90.npz": "train-43-20-0",
+
+  "alice_43_91.npz": "train-43-20-1",
+
+  "alice_43_92.npz": "train-43-21-0",
+
+  "alice_43_93.npz": "train-43-21-1",
+
+  "alice_43_94.npz": "train-43-21-2",
+
+  "alice_43_95.npz": "train-43-21-3",
+
+  "alice_43_96.npz": "train-43-21-4",
+
+  "alice_43_97.npz": "train-43-21-5",
+
+  "alice_43_98.npz": "train-43-21-6",
+
+  "alice_43_99.npz": "train-43-21-7",
+
+  "alice_43_100.npz": "train-43-21-8",
+
+  "alice_43_101.npz": "train-43-21-9",
+
+  "alice_43_102.npz": "train-43-21-10",
+
+  "alice_43_103.npz": "train-43-21-11",
+
+  "alice_43_104.npz": "train-43-22-0",
+
+  "alice_43_105.npz": "train-43-22-1",
+
+  "alice_43_106.npz": "train-43-22-2",
+
+  "alice_43_107.npz": "train-43-22-3",
+
+  "alice_43_108.npz": "train-43-23-0",
+
+  "alice_43_109.npz": "train-43-24-0",
+
+  "alice_43_110.npz": "train-43-24-1",
+
+  "alice_43_111.npz": "train-43-25-0",
+
+  "alice_43_112.npz": "train-43-25-1",
+
+  "alice_43_113.npz": "train-43-26-0",
+
+  "alice_43_114.npz": "train-43-26-1",
+
+  "alice_43_115.npz": "train-43-26-2",
+
+  "alice_43_116.npz": "train-43-26-3",
+
+  "alice_43_117.npz": "train-43-26-4",
+
+  "alice_43_118.npz": "train-43-26-5",
+
+  "alice_43_119.npz": "train-43-26-6",
+
+  "alice_43_120.npz": "train-43-27-0",
+
+  "alice_43_121.npz": "train-43-27-1",
+
+  "alice_43_122.npz": "train-43-28-0",
+
+  "alice_43_123.npz": "train-43-28-1",
+
+  "alice_43_124.npz": "train-43-29-0",
+
+  "alice_43_125.npz": "train-43-29-1",
+
+  "alice_43_126.npz": "train-43-30-0",
+
+  "alice_43_127.npz": "train-43-31-0",
+
+  "alice_43_128.npz": "train-43-31-1",
+
+  "alice_43_129.npz": "train-43-31-2",
+
+  "alice_43_130.npz": "train-43-32-0",
+
+  "alice_43_131.npz": "train-43-33-0",
+
+  "alice_43_132.npz": "train-43-33-1",
+
+  "alice_43_133.npz": "train-43-33-2",
+
+  "alice_43_134.npz": "train-43-34-0",
+
+  "alice_43_135.npz": "train-43-34-1",
+
+  "alice_43_136.npz": "train-43-35-0",
+
+  "alice_43_137.npz": "train-43-36-0",
+
+  "alice_43_138.npz": "train-43-36-1",
+
+  "alice_43_139.npz": "train-43-38-0",
+
+  "alice_43_140.npz": "train-43-39-0",
+
+  "alice_43_141.npz": "train-43-39-1",
+
+  "alice_43_142.npz": "train-43-39-2",
+
+  "alice_43_143.npz": "train-43-39-3",
+
+  "alice_43_144.npz": "train-43-40-0",
+
+  "alice_43_145.npz": "train-43-41-0",
+
+  "alice_43_146.npz": "train-43-41-1",
+
+  "alice_43_147.npz": "train-43-41-2",
+
+  "alice_43_148.npz": "train-43-41-3",
+
+  "alice_43_149.npz": "train-43-42-0",
+
+  "alice_43_150.npz": "train-43-43-0",
+
+  "alice_43_151.npz": "train-43-44-0",
+
+  "alice_43_152.npz": "train-43-44-1",
+
+  "alice_43_153.npz": "train-43-44-2",
+
+  "alice_43_154.npz": "train-43-45-0",
+
+  "alice_43_155.npz": "train-43-45-1",
+
+  "alice_43_156.npz": "train-43-45-2",
+
+  "alice_43_157.npz": "train-43-45-3",
+
+  "alice_43_158.npz": "train-43-45-4",
+
+  "alice_43_159.npz": "train-43-45-5",
+
+  "alice_43_160.npz": "train-43-45-6",
+
+  "alice_43_161.npz": "train-43-46-0",
+
+  "alice_43_162.npz": "train-43-48-0",
+
+  "alice_43_163.npz": "train-43-48-1",
+
+  "alice_43_164.npz": "train-43-48-2",
+
+  "alice_43_165.npz": "train-43-49-0",
+
+  "alice_43_166.npz": "train-43-49-1",
+
+  "alice_43_167.npz": "train-43-49-2",
+
+  "alice_43_168.npz": "train-43-49-3",
+
+  "alice_43_169.npz": "train-43-49-4",
+
+  "alice_43_170.npz": "train-43-49-5",
+
+  "alice_43_171.npz": "train-43-49-6",
+
+  "alice_43_172.npz": "train-43-50-0",
+
+  "alice_43_173.npz": "train-43-50-1",
+
+  "alice_43_174.npz": "train-43-50-2",
+
+  "alice_43_175.npz": "train-43-50-3",
+
+  "alice_43_176.npz": "train-43-50-4",
+
+  "alice_43_177.npz": "train-43-51-0",
+
+  "alice_43_178.npz": "train-43-51-1",
+
+  "alice_43_179.npz": "train-43-51-2",
+
+  "alice_43_180.npz": "train-43-51-3",
+
+  "alice_43_181.npz": "train-43-51-4",
+
+  "alice_43_182.npz": "train-43-51-5",
+
+  "alice_43_183.npz": "train-43-52-0",
+
+  "alice_43_184.npz": "train-43-52-1",
+
+  "alice_43_185.npz": "train-43-52-2",
+
+  "alice_43_186.npz": "train-43-52-3",
+
+  "alice_43_187.npz": "train-43-52-4",
+
+  "alice_43_188.npz": "train-43-52-5",
+
+  "alice_43_189.npz": "train-43-52-6",
+
+  "alice_43_190.npz": "train-43-52-7",
+
+  "alice_43_191.npz": "train-43-53-0",
+
+  "alice_43_192.npz": "train-43-53-1",
+
+  "alice_43_193.npz": "train-43-53-2",
+
+  "alice_43_194.npz": "train-43-53-3",
+
+  "alice_43_195.npz": "train-43-53-4",
+
+  "alice_43_196.npz": "train-43-53-5",
+
+  "alice_43_197.npz": "train-43-53-6",
+
+  "alice_43_198.npz": "train-43-54-0",
+
+  "alice_43_199.npz": "train-43-54-1",
+
+  "alice_43_200.npz": "train-43-54-2",
+
+  "alice_43_201.npz": "train-43-54-3",
+
+  "alice_43_202.npz": "train-43-55-0",
+
+  "alice_43_203.npz": "train-43-55-1",
+
+  "alice_43_204.npz": "train-43-55-2",
+
+  "alice_43_205.npz": "train-43-55-3",
+
+  "alice_43_206.npz": "train-43-55-4",
+
+  "alice_43_207.npz": "train-43-55-5",
+
+  "alice_43_208.npz": "train-43-55-6",
+
+  "alice_43_209.npz": "train-43-55-7",
+
+  "alice_43_210.npz": "train-43-56-0",
+
+  "alice_43_211.npz": "train-43-56-1",
+
+  "alice_43_212.npz": "train-43-56-2",
+
+  "alice_43_213.npz": "train-43-56-3",
+
+  "alice_43_214.npz": "train-43-56-4",
+
+  "alice_43_215.npz": "train-43-56-5",
+
+  "alice_43_216.npz": "train-43-57-0",
+
+  "alice_43_217.npz": "train-43-57-1",
+
+  "alice_43_218.npz": "train-43-57-2",
+
+  "alice_43_219.npz": "train-43-57-3",
+
+  "alice_43_220.npz": "train-43-57-4",
+
+  "alice_43_221.npz": "train-43-57-5",
+
+  "alice_43_222.npz": "train-43-57-6",
+
+  "alice_43_223.npz": "train-43-57-7",
+
+  "alice_43_224.npz": "train-43-57-8",
+
+  "alice_43_225.npz": "train-43-57-9",
+
+  "alice_43_226.npz": "train-43-58-0",
+
+  "alice_43_227.npz": "train-43-59-0",
+
+  "alice_43_228.npz": "train-43-59-1",
+
+  "alice_43_229.npz": "train-43-60-0",
+
+  "alice_43_230.npz": "train-43-60-1",
+
+  "alice_43_231.npz": "train-43-60-2",
+
+  "alice_43_232.npz": "train-43-60-3",
+
+  "alice_43_233.npz": "train-43-60-4",
+
+  "alice_43_234.npz": "train-43-61-0",
+
+  "alice_43_235.npz": "train-43-61-1",
+
+  "alice_43_236.npz": "train-43-61-2",
+
+  "alice_43_237.npz": "train-43-61-3",
+
+  "alice_43_238.npz": "train-43-61-4",
+
+  "alice_43_239.npz": "train-43-61-5",
+
+  "alice_43_240.npz": "train-43-61-6",
+
+  "alice_43_241.npz": "train-43-61-7",
+
+  "alice_43_242.npz": "train-43-61-8",
+
+  "alice_43_243.npz": "train-43-61-9",
+
+  "alice_43_244.npz": "train-43-61-10",
+
+  "alice_43_245.npz": "train-43-61-11",
+
+  "alice_43_246.npz": "train-43-61-12",
+
+  "alice_43_247.npz": "train-43-62-0",
+
+  "alice_43_248.npz": "train-43-62-1",
+
+  "alice_43_249.npz": "train-43-62-2",
+
+  "alice_43_250.npz": "train-43-62-3",
+
+  "alice_43_251.npz": "train-43-63-0",
+
+  "alice_43_252.npz": "train-43-63-1",
+
+  "alice_43_253.npz": "train-43-63-2",
+
+  "alice_43_254.npz": "train-43-63-3",
+
+  "alice_43_255.npz": "train-43-63-4",
+
+  "alice_43_256.npz": "train-43-63-5",
+
+  "alice_43_257.npz": "train-43-63-6",
+
+  "alice_43_258.npz": "train-43-63-7",
+
+  "alice_43_259.npz": "train-43-63-8",
+
+  "alice_43_260.npz": "train-43-63-9",
+
+  "alice_43_261.npz": "train-43-63-10",
+
+  "alice_43_262.npz": "train-43-63-11",
+
+  "alice_43_263.npz": "train-43-63-12",
+
+  "alice_43_264.npz": "train-43-63-13",
+
+  "alice_43_265.npz": "train-43-63-14",
+
+  "alice_43_266.npz": "train-43-63-15",
+
+  "alice_43_267.npz": "train-43-63-16",
+
+  "alice_43_268.npz": "train-43-63-17",
+
+  "alice_43_269.npz": "train-43-64-0",
+
+  "alice_43_270.npz": "train-43-64-1",
+
+  "alice_43_271.npz": "train-43-64-2",
+
+  "alice_43_272.npz": "train-43-64-3",
+
+  "alice_43_273.npz": "train-43-64-4",
+
+  "alice_43_274.npz": "train-43-64-5",
+
+  "alice_43_275.npz": "train-43-64-6",
+
+  "alice_43_276.npz": "train-43-64-7",
+
+  "alice_43_277.npz": "train-43-64-8",
+
+  "alice_43_278.npz": "train-43-64-9",
+  "alice_43_279.npz": "train-43-64-9",
+
+  "alice_43_280.npz": "train-43-65-0",
+
+  "alice_43_281.npz": "train-43-66-0",
+
+  "alice_45_0.npz": "train-45-0-0",
+
+  "alice_45_1.npz": "train-45-0-1",
+
+  "alice_45_2.npz": "train-45-0-2",
+
+  "alice_45_3.npz": "train-45-0-3",
+
+  "alice_45_4.npz": "train-45-0-4",
+
+  "alice_45_5.npz": "train-45-0-5",
+
+  "alice_45_6.npz": "train-45-0-6",
+
+  "alice_45_7.npz": "train-45-0-7",
+
+  "alice_45_8.npz": "train-45-0-8",
+
+  "alice_45_9.npz": "train-45-1-0",
+
+  "alice_45_10.npz": "train-45-1-1",
+
+  "alice_45_11.npz": "train-45-1-2",
+
+  "alice_45_12.npz": "train-45-1-3",
+
+  "alice_45_13.npz": "train-45-1-4",
+
+  "alice_45_14.npz": "train-45-1-5",
+
+  "alice_45_15.npz": "train-45-1-6",
+
+  "alice_45_16.npz": "train-45-1-7",
+
+  "alice_45_17.npz": "train-45-1-8",
+
+  "alice_45_18.npz": "train-45-1-9",
+
+  "alice_45_19.npz": "train-45-2-0",
+
+  "alice_45_20.npz": "train-45-2-1",
+
+  "alice_45_21.npz": "train-45-2-2",
+
+  "alice_45_22.npz": "train-45-2-3",
+
+  "alice_45_23.npz": "train-45-3-0",
+
+  "alice_45_24.npz": "train-45-4-0",
+
+  "alice_45_25.npz": "train-45-5-0",
+
+  "alice_45_26.npz": "train-45-5-1",
+
+  "alice_45_27.npz": "train-45-5-2",
+
+  "alice_45_28.npz": "train-45-5-3",
+
+  "alice_45_29.npz": "train-45-5-4",
+
+  "alice_45_30.npz": "train-45-5-5",
+
+  "alice_45_31.npz": "train-45-5-6",
+
+  "alice_45_32.npz": "train-45-5-7",
+
+  "alice_45_33.npz": "train-45-5-8",
+
+  "alice_45_34.npz": "train-45-5-9",
+
+  "alice_45_35.npz": "train-45-5-10",
+
+  "alice_45_36.npz": "train-45-5-11",
+
+  "alice_45_37.npz": "train-45-5-12",
+
+  "alice_45_38.npz": "train-45-5-13",
+
+  "alice_45_39.npz": "train-45-5-14",
+
+  "alice_45_40.npz": "train-45-5-15",
+
+  "alice_45_41.npz": "train-45-5-16",
+
+  "alice_45_42.npz": "train-45-5-17",
+
+  "alice_45_43.npz": "train-45-6-0",
+
+  "alice_45_44.npz": "train-45-6-1",
+
+  "alice_45_45.npz": "train-45-6-2",
+
+  "alice_45_46.npz": "train-45-6-3",
+
+  "alice_45_47.npz": "train-45-7-0",
+
+  "alice_45_48.npz": "train-45-7-1",
+
+  "alice_45_49.npz": "train-45-7-2",
+
+  "alice_45_50.npz": "train-45-7-3",
+
+  "alice_45_51.npz": "train-45-7-4",
+
+  "alice_45_52.npz": "train-45-7-5",
+
+  "alice_45_53.npz": "train-45-8-0",
+
+  "alice_45_54.npz": "train-45-8-1",
+
+  "alice_45_55.npz": "train-45-8-2",
+
+  "alice_45_56.npz": "train-45-8-3",
+
+  "alice_45_57.npz": "train-45-8-4",
+
+  "alice_45_58.npz": "train-45-8-5",
+
+  "alice_45_59.npz": "train-45-9-0",
+
+  "alice_45_60.npz": "train-45-9-1",
+
+  "alice_45_61.npz": "train-45-9-2",
+
+  "alice_45_62.npz": "train-45-9-3",
+
+  "alice_45_63.npz": "train-45-9-4",
+
+  "alice_45_64.npz": "train-45-9-5",
+
+  "alice_45_65.npz": "train-45-9-6",
+
+  "alice_45_66.npz": "train-45-9-7",
+
+  "alice_45_67.npz": "train-45-9-8",
+
+  "alice_45_68.npz": "train-45-10-0",
+
+  "alice_45_69.npz": "train-45-10-1",
+
+  "alice_45_70.npz": "train-45-10-2",
+
+  "alice_45_71.npz": "train-45-10-3",
+
+  "alice_45_72.npz": "train-45-10-4",
+
+  "alice_45_73.npz": "train-45-10-5",
+
+  "alice_45_74.npz": "train-45-10-6",
+
+  "alice_45_75.npz": "train-45-10-7",
+
+  "alice_45_76.npz": "train-45-10-8",
+
+  "alice_45_77.npz": "train-45-12-0",
+
+  "alice_45_78.npz": "train-45-12-1",
+
+  "alice_45_79.npz": "train-45-12-2",
+
+  "alice_45_80.npz": "train-45-13-0",
+
+  "alice_45_81.npz": "train-45-14-0",
+
+  "alice_45_82.npz": "train-45-14-1",
+
+  "alice_45_83.npz": "train-45-14-2",
+
+  "alice_45_84.npz": "train-45-15-0",
+
+  "alice_45_85.npz": "train-45-16-0",
+
+  "alice_45_86.npz": "train-45-17-0",
+
+  "alice_45_87.npz": "train-45-17-1",
+
+  "alice_45_88.npz": "train-45-18-0",
+
+  "alice_45_89.npz": "train-45-18-1",
+
+  "alice_45_90.npz": "train-45-20-0",
+
+  "alice_45_91.npz": "train-45-20-1",
+
+  "alice_45_92.npz": "train-45-21-0",
+
+  "alice_45_93.npz": "train-45-21-1",
+
+  "alice_45_94.npz": "train-45-21-2",
+
+  "alice_45_95.npz": "train-45-21-3",
+
+  "alice_45_96.npz": "train-45-21-4",
+
+  "alice_45_97.npz": "train-45-21-5",
+
+  "alice_45_98.npz": "train-45-21-6",
+
+  "alice_45_99.npz": "train-45-21-7",
+
+  "alice_45_100.npz": "train-45-21-8",
+
+  "alice_45_101.npz": "train-45-21-9",
+
+  "alice_45_102.npz": "train-45-21-10",
+
+  "alice_45_103.npz": "train-45-21-11",
+
+  "alice_45_104.npz": "train-45-22-0",
+
+  "alice_45_105.npz": "train-45-22-1",
+
+  "alice_45_106.npz": "train-45-22-2",
+
+  "alice_45_107.npz": "train-45-22-3",
+
+  "alice_45_108.npz": "train-45-23-0",
+
+  "alice_45_109.npz": "train-45-24-0",
+
+  "alice_45_110.npz": "train-45-24-1",
+
+  "alice_45_111.npz": "train-45-25-0",
+
+  "alice_45_112.npz": "train-45-25-1",
+
+  "alice_45_113.npz": "train-45-26-0",
+
+  "alice_45_114.npz": "train-45-26-1",
+
+  "alice_45_115.npz": "train-45-26-2",
+
+  "alice_45_116.npz": "train-45-26-3",
+
+  "alice_45_117.npz": "train-45-26-4",
+
+  "alice_45_118.npz": "train-45-26-5",
+
+  "alice_45_119.npz": "train-45-26-6",
+
+  "alice_45_120.npz": "train-45-27-0",
+
+  "alice_45_121.npz": "train-45-27-1",
+
+  "alice_45_122.npz": "train-45-28-0",
+
+  "alice_45_123.npz": "train-45-28-1",
+
+  "alice_45_124.npz": "train-45-29-0",
+
+  "alice_45_125.npz": "train-45-29-1",
+
+  "alice_45_126.npz": "train-45-30-0",
+
+  "alice_45_127.npz": "train-45-31-0",
+
+  "alice_45_128.npz": "train-45-31-1",
+
+  "alice_45_129.npz": "train-45-31-2",
+
+  "alice_45_130.npz": "train-45-32-0",
+
+  "alice_45_131.npz": "train-45-33-0",
+
+  "alice_45_132.npz": "train-45-33-1",
+
+  "alice_45_133.npz": "train-45-33-2",
+
+  "alice_45_134.npz": "train-45-34-0",
+
+  "alice_45_135.npz": "train-45-34-1",
+
+  "alice_45_136.npz": "train-45-35-0",
+
+  "alice_45_137.npz": "train-45-36-0",
+
+  "alice_45_138.npz": "train-45-36-1",
+
+  "alice_45_139.npz": "train-45-38-0",
+
+  "alice_45_140.npz": "train-45-39-0",
+
+  "alice_45_141.npz": "train-45-39-1",
+
+  "alice_45_142.npz": "train-45-39-2",
+
+  "alice_45_143.npz": "train-45-39-3",
+
+  "alice_45_144.npz": "train-45-40-0",
+
+  "alice_45_145.npz": "train-45-41-0",
+
+  "alice_45_146.npz": "train-45-41-1",
+
+  "alice_45_147.npz": "train-45-41-2",
+
+  "alice_45_148.npz": "train-45-41-3",
+
+  "alice_45_149.npz": "train-45-42-0",
+
+  "alice_45_150.npz": "train-45-43-0",
+
+  "alice_45_151.npz": "train-45-44-0",
+
+  "alice_45_152.npz": "train-45-44-1",
+
+  "alice_45_153.npz": "train-45-44-2",
+
+  "alice_45_154.npz": "train-45-45-0",
+
+  "alice_45_155.npz": "train-45-45-1",
+
+  "alice_45_156.npz": "train-45-45-2",
+
+  "alice_45_157.npz": "train-45-45-3",
+
+  "alice_45_158.npz": "train-45-45-4",
+
+  "alice_45_159.npz": "train-45-45-5",
+
+  "alice_45_160.npz": "train-45-45-6",
+
+  "alice_45_161.npz": "train-45-46-0",
+
+  "alice_45_162.npz": "train-45-48-0",
+
+  "alice_45_163.npz": "train-45-48-1",
+
+  "alice_45_164.npz": "train-45-48-2",
+
+  "alice_45_165.npz": "train-45-49-0",
+
+  "alice_45_166.npz": "train-45-49-1",
+
+  "alice_45_167.npz": "train-45-49-2",
+
+  "alice_45_168.npz": "train-45-49-3",
+
+  "alice_45_169.npz": "train-45-49-4",
+
+  "alice_45_170.npz": "train-45-49-5",
+
+  "alice_45_171.npz": "train-45-49-6",
+
+  "alice_45_172.npz": "train-45-50-0",
+
+  "alice_45_173.npz": "train-45-50-1",
+
+  "alice_45_174.npz": "train-45-50-2",
+
+  "alice_45_175.npz": "train-45-50-3",
+
+  "alice_45_176.npz": "train-45-50-4",
+
+  "alice_45_177.npz": "train-45-51-0",
+
+  "alice_45_178.npz": "train-45-51-1",
+
+  "alice_45_179.npz": "train-45-51-2",
+
+  "alice_45_180.npz": "train-45-51-3",
+
+  "alice_45_181.npz": "train-45-51-4",
+
+  "alice_45_182.npz": "train-45-51-5",
+
+  "alice_45_183.npz": "train-45-52-0",
+
+  "alice_45_184.npz": "train-45-52-1",
+
+  "alice_45_185.npz": "train-45-52-2",
+
+  "alice_45_186.npz": "train-45-52-3",
+
+  "alice_45_187.npz": "train-45-52-4",
+
+  "alice_45_188.npz": "train-45-52-5",
+
+  "alice_45_189.npz": "train-45-52-6",
+
+  "alice_45_190.npz": "train-45-52-7",
+
+  "alice_45_191.npz": "train-45-53-0",
+
+  "alice_45_192.npz": "train-45-53-1",
+
+  "alice_45_193.npz": "train-45-53-2",
+
+  "alice_45_194.npz": "train-45-53-3",
+
+  "alice_45_195.npz": "train-45-53-4",
+
+  "alice_45_196.npz": "train-45-53-5",
+
+  "alice_45_197.npz": "train-45-53-6",
+
+  "alice_45_198.npz": "train-45-54-0",
+
+  "alice_45_199.npz": "train-45-54-1",
+
+  "alice_45_200.npz": "train-45-54-2",
+
+  "alice_45_201.npz": "train-45-54-3",
+
+  "alice_45_202.npz": "train-45-55-0",
+
+  "alice_45_203.npz": "train-45-55-1",
+
+  "alice_45_204.npz": "train-45-55-2",
+
+  "alice_45_205.npz": "train-45-55-3",
+
+  "alice_45_206.npz": "train-45-55-4",
+
+  "alice_45_207.npz": "train-45-55-5",
+
+  "alice_45_208.npz": "train-45-55-6",
+
+  "alice_45_209.npz": "train-45-55-7",
+
+  "alice_45_210.npz": "train-45-56-0",
+
+  "alice_45_211.npz": "train-45-56-1",
+
+  "alice_45_212.npz": "train-45-56-2",
+
+  "alice_45_213.npz": "train-45-56-3",
+
+  "alice_45_214.npz": "train-45-56-4",
+
+  "alice_45_215.npz": "train-45-56-5",
+
+  "alice_45_216.npz": "train-45-57-0",
+
+  "alice_45_217.npz": "train-45-57-1",
+
+  "alice_45_218.npz": "train-45-57-2",
+
+  "alice_45_219.npz": "train-45-57-3",
+
+  "alice_45_220.npz": "train-45-57-4",
+
+  "alice_45_221.npz": "train-45-57-5",
+
+  "alice_45_222.npz": "train-45-57-6",
+
+  "alice_45_223.npz": "train-45-57-7",
+
+  "alice_45_224.npz": "train-45-57-8",
+
+  "alice_45_225.npz": "train-45-57-9",
+
+  "alice_45_226.npz": "train-45-58-0",
+
+  "alice_45_227.npz": "train-45-59-0",
+
+  "alice_45_228.npz": "train-45-59-1",
+
+  "alice_45_229.npz": "train-45-60-0",
+
+  "alice_45_230.npz": "train-45-60-1",
+
+  "alice_45_231.npz": "train-45-60-2",
+
+  "alice_45_232.npz": "train-45-60-3",
+
+  "alice_45_233.npz": "train-45-60-4",
+
+  "alice_45_234.npz": "train-45-61-0",
+
+  "alice_45_235.npz": "train-45-61-1",
+
+  "alice_45_236.npz": "train-45-61-2",
+
+  "alice_45_237.npz": "train-45-61-3",
+
+  "alice_45_238.npz": "train-45-61-4",
+
+  "alice_45_239.npz": "train-45-61-5",
+
+  "alice_45_240.npz": "train-45-61-6",
+
+  "alice_45_241.npz": "train-45-61-7",
+
+  "alice_45_242.npz": "train-45-61-8",
+
+  "alice_45_243.npz": "train-45-61-9",
+
+  "alice_45_244.npz": "train-45-61-10",
+
+  "alice_45_245.npz": "train-45-61-11",
+
+  "alice_45_246.npz": "train-45-61-12",
+
+  "alice_45_247.npz": "train-45-62-0",
+
+  "alice_45_248.npz": "train-45-62-1",
+
+  "alice_45_249.npz": "train-45-62-2",
+
+  "alice_45_250.npz": "train-45-62-3",
+
+  "alice_45_251.npz": "train-45-63-0",
+
+  "alice_45_252.npz": "train-45-63-1",
+
+  "alice_45_253.npz": "train-45-63-2",
+
+  "alice_45_254.npz": "train-45-63-3",
+
+  "alice_45_255.npz": "train-45-63-4",
+
+  "alice_45_256.npz": "train-45-63-5",
+
+  "alice_45_257.npz": "train-45-63-6",
+
+  "alice_45_258.npz": "train-45-63-7",
+
+  "alice_45_259.npz": "train-45-63-8",
+
+  "alice_45_260.npz": "train-45-63-9",
+
+  "alice_45_261.npz": "train-45-63-10",
+
+  "alice_45_262.npz": "train-45-63-11",
+
+  "alice_45_263.npz": "train-45-63-12",
+
+  "alice_45_264.npz": "train-45-63-13",
+
+  "alice_45_265.npz": "train-45-63-14",
+
+  "alice_45_266.npz": "train-45-63-15",
+
+  "alice_45_267.npz": "train-45-63-16",
+
+  "alice_45_268.npz": "train-45-63-17",
+
+  "alice_45_269.npz": "train-45-64-0",
+
+  "alice_45_270.npz": "train-45-64-1",
+
+  "alice_45_271.npz": "train-45-64-2",
+
+  "alice_45_272.npz": "train-45-64-3",
+
+  "alice_45_273.npz": "train-45-64-4",
+
+  "alice_45_274.npz": "train-45-64-5",
+
+  "alice_45_275.npz": "train-45-64-6",
+
+  "alice_45_276.npz": "train-45-64-7",
+
+  "alice_45_277.npz": "train-45-64-8",
+
+  "alice_45_278.npz": "train-45-64-9",
+  "alice_45_279.npz": "train-45-64-9",
+
+  "alice_45_280.npz": "train-45-65-0",
+
+  "alice_45_281.npz": "train-45-66-0",
+
+  "alice_49_0.npz": "train-49-0-0",
+
+  "alice_49_1.npz": "train-49-0-1",
+
+  "alice_49_2.npz": "train-49-0-2",
+
+  "alice_49_3.npz": "train-49-0-3",
+
+  "alice_49_4.npz": "train-49-0-4",
+
+  "alice_49_5.npz": "train-49-0-5",
+
+  "alice_49_6.npz": "train-49-0-6",
+
+  "alice_49_7.npz": "train-49-0-7",
+
+  "alice_49_8.npz": "train-49-0-8",
+
+  "alice_49_9.npz": "train-49-1-0",
+
+  "alice_49_10.npz": "train-49-1-1",
+
+  "alice_49_11.npz": "train-49-1-2",
+
+  "alice_49_12.npz": "train-49-1-3",
+
+  "alice_49_13.npz": "train-49-1-4",
+
+  "alice_49_14.npz": "train-49-1-5",
+
+  "alice_49_15.npz": "train-49-1-6",
+
+  "alice_49_16.npz": "train-49-1-7",
+
+  "alice_49_17.npz": "train-49-1-8",
+
+  "alice_49_18.npz": "train-49-1-9",
+
+  "alice_49_19.npz": "train-49-2-0",
+
+  "alice_49_20.npz": "train-49-2-1",
+
+  "alice_49_21.npz": "train-49-2-2",
+
+  "alice_49_22.npz": "train-49-2-3",
+
+  "alice_49_23.npz": "train-49-3-0",
+
+  "alice_49_24.npz": "train-49-4-0",
+
+  "alice_49_25.npz": "train-49-5-0",
+
+  "alice_49_26.npz": "train-49-5-1",
+
+  "alice_49_27.npz": "train-49-5-2",
+
+  "alice_49_28.npz": "train-49-5-3",
+
+  "alice_49_29.npz": "train-49-5-4",
+
+  "alice_49_30.npz": "train-49-5-5",
+
+  "alice_49_31.npz": "train-49-5-6",
+
+  "alice_49_32.npz": "train-49-5-7",
+
+  "alice_49_33.npz": "train-49-5-8",
+
+  "alice_49_34.npz": "train-49-5-9",
+
+  "alice_49_35.npz": "train-49-5-10",
+
+  "alice_49_36.npz": "train-49-5-11",
+
+  "alice_49_37.npz": "train-49-5-12",
+
+  "alice_49_38.npz": "train-49-5-13",
+
+  "alice_49_39.npz": "train-49-5-14",
+
+  "alice_49_40.npz": "train-49-5-15",
+
+  "alice_49_41.npz": "train-49-5-16",
+
+  "alice_49_42.npz": "train-49-5-17",
+
+  "alice_49_43.npz": "train-49-6-0",
+
+  "alice_49_44.npz": "train-49-6-1",
+
+  "alice_49_45.npz": "train-49-6-2",
+
+  "alice_49_46.npz": "train-49-6-3",
+
+  "alice_49_47.npz": "train-49-7-0",
+
+  "alice_49_48.npz": "train-49-7-1",
+
+  "alice_49_49.npz": "train-49-7-2",
+
+  "alice_49_50.npz": "train-49-7-3",
+
+  "alice_49_51.npz": "train-49-7-4",
+
+  "alice_49_52.npz": "train-49-7-5",
+
+  "alice_49_53.npz": "train-49-8-0",
+
+  "alice_49_54.npz": "train-49-8-1",
+
+  "alice_49_55.npz": "train-49-8-2",
+
+  "alice_49_56.npz": "train-49-8-3",
+
+  "alice_49_57.npz": "train-49-8-4",
+
+  "alice_49_58.npz": "train-49-8-5",
+
+  "alice_49_59.npz": "train-49-9-0",
+
+  "alice_49_60.npz": "train-49-9-1",
+
+  "alice_49_61.npz": "train-49-9-2",
+
+  "alice_49_62.npz": "train-49-9-3",
+
+  "alice_49_63.npz": "train-49-9-4",
+
+  "alice_49_64.npz": "train-49-9-5",
+
+  "alice_49_65.npz": "train-49-9-6",
+
+  "alice_49_66.npz": "train-49-9-7",
+
+  "alice_49_67.npz": "train-49-9-8",
+
+  "alice_49_68.npz": "train-49-10-0",
+
+  "alice_49_69.npz": "train-49-10-1",
+
+  "alice_49_70.npz": "train-49-10-2",
+
+  "alice_49_71.npz": "train-49-10-3",
+
+  "alice_49_72.npz": "train-49-10-4",
+
+  "alice_49_73.npz": "train-49-10-5",
+
+  "alice_49_74.npz": "train-49-10-6",
+
+  "alice_49_75.npz": "train-49-10-7",
+
+  "alice_49_76.npz": "train-49-10-8",
+
+  "alice_49_77.npz": "train-49-12-0",
+
+  "alice_49_78.npz": "train-49-12-1",
+
+  "alice_49_79.npz": "train-49-12-2",
+
+  "alice_49_80.npz": "train-49-13-0",
+
+  "alice_49_81.npz": "train-49-14-0",
+
+  "alice_49_82.npz": "train-49-14-1",
+
+  "alice_49_83.npz": "train-49-14-2",
+
+  "alice_49_84.npz": "train-49-15-0",
+
+  "alice_49_85.npz": "train-49-16-0",
+
+  "alice_49_86.npz": "train-49-17-0",
+
+  "alice_49_87.npz": "train-49-17-1",
+
+  "alice_49_88.npz": "train-49-18-0",
+
+  "alice_49_89.npz": "train-49-18-1",
+
+  "alice_49_90.npz": "train-49-20-0",
+
+  "alice_49_91.npz": "train-49-20-1",
+
+  "alice_49_92.npz": "train-49-21-0",
+
+  "alice_49_93.npz": "train-49-21-1",
+
+  "alice_49_94.npz": "train-49-21-2",
+
+  "alice_49_95.npz": "train-49-21-3",
+
+  "alice_49_96.npz": "train-49-21-4",
+
+  "alice_49_97.npz": "train-49-21-5",
+
+  "alice_49_98.npz": "train-49-21-6",
+
+  "alice_49_99.npz": "train-49-21-7",
+
+  "alice_49_100.npz": "train-49-21-8",
+
+  "alice_49_101.npz": "train-49-21-9",
+
+  "alice_49_102.npz": "train-49-21-10",
+
+  "alice_49_103.npz": "train-49-21-11",
+
+  "alice_49_104.npz": "train-49-22-0",
+
+  "alice_49_105.npz": "train-49-22-1",
+
+  "alice_49_106.npz": "train-49-22-2",
+
+  "alice_49_107.npz": "train-49-22-3",
+
+  "alice_49_108.npz": "train-49-23-0",
+
+  "alice_49_109.npz": "train-49-24-0",
+
+  "alice_49_110.npz": "train-49-24-1",
+
+  "alice_49_111.npz": "train-49-25-0",
+
+  "alice_49_112.npz": "train-49-25-1",
+
+  "alice_49_113.npz": "train-49-26-0",
+
+  "alice_49_114.npz": "train-49-26-1",
+
+  "alice_49_115.npz": "train-49-26-2",
+
+  "alice_49_116.npz": "train-49-26-3",
+
+  "alice_49_117.npz": "train-49-26-4",
+
+  "alice_49_118.npz": "train-49-26-5",
+
+  "alice_49_119.npz": "train-49-26-6",
+
+  "alice_49_120.npz": "train-49-27-0",
+
+  "alice_49_121.npz": "train-49-27-1",
+
+  "alice_49_122.npz": "train-49-28-0",
+
+  "alice_49_123.npz": "train-49-28-1",
+
+  "alice_49_124.npz": "train-49-29-0",
+
+  "alice_49_125.npz": "train-49-29-1",
+
+  "alice_49_126.npz": "train-49-30-0",
+
+  "alice_49_127.npz": "train-49-31-0",
+
+  "alice_49_128.npz": "train-49-31-1",
+
+  "alice_49_129.npz": "train-49-31-2",
+
+  "alice_49_130.npz": "train-49-32-0",
+
+  "alice_49_131.npz": "train-49-33-0",
+
+  "alice_49_132.npz": "train-49-33-1",
+
+  "alice_49_133.npz": "train-49-33-2",
+
+  "alice_49_134.npz": "train-49-34-0",
+
+  "alice_49_135.npz": "train-49-34-1",
+
+  "alice_49_136.npz": "train-49-35-0",
+
+  "alice_49_137.npz": "train-49-36-0",
+
+  "alice_49_138.npz": "train-49-36-1",
+
+  "alice_49_139.npz": "train-49-38-0",
+
+  "alice_49_140.npz": "train-49-39-0",
+
+  "alice_49_141.npz": "train-49-39-1",
+
+  "alice_49_142.npz": "train-49-39-2",
+
+  "alice_49_143.npz": "train-49-39-3",
+
+  "alice_49_144.npz": "train-49-40-0",
+
+  "alice_49_145.npz": "train-49-41-0",
+
+  "alice_49_146.npz": "train-49-41-1",
+
+  "alice_49_147.npz": "train-49-41-2",
+
+  "alice_49_148.npz": "train-49-41-3",
+
+  "alice_49_149.npz": "train-49-42-0",
+
+  "alice_49_150.npz": "train-49-43-0",
+
+  "alice_49_151.npz": "train-49-44-0",
+
+  "alice_49_152.npz": "train-49-44-1",
+
+  "alice_49_153.npz": "train-49-44-2",
+
+  "alice_49_154.npz": "train-49-45-0",
+
+  "alice_49_155.npz": "train-49-45-1",
+
+  "alice_49_156.npz": "train-49-45-2",
+
+  "alice_49_157.npz": "train-49-45-3",
+
+  "alice_49_158.npz": "train-49-45-4",
+
+  "alice_49_159.npz": "train-49-45-5",
+
+  "alice_49_160.npz": "train-49-45-6",
+
+  "alice_49_161.npz": "train-49-46-0",
+
+  "alice_49_162.npz": "train-49-48-0",
+
+  "alice_49_163.npz": "train-49-48-1",
+
+  "alice_49_164.npz": "train-49-48-2",
+
+  "alice_49_165.npz": "train-49-49-0",
+
+  "alice_49_166.npz": "train-49-49-1",
+
+  "alice_49_167.npz": "train-49-49-2",
+
+  "alice_49_168.npz": "train-49-49-3",
+
+  "alice_49_169.npz": "train-49-49-4",
+
+  "alice_49_170.npz": "train-49-49-5",
+
+  "alice_49_171.npz": "train-49-49-6",
+
+  "alice_49_172.npz": "train-49-50-0",
+
+  "alice_49_173.npz": "train-49-50-1",
+
+  "alice_49_174.npz": "train-49-50-2",
+
+  "alice_49_175.npz": "train-49-50-3",
+
+  "alice_49_176.npz": "train-49-50-4",
+
+  "alice_49_177.npz": "train-49-51-0",
+
+  "alice_49_178.npz": "train-49-51-1",
+
+  "alice_49_179.npz": "train-49-51-2",
+
+  "alice_49_180.npz": "train-49-51-3",
+
+  "alice_49_181.npz": "train-49-51-4",
+
+  "alice_49_182.npz": "train-49-51-5",
+
+  "alice_49_183.npz": "train-49-52-0",
+
+  "alice_49_184.npz": "train-49-52-1",
+
+  "alice_49_185.npz": "train-49-52-2",
+
+  "alice_49_186.npz": "train-49-52-3",
+
+  "alice_49_187.npz": "train-49-52-4",
+
+  "alice_49_188.npz": "train-49-52-5",
+
+  "alice_49_189.npz": "train-49-52-6",
+
+  "alice_49_190.npz": "train-49-52-7",
+
+  "alice_49_191.npz": "train-49-53-0",
+
+  "alice_49_192.npz": "train-49-53-1",
+
+  "alice_49_193.npz": "train-49-53-2",
+
+  "alice_49_194.npz": "train-49-53-3",
+
+  "alice_49_195.npz": "train-49-53-4",
+
+  "alice_49_196.npz": "train-49-53-5",
+
+  "alice_49_197.npz": "train-49-53-6",
+
+  "alice_49_198.npz": "train-49-54-0",
+
+  "alice_49_199.npz": "train-49-54-1",
+
+  "alice_49_200.npz": "train-49-54-2",
+
+  "alice_49_201.npz": "train-49-54-3",
+
+  "alice_49_202.npz": "train-49-55-0",
+
+  "alice_49_203.npz": "train-49-55-1",
+
+  "alice_49_204.npz": "train-49-55-2",
+
+  "alice_49_205.npz": "train-49-55-3",
+
+  "alice_49_206.npz": "train-49-55-4",
+
+  "alice_49_207.npz": "train-49-55-5",
+
+  "alice_49_208.npz": "train-49-55-6",
+
+  "alice_49_209.npz": "train-49-55-7",
+
+  "alice_49_210.npz": "train-49-56-0",
+
+  "alice_49_211.npz": "train-49-56-1",
+
+  "alice_49_212.npz": "train-49-56-2",
+
+  "alice_49_213.npz": "train-49-56-3",
+
+  "alice_49_214.npz": "train-49-56-4",
+
+  "alice_49_215.npz": "train-49-56-5",
+
+  "alice_49_216.npz": "train-49-57-0",
+
+  "alice_49_217.npz": "train-49-57-1",
+
+  "alice_49_218.npz": "train-49-57-2",
+
+  "alice_49_219.npz": "train-49-57-3",
+
+  "alice_49_220.npz": "train-49-57-4",
+
+  "alice_49_221.npz": "train-49-57-5",
+
+  "alice_49_222.npz": "train-49-57-6",
+
+  "alice_49_223.npz": "train-49-57-7",
+
+  "alice_49_224.npz": "train-49-57-8",
+
+  "alice_49_225.npz": "train-49-57-9",
+
+  "alice_49_226.npz": "train-49-58-0",
+
+  "alice_49_227.npz": "train-49-59-0",
+
+  "alice_49_228.npz": "train-49-59-1",
+
+  "alice_49_229.npz": "train-49-60-0",
+
+  "alice_49_230.npz": "train-49-60-1",
+
+  "alice_49_231.npz": "train-49-60-2",
+
+  "alice_49_232.npz": "train-49-60-3",
+
+  "alice_49_233.npz": "train-49-60-4",
+
+  "alice_49_234.npz": "train-49-61-0",
+
+  "alice_49_235.npz": "train-49-61-1",
+
+  "alice_49_236.npz": "train-49-61-2",
+
+  "alice_49_237.npz": "train-49-61-3",
+
+  "alice_49_238.npz": "train-49-61-4",
+
+  "alice_49_239.npz": "train-49-61-5",
+
+  "alice_49_240.npz": "train-49-61-6",
+
+  "alice_49_241.npz": "train-49-61-7",
+
+  "alice_49_242.npz": "train-49-61-8",
+
+  "alice_49_243.npz": "train-49-61-9",
+
+  "alice_49_244.npz": "train-49-61-10",
+
+  "alice_49_245.npz": "train-49-61-11",
+
+  "alice_49_246.npz": "train-49-61-12",
+
+  "alice_49_247.npz": "train-49-62-0",
+
+  "alice_49_248.npz": "train-49-62-1",
+
+  "alice_49_249.npz": "train-49-62-2",
+
+  "alice_49_250.npz": "train-49-62-3",
+
+  "alice_49_251.npz": "train-49-63-0",
+
+  "alice_49_252.npz": "train-49-63-1",
+
+  "alice_49_253.npz": "train-49-63-2",
+
+  "alice_49_254.npz": "train-49-63-3",
+
+  "alice_49_255.npz": "train-49-63-4",
+
+  "alice_49_256.npz": "train-49-63-5",
+
+  "alice_49_257.npz": "train-49-63-6",
+
+  "alice_49_258.npz": "train-49-63-7",
+
+  "alice_49_259.npz": "train-49-63-8",
+
+  "alice_49_260.npz": "train-49-63-9",
+
+  "alice_49_261.npz": "train-49-63-10",
+
+  "alice_49_262.npz": "train-49-63-11",
+
+  "alice_49_263.npz": "train-49-63-12",
+
+  "alice_49_264.npz": "train-49-63-13",
+
+  "alice_49_265.npz": "train-49-63-14",
+
+  "alice_49_266.npz": "train-49-63-15",
+
+  "alice_49_267.npz": "train-49-63-16",
+
+  "alice_49_268.npz": "train-49-63-17",
+
+  "alice_49_269.npz": "train-49-64-0",
+
+  "alice_49_270.npz": "train-49-64-1",
+
+  "alice_49_271.npz": "train-49-64-2",
+
+  "alice_49_272.npz": "train-49-64-3",
+
+  "alice_49_273.npz": "train-49-64-4",
+
+  "alice_49_274.npz": "train-49-64-5",
+
+  "alice_49_275.npz": "train-49-64-6",
+
+  "alice_49_276.npz": "train-49-64-7",
+
+  "alice_49_277.npz": "train-49-64-8",
+
+  "alice_49_278.npz": "train-49-64-9",
+
+  "alice_49_279.npz": "train-49-64-9",
+
+
+  "alice_49_280.npz": "train-49-65-0",
+
+  "alice_49_281.npz": "train-49-66-0",
+
+  "alice_26_0.npz": "train-26-0-0",
+
+  "alice_26_1.npz": "train-26-0-1",
+
+  "alice_26_2.npz": "train-26-0-2",
+
+  "alice_26_3.npz": "train-26-0-3",
+
+  "alice_26_4.npz": "train-26-0-4",
+
+  "alice_26_5.npz": "train-26-0-5",
+
+  "alice_26_6.npz": "train-26-0-6",
+
+  "alice_26_7.npz": "train-26-0-7",
+
+  "alice_26_8.npz": "train-26-0-8",
+
+  "alice_26_9.npz": "train-26-1-0",
+
+  "alice_26_10.npz": "train-26-1-1",
+
+  "alice_26_11.npz": "train-26-1-2",
+
+  "alice_26_12.npz": "train-26-1-3",
+
+  "alice_26_13.npz": "train-26-1-4",
+
+  "alice_26_14.npz": "train-26-1-5",
+
+  "alice_26_15.npz": "train-26-1-6",
+
+  "alice_26_16.npz": "train-26-1-7",
+
+  "alice_26_17.npz": "train-26-1-8",
+
+  "alice_26_18.npz": "train-26-1-9",
+
+  "alice_26_19.npz": "train-26-2-0",
+
+  "alice_26_20.npz": "train-26-2-1",
+
+  "alice_26_21.npz": "train-26-2-2",
+
+  "alice_26_22.npz": "train-26-2-3",
+
+  "alice_26_23.npz": "train-26-3-0",
+
+  "alice_26_24.npz": "train-26-4-0",
+
+  "alice_26_25.npz": "train-26-5-0",
+
+  "alice_26_26.npz": "train-26-5-1",
+
+  "alice_26_27.npz": "train-26-5-2",
+
+  "alice_26_28.npz": "train-26-5-3",
+
+  "alice_26_29.npz": "train-26-5-4",
+
+  "alice_26_30.npz": "train-26-5-5",
+
+  "alice_26_31.npz": "train-26-5-6",
+
+  "alice_26_32.npz": "train-26-5-7",
+
+  "alice_26_33.npz": "train-26-5-8",
+
+  "alice_26_34.npz": "train-26-5-9",
+
+  "alice_26_35.npz": "train-26-5-10",
+
+  "alice_26_36.npz": "train-26-5-11",
+
+  "alice_26_37.npz": "train-26-5-12",
+
+  "alice_26_38.npz": "train-26-5-13",
+
+  "alice_26_39.npz": "train-26-5-14",
+
+  "alice_26_40.npz": "train-26-5-15",
+
+  "alice_26_41.npz": "train-26-5-16",
+
+  "alice_26_42.npz": "train-26-5-17",
+
+  "alice_26_43.npz": "train-26-6-0",
+
+  "alice_26_44.npz": "train-26-6-1",
+
+  "alice_26_45.npz": "train-26-6-2",
+
+  "alice_26_46.npz": "train-26-6-3",
+
+  "alice_26_47.npz": "train-26-7-0",
+
+  "alice_26_48.npz": "train-26-7-1",
+
+  "alice_26_49.npz": "train-26-7-2",
+
+  "alice_26_50.npz": "train-26-7-3",
+
+  "alice_26_51.npz": "train-26-7-4",
+
+  "alice_26_52.npz": "train-26-7-5",
+
+  "alice_26_53.npz": "train-26-8-0",
+
+  "alice_26_54.npz": "train-26-8-1",
+
+  "alice_26_55.npz": "train-26-8-2",
+
+  "alice_26_56.npz": "train-26-8-3",
+
+  "alice_26_57.npz": "train-26-8-4",
+
+  "alice_26_58.npz": "train-26-8-5",
+
+  "alice_26_59.npz": "train-26-9-0",
+
+  "alice_26_60.npz": "train-26-9-1",
+
+  "alice_26_61.npz": "train-26-9-2",
+
+  "alice_26_62.npz": "train-26-9-3",
+
+  "alice_26_63.npz": "train-26-9-4",
+
+  "alice_26_64.npz": "train-26-9-5",
+
+  "alice_26_65.npz": "train-26-9-6",
+
+  "alice_26_66.npz": "train-26-9-7",
+
+  "alice_26_67.npz": "train-26-9-8",
+
+  "alice_26_68.npz": "train-26-10-0",
+
+  "alice_26_69.npz": "train-26-10-1",
+
+  "alice_26_70.npz": "train-26-10-2",
+
+  "alice_26_71.npz": "train-26-10-3",
+
+  "alice_26_72.npz": "train-26-10-4",
+
+  "alice_26_73.npz": "train-26-10-5",
+
+  "alice_26_74.npz": "train-26-10-6",
+
+  "alice_26_75.npz": "train-26-10-7",
+
+  "alice_26_76.npz": "train-26-10-8",
+
+  "alice_26_77.npz": "train-26-12-0",
+
+  "alice_26_78.npz": "train-26-12-1",
+
+  "alice_26_79.npz": "train-26-12-2",
+
+  "alice_26_80.npz": "train-26-13-0",
+
+  "alice_26_81.npz": "train-26-14-0",
+
+  "alice_26_82.npz": "train-26-14-1",
+
+  "alice_26_83.npz": "train-26-14-2",
+
+  "alice_26_84.npz": "train-26-15-0",
+
+  "alice_26_85.npz": "train-26-16-0",
+
+  "alice_26_86.npz": "train-26-17-0",
+
+  "alice_26_87.npz": "train-26-17-1",
+
+  "alice_26_88.npz": "train-26-18-0",
+
+  "alice_26_89.npz": "train-26-18-1",
+
+  "alice_26_90.npz": "train-26-20-0",
+
+  "alice_26_91.npz": "train-26-20-1",
+
+  "alice_26_92.npz": "train-26-21-0",
+
+  "alice_26_93.npz": "train-26-21-1",
+
+  "alice_26_94.npz": "train-26-21-2",
+
+  "alice_26_95.npz": "train-26-21-3",
+
+  "alice_26_96.npz": "train-26-21-4",
+
+  "alice_26_97.npz": "train-26-21-5",
+
+  "alice_26_98.npz": "train-26-21-6",
+
+  "alice_26_99.npz": "train-26-21-7",
+
+  "alice_26_100.npz": "train-26-21-8",
+
+  "alice_26_101.npz": "train-26-21-9",
+
+  "alice_26_102.npz": "train-26-21-10",
+
+  "alice_26_103.npz": "train-26-21-11",
+
+  "alice_26_104.npz": "train-26-22-0",
+
+  "alice_26_105.npz": "train-26-22-1",
+
+  "alice_26_106.npz": "train-26-22-2",
+
+  "alice_26_107.npz": "train-26-22-3",
+
+  "alice_26_108.npz": "train-26-23-0",
+
+  "alice_26_109.npz": "train-26-24-0",
+
+  "alice_26_110.npz": "train-26-24-1",
+
+  "alice_26_111.npz": "train-26-25-0",
+
+  "alice_26_112.npz": "train-26-25-1",
+
+  "alice_26_113.npz": "train-26-26-0",
+
+  "alice_26_114.npz": "train-26-26-1",
+
+  "alice_26_115.npz": "train-26-26-2",
+
+  "alice_26_116.npz": "train-26-26-3",
+
+  "alice_26_117.npz": "train-26-26-4",
+
+  "alice_26_118.npz": "train-26-26-5",
+
+  "alice_26_119.npz": "train-26-26-6",
+
+  "alice_26_120.npz": "train-26-27-0",
+
+  "alice_26_121.npz": "train-26-27-1",
+
+  "alice_26_122.npz": "train-26-28-0",
+
+  "alice_26_123.npz": "train-26-28-1",
+
+  "alice_26_124.npz": "train-26-29-0",
+
+  "alice_26_125.npz": "train-26-29-1",
+
+  "alice_26_126.npz": "train-26-30-0",
+
+  "alice_26_127.npz": "train-26-31-0",
+
+  "alice_26_128.npz": "train-26-31-1",
+
+  "alice_26_129.npz": "train-26-31-2",
+
+  "alice_26_130.npz": "train-26-32-0",
+
+  "alice_26_131.npz": "train-26-33-0",
+
+  "alice_26_132.npz": "train-26-33-1",
+
+  "alice_26_133.npz": "train-26-33-2",
+
+  "alice_26_134.npz": "train-26-34-0",
+
+  "alice_26_135.npz": "train-26-34-1",
+
+  "alice_26_136.npz": "train-26-35-0",
+
+  "alice_26_137.npz": "train-26-36-0",
+
+  "alice_26_138.npz": "train-26-36-1",
+
+  "alice_26_139.npz": "train-26-38-0",
+
+  "alice_26_140.npz": "train-26-39-0",
+
+  "alice_26_141.npz": "train-26-39-1",
+
+  "alice_26_142.npz": "train-26-39-2",
+
+  "alice_26_143.npz": "train-26-39-3",
+
+  "alice_26_144.npz": "train-26-40-0",
+
+  "alice_26_145.npz": "train-26-41-0",
+
+  "alice_26_146.npz": "train-26-41-1",
+
+  "alice_26_147.npz": "train-26-41-2",
+
+  "alice_26_148.npz": "train-26-41-3",
+
+  "alice_26_149.npz": "train-26-42-0",
+
+  "alice_26_150.npz": "train-26-43-0",
+
+  "alice_26_151.npz": "train-26-44-0",
+
+  "alice_26_152.npz": "train-26-44-1",
+
+  "alice_26_153.npz": "train-26-44-2",
+
+  "alice_26_154.npz": "train-26-45-0",
+
+  "alice_26_155.npz": "train-26-45-1",
+
+  "alice_26_156.npz": "train-26-45-2",
+
+  "alice_26_157.npz": "train-26-45-3",
+
+  "alice_26_158.npz": "train-26-45-4",
+
+  "alice_26_159.npz": "train-26-45-5",
+
+  "alice_26_160.npz": "train-26-45-6",
+
+  "alice_26_161.npz": "train-26-46-0",
+
+  "alice_26_162.npz": "train-26-48-0",
+
+  "alice_26_163.npz": "train-26-48-1",
+
+  "alice_26_164.npz": "train-26-48-2",
+
+  "alice_26_165.npz": "train-26-49-0",
+
+  "alice_26_166.npz": "train-26-49-1",
+
+  "alice_26_167.npz": "train-26-49-2",
+
+  "alice_26_168.npz": "train-26-49-3",
+
+  "alice_26_169.npz": "train-26-49-4",
+
+  "alice_26_170.npz": "train-26-49-5",
+
+  "alice_26_171.npz": "train-26-49-6",
+
+  "alice_26_172.npz": "train-26-50-0",
+
+  "alice_26_173.npz": "train-26-50-1",
+
+  "alice_26_174.npz": "train-26-50-2",
+
+  "alice_26_175.npz": "train-26-50-3",
+
+  "alice_26_176.npz": "train-26-50-4",
+
+  "alice_26_177.npz": "train-26-51-0",
+
+  "alice_26_178.npz": "train-26-51-1",
+
+  "alice_26_179.npz": "train-26-51-2",
+
+  "alice_26_180.npz": "train-26-51-3",
+
+  "alice_26_181.npz": "train-26-51-4",
+
+  "alice_26_182.npz": "train-26-51-5",
+
+  "alice_26_183.npz": "train-26-52-0",
+
+  "alice_26_184.npz": "train-26-52-1",
+
+  "alice_26_185.npz": "train-26-52-2",
+
+  "alice_26_186.npz": "train-26-52-3",
+
+  "alice_26_187.npz": "train-26-52-4",
+
+  "alice_26_188.npz": "train-26-52-5",
+
+  "alice_26_189.npz": "train-26-52-6",
+
+  "alice_26_190.npz": "train-26-52-7",
+
+  "alice_26_191.npz": "train-26-53-0",
+
+  "alice_26_192.npz": "train-26-53-1",
+
+  "alice_26_193.npz": "train-26-53-2",
+
+  "alice_26_194.npz": "train-26-53-3",
+
+  "alice_26_195.npz": "train-26-53-4",
+
+  "alice_26_196.npz": "train-26-53-5",
+
+  "alice_26_197.npz": "train-26-53-6",
+
+  "alice_26_198.npz": "train-26-54-0",
+
+  "alice_26_199.npz": "train-26-54-1",
+
+  "alice_26_200.npz": "train-26-54-2",
+
+  "alice_26_201.npz": "train-26-54-3",
+
+  "alice_26_202.npz": "train-26-55-0",
+
+  "alice_26_203.npz": "train-26-55-1",
+
+  "alice_26_204.npz": "train-26-55-2",
+
+  "alice_26_205.npz": "train-26-55-3",
+
+  "alice_26_206.npz": "train-26-55-4",
+
+  "alice_26_207.npz": "train-26-55-5",
+
+  "alice_26_208.npz": "train-26-55-6",
+
+  "alice_26_209.npz": "train-26-55-7",
+
+  "alice_26_210.npz": "train-26-56-0",
+
+  "alice_26_211.npz": "train-26-56-1",
+
+  "alice_26_212.npz": "train-26-56-2",
+
+  "alice_26_213.npz": "train-26-56-3",
+
+  "alice_26_214.npz": "train-26-56-4",
+
+  "alice_26_215.npz": "train-26-56-5",
+
+  "alice_26_216.npz": "train-26-57-0",
+
+  "alice_26_217.npz": "train-26-57-1",
+
+  "alice_26_218.npz": "train-26-57-2",
+
+  "alice_26_219.npz": "train-26-57-3",
+
+  "alice_26_220.npz": "train-26-57-4",
+
+  "alice_26_221.npz": "train-26-57-5",
+
+  "alice_26_222.npz": "train-26-57-6",
+
+  "alice_26_223.npz": "train-26-57-7",
+
+  "alice_26_224.npz": "train-26-57-8",
+
+  "alice_26_225.npz": "train-26-57-9",
+
+  "alice_26_226.npz": "train-26-58-0",
+
+  "alice_26_227.npz": "train-26-59-0",
+
+  "alice_26_228.npz": "train-26-59-1",
+
+  "alice_26_229.npz": "train-26-60-0",
+
+  "alice_26_230.npz": "train-26-60-1",
+
+  "alice_26_231.npz": "train-26-60-2",
+
+  "alice_26_232.npz": "train-26-60-3",
+
+  "alice_26_233.npz": "train-26-60-4",
+
+  "alice_26_234.npz": "train-26-61-0",
+
+  "alice_26_235.npz": "train-26-61-1",
+
+  "alice_26_236.npz": "train-26-61-2",
+
+  "alice_26_237.npz": "train-26-61-3",
+
+  "alice_26_238.npz": "train-26-61-4",
+
+  "alice_26_239.npz": "train-26-61-5",
+
+  "alice_26_240.npz": "train-26-61-6",
+
+  "alice_26_241.npz": "train-26-61-7",
+
+  "alice_26_242.npz": "train-26-61-8",
+
+  "alice_26_243.npz": "train-26-61-9",
+
+  "alice_26_244.npz": "train-26-61-10",
+
+  "alice_26_245.npz": "train-26-61-11",
+
+  "alice_26_246.npz": "train-26-61-12",
+
+  "alice_26_247.npz": "train-26-62-0",
+
+  "alice_26_248.npz": "train-26-62-1",
+
+  "alice_26_249.npz": "train-26-62-2",
+
+  "alice_26_250.npz": "train-26-62-3",
+
+  "alice_26_251.npz": "train-26-63-0",
+
+  "alice_26_252.npz": "train-26-63-1",
+
+  "alice_26_253.npz": "train-26-63-2",
+
+  "alice_26_254.npz": "train-26-63-3",
+
+  "alice_26_255.npz": "train-26-63-4",
+
+  "alice_26_256.npz": "train-26-63-5",
+
+  "alice_26_257.npz": "train-26-63-6",
+
+  "alice_26_258.npz": "train-26-63-7",
+
+  "alice_26_259.npz": "train-26-63-8",
+
+  "alice_26_260.npz": "train-26-63-9",
+
+  "alice_26_261.npz": "train-26-63-10",
+
+  "alice_26_262.npz": "train-26-63-11",
+
+  "alice_26_263.npz": "train-26-63-12",
+
+  "alice_26_264.npz": "train-26-63-13",
+
+  "alice_26_265.npz": "train-26-63-14",
+
+  "alice_26_266.npz": "train-26-63-15",
+
+  "alice_26_267.npz": "train-26-63-16",
+
+  "alice_26_268.npz": "train-26-63-17",
+
+  "alice_26_269.npz": "train-26-64-0",
+
+  "alice_26_270.npz": "train-26-64-1",
+
+  "alice_26_271.npz": "train-26-64-2",
+
+  "alice_26_272.npz": "train-26-64-3",
+
+  "alice_26_273.npz": "train-26-64-4",
+
+  "alice_26_274.npz": "train-26-64-5",
+
+  "alice_26_275.npz": "train-26-64-6",
+
+  "alice_26_276.npz": "train-26-64-7",
+
+  "alice_26_277.npz": "train-26-64-8",
+
+  "alice_26_278.npz": "train-26-64-9",
+  "alice_26_279.npz": "train-26-64-9",
+
+  "alice_26_280.npz": "train-26-65-0",
+
+  "alice_26_281.npz": "train-26-66-0",
+
+  "alice_22_0.npz": "train-22-0-0",
+
+  "alice_22_1.npz": "train-22-0-1",
+
+  "alice_22_2.npz": "train-22-0-2",
+
+  "alice_22_3.npz": "train-22-0-3",
+
+  "alice_22_4.npz": "train-22-0-4",
+
+  "alice_22_5.npz": "train-22-0-5",
+
+  "alice_22_6.npz": "train-22-0-6",
+
+  "alice_22_7.npz": "train-22-0-7",
+
+  "alice_22_8.npz": "train-22-0-8",
+
+  "alice_22_9.npz": "train-22-1-0",
+
+  "alice_22_10.npz": "train-22-1-1",
+
+  "alice_22_11.npz": "train-22-1-2",
+
+  "alice_22_12.npz": "train-22-1-3",
+
+  "alice_22_13.npz": "train-22-1-4",
+
+  "alice_22_14.npz": "train-22-1-5",
+
+  "alice_22_15.npz": "train-22-1-6",
+
+  "alice_22_16.npz": "train-22-1-7",
+
+  "alice_22_17.npz": "train-22-1-8",
+
+  "alice_22_18.npz": "train-22-1-9",
+
+  "alice_22_19.npz": "train-22-2-0",
+
+  "alice_22_20.npz": "train-22-2-1",
+
+  "alice_22_21.npz": "train-22-2-2",
+
+  "alice_22_22.npz": "train-22-2-3",
+
+  "alice_22_23.npz": "train-22-3-0",
+
+  "alice_22_24.npz": "train-22-4-0",
+
+  "alice_22_25.npz": "train-22-5-0",
+
+  "alice_22_26.npz": "train-22-5-1",
+
+  "alice_22_27.npz": "train-22-5-2",
+
+  "alice_22_28.npz": "train-22-5-3",
+
+  "alice_22_29.npz": "train-22-5-4",
+
+  "alice_22_30.npz": "train-22-5-5",
+
+  "alice_22_31.npz": "train-22-5-6",
+
+  "alice_22_32.npz": "train-22-5-7",
+
+  "alice_22_33.npz": "train-22-5-8",
+
+  "alice_22_34.npz": "train-22-5-9",
+
+  "alice_22_35.npz": "train-22-5-10",
+
+  "alice_22_36.npz": "train-22-5-11",
+
+  "alice_22_37.npz": "train-22-5-12",
+
+  "alice_22_38.npz": "train-22-5-13",
+
+  "alice_22_39.npz": "train-22-5-14",
+
+  "alice_22_40.npz": "train-22-5-15",
+
+  "alice_22_41.npz": "train-22-5-16",
+
+  "alice_22_42.npz": "train-22-5-17",
+
+  "alice_22_43.npz": "train-22-6-0",
+
+  "alice_22_44.npz": "train-22-6-1",
+
+  "alice_22_45.npz": "train-22-6-2",
+
+  "alice_22_46.npz": "train-22-6-3",
+
+  "alice_22_47.npz": "train-22-7-0",
+
+  "alice_22_48.npz": "train-22-7-1",
+
+  "alice_22_49.npz": "train-22-7-2",
+
+  "alice_22_50.npz": "train-22-7-3",
+
+  "alice_22_51.npz": "train-22-7-4",
+
+  "alice_22_52.npz": "train-22-7-5",
+
+  "alice_22_53.npz": "train-22-8-0",
+
+  "alice_22_54.npz": "train-22-8-1",
+
+  "alice_22_55.npz": "train-22-8-2",
+
+  "alice_22_56.npz": "train-22-8-3",
+
+  "alice_22_57.npz": "train-22-8-4",
+
+  "alice_22_58.npz": "train-22-8-5",
+
+  "alice_22_59.npz": "train-22-9-0",
+
+  "alice_22_60.npz": "train-22-9-1",
+
+  "alice_22_61.npz": "train-22-9-2",
+
+  "alice_22_62.npz": "train-22-9-3",
+
+  "alice_22_63.npz": "train-22-9-4",
+
+  "alice_22_64.npz": "train-22-9-5",
+
+  "alice_22_65.npz": "train-22-9-6",
+
+  "alice_22_66.npz": "train-22-9-7",
+
+  "alice_22_67.npz": "train-22-9-8",
+
+  "alice_22_68.npz": "train-22-10-0",
+
+  "alice_22_69.npz": "train-22-10-1",
+
+  "alice_22_70.npz": "train-22-10-2",
+
+  "alice_22_71.npz": "train-22-10-3",
+
+  "alice_22_72.npz": "train-22-10-4",
+
+  "alice_22_73.npz": "train-22-10-5",
+
+  "alice_22_74.npz": "train-22-10-6",
+
+  "alice_22_75.npz": "train-22-10-7",
+
+  "alice_22_76.npz": "train-22-10-8",
+
+  "alice_22_77.npz": "train-22-12-0",
+
+  "alice_22_78.npz": "train-22-12-1",
+
+  "alice_22_79.npz": "train-22-12-2",
+
+  "alice_22_80.npz": "train-22-13-0",
+
+  "alice_22_81.npz": "train-22-14-0",
+
+  "alice_22_82.npz": "train-22-14-1",
+
+  "alice_22_83.npz": "train-22-14-2",
+
+  "alice_22_84.npz": "train-22-15-0",
+
+  "alice_22_85.npz": "train-22-16-0",
+
+  "alice_22_86.npz": "train-22-17-0",
+
+  "alice_22_87.npz": "train-22-17-1",
+
+  "alice_22_88.npz": "train-22-18-0",
+
+  "alice_22_89.npz": "train-22-18-1",
+
+  "alice_22_90.npz": "train-22-20-0",
+
+  "alice_22_91.npz": "train-22-20-1",
+
+  "alice_22_92.npz": "train-22-21-0",
+
+  "alice_22_93.npz": "train-22-21-1",
+
+  "alice_22_94.npz": "train-22-21-2",
+
+  "alice_22_95.npz": "train-22-21-3",
+
+  "alice_22_96.npz": "train-22-21-4",
+
+  "alice_22_97.npz": "train-22-21-5",
+
+  "alice_22_98.npz": "train-22-21-6",
+
+  "alice_22_99.npz": "train-22-21-7",
+
+  "alice_22_100.npz": "train-22-21-8",
+
+  "alice_22_101.npz": "train-22-21-9",
+
+  "alice_22_102.npz": "train-22-21-10",
+
+  "alice_22_103.npz": "train-22-21-11",
+
+  "alice_22_104.npz": "train-22-22-0",
+
+  "alice_22_105.npz": "train-22-22-1",
+
+  "alice_22_106.npz": "train-22-22-2",
+
+  "alice_22_107.npz": "train-22-22-3",
+
+  "alice_22_108.npz": "train-22-23-0",
+
+  "alice_22_109.npz": "train-22-24-0",
+
+  "alice_22_110.npz": "train-22-24-1",
+
+  "alice_22_111.npz": "train-22-25-0",
+
+  "alice_22_112.npz": "train-22-25-1",
+
+  "alice_22_113.npz": "train-22-26-0",
+
+  "alice_22_114.npz": "train-22-26-1",
+
+  "alice_22_115.npz": "train-22-26-2",
+
+  "alice_22_116.npz": "train-22-26-3",
+
+  "alice_22_117.npz": "train-22-26-4",
+
+  "alice_22_118.npz": "train-22-26-5",
+
+  "alice_22_119.npz": "train-22-26-6",
+
+  "alice_22_120.npz": "train-22-27-0",
+
+  "alice_22_121.npz": "train-22-27-1",
+
+  "alice_22_122.npz": "train-22-28-0",
+
+  "alice_22_123.npz": "train-22-28-1",
+
+  "alice_22_124.npz": "train-22-29-0",
+
+  "alice_22_125.npz": "train-22-29-1",
+
+  "alice_22_126.npz": "train-22-30-0",
+
+  "alice_22_127.npz": "train-22-31-0",
+
+  "alice_22_128.npz": "train-22-31-1",
+
+  "alice_22_129.npz": "train-22-31-2",
+
+  "alice_22_130.npz": "train-22-32-0",
+
+  "alice_22_131.npz": "train-22-33-0",
+
+  "alice_22_132.npz": "train-22-33-1",
+
+  "alice_22_133.npz": "train-22-33-2",
+
+  "alice_22_134.npz": "train-22-34-0",
+
+  "alice_22_135.npz": "train-22-34-1",
+
+  "alice_22_136.npz": "train-22-35-0",
+
+  "alice_22_137.npz": "train-22-36-0",
+
+  "alice_22_138.npz": "train-22-36-1",
+
+  "alice_22_139.npz": "train-22-38-0",
+
+  "alice_22_140.npz": "train-22-39-0",
+
+  "alice_22_141.npz": "train-22-39-1",
+
+  "alice_22_142.npz": "train-22-39-2",
+
+  "alice_22_143.npz": "train-22-39-3",
+
+  "alice_22_144.npz": "train-22-40-0",
+
+  "alice_22_145.npz": "train-22-41-0",
+
+  "alice_22_146.npz": "train-22-41-1",
+
+  "alice_22_147.npz": "train-22-41-2",
+
+  "alice_22_148.npz": "train-22-41-3",
+
+  "alice_22_149.npz": "train-22-42-0",
+
+  "alice_22_150.npz": "train-22-43-0",
+
+  "alice_22_151.npz": "train-22-44-0",
+
+  "alice_22_152.npz": "train-22-44-1",
+
+  "alice_22_153.npz": "train-22-44-2",
+
+  "alice_22_154.npz": "train-22-45-0",
+
+  "alice_22_155.npz": "train-22-45-1",
+
+  "alice_22_156.npz": "train-22-45-2",
+
+  "alice_22_157.npz": "train-22-45-3",
+
+  "alice_22_158.npz": "train-22-45-4",
+
+  "alice_22_159.npz": "train-22-45-5",
+
+  "alice_22_160.npz": "train-22-45-6",
+
+  "alice_22_161.npz": "train-22-46-0",
+
+  "alice_22_162.npz": "train-22-48-0",
+
+  "alice_22_163.npz": "train-22-48-1",
+
+  "alice_22_164.npz": "train-22-48-2",
+
+  "alice_22_165.npz": "train-22-49-0",
+
+  "alice_22_166.npz": "train-22-49-1",
+
+  "alice_22_167.npz": "train-22-49-2",
+
+  "alice_22_168.npz": "train-22-49-3",
+
+  "alice_22_169.npz": "train-22-49-4",
+
+  "alice_22_170.npz": "train-22-49-5",
+
+  "alice_22_171.npz": "train-22-49-6",
+
+  "alice_22_172.npz": "train-22-50-0",
+
+  "alice_22_173.npz": "train-22-50-1",
+
+  "alice_22_174.npz": "train-22-50-2",
+
+  "alice_22_175.npz": "train-22-50-3",
+
+  "alice_22_176.npz": "train-22-50-4",
+
+  "alice_22_177.npz": "train-22-51-0",
+
+  "alice_22_178.npz": "train-22-51-1",
+
+  "alice_22_179.npz": "train-22-51-2",
+
+  "alice_22_180.npz": "train-22-51-3",
+
+  "alice_22_181.npz": "train-22-51-4",
+
+  "alice_22_182.npz": "train-22-51-5",
+
+  "alice_22_183.npz": "train-22-52-0",
+
+  "alice_22_184.npz": "train-22-52-1",
+
+  "alice_22_185.npz": "train-22-52-2",
+
+  "alice_22_186.npz": "train-22-52-3",
+
+  "alice_22_187.npz": "train-22-52-4",
+
+  "alice_22_188.npz": "train-22-52-5",
+
+  "alice_22_189.npz": "train-22-52-6",
+
+  "alice_22_190.npz": "train-22-52-7",
+
+  "alice_22_191.npz": "train-22-53-0",
+
+  "alice_22_192.npz": "train-22-53-1",
+
+  "alice_22_193.npz": "train-22-53-2",
+
+  "alice_22_194.npz": "train-22-53-3",
+
+  "alice_22_195.npz": "train-22-53-4",
+
+  "alice_22_196.npz": "train-22-53-5",
+
+  "alice_22_197.npz": "train-22-53-6",
+
+  "alice_22_198.npz": "train-22-54-0",
+
+  "alice_22_199.npz": "train-22-54-1",
+
+  "alice_22_200.npz": "train-22-54-2",
+
+  "alice_22_201.npz": "train-22-54-3",
+
+  "alice_22_202.npz": "train-22-55-0",
+
+  "alice_22_203.npz": "train-22-55-1",
+
+  "alice_22_204.npz": "train-22-55-2",
+
+  "alice_22_205.npz": "train-22-55-3",
+
+  "alice_22_206.npz": "train-22-55-4",
+
+  "alice_22_207.npz": "train-22-55-5",
+
+  "alice_22_208.npz": "train-22-55-6",
+
+  "alice_22_209.npz": "train-22-55-7",
+
+  "alice_22_210.npz": "train-22-56-0",
+
+  "alice_22_211.npz": "train-22-56-1",
+
+  "alice_22_212.npz": "train-22-56-2",
+
+  "alice_22_213.npz": "train-22-56-3",
+
+  "alice_22_214.npz": "train-22-56-4",
+
+  "alice_22_215.npz": "train-22-56-5",
+
+  "alice_22_216.npz": "train-22-57-0",
+
+  "alice_22_217.npz": "train-22-57-1",
+
+  "alice_22_218.npz": "train-22-57-2",
+
+  "alice_22_219.npz": "train-22-57-3",
+
+  "alice_22_220.npz": "train-22-57-4",
+
+  "alice_22_221.npz": "train-22-57-5",
+
+  "alice_22_222.npz": "train-22-57-6",
+
+  "alice_22_223.npz": "train-22-57-7",
+
+  "alice_22_224.npz": "train-22-57-8",
+
+  "alice_22_225.npz": "train-22-57-9",
+
+  "alice_22_226.npz": "train-22-58-0",
+
+  "alice_22_227.npz": "train-22-59-0",
+
+  "alice_22_228.npz": "train-22-59-1",
+
+  "alice_22_229.npz": "train-22-60-0",
+
+  "alice_22_230.npz": "train-22-60-1",
+
+  "alice_22_231.npz": "train-22-60-2",
+
+  "alice_22_232.npz": "train-22-60-3",
+
+  "alice_22_233.npz": "train-22-60-4",
+
+  "alice_22_234.npz": "train-22-61-0",
+
+  "alice_22_235.npz": "train-22-61-1",
+
+  "alice_22_236.npz": "train-22-61-2",
+
+  "alice_22_237.npz": "train-22-61-3",
+
+  "alice_22_238.npz": "train-22-61-4",
+
+  "alice_22_239.npz": "train-22-61-5",
+
+  "alice_22_240.npz": "train-22-61-6",
+
+  "alice_22_241.npz": "train-22-61-7",
+
+  "alice_22_242.npz": "train-22-61-8",
+
+  "alice_22_243.npz": "train-22-61-9",
+
+  "alice_22_244.npz": "train-22-61-10",
+
+  "alice_22_245.npz": "train-22-61-11",
+
+  "alice_22_246.npz": "train-22-61-12",
+
+  "alice_22_247.npz": "train-22-62-0",
+
+  "alice_22_248.npz": "train-22-62-1",
+
+  "alice_22_249.npz": "train-22-62-2",
+
+  "alice_22_250.npz": "train-22-62-3",
+
+  "alice_22_251.npz": "train-22-63-0",
+
+  "alice_22_252.npz": "train-22-63-1",
+
+  "alice_22_253.npz": "train-22-63-2",
+
+  "alice_22_254.npz": "train-22-63-3",
+
+  "alice_22_255.npz": "train-22-63-4",
+
+  "alice_22_256.npz": "train-22-63-5",
+
+  "alice_22_257.npz": "train-22-63-6",
+
+  "alice_22_258.npz": "train-22-63-7",
+
+  "alice_22_259.npz": "train-22-63-8",
+
+  "alice_22_260.npz": "train-22-63-9",
+
+  "alice_22_261.npz": "train-22-63-10",
+
+  "alice_22_262.npz": "train-22-63-11",
+
+  "alice_22_263.npz": "train-22-63-12",
+
+  "alice_22_264.npz": "train-22-63-13",
+
+  "alice_22_265.npz": "train-22-63-14",
+
+  "alice_22_266.npz": "train-22-63-15",
+
+  "alice_22_267.npz": "train-22-63-16",
+
+  "alice_22_268.npz": "train-22-63-17",
+
+  "alice_22_269.npz": "train-22-64-0",
+
+  "alice_22_270.npz": "train-22-64-1",
+
+  "alice_22_271.npz": "train-22-64-2",
+
+  "alice_22_272.npz": "train-22-64-3",
+
+  "alice_22_273.npz": "train-22-64-4",
+
+  "alice_22_274.npz": "train-22-64-5",
+
+  "alice_22_275.npz": "train-22-64-6",
+
+  "alice_22_276.npz": "train-22-64-7",
+
+  "alice_22_277.npz": "train-22-64-8",
+
+  "alice_22_278.npz": "train-22-64-9",
+  "alice_22_279.npz": "train-22-64-9",
+
+  "alice_22_280.npz": "train-22-65-0",
+
+  "alice_22_281.npz": "train-22-66-0",
+
+  "alice_50_0.npz": "train-50-0-0",
+
+  "alice_50_1.npz": "train-50-0-1",
+
+  "alice_50_2.npz": "train-50-0-2",
+
+  "alice_50_3.npz": "train-50-0-3",
+
+  "alice_50_4.npz": "train-50-0-4",
+
+  "alice_50_5.npz": "train-50-0-5",
+
+  "alice_50_6.npz": "train-50-0-6",
+
+  "alice_50_7.npz": "train-50-0-7",
+
+  "alice_50_8.npz": "train-50-0-8",
+
+  "alice_50_9.npz": "train-50-1-0",
+
+  "alice_50_10.npz": "train-50-1-1",
+
+  "alice_50_11.npz": "train-50-1-2",
+
+  "alice_50_12.npz": "train-50-1-3",
+
+  "alice_50_13.npz": "train-50-1-4",
+
+  "alice_50_14.npz": "train-50-1-5",
+
+  "alice_50_15.npz": "train-50-1-6",
+
+  "alice_50_16.npz": "train-50-1-7",
+
+  "alice_50_17.npz": "train-50-1-8",
+
+  "alice_50_18.npz": "train-50-1-9",
+
+  "alice_50_19.npz": "train-50-2-0",
+
+  "alice_50_20.npz": "train-50-2-1",
+
+  "alice_50_21.npz": "train-50-2-2",
+
+  "alice_50_22.npz": "train-50-2-3",
+
+  "alice_50_23.npz": "train-50-3-0",
+
+  "alice_50_24.npz": "train-50-4-0",
+
+  "alice_50_25.npz": "train-50-5-0",
+
+  "alice_50_26.npz": "train-50-5-1",
+
+  "alice_50_27.npz": "train-50-5-2",
+
+  "alice_50_28.npz": "train-50-5-3",
+
+  "alice_50_29.npz": "train-50-5-4",
+
+  "alice_50_30.npz": "train-50-5-5",
+
+  "alice_50_31.npz": "train-50-5-6",
+
+  "alice_50_32.npz": "train-50-5-7",
+
+  "alice_50_33.npz": "train-50-5-8",
+
+  "alice_50_34.npz": "train-50-5-9",
+
+  "alice_50_35.npz": "train-50-5-10",
+
+  "alice_50_36.npz": "train-50-5-11",
+
+  "alice_50_37.npz": "train-50-5-12",
+
+  "alice_50_38.npz": "train-50-5-13",
+
+  "alice_50_39.npz": "train-50-5-14",
+
+  "alice_50_40.npz": "train-50-5-15",
+
+  "alice_50_41.npz": "train-50-5-16",
+
+  "alice_50_42.npz": "train-50-5-17",
+
+  "alice_50_43.npz": "train-50-6-0",
+
+  "alice_50_44.npz": "train-50-6-1",
+
+  "alice_50_45.npz": "train-50-6-2",
+
+  "alice_50_46.npz": "train-50-6-3",
+
+  "alice_50_47.npz": "train-50-7-0",
+
+  "alice_50_48.npz": "train-50-7-1",
+
+  "alice_50_49.npz": "train-50-7-2",
+
+  "alice_50_50.npz": "train-50-7-3",
+
+  "alice_50_51.npz": "train-50-7-4",
+
+  "alice_50_52.npz": "train-50-7-5",
+
+  "alice_50_53.npz": "train-50-8-0",
+
+  "alice_50_54.npz": "train-50-8-1",
+
+  "alice_50_55.npz": "train-50-8-2",
+
+  "alice_50_56.npz": "train-50-8-3",
+
+  "alice_50_57.npz": "train-50-8-4",
+
+  "alice_50_58.npz": "train-50-8-5",
+
+  "alice_50_59.npz": "train-50-9-0",
+
+  "alice_50_60.npz": "train-50-9-1",
+
+  "alice_50_61.npz": "train-50-9-2",
+
+  "alice_50_62.npz": "train-50-9-3",
+
+  "alice_50_63.npz": "train-50-9-4",
+
+  "alice_50_64.npz": "train-50-9-5",
+
+  "alice_50_65.npz": "train-50-9-6",
+
+  "alice_50_66.npz": "train-50-9-7",
+
+  "alice_50_67.npz": "train-50-9-8",
+
+  "alice_50_68.npz": "train-50-10-0",
+
+  "alice_50_69.npz": "train-50-10-1",
+
+  "alice_50_70.npz": "train-50-10-2",
+
+  "alice_50_71.npz": "train-50-10-3",
+
+  "alice_50_72.npz": "train-50-10-4",
+
+  "alice_50_73.npz": "train-50-10-5",
+
+  "alice_50_74.npz": "train-50-10-6",
+
+  "alice_50_75.npz": "train-50-10-7",
+
+  "alice_50_76.npz": "train-50-10-8",
+
+  "alice_50_77.npz": "train-50-12-0",
+
+  "alice_50_78.npz": "train-50-12-1",
+
+  "alice_50_79.npz": "train-50-12-2",
+
+  "alice_50_80.npz": "train-50-13-0",
+
+  "alice_50_81.npz": "train-50-14-0",
+
+  "alice_50_82.npz": "train-50-14-1",
+
+  "alice_50_83.npz": "train-50-14-2",
+
+  "alice_50_84.npz": "train-50-15-0",
+
+  "alice_50_85.npz": "train-50-16-0",
+
+  "alice_50_86.npz": "train-50-17-0",
+
+  "alice_50_87.npz": "train-50-17-1",
+
+  "alice_50_88.npz": "train-50-18-0",
+
+  "alice_50_89.npz": "train-50-18-1",
+
+  "alice_50_90.npz": "train-50-20-0",
+
+  "alice_50_91.npz": "train-50-20-1",
+
+  "alice_50_92.npz": "train-50-21-0",
+
+  "alice_50_93.npz": "train-50-21-1",
+
+  "alice_50_94.npz": "train-50-21-2",
+
+  "alice_50_95.npz": "train-50-21-3",
+
+  "alice_50_96.npz": "train-50-21-4",
+
+  "alice_50_97.npz": "train-50-21-5",
+
+  "alice_50_98.npz": "train-50-21-6",
+
+  "alice_50_99.npz": "train-50-21-7",
+
+  "alice_50_100.npz": "train-50-21-8",
+
+  "alice_50_101.npz": "train-50-21-9",
+
+  "alice_50_102.npz": "train-50-21-10",
+
+  "alice_50_103.npz": "train-50-21-11",
+
+  "alice_50_104.npz": "train-50-22-0",
+
+  "alice_50_105.npz": "train-50-22-1",
+
+  "alice_50_106.npz": "train-50-22-2",
+
+  "alice_50_107.npz": "train-50-22-3",
+
+  "alice_50_108.npz": "train-50-23-0",
+
+  "alice_50_109.npz": "train-50-24-0",
+
+  "alice_50_110.npz": "train-50-24-1",
+
+  "alice_50_111.npz": "train-50-25-0",
+
+  "alice_50_112.npz": "train-50-25-1",
+
+  "alice_50_113.npz": "train-50-26-0",
+
+  "alice_50_114.npz": "train-50-26-1",
+
+  "alice_50_115.npz": "train-50-26-2",
+
+  "alice_50_116.npz": "train-50-26-3",
+
+  "alice_50_117.npz": "train-50-26-4",
+
+  "alice_50_118.npz": "train-50-26-5",
+
+  "alice_50_119.npz": "train-50-26-6",
+
+  "alice_50_120.npz": "train-50-27-0",
+
+  "alice_50_121.npz": "train-50-27-1",
+
+  "alice_50_122.npz": "train-50-28-0",
+
+  "alice_50_123.npz": "train-50-28-1",
+
+  "alice_50_124.npz": "train-50-29-0",
+
+  "alice_50_125.npz": "train-50-29-1",
+
+  "alice_50_126.npz": "train-50-30-0",
+
+  "alice_50_127.npz": "train-50-31-0",
+
+  "alice_50_128.npz": "train-50-31-1",
+
+  "alice_50_129.npz": "train-50-31-2",
+
+  "alice_50_130.npz": "train-50-32-0",
+
+  "alice_50_131.npz": "train-50-33-0",
+
+  "alice_50_132.npz": "train-50-33-1",
+
+  "alice_50_133.npz": "train-50-33-2",
+
+  "alice_50_134.npz": "train-50-34-0",
+
+  "alice_50_135.npz": "train-50-34-1",
+
+  "alice_50_136.npz": "train-50-35-0",
+
+  "alice_50_137.npz": "train-50-36-0",
+
+  "alice_50_138.npz": "train-50-36-1",
+
+  "alice_50_139.npz": "train-50-38-0",
+
+  "alice_50_140.npz": "train-50-39-0",
+
+  "alice_50_141.npz": "train-50-39-1",
+
+  "alice_50_142.npz": "train-50-39-2",
+
+  "alice_50_143.npz": "train-50-39-3",
+
+  "alice_50_144.npz": "train-50-40-0",
+
+  "alice_50_145.npz": "train-50-41-0",
+
+  "alice_50_146.npz": "train-50-41-1",
+
+  "alice_50_147.npz": "train-50-41-2",
+
+  "alice_50_148.npz": "train-50-41-3",
+
+  "alice_50_149.npz": "train-50-42-0",
+
+  "alice_50_150.npz": "train-50-43-0",
+
+  "alice_50_151.npz": "train-50-44-0",
+
+  "alice_50_152.npz": "train-50-44-1",
+
+  "alice_50_153.npz": "train-50-44-2",
+
+  "alice_50_154.npz": "train-50-45-0",
+
+  "alice_50_155.npz": "train-50-45-1",
+
+  "alice_50_156.npz": "train-50-45-2",
+
+  "alice_50_157.npz": "train-50-45-3",
+
+  "alice_50_158.npz": "train-50-45-4",
+
+  "alice_50_159.npz": "train-50-45-5",
+
+  "alice_50_160.npz": "train-50-45-6",
+
+  "alice_50_161.npz": "train-50-46-0",
+
+  "alice_50_162.npz": "train-50-48-0",
+
+  "alice_50_163.npz": "train-50-48-1",
+
+  "alice_50_164.npz": "train-50-48-2",
+
+  "alice_50_165.npz": "train-50-49-0",
+
+  "alice_50_166.npz": "train-50-49-1",
+
+  "alice_50_167.npz": "train-50-49-2",
+
+  "alice_50_168.npz": "train-50-49-3",
+
+  "alice_50_169.npz": "train-50-49-4",
+
+  "alice_50_170.npz": "train-50-49-5",
+
+  "alice_50_171.npz": "train-50-49-6",
+
+  "alice_50_172.npz": "train-50-50-0",
+
+  "alice_50_173.npz": "train-50-50-1",
+
+  "alice_50_174.npz": "train-50-50-2",
+
+  "alice_50_175.npz": "train-50-50-3",
+
+  "alice_50_176.npz": "train-50-50-4",
+
+  "alice_50_177.npz": "train-50-51-0",
+
+  "alice_50_178.npz": "train-50-51-1",
+
+  "alice_50_179.npz": "train-50-51-2",
+
+  "alice_50_180.npz": "train-50-51-3",
+
+  "alice_50_181.npz": "train-50-51-4",
+
+  "alice_50_182.npz": "train-50-51-5",
+
+  "alice_50_183.npz": "train-50-52-0",
+
+  "alice_50_184.npz": "train-50-52-1",
+
+  "alice_50_185.npz": "train-50-52-2",
+
+  "alice_50_186.npz": "train-50-52-3",
+
+  "alice_50_187.npz": "train-50-52-4",
+
+  "alice_50_188.npz": "train-50-52-5",
+
+  "alice_50_189.npz": "train-50-52-6",
+
+  "alice_50_190.npz": "train-50-52-7",
+
+  "alice_50_191.npz": "train-50-53-0",
+
+  "alice_50_192.npz": "train-50-53-1",
+
+  "alice_50_193.npz": "train-50-53-2",
+
+  "alice_50_194.npz": "train-50-53-3",
+
+  "alice_50_195.npz": "train-50-53-4",
+
+  "alice_50_196.npz": "train-50-53-5",
+
+  "alice_50_197.npz": "train-50-53-6",
+
+  "alice_50_198.npz": "train-50-54-0",
+
+  "alice_50_199.npz": "train-50-54-1",
+
+  "alice_50_200.npz": "train-50-54-2",
+
+  "alice_50_201.npz": "train-50-54-3",
+
+  "alice_50_202.npz": "train-50-55-0",
+
+  "alice_50_203.npz": "train-50-55-1",
+
+  "alice_50_204.npz": "train-50-55-2",
+
+  "alice_50_205.npz": "train-50-55-3",
+
+  "alice_50_206.npz": "train-50-55-4",
+
+  "alice_50_207.npz": "train-50-55-5",
+
+  "alice_50_208.npz": "train-50-55-6",
+
+  "alice_50_209.npz": "train-50-55-7",
+
+  "alice_50_210.npz": "train-50-56-0",
+
+  "alice_50_211.npz": "train-50-56-1",
+
+  "alice_50_212.npz": "train-50-56-2",
+
+  "alice_50_213.npz": "train-50-56-3",
+
+  "alice_50_214.npz": "train-50-56-4",
+
+  "alice_50_215.npz": "train-50-56-5",
+
+  "alice_50_216.npz": "train-50-57-0",
+
+  "alice_50_217.npz": "train-50-57-1",
+
+  "alice_50_218.npz": "train-50-57-2",
+
+  "alice_50_219.npz": "train-50-57-3",
+
+  "alice_50_220.npz": "train-50-57-4",
+
+  "alice_50_221.npz": "train-50-57-5",
+
+  "alice_50_222.npz": "train-50-57-6",
+
+  "alice_50_223.npz": "train-50-57-7",
+
+  "alice_50_224.npz": "train-50-57-8",
+
+  "alice_50_225.npz": "train-50-57-9",
+
+  "alice_50_226.npz": "train-50-58-0",
+
+  "alice_50_227.npz": "train-50-59-0",
+
+  "alice_50_228.npz": "train-50-59-1",
+
+  "alice_50_229.npz": "train-50-60-0",
+
+  "alice_50_230.npz": "train-50-60-1",
+
+  "alice_50_231.npz": "train-50-60-2",
+
+  "alice_50_232.npz": "train-50-60-3",
+
+  "alice_50_233.npz": "train-50-60-4",
+
+  "alice_50_234.npz": "train-50-61-0",
+
+  "alice_50_235.npz": "train-50-61-1",
+
+  "alice_50_236.npz": "train-50-61-2",
+
+  "alice_50_237.npz": "train-50-61-3",
+
+  "alice_50_238.npz": "train-50-61-4",
+
+  "alice_50_239.npz": "train-50-61-5",
+
+  "alice_50_240.npz": "train-50-61-6",
+
+  "alice_50_241.npz": "train-50-61-7",
+
+  "alice_50_242.npz": "train-50-61-8",
+
+  "alice_50_243.npz": "train-50-61-9",
+
+  "alice_50_244.npz": "train-50-61-10",
+
+  "alice_50_245.npz": "train-50-61-11",
+
+  "alice_50_246.npz": "train-50-61-12",
+
+  "alice_50_247.npz": "train-50-62-0",
+
+  "alice_50_248.npz": "train-50-62-1",
+
+  "alice_50_249.npz": "train-50-62-2",
+
+  "alice_50_250.npz": "train-50-62-3",
+
+  "alice_50_251.npz": "train-50-63-0",
+
+  "alice_50_252.npz": "train-50-63-1",
+
+  "alice_50_253.npz": "train-50-63-2",
+
+  "alice_50_254.npz": "train-50-63-3",
+
+  "alice_50_255.npz": "train-50-63-4",
+
+  "alice_50_256.npz": "train-50-63-5",
+
+  "alice_50_257.npz": "train-50-63-6",
+
+  "alice_50_258.npz": "train-50-63-7",
+
+  "alice_50_259.npz": "train-50-63-8",
+
+  "alice_50_260.npz": "train-50-63-9",
+
+  "alice_50_261.npz": "train-50-63-10",
+
+  "alice_50_262.npz": "train-50-63-11",
+
+  "alice_50_263.npz": "train-50-63-12",
+
+  "alice_50_264.npz": "train-50-63-13",
+
+  "alice_50_265.npz": "train-50-63-14",
+
+  "alice_50_266.npz": "train-50-63-15",
+
+  "alice_50_267.npz": "train-50-63-16",
+
+  "alice_50_268.npz": "train-50-63-17",
+
+  "alice_50_269.npz": "train-50-64-0",
+
+  "alice_50_270.npz": "train-50-64-1",
+
+  "alice_50_271.npz": "train-50-64-2",
+
+  "alice_50_272.npz": "train-50-64-3",
+
+  "alice_50_273.npz": "train-50-64-4",
+
+  "alice_50_274.npz": "train-50-64-5",
+
+  "alice_50_275.npz": "train-50-64-6",
+
+  "alice_50_276.npz": "train-50-64-7",
+
+  "alice_50_277.npz": "train-50-64-8",
+
+  "alice_50_278.npz": "train-50-64-9",
+  "alice_50_279.npz": "train-50-64-9",
+
+  "alice_50_280.npz": "train-50-65-0",
+
+  "alice_50_281.npz": "train-50-66-0",
+
+  "alice_37_0.npz": "train-37-0-0",
+
+  "alice_37_1.npz": "train-37-0-1",
+
+  "alice_37_2.npz": "train-37-0-2",
+
+  "alice_37_3.npz": "train-37-0-3",
+
+  "alice_37_4.npz": "train-37-0-4",
+
+  "alice_37_5.npz": "train-37-0-5",
+
+  "alice_37_6.npz": "train-37-0-6",
+
+  "alice_37_7.npz": "train-37-0-7",
+
+  "alice_37_8.npz": "train-37-0-8",
+
+  "alice_37_9.npz": "train-37-1-0",
+
+  "alice_37_10.npz": "train-37-1-1",
+
+  "alice_37_11.npz": "train-37-1-2",
+
+  "alice_37_12.npz": "train-37-1-3",
+
+  "alice_37_13.npz": "train-37-1-4",
+
+  "alice_37_14.npz": "train-37-1-5",
+
+  "alice_37_15.npz": "train-37-1-6",
+
+  "alice_37_16.npz": "train-37-1-7",
+
+  "alice_37_17.npz": "train-37-1-8",
+
+  "alice_37_18.npz": "train-37-1-9",
+
+  "alice_37_19.npz": "train-37-2-0",
+
+  "alice_37_20.npz": "train-37-2-1",
+
+  "alice_37_21.npz": "train-37-2-2",
+
+  "alice_37_22.npz": "train-37-2-3",
+
+  "alice_37_23.npz": "train-37-3-0",
+
+  "alice_37_24.npz": "train-37-4-0",
+
+  "alice_37_25.npz": "train-37-5-0",
+
+  "alice_37_26.npz": "train-37-5-1",
+
+  "alice_37_27.npz": "train-37-5-2",
+
+  "alice_37_28.npz": "train-37-5-3",
+
+  "alice_37_29.npz": "train-37-5-4",
+
+  "alice_37_30.npz": "train-37-5-5",
+
+  "alice_37_31.npz": "train-37-5-6",
+
+  "alice_37_32.npz": "train-37-5-7",
+
+  "alice_37_33.npz": "train-37-5-8",
+
+  "alice_37_34.npz": "train-37-5-9",
+
+  "alice_37_35.npz": "train-37-5-10",
+
+  "alice_37_36.npz": "train-37-5-11",
+
+  "alice_37_37.npz": "train-37-5-12",
+
+  "alice_37_38.npz": "train-37-5-13",
+
+  "alice_37_39.npz": "train-37-5-14",
+
+  "alice_37_40.npz": "train-37-5-15",
+
+  "alice_37_41.npz": "train-37-5-16",
+
+  "alice_37_42.npz": "train-37-5-17",
+
+  "alice_37_43.npz": "train-37-6-0",
+
+  "alice_37_44.npz": "train-37-6-1",
+
+  "alice_37_45.npz": "train-37-6-2",
+
+  "alice_37_46.npz": "train-37-6-3",
+
+  "alice_37_47.npz": "train-37-7-0",
+
+  "alice_37_48.npz": "train-37-7-1",
+
+  "alice_37_49.npz": "train-37-7-2",
+
+  "alice_37_50.npz": "train-37-7-3",
+
+  "alice_37_51.npz": "train-37-7-4",
+
+  "alice_37_52.npz": "train-37-7-5",
+
+  "alice_37_53.npz": "train-37-8-0",
+
+  "alice_37_54.npz": "train-37-8-1",
+
+  "alice_37_55.npz": "train-37-8-2",
+
+  "alice_37_56.npz": "train-37-8-3",
+
+  "alice_37_57.npz": "train-37-8-4",
+
+  "alice_37_58.npz": "train-37-8-5",
+
+  "alice_37_59.npz": "train-37-9-0",
+
+  "alice_37_60.npz": "train-37-9-1",
+
+  "alice_37_61.npz": "train-37-9-2",
+
+  "alice_37_62.npz": "train-37-9-3",
+
+  "alice_37_63.npz": "train-37-9-4",
+
+  "alice_37_64.npz": "train-37-9-5",
+
+  "alice_37_65.npz": "train-37-9-6",
+
+  "alice_37_66.npz": "train-37-9-7",
+
+  "alice_37_67.npz": "train-37-9-8",
+
+  "alice_37_68.npz": "train-37-10-0",
+
+  "alice_37_69.npz": "train-37-10-1",
+
+  "alice_37_70.npz": "train-37-10-2",
+
+  "alice_37_71.npz": "train-37-10-3",
+
+  "alice_37_72.npz": "train-37-10-4",
+
+  "alice_37_73.npz": "train-37-10-5",
+
+  "alice_37_74.npz": "train-37-10-6",
+
+  "alice_37_75.npz": "train-37-10-7",
+
+  "alice_37_76.npz": "train-37-10-8",
+
+  "alice_37_77.npz": "train-37-12-0",
+
+  "alice_37_78.npz": "train-37-12-1",
+
+  "alice_37_79.npz": "train-37-12-2",
+
+  "alice_37_80.npz": "train-37-13-0",
+
+  "alice_37_81.npz": "train-37-14-0",
+
+  "alice_37_82.npz": "train-37-14-1",
+
+  "alice_37_83.npz": "train-37-14-2",
+
+  "alice_37_84.npz": "train-37-15-0",
+
+  "alice_37_85.npz": "train-37-16-0",
+
+  "alice_37_86.npz": "train-37-17-0",
+
+  "alice_37_87.npz": "train-37-17-1",
+
+  "alice_37_88.npz": "train-37-18-0",
+
+  "alice_37_89.npz": "train-37-18-1",
+
+  "alice_37_90.npz": "train-37-20-0",
+
+  "alice_37_91.npz": "train-37-20-1",
+
+  "alice_37_92.npz": "train-37-21-0",
+
+  "alice_37_93.npz": "train-37-21-1",
+
+  "alice_37_94.npz": "train-37-21-2",
+
+  "alice_37_95.npz": "train-37-21-3",
+
+  "alice_37_96.npz": "train-37-21-4",
+
+  "alice_37_97.npz": "train-37-21-5",
+
+  "alice_37_98.npz": "train-37-21-6",
+
+  "alice_37_99.npz": "train-37-21-7",
+
+  "alice_37_100.npz": "train-37-21-8",
+
+  "alice_37_101.npz": "train-37-21-9",
+
+  "alice_37_102.npz": "train-37-21-10",
+
+  "alice_37_103.npz": "train-37-21-11",
+
+  "alice_37_104.npz": "train-37-22-0",
+
+  "alice_37_105.npz": "train-37-22-1",
+
+  "alice_37_106.npz": "train-37-22-2",
+
+  "alice_37_107.npz": "train-37-22-3",
+
+  "alice_37_108.npz": "train-37-23-0",
+
+  "alice_37_109.npz": "train-37-24-0",
+
+  "alice_37_110.npz": "train-37-24-1",
+
+  "alice_37_111.npz": "train-37-25-0",
+
+  "alice_37_112.npz": "train-37-25-1",
+
+  "alice_37_113.npz": "train-37-26-0",
+
+  "alice_37_114.npz": "train-37-26-1",
+
+  "alice_37_115.npz": "train-37-26-2",
+
+  "alice_37_116.npz": "train-37-26-3",
+
+  "alice_37_117.npz": "train-37-26-4",
+
+  "alice_37_118.npz": "train-37-26-5",
+
+  "alice_37_119.npz": "train-37-26-6",
+
+  "alice_37_120.npz": "train-37-27-0",
+
+  "alice_37_121.npz": "train-37-27-1",
+
+  "alice_37_122.npz": "train-37-28-0",
+
+  "alice_37_123.npz": "train-37-28-1",
+
+  "alice_37_124.npz": "train-37-29-0",
+
+  "alice_37_125.npz": "train-37-29-1",
+
+  "alice_37_126.npz": "train-37-30-0",
+
+  "alice_37_127.npz": "train-37-31-0",
+
+  "alice_37_128.npz": "train-37-31-1",
+
+  "alice_37_129.npz": "train-37-31-2",
+
+  "alice_37_130.npz": "train-37-32-0",
+
+  "alice_37_131.npz": "train-37-33-0",
+
+  "alice_37_132.npz": "train-37-33-1",
+
+  "alice_37_133.npz": "train-37-33-2",
+
+  "alice_37_134.npz": "train-37-34-0",
+
+  "alice_37_135.npz": "train-37-34-1",
+
+  "alice_37_136.npz": "train-37-35-0",
+
+  "alice_37_137.npz": "train-37-36-0",
+
+  "alice_37_138.npz": "train-37-36-1",
+
+  "alice_37_139.npz": "train-37-38-0",
+
+  "alice_37_140.npz": "train-37-39-0",
+
+  "alice_37_141.npz": "train-37-39-1",
+
+  "alice_37_142.npz": "train-37-39-2",
+
+  "alice_37_143.npz": "train-37-39-3",
+
+  "alice_37_144.npz": "train-37-40-0",
+
+  "alice_37_145.npz": "train-37-41-0",
+
+  "alice_37_146.npz": "train-37-41-1",
+
+  "alice_37_147.npz": "train-37-41-2",
+
+  "alice_37_148.npz": "train-37-41-3",
+
+  "alice_37_149.npz": "train-37-42-0",
+
+  "alice_37_150.npz": "train-37-43-0",
+
+  "alice_37_151.npz": "train-37-44-0",
+
+  "alice_37_152.npz": "train-37-44-1",
+
+  "alice_37_153.npz": "train-37-44-2",
+
+  "alice_37_154.npz": "train-37-45-0",
+
+  "alice_37_155.npz": "train-37-45-1",
+
+  "alice_37_156.npz": "train-37-45-2",
+
+  "alice_37_157.npz": "train-37-45-3",
+
+  "alice_37_158.npz": "train-37-45-4",
+
+  "alice_37_159.npz": "train-37-45-5",
+
+  "alice_37_160.npz": "train-37-45-6",
+
+  "alice_37_161.npz": "train-37-46-0",
+
+  "alice_37_162.npz": "train-37-48-0",
+
+  "alice_37_163.npz": "train-37-48-1",
+
+  "alice_37_164.npz": "train-37-48-2",
+
+  "alice_37_165.npz": "train-37-49-0",
+
+  "alice_37_166.npz": "train-37-49-1",
+
+  "alice_37_167.npz": "train-37-49-2",
+
+  "alice_37_168.npz": "train-37-49-3",
+
+  "alice_37_169.npz": "train-37-49-4",
+
+  "alice_37_170.npz": "train-37-49-5",
+
+  "alice_37_171.npz": "train-37-49-6",
+
+  "alice_37_172.npz": "train-37-50-0",
+
+  "alice_37_173.npz": "train-37-50-1",
+
+  "alice_37_174.npz": "train-37-50-2",
+
+  "alice_37_175.npz": "train-37-50-3",
+
+  "alice_37_176.npz": "train-37-50-4",
+
+  "alice_37_177.npz": "train-37-51-0",
+
+  "alice_37_178.npz": "train-37-51-1",
+
+  "alice_37_179.npz": "train-37-51-2",
+
+  "alice_37_180.npz": "train-37-51-3",
+
+  "alice_37_181.npz": "train-37-51-4",
+
+  "alice_37_182.npz": "train-37-51-5",
+
+  "alice_37_183.npz": "train-37-52-0",
+
+  "alice_37_184.npz": "train-37-52-1",
+
+  "alice_37_185.npz": "train-37-52-2",
+
+  "alice_37_186.npz": "train-37-52-3",
+
+  "alice_37_187.npz": "train-37-52-4",
+
+  "alice_37_188.npz": "train-37-52-5",
+
+  "alice_37_189.npz": "train-37-52-6",
+
+  "alice_37_190.npz": "train-37-52-7",
+
+  "alice_37_191.npz": "train-37-53-0",
+
+  "alice_37_192.npz": "train-37-53-1",
+
+  "alice_37_193.npz": "train-37-53-2",
+
+  "alice_37_194.npz": "train-37-53-3",
+
+  "alice_37_195.npz": "train-37-53-4",
+
+  "alice_37_196.npz": "train-37-53-5",
+
+  "alice_37_197.npz": "train-37-53-6",
+
+  "alice_37_198.npz": "train-37-54-0",
+
+  "alice_37_199.npz": "train-37-54-1",
+
+  "alice_37_200.npz": "train-37-54-2",
+
+  "alice_37_201.npz": "train-37-54-3",
+
+  "alice_37_202.npz": "train-37-55-0",
+
+  "alice_37_203.npz": "train-37-55-1",
+
+  "alice_37_204.npz": "train-37-55-2",
+
+  "alice_37_205.npz": "train-37-55-3",
+
+  "alice_37_206.npz": "train-37-55-4",
+
+  "alice_37_207.npz": "train-37-55-5",
+
+  "alice_37_208.npz": "train-37-55-6",
+
+  "alice_37_209.npz": "train-37-55-7",
+
+  "alice_37_210.npz": "train-37-56-0",
+
+  "alice_37_211.npz": "train-37-56-1",
+
+  "alice_37_212.npz": "train-37-56-2",
+
+  "alice_37_213.npz": "train-37-56-3",
+
+  "alice_37_214.npz": "train-37-56-4",
+
+  "alice_37_215.npz": "train-37-56-5",
+
+  "alice_37_216.npz": "train-37-57-0",
+
+  "alice_37_217.npz": "train-37-57-1",
+
+  "alice_37_218.npz": "train-37-57-2",
+
+  "alice_37_219.npz": "train-37-57-3",
+
+  "alice_37_220.npz": "train-37-57-4",
+
+  "alice_37_221.npz": "train-37-57-5",
+
+  "alice_37_222.npz": "train-37-57-6",
+
+  "alice_37_223.npz": "train-37-57-7",
+
+  "alice_37_224.npz": "train-37-57-8",
+
+  "alice_37_225.npz": "train-37-57-9",
+
+  "alice_37_226.npz": "train-37-58-0",
+
+  "alice_37_227.npz": "train-37-59-0",
+
+  "alice_37_228.npz": "train-37-59-1",
+
+  "alice_37_229.npz": "train-37-60-0",
+
+  "alice_37_230.npz": "train-37-60-1",
+
+  "alice_37_231.npz": "train-37-60-2",
+
+  "alice_37_232.npz": "train-37-60-3",
+
+  "alice_37_233.npz": "train-37-60-4",
+
+  "alice_37_234.npz": "train-37-61-0",
+
+  "alice_37_235.npz": "train-37-61-1",
+
+  "alice_37_236.npz": "train-37-61-2",
+
+  "alice_37_237.npz": "train-37-61-3",
+
+  "alice_37_238.npz": "train-37-61-4",
+
+  "alice_37_239.npz": "train-37-61-5",
+
+  "alice_37_240.npz": "train-37-61-6",
+
+  "alice_37_241.npz": "train-37-61-7",
+
+  "alice_37_242.npz": "train-37-61-8",
+
+  "alice_37_243.npz": "train-37-61-9",
+
+  "alice_37_244.npz": "train-37-61-10",
+
+  "alice_37_245.npz": "train-37-61-11",
+
+  "alice_37_246.npz": "train-37-61-12",
+
+  "alice_37_247.npz": "train-37-62-0",
+
+  "alice_37_248.npz": "train-37-62-1",
+
+  "alice_37_249.npz": "train-37-62-2",
+
+  "alice_37_250.npz": "train-37-62-3",
+
+  "alice_37_251.npz": "train-37-63-0",
+
+  "alice_37_252.npz": "train-37-63-1",
+
+  "alice_37_253.npz": "train-37-63-2",
+
+  "alice_37_254.npz": "train-37-63-3",
+
+  "alice_37_255.npz": "train-37-63-4",
+
+  "alice_37_256.npz": "train-37-63-5",
+
+  "alice_37_257.npz": "train-37-63-6",
+
+  "alice_37_258.npz": "train-37-63-7",
+
+  "alice_37_259.npz": "train-37-63-8",
+
+  "alice_37_260.npz": "train-37-63-9",
+
+  "alice_37_261.npz": "train-37-63-10",
+
+  "alice_37_262.npz": "train-37-63-11",
+
+  "alice_37_263.npz": "train-37-63-12",
+
+  "alice_37_264.npz": "train-37-63-13",
+
+  "alice_37_265.npz": "train-37-63-14",
+
+  "alice_37_266.npz": "train-37-63-15",
+
+  "alice_37_267.npz": "train-37-63-16",
+
+  "alice_37_268.npz": "train-37-63-17",
+
+  "alice_37_269.npz": "train-37-64-0",
+
+  "alice_37_270.npz": "train-37-64-1",
+
+  "alice_37_271.npz": "train-37-64-2",
+
+  "alice_37_272.npz": "train-37-64-3",
+
+  "alice_37_273.npz": "train-37-64-4",
+
+  "alice_37_274.npz": "train-37-64-5",
+
+  "alice_37_275.npz": "train-37-64-6",
+
+  "alice_37_276.npz": "train-37-64-7",
+
+  "alice_37_277.npz": "train-37-64-8",
+
+  "alice_37_278.npz": "train-37-64-9",
+  "alice_37_279.npz": "train-37-64-9",
+
+
+  "alice_37_280.npz": "train-37-65-0",
+
+  "alice_37_281.npz": "train-37-66-0",
+
+  "alice_18_322.npz": "val-18-75-0",
+
+  "alice_18_323.npz": "val-18-75-1",
+
+  "alice_18_324.npz": "val-18-75-2",
+
+  "alice_18_325.npz": "val-18-75-3",
+
+  "alice_18_326.npz": "val-18-75-4",
+
+  "alice_18_327.npz": "val-18-75-5",
+
+  "alice_18_328.npz": "val-18-75-6",
+
+  "alice_18_329.npz": "val-18-75-7",
+
+  "alice_18_330.npz": "val-18-75-8",
+
+  "alice_18_331.npz": "val-18-75-9",
+
+  "alice_18_332.npz": "val-18-75-10",
+
+  "alice_18_333.npz": "val-18-75-11",
+
+  "alice_18_334.npz": "val-18-76-0",
+
+  "alice_18_335.npz": "val-18-76-1",
+
+  "alice_18_336.npz": "val-18-77-0",
+
+  "alice_18_337.npz": "val-18-77-1",
+
+  "alice_18_338.npz": "val-18-78-0",
+
+  "alice_18_339.npz": "val-18-78-1",
+
+  "alice_18_340.npz": "val-18-78-2",
+
+  "alice_18_341.npz": "val-18-78-3",
+
+  "alice_18_342.npz": "val-18-78-4",
+
+  "alice_18_343.npz": "val-18-78-5",
+
+  "alice_18_344.npz": "val-18-78-6",
+
+  "alice_18_345.npz": "val-18-79-0",
+
+  "alice_18_346.npz": "val-18-79-1",
+
+  "alice_18_347.npz": "val-18-79-2",
+
+  "alice_18_348.npz": "val-18-79-3",
+
+  "alice_18_349.npz": "val-18-79-4",
+
+  "alice_18_350.npz": "val-18-79-5",
+
+  "alice_18_351.npz": "val-18-79-6",
+
+  "alice_18_352.npz": "val-18-80-0",
+
+  "alice_18_353.npz": "val-18-80-1",
+
+  "alice_18_354.npz": "val-18-80-2",
+
+  "alice_18_355.npz": "val-18-81-0",
+
+  "alice_18_356.npz": "val-18-82-0",
+
+  "alice_18_357.npz": "val-18-82-1",
+
+  "alice_18_358.npz": "val-18-82-2",
+
+  "alice_18_359.npz": "val-18-82-3",
+
+  "alice_18_360.npz": "val-18-82-4",
+
+  "alice_18_361.npz": "val-18-82-5",
+
+  "alice_48_322.npz": "val-48-75-0",
+
+  "alice_48_323.npz": "val-48-75-1",
+
+  "alice_48_324.npz": "val-48-75-2",
+
+  "alice_48_325.npz": "val-48-75-3",
+
+  "alice_48_326.npz": "val-48-75-4",
+
+  "alice_48_327.npz": "val-48-75-5",
+
+  "alice_48_328.npz": "val-48-75-6",
+
+  "alice_48_329.npz": "val-48-75-7",
+
+  "alice_48_330.npz": "val-48-75-8",
+
+  "alice_48_331.npz": "val-48-75-9",
+
+  "alice_48_332.npz": "val-48-75-10",
+
+  "alice_48_333.npz": "val-48-75-11",
+
+  "alice_48_334.npz": "val-48-76-0",
+
+  "alice_48_335.npz": "val-48-76-1",
+
+  "alice_48_336.npz": "val-48-77-0",
+
+  "alice_48_337.npz": "val-48-77-1",
+
+  "alice_48_338.npz": "val-48-78-0",
+
+  "alice_48_339.npz": "val-48-78-1",
+
+  "alice_48_340.npz": "val-48-78-2",
+
+  "alice_48_341.npz": "val-48-78-3",
+
+  "alice_48_342.npz": "val-48-78-4",
+
+  "alice_48_343.npz": "val-48-78-5",
+
+  "alice_48_344.npz": "val-48-78-6",
+
+  "alice_48_345.npz": "val-48-79-0",
+
+  "alice_48_346.npz": "val-48-79-1",
+
+  "alice_48_347.npz": "val-48-79-2",
+
+  "alice_48_348.npz": "val-48-79-3",
+
+  "alice_48_349.npz": "val-48-79-4",
+
+  "alice_48_350.npz": "val-48-79-5",
+
+  "alice_48_351.npz": "val-48-79-6",
+
+  "alice_48_352.npz": "val-48-80-0",
+
+  "alice_48_353.npz": "val-48-80-1",
+
+  "alice_48_354.npz": "val-48-80-2",
+
+  "alice_48_355.npz": "val-48-81-0",
+
+  "alice_48_356.npz": "val-48-82-0",
+
+  "alice_48_357.npz": "val-48-82-1",
+
+  "alice_48_358.npz": "val-48-82-2",
+
+  "alice_48_359.npz": "val-48-82-3",
+
+  "alice_48_360.npz": "val-48-82-4",
+
+  "alice_48_361.npz": "val-48-82-5",
+
+  "alice_31_322.npz": "val-31-75-0",
+
+  "alice_31_323.npz": "val-31-75-1",
+
+  "alice_31_324.npz": "val-31-75-2",
+
+  "alice_31_325.npz": "val-31-75-3",
+
+  "alice_31_326.npz": "val-31-75-4",
+
+  "alice_31_327.npz": "val-31-75-5",
+
+  "alice_31_328.npz": "val-31-75-6",
+
+  "alice_31_329.npz": "val-31-75-7",
+
+  "alice_31_330.npz": "val-31-75-8",
+
+  "alice_31_331.npz": "val-31-75-9",
+
+  "alice_31_332.npz": "val-31-75-10",
+
+  "alice_31_333.npz": "val-31-75-11",
+
+  "alice_31_334.npz": "val-31-76-0",
+
+  "alice_31_335.npz": "val-31-76-1",
+
+  "alice_31_336.npz": "val-31-77-0",
+
+  "alice_31_337.npz": "val-31-77-1",
+
+  "alice_31_338.npz": "val-31-78-0",
+
+  "alice_31_339.npz": "val-31-78-1",
+
+  "alice_31_340.npz": "val-31-78-2",
+
+  "alice_31_341.npz": "val-31-78-3",
+
+  "alice_31_342.npz": "val-31-78-4",
+
+  "alice_31_343.npz": "val-31-78-5",
+
+  "alice_31_344.npz": "val-31-78-6",
+
+  "alice_31_345.npz": "val-31-79-0",
+
+  "alice_31_346.npz": "val-31-79-1",
+
+  "alice_31_347.npz": "val-31-79-2",
+
+  "alice_31_348.npz": "val-31-79-3",
+
+  "alice_31_349.npz": "val-31-79-4",
+
+  "alice_31_350.npz": "val-31-79-5",
+
+  "alice_31_351.npz": "val-31-79-6",
+
+  "alice_31_352.npz": "val-31-80-0",
+
+  "alice_31_353.npz": "val-31-80-1",
+
+  "alice_31_354.npz": "val-31-80-2",
+
+  "alice_31_355.npz": "val-31-81-0",
+
+  "alice_31_356.npz": "val-31-82-0",
+
+  "alice_31_357.npz": "val-31-82-1",
+
+  "alice_31_358.npz": "val-31-82-2",
+
+  "alice_31_359.npz": "val-31-82-3",
+
+  "alice_31_360.npz": "val-31-82-4",
+
+  "alice_31_361.npz": "val-31-82-5",
+
+  "alice_47_322.npz": "val-47-75-0",
+
+  "alice_47_323.npz": "val-47-75-1",
+
+  "alice_47_324.npz": "val-47-75-2",
+
+  "alice_47_325.npz": "val-47-75-3",
+
+  "alice_47_326.npz": "val-47-75-4",
+
+  "alice_47_327.npz": "val-47-75-5",
+
+  "alice_47_328.npz": "val-47-75-6",
+
+  "alice_47_329.npz": "val-47-75-7",
+
+  "alice_47_330.npz": "val-47-75-8",
+
+  "alice_47_331.npz": "val-47-75-9",
+
+  "alice_47_332.npz": "val-47-75-10",
+
+  "alice_47_333.npz": "val-47-75-11",
+
+  "alice_47_334.npz": "val-47-76-0",
+
+  "alice_47_335.npz": "val-47-76-1",
+
+  "alice_47_336.npz": "val-47-77-0",
+
+  "alice_47_337.npz": "val-47-77-1",
+
+  "alice_47_338.npz": "val-47-78-0",
+
+  "alice_47_339.npz": "val-47-78-1",
+
+  "alice_47_340.npz": "val-47-78-2",
+
+  "alice_47_341.npz": "val-47-78-3",
+
+  "alice_47_342.npz": "val-47-78-4",
+
+  "alice_47_343.npz": "val-47-78-5",
+
+  "alice_47_344.npz": "val-47-78-6",
+
+  "alice_47_345.npz": "val-47-79-0",
+
+  "alice_47_346.npz": "val-47-79-1",
+
+  "alice_47_347.npz": "val-47-79-2",
+
+  "alice_47_348.npz": "val-47-79-3",
+
+  "alice_47_349.npz": "val-47-79-4",
+
+  "alice_47_350.npz": "val-47-79-5",
+
+  "alice_47_351.npz": "val-47-79-6",
+
+  "alice_47_352.npz": "val-47-80-0",
+
+  "alice_47_353.npz": "val-47-80-1",
+
+  "alice_47_354.npz": "val-47-80-2",
+
+  "alice_47_355.npz": "val-47-81-0",
+
+  "alice_47_356.npz": "val-47-82-0",
+
+  "alice_47_357.npz": "val-47-82-1",
+
+  "alice_47_358.npz": "val-47-82-2",
+
+  "alice_47_359.npz": "val-47-82-3",
+
+  "alice_47_360.npz": "val-47-82-4",
+
+  "alice_47_361.npz": "val-47-82-5",
+
+  "alice_51_322.npz": "val-51-75-0",
+
+  "alice_51_323.npz": "val-51-75-1",
+
+  "alice_51_324.npz": "val-51-75-2",
+
+  "alice_51_325.npz": "val-51-75-3",
+
+  "alice_51_326.npz": "val-51-75-4",
+
+  "alice_51_327.npz": "val-51-75-5",
+
+  "alice_51_328.npz": "val-51-75-6",
+
+  "alice_51_329.npz": "val-51-75-7",
+
+  "alice_51_330.npz": "val-51-75-8",
+
+  "alice_51_331.npz": "val-51-75-9",
+
+  "alice_51_332.npz": "val-51-75-10",
+
+  "alice_51_333.npz": "val-51-75-11",
+
+  "alice_51_334.npz": "val-51-76-0",
+
+  "alice_51_335.npz": "val-51-76-1",
+
+  "alice_51_336.npz": "val-51-77-0",
+
+  "alice_51_337.npz": "val-51-77-1",
+
+  "alice_51_338.npz": "val-51-78-0",
+
+  "alice_51_339.npz": "val-51-78-1",
+
+  "alice_51_340.npz": "val-51-78-2",
+
+  "alice_51_341.npz": "val-51-78-3",
+
+  "alice_51_342.npz": "val-51-78-4",
+
+  "alice_51_343.npz": "val-51-78-5",
+
+  "alice_51_344.npz": "val-51-78-6",
+
+  "alice_51_345.npz": "val-51-79-0",
+
+  "alice_51_346.npz": "val-51-79-1",
+
+  "alice_51_347.npz": "val-51-79-2",
+
+  "alice_51_348.npz": "val-51-79-3",
+
+  "alice_51_349.npz": "val-51-79-4",
+
+  "alice_51_350.npz": "val-51-79-5",
+
+  "alice_51_351.npz": "val-51-79-6",
+
+  "alice_51_352.npz": "val-51-80-0",
+
+  "alice_51_353.npz": "val-51-80-1",
+
+  "alice_51_354.npz": "val-51-80-2",
+
+  "alice_51_355.npz": "val-51-81-0",
+
+  "alice_51_356.npz": "val-51-82-0",
+
+  "alice_51_357.npz": "val-51-82-1",
+
+  "alice_51_358.npz": "val-51-82-2",
+
+  "alice_51_359.npz": "val-51-82-3",
+
+  "alice_51_360.npz": "val-51-82-4",
+
+  "alice_51_361.npz": "val-51-82-5",
+
+  "alice_24_322.npz": "val-24-75-0",
+
+  "alice_24_323.npz": "val-24-75-1",
+
+  "alice_24_324.npz": "val-24-75-2",
+
+  "alice_24_325.npz": "val-24-75-3",
+
+  "alice_24_326.npz": "val-24-75-4",
+
+  "alice_24_327.npz": "val-24-75-5",
+
+  "alice_24_328.npz": "val-24-75-6",
+
+  "alice_24_329.npz": "val-24-75-7",
+
+  "alice_24_330.npz": "val-24-75-8",
+
+  "alice_24_331.npz": "val-24-75-9",
+
+  "alice_24_332.npz": "val-24-75-10",
+
+  "alice_24_333.npz": "val-24-75-11",
+
+  "alice_24_334.npz": "val-24-76-0",
+
+  "alice_24_335.npz": "val-24-76-1",
+
+  "alice_24_336.npz": "val-24-77-0",
+
+  "alice_24_337.npz": "val-24-77-1",
+
+  "alice_24_338.npz": "val-24-78-0",
+
+  "alice_24_339.npz": "val-24-78-1",
+
+  "alice_24_340.npz": "val-24-78-2",
+
+  "alice_24_341.npz": "val-24-78-3",
+
+  "alice_24_342.npz": "val-24-78-4",
+
+  "alice_24_343.npz": "val-24-78-5",
+
+  "alice_24_344.npz": "val-24-78-6",
+
+  "alice_24_345.npz": "val-24-79-0",
+
+  "alice_24_346.npz": "val-24-79-1",
+
+  "alice_24_347.npz": "val-24-79-2",
+
+  "alice_24_348.npz": "val-24-79-3",
+
+  "alice_24_349.npz": "val-24-79-4",
+
+  "alice_24_350.npz": "val-24-79-5",
+
+  "alice_24_351.npz": "val-24-79-6",
+
+  "alice_24_352.npz": "val-24-80-0",
+
+  "alice_24_353.npz": "val-24-80-1",
+
+  "alice_24_354.npz": "val-24-80-2",
+
+  "alice_24_355.npz": "val-24-81-0",
+
+  "alice_24_356.npz": "val-24-82-0",
+
+  "alice_24_357.npz": "val-24-82-1",
+
+  "alice_24_358.npz": "val-24-82-2",
+
+  "alice_24_359.npz": "val-24-82-3",
+
+  "alice_24_360.npz": "val-24-82-4",
+
+  "alice_24_361.npz": "val-24-82-5",
+
+  "alice_35_322.npz": "val-35-75-0",
+
+  "alice_35_323.npz": "val-35-75-1",
+
+  "alice_35_324.npz": "val-35-75-2",
+
+  "alice_35_325.npz": "val-35-75-3",
+
+  "alice_35_326.npz": "val-35-75-4",
+
+  "alice_35_327.npz": "val-35-75-5",
+
+  "alice_35_328.npz": "val-35-75-6",
+
+  "alice_35_329.npz": "val-35-75-7",
+
+  "alice_35_330.npz": "val-35-75-8",
+
+  "alice_35_331.npz": "val-35-75-9",
+
+  "alice_35_332.npz": "val-35-75-10",
+
+  "alice_35_333.npz": "val-35-75-11",
+
+  "alice_35_334.npz": "val-35-76-0",
+
+  "alice_35_335.npz": "val-35-76-1",
+
+  "alice_35_336.npz": "val-35-77-0",
+
+  "alice_35_337.npz": "val-35-77-1",
+
+  "alice_35_338.npz": "val-35-78-0",
+
+  "alice_35_339.npz": "val-35-78-1",
+
+  "alice_35_340.npz": "val-35-78-2",
+
+  "alice_35_341.npz": "val-35-78-3",
+
+  "alice_35_342.npz": "val-35-78-4",
+
+  "alice_35_343.npz": "val-35-78-5",
+
+  "alice_35_344.npz": "val-35-78-6",
+
+  "alice_35_345.npz": "val-35-79-0",
+
+  "alice_35_346.npz": "val-35-79-1",
+
+  "alice_35_347.npz": "val-35-79-2",
+
+  "alice_35_348.npz": "val-35-79-3",
+
+  "alice_35_349.npz": "val-35-79-4",
+
+  "alice_35_350.npz": "val-35-79-5",
+
+  "alice_35_351.npz": "val-35-79-6",
+
+  "alice_35_352.npz": "val-35-80-0",
+
+  "alice_35_353.npz": "val-35-80-1",
+
+  "alice_35_354.npz": "val-35-80-2",
+
+  "alice_35_355.npz": "val-35-81-0",
+
+  "alice_35_356.npz": "val-35-82-0",
+
+  "alice_35_357.npz": "val-35-82-1",
+
+  "alice_35_358.npz": "val-35-82-2",
+
+  "alice_35_359.npz": "val-35-82-3",
+
+  "alice_35_360.npz": "val-35-82-4",
+
+  "alice_35_361.npz": "val-35-82-5",
+
+  "alice_28_322.npz": "val-28-75-0",
+
+  "alice_28_323.npz": "val-28-75-1",
+
+  "alice_28_324.npz": "val-28-75-2",
+
+  "alice_28_325.npz": "val-28-75-3",
+
+  "alice_28_326.npz": "val-28-75-4",
+
+  "alice_28_327.npz": "val-28-75-5",
+
+  "alice_28_328.npz": "val-28-75-6",
+
+  "alice_28_329.npz": "val-28-75-7",
+
+  "alice_28_330.npz": "val-28-75-8",
+
+  "alice_28_331.npz": "val-28-75-9",
+
+  "alice_28_332.npz": "val-28-75-10",
+
+  "alice_28_333.npz": "val-28-75-11",
+
+  "alice_28_334.npz": "val-28-76-0",
+
+  "alice_28_335.npz": "val-28-76-1",
+
+  "alice_28_336.npz": "val-28-77-0",
+
+  "alice_28_337.npz": "val-28-77-1",
+
+  "alice_28_338.npz": "val-28-78-0",
+
+  "alice_28_339.npz": "val-28-78-1",
+
+  "alice_28_340.npz": "val-28-78-2",
+
+  "alice_28_341.npz": "val-28-78-3",
+
+  "alice_28_342.npz": "val-28-78-4",
+
+  "alice_28_343.npz": "val-28-78-5",
+
+  "alice_28_344.npz": "val-28-78-6",
+
+  "alice_28_345.npz": "val-28-79-0",
+
+  "alice_28_346.npz": "val-28-79-1",
+
+  "alice_28_347.npz": "val-28-79-2",
+
+  "alice_28_348.npz": "val-28-79-3",
+
+  "alice_28_349.npz": "val-28-79-4",
+
+  "alice_28_350.npz": "val-28-79-5",
+
+  "alice_28_351.npz": "val-28-79-6",
+
+  "alice_28_352.npz": "val-28-80-0",
+
+  "alice_28_353.npz": "val-28-80-1",
+
+  "alice_28_354.npz": "val-28-80-2",
+
+  "alice_28_355.npz": "val-28-81-0",
+
+  "alice_28_356.npz": "val-28-82-0",
+
+  "alice_28_357.npz": "val-28-82-1",
+
+  "alice_28_358.npz": "val-28-82-2",
+
+  "alice_28_359.npz": "val-28-82-3",
+
+  "alice_28_360.npz": "val-28-82-4",
+
+  "alice_28_361.npz": "val-28-82-5",
+
+  "alice_53_322.npz": "val-53-75-0",
+
+  "alice_53_323.npz": "val-53-75-1",
+
+  "alice_53_324.npz": "val-53-75-2",
+
+  "alice_53_325.npz": "val-53-75-3",
+
+  "alice_53_326.npz": "val-53-75-4",
+
+  "alice_53_327.npz": "val-53-75-5",
+
+  "alice_53_328.npz": "val-53-75-6",
+
+  "alice_53_329.npz": "val-53-75-7",
+
+  "alice_53_330.npz": "val-53-75-8",
+
+  "alice_53_331.npz": "val-53-75-9",
+
+  "alice_53_332.npz": "val-53-75-10",
+
+  "alice_53_333.npz": "val-53-75-11",
+
+  "alice_53_334.npz": "val-53-76-0",
+
+  "alice_53_335.npz": "val-53-76-1",
+
+  "alice_53_336.npz": "val-53-77-0",
+
+  "alice_53_337.npz": "val-53-77-1",
+
+  "alice_53_338.npz": "val-53-78-0",
+
+  "alice_53_339.npz": "val-53-78-1",
+
+  "alice_53_340.npz": "val-53-78-2",
+
+  "alice_53_341.npz": "val-53-78-3",
+
+  "alice_53_342.npz": "val-53-78-4",
+
+  "alice_53_343.npz": "val-53-78-5",
+
+  "alice_53_344.npz": "val-53-78-6",
+
+  "alice_53_345.npz": "val-53-79-0",
+
+  "alice_53_346.npz": "val-53-79-1",
+
+  "alice_53_347.npz": "val-53-79-2",
+
+  "alice_53_348.npz": "val-53-79-3",
+
+  "alice_53_349.npz": "val-53-79-4",
+
+  "alice_53_350.npz": "val-53-79-5",
+
+  "alice_53_351.npz": "val-53-79-6",
+
+  "alice_53_352.npz": "val-53-80-0",
+
+  "alice_53_353.npz": "val-53-80-1",
+
+  "alice_53_354.npz": "val-53-80-2",
+
+  "alice_53_355.npz": "val-53-81-0",
+
+  "alice_53_356.npz": "val-53-82-0",
+
+  "alice_53_357.npz": "val-53-82-1",
+
+  "alice_53_358.npz": "val-53-82-2",
+
+  "alice_53_359.npz": "val-53-82-3",
+
+  "alice_53_360.npz": "val-53-82-4",
+
+  "alice_53_361.npz": "val-53-82-5",
+
+  "alice_23_322.npz": "val-23-75-0",
+
+  "alice_23_323.npz": "val-23-75-1",
+
+  "alice_23_324.npz": "val-23-75-2",
+
+  "alice_23_325.npz": "val-23-75-3",
+
+  "alice_23_326.npz": "val-23-75-4",
+
+  "alice_23_327.npz": "val-23-75-5",
+
+  "alice_23_328.npz": "val-23-75-6",
+
+  "alice_23_329.npz": "val-23-75-7",
+
+  "alice_23_330.npz": "val-23-75-8",
+
+  "alice_23_331.npz": "val-23-75-9",
+
+  "alice_23_332.npz": "val-23-75-10",
+
+  "alice_23_333.npz": "val-23-75-11",
+
+  "alice_23_334.npz": "val-23-76-0",
+
+  "alice_23_335.npz": "val-23-76-1",
+
+  "alice_23_336.npz": "val-23-77-0",
+
+  "alice_23_337.npz": "val-23-77-1",
+
+  "alice_23_338.npz": "val-23-78-0",
+
+  "alice_23_339.npz": "val-23-78-1",
+
+  "alice_23_340.npz": "val-23-78-2",
+
+  "alice_23_341.npz": "val-23-78-3",
+
+  "alice_23_342.npz": "val-23-78-4",
+
+  "alice_23_343.npz": "val-23-78-5",
+
+  "alice_23_344.npz": "val-23-78-6",
+
+  "alice_23_345.npz": "val-23-79-0",
+
+  "alice_23_346.npz": "val-23-79-1",
+
+  "alice_23_347.npz": "val-23-79-2",
+
+  "alice_23_348.npz": "val-23-79-3",
+
+  "alice_23_349.npz": "val-23-79-4",
+
+  "alice_23_350.npz": "val-23-79-5",
+
+  "alice_23_351.npz": "val-23-79-6",
+
+  "alice_23_352.npz": "val-23-80-0",
+
+  "alice_23_353.npz": "val-23-80-1",
+
+  "alice_23_354.npz": "val-23-80-2",
+
+  "alice_23_355.npz": "val-23-81-0",
+
+  "alice_23_356.npz": "val-23-82-0",
+
+  "alice_23_357.npz": "val-23-82-1",
+
+  "alice_23_358.npz": "val-23-82-2",
+
+  "alice_23_359.npz": "val-23-82-3",
+
+  "alice_23_360.npz": "val-23-82-4",
+
+  "alice_23_361.npz": "val-23-82-5",
+
+  "alice_36_322.npz": "val-36-75-0",
+
+  "alice_36_323.npz": "val-36-75-1",
+
+  "alice_36_324.npz": "val-36-75-2",
+
+  "alice_36_325.npz": "val-36-75-3",
+
+  "alice_36_326.npz": "val-36-75-4",
+
+  "alice_36_327.npz": "val-36-75-5",
+
+  "alice_36_328.npz": "val-36-75-6",
+
+  "alice_36_329.npz": "val-36-75-7",
+
+  "alice_36_330.npz": "val-36-75-8",
+
+  "alice_36_331.npz": "val-36-75-9",
+
+  "alice_36_332.npz": "val-36-75-10",
+
+  "alice_36_333.npz": "val-36-75-11",
+
+  "alice_36_334.npz": "val-36-76-0",
+
+  "alice_36_335.npz": "val-36-76-1",
+
+  "alice_36_336.npz": "val-36-77-0",
+
+  "alice_36_337.npz": "val-36-77-1",
+
+  "alice_36_338.npz": "val-36-78-0",
+
+  "alice_36_339.npz": "val-36-78-1",
+
+  "alice_36_340.npz": "val-36-78-2",
+
+  "alice_36_341.npz": "val-36-78-3",
+
+  "alice_36_342.npz": "val-36-78-4",
+
+  "alice_36_343.npz": "val-36-78-5",
+
+  "alice_36_344.npz": "val-36-78-6",
+
+  "alice_36_345.npz": "val-36-79-0",
+
+  "alice_36_346.npz": "val-36-79-1",
+
+  "alice_36_347.npz": "val-36-79-2",
+
+  "alice_36_348.npz": "val-36-79-3",
+
+  "alice_36_349.npz": "val-36-79-4",
+
+  "alice_36_350.npz": "val-36-79-5",
+
+  "alice_36_351.npz": "val-36-79-6",
+
+  "alice_36_352.npz": "val-36-80-0",
+
+  "alice_36_353.npz": "val-36-80-1",
+
+  "alice_36_354.npz": "val-36-80-2",
+
+  "alice_36_355.npz": "val-36-81-0",
+
+  "alice_36_356.npz": "val-36-82-0",
+
+  "alice_36_357.npz": "val-36-82-1",
+
+  "alice_36_358.npz": "val-36-82-2",
+
+  "alice_36_359.npz": "val-36-82-3",
+
+  "alice_36_360.npz": "val-36-82-4",
+
+  "alice_36_361.npz": "val-36-82-5",
+
+  "alice_42_322.npz": "val-42-75-0",
+
+  "alice_42_323.npz": "val-42-75-1",
+
+  "alice_42_324.npz": "val-42-75-2",
+
+  "alice_42_325.npz": "val-42-75-3",
+
+  "alice_42_326.npz": "val-42-75-4",
+
+  "alice_42_327.npz": "val-42-75-5",
+
+  "alice_42_328.npz": "val-42-75-6",
+
+  "alice_42_329.npz": "val-42-75-7",
+
+  "alice_42_330.npz": "val-42-75-8",
+
+  "alice_42_331.npz": "val-42-75-9",
+
+  "alice_42_332.npz": "val-42-75-10",
+
+  "alice_42_333.npz": "val-42-75-11",
+
+  "alice_42_334.npz": "val-42-76-0",
+
+  "alice_42_335.npz": "val-42-76-1",
+
+  "alice_42_336.npz": "val-42-77-0",
+
+  "alice_42_337.npz": "val-42-77-1",
+
+  "alice_42_338.npz": "val-42-78-0",
+
+  "alice_42_339.npz": "val-42-78-1",
+
+  "alice_42_340.npz": "val-42-78-2",
+
+  "alice_42_341.npz": "val-42-78-3",
+
+  "alice_42_342.npz": "val-42-78-4",
+
+  "alice_42_343.npz": "val-42-78-5",
+
+  "alice_42_344.npz": "val-42-78-6",
+
+  "alice_42_345.npz": "val-42-79-0",
+
+  "alice_42_346.npz": "val-42-79-1",
+
+  "alice_42_347.npz": "val-42-79-2",
+
+  "alice_42_348.npz": "val-42-79-3",
+
+  "alice_42_349.npz": "val-42-79-4",
+
+  "alice_42_350.npz": "val-42-79-5",
+
+  "alice_42_351.npz": "val-42-79-6",
+
+  "alice_42_352.npz": "val-42-80-0",
+
+  "alice_42_353.npz": "val-42-80-1",
+
+  "alice_42_354.npz": "val-42-80-2",
+
+  "alice_42_355.npz": "val-42-81-0",
+
+  "alice_42_356.npz": "val-42-82-0",
+
+  "alice_42_357.npz": "val-42-82-1",
+
+  "alice_42_358.npz": "val-42-82-2",
+
+  "alice_42_359.npz": "val-42-82-3",
+
+  "alice_42_360.npz": "val-42-82-4",
+
+  "alice_42_361.npz": "val-42-82-5",
+
+  "alice_44_322.npz": "val-44-75-0",
+
+  "alice_44_323.npz": "val-44-75-1",
+
+  "alice_44_324.npz": "val-44-75-2",
+
+  "alice_44_325.npz": "val-44-75-3",
+
+  "alice_44_326.npz": "val-44-75-4",
+
+  "alice_44_327.npz": "val-44-75-5",
+
+  "alice_44_328.npz": "val-44-75-6",
+
+  "alice_44_329.npz": "val-44-75-7",
+
+  "alice_44_330.npz": "val-44-75-8",
+
+  "alice_44_331.npz": "val-44-75-9",
+
+  "alice_44_332.npz": "val-44-75-10",
+
+  "alice_44_333.npz": "val-44-75-11",
+
+  "alice_44_334.npz": "val-44-76-0",
+
+  "alice_44_335.npz": "val-44-76-1",
+
+  "alice_44_336.npz": "val-44-77-0",
+
+  "alice_44_337.npz": "val-44-77-1",
+
+  "alice_44_338.npz": "val-44-78-0",
+
+  "alice_44_339.npz": "val-44-78-1",
+
+  "alice_44_340.npz": "val-44-78-2",
+
+  "alice_44_341.npz": "val-44-78-3",
+
+  "alice_44_342.npz": "val-44-78-4",
+
+  "alice_44_343.npz": "val-44-78-5",
+
+  "alice_44_344.npz": "val-44-78-6",
+
+  "alice_44_345.npz": "val-44-79-0",
+
+  "alice_44_346.npz": "val-44-79-1",
+
+  "alice_44_347.npz": "val-44-79-2",
+
+  "alice_44_348.npz": "val-44-79-3",
+
+  "alice_44_349.npz": "val-44-79-4",
+
+  "alice_44_350.npz": "val-44-79-5",
+
+  "alice_44_351.npz": "val-44-79-6",
+
+  "alice_44_352.npz": "val-44-80-0",
+
+  "alice_44_353.npz": "val-44-80-1",
+
+  "alice_44_354.npz": "val-44-80-2",
+
+  "alice_44_355.npz": "val-44-81-0",
+
+  "alice_44_356.npz": "val-44-82-0",
+
+  "alice_44_357.npz": "val-44-82-1",
+
+  "alice_44_358.npz": "val-44-82-2",
+
+  "alice_44_359.npz": "val-44-82-3",
+
+  "alice_44_360.npz": "val-44-82-4",
+
+  "alice_44_361.npz": "val-44-82-5",
+
+  "alice_39_322.npz": "val-39-75-0",
+
+  "alice_39_323.npz": "val-39-75-1",
+
+  "alice_39_324.npz": "val-39-75-2",
+
+  "alice_39_325.npz": "val-39-75-3",
+
+  "alice_39_326.npz": "val-39-75-4",
+
+  "alice_39_327.npz": "val-39-75-5",
+
+  "alice_39_328.npz": "val-39-75-6",
+
+  "alice_39_329.npz": "val-39-75-7",
+
+  "alice_39_330.npz": "val-39-75-8",
+
+  "alice_39_331.npz": "val-39-75-9",
+
+  "alice_39_332.npz": "val-39-75-10",
+
+  "alice_39_333.npz": "val-39-75-11",
+
+  "alice_39_334.npz": "val-39-76-0",
+
+  "alice_39_335.npz": "val-39-76-1",
+
+  "alice_39_336.npz": "val-39-77-0",
+
+  "alice_39_337.npz": "val-39-77-1",
+
+  "alice_39_338.npz": "val-39-78-0",
+
+  "alice_39_339.npz": "val-39-78-1",
+
+  "alice_39_340.npz": "val-39-78-2",
+
+  "alice_39_341.npz": "val-39-78-3",
+
+  "alice_39_342.npz": "val-39-78-4",
+
+  "alice_39_343.npz": "val-39-78-5",
+
+  "alice_39_344.npz": "val-39-78-6",
+
+  "alice_39_345.npz": "val-39-79-0",
+
+  "alice_39_346.npz": "val-39-79-1",
+
+  "alice_39_347.npz": "val-39-79-2",
+
+  "alice_39_348.npz": "val-39-79-3",
+
+  "alice_39_349.npz": "val-39-79-4",
+
+  "alice_39_350.npz": "val-39-79-5",
+
+  "alice_39_351.npz": "val-39-79-6",
+
+  "alice_39_352.npz": "val-39-80-0",
+
+  "alice_39_353.npz": "val-39-80-1",
+
+  "alice_39_354.npz": "val-39-80-2",
+
+  "alice_39_355.npz": "val-39-81-0",
+
+  "alice_39_356.npz": "val-39-82-0",
+
+  "alice_39_357.npz": "val-39-82-1",
+
+  "alice_39_358.npz": "val-39-82-2",
+
+  "alice_39_359.npz": "val-39-82-3",
+
+  "alice_39_360.npz": "val-39-82-4",
+
+  "alice_39_361.npz": "val-39-82-5",
+
+  "alice_41_322.npz": "val-41-75-0",
+
+  "alice_41_323.npz": "val-41-75-1",
+
+  "alice_41_324.npz": "val-41-75-2",
+
+  "alice_41_325.npz": "val-41-75-3",
+
+  "alice_41_326.npz": "val-41-75-4",
+
+  "alice_41_327.npz": "val-41-75-5",
+
+  "alice_41_328.npz": "val-41-75-6",
+
+  "alice_41_329.npz": "val-41-75-7",
+
+  "alice_41_330.npz": "val-41-75-8",
+
+  "alice_41_331.npz": "val-41-75-9",
+
+  "alice_41_332.npz": "val-41-75-10",
+
+  "alice_41_333.npz": "val-41-75-11",
+
+  "alice_41_334.npz": "val-41-76-0",
+
+  "alice_41_335.npz": "val-41-76-1",
+
+  "alice_41_336.npz": "val-41-77-0",
+
+  "alice_41_337.npz": "val-41-77-1",
+
+  "alice_41_338.npz": "val-41-78-0",
+
+  "alice_41_339.npz": "val-41-78-1",
+
+  "alice_41_340.npz": "val-41-78-2",
+
+  "alice_41_341.npz": "val-41-78-3",
+
+  "alice_41_342.npz": "val-41-78-4",
+
+  "alice_41_343.npz": "val-41-78-5",
+
+  "alice_41_344.npz": "val-41-78-6",
+
+  "alice_41_345.npz": "val-41-79-0",
+
+  "alice_41_346.npz": "val-41-79-1",
+
+  "alice_41_347.npz": "val-41-79-2",
+
+  "alice_41_348.npz": "val-41-79-3",
+
+  "alice_41_349.npz": "val-41-79-4",
+
+  "alice_41_350.npz": "val-41-79-5",
+
+  "alice_41_351.npz": "val-41-79-6",
+
+  "alice_41_352.npz": "val-41-80-0",
+
+  "alice_41_353.npz": "val-41-80-1",
+
+  "alice_41_354.npz": "val-41-80-2",
+
+  "alice_41_355.npz": "val-41-81-0",
+
+  "alice_41_356.npz": "val-41-82-0",
+
+  "alice_41_357.npz": "val-41-82-1",
+
+  "alice_41_358.npz": "val-41-82-2",
+
+  "alice_41_359.npz": "val-41-82-3",
+
+  "alice_41_360.npz": "val-41-82-4",
+
+  "alice_41_361.npz": "val-41-82-5",
+
+  "alice_30_322.npz": "val-30-75-0",
+
+  "alice_30_323.npz": "val-30-75-1",
+
+  "alice_30_324.npz": "val-30-75-2",
+
+  "alice_30_325.npz": "val-30-75-3",
+
+  "alice_30_326.npz": "val-30-75-4",
+
+  "alice_30_327.npz": "val-30-75-5",
+
+  "alice_30_328.npz": "val-30-75-6",
+
+  "alice_30_329.npz": "val-30-75-7",
+
+  "alice_30_330.npz": "val-30-75-8",
+
+  "alice_30_331.npz": "val-30-75-9",
+
+  "alice_30_332.npz": "val-30-75-10",
+
+  "alice_30_333.npz": "val-30-75-11",
+
+  "alice_30_334.npz": "val-30-76-0",
+
+  "alice_30_335.npz": "val-30-76-1",
+
+  "alice_30_336.npz": "val-30-77-0",
+
+  "alice_30_337.npz": "val-30-77-1",
+
+  "alice_30_338.npz": "val-30-78-0",
+
+  "alice_30_339.npz": "val-30-78-1",
+
+  "alice_30_340.npz": "val-30-78-2",
+
+  "alice_30_341.npz": "val-30-78-3",
+
+  "alice_30_342.npz": "val-30-78-4",
+
+  "alice_30_343.npz": "val-30-78-5",
+
+  "alice_30_344.npz": "val-30-78-6",
+
+  "alice_30_345.npz": "val-30-79-0",
+
+  "alice_30_346.npz": "val-30-79-1",
+
+  "alice_30_347.npz": "val-30-79-2",
+
+  "alice_30_348.npz": "val-30-79-3",
+
+  "alice_30_349.npz": "val-30-79-4",
+
+  "alice_30_350.npz": "val-30-79-5",
+
+  "alice_30_351.npz": "val-30-79-6",
+
+  "alice_30_352.npz": "val-30-80-0",
+
+  "alice_30_353.npz": "val-30-80-1",
+
+  "alice_30_354.npz": "val-30-80-2",
+
+  "alice_30_355.npz": "val-30-81-0",
+
+  "alice_30_356.npz": "val-30-82-0",
+
+  "alice_30_357.npz": "val-30-82-1",
+
+  "alice_30_358.npz": "val-30-82-2",
+
+  "alice_30_359.npz": "val-30-82-3",
+
+  "alice_30_360.npz": "val-30-82-4",
+
+  "alice_30_361.npz": "val-30-82-5",
+
+  "alice_43_322.npz": "val-43-75-0",
+
+  "alice_43_323.npz": "val-43-75-1",
+
+  "alice_43_324.npz": "val-43-75-2",
+
+  "alice_43_325.npz": "val-43-75-3",
+
+  "alice_43_326.npz": "val-43-75-4",
+
+  "alice_43_327.npz": "val-43-75-5",
+
+  "alice_43_328.npz": "val-43-75-6",
+
+  "alice_43_329.npz": "val-43-75-7",
+
+  "alice_43_330.npz": "val-43-75-8",
+
+  "alice_43_331.npz": "val-43-75-9",
+
+  "alice_43_332.npz": "val-43-75-10",
+
+  "alice_43_333.npz": "val-43-75-11",
+
+  "alice_43_334.npz": "val-43-76-0",
+
+  "alice_43_335.npz": "val-43-76-1",
+
+  "alice_43_336.npz": "val-43-77-0",
+
+  "alice_43_337.npz": "val-43-77-1",
+
+  "alice_43_338.npz": "val-43-78-0",
+
+  "alice_43_339.npz": "val-43-78-1",
+
+  "alice_43_340.npz": "val-43-78-2",
+
+  "alice_43_341.npz": "val-43-78-3",
+
+  "alice_43_342.npz": "val-43-78-4",
+
+  "alice_43_343.npz": "val-43-78-5",
+
+  "alice_43_344.npz": "val-43-78-6",
+
+  "alice_43_345.npz": "val-43-79-0",
+
+  "alice_43_346.npz": "val-43-79-1",
+
+  "alice_43_347.npz": "val-43-79-2",
+
+  "alice_43_348.npz": "val-43-79-3",
+
+  "alice_43_349.npz": "val-43-79-4",
+
+  "alice_43_350.npz": "val-43-79-5",
+
+  "alice_43_351.npz": "val-43-79-6",
+
+  "alice_43_352.npz": "val-43-80-0",
+
+  "alice_43_353.npz": "val-43-80-1",
+
+  "alice_43_354.npz": "val-43-80-2",
+
+  "alice_43_355.npz": "val-43-81-0",
+
+  "alice_43_356.npz": "val-43-82-0",
+
+  "alice_43_357.npz": "val-43-82-1",
+
+  "alice_43_358.npz": "val-43-82-2",
+
+  "alice_43_359.npz": "val-43-82-3",
+
+  "alice_43_360.npz": "val-43-82-4",
+
+  "alice_43_361.npz": "val-43-82-5",
+
+  "alice_45_322.npz": "val-45-75-0",
+
+  "alice_45_323.npz": "val-45-75-1",
+
+  "alice_45_324.npz": "val-45-75-2",
+
+  "alice_45_325.npz": "val-45-75-3",
+
+  "alice_45_326.npz": "val-45-75-4",
+
+  "alice_45_327.npz": "val-45-75-5",
+
+  "alice_45_328.npz": "val-45-75-6",
+
+  "alice_45_329.npz": "val-45-75-7",
+
+  "alice_45_330.npz": "val-45-75-8",
+
+  "alice_45_331.npz": "val-45-75-9",
+
+  "alice_45_332.npz": "val-45-75-10",
+
+  "alice_45_333.npz": "val-45-75-11",
+
+  "alice_45_334.npz": "val-45-76-0",
+
+  "alice_45_335.npz": "val-45-76-1",
+
+  "alice_45_336.npz": "val-45-77-0",
+
+  "alice_45_337.npz": "val-45-77-1",
+
+  "alice_45_338.npz": "val-45-78-0",
+
+  "alice_45_339.npz": "val-45-78-1",
+
+  "alice_45_340.npz": "val-45-78-2",
+
+  "alice_45_341.npz": "val-45-78-3",
+
+  "alice_45_342.npz": "val-45-78-4",
+
+  "alice_45_343.npz": "val-45-78-5",
+
+  "alice_45_344.npz": "val-45-78-6",
+
+  "alice_45_345.npz": "val-45-79-0",
+
+  "alice_45_346.npz": "val-45-79-1",
+
+  "alice_45_347.npz": "val-45-79-2",
+
+  "alice_45_348.npz": "val-45-79-3",
+
+  "alice_45_349.npz": "val-45-79-4",
+
+  "alice_45_350.npz": "val-45-79-5",
+
+  "alice_45_351.npz": "val-45-79-6",
+
+  "alice_45_352.npz": "val-45-80-0",
+
+  "alice_45_353.npz": "val-45-80-1",
+
+  "alice_45_354.npz": "val-45-80-2",
+
+  "alice_45_355.npz": "val-45-81-0",
+
+  "alice_45_356.npz": "val-45-82-0",
+
+  "alice_45_357.npz": "val-45-82-1",
+
+  "alice_45_358.npz": "val-45-82-2",
+
+  "alice_45_359.npz": "val-45-82-3",
+
+  "alice_45_360.npz": "val-45-82-4",
+
+  "alice_45_361.npz": "val-45-82-5",
+
+  "alice_49_322.npz": "val-49-75-0",
+
+  "alice_49_323.npz": "val-49-75-1",
+
+  "alice_49_324.npz": "val-49-75-2",
+
+  "alice_49_325.npz": "val-49-75-3",
+
+  "alice_49_326.npz": "val-49-75-4",
+
+  "alice_49_327.npz": "val-49-75-5",
+
+  "alice_49_328.npz": "val-49-75-6",
+
+  "alice_49_329.npz": "val-49-75-7",
+
+  "alice_49_330.npz": "val-49-75-8",
+
+  "alice_49_331.npz": "val-49-75-9",
+
+  "alice_49_332.npz": "val-49-75-10",
+
+  "alice_49_333.npz": "val-49-75-11",
+
+  "alice_49_334.npz": "val-49-76-0",
+
+  "alice_49_335.npz": "val-49-76-1",
+
+  "alice_49_336.npz": "val-49-77-0",
+
+  "alice_49_337.npz": "val-49-77-1",
+
+  "alice_49_338.npz": "val-49-78-0",
+
+  "alice_49_339.npz": "val-49-78-1",
+
+  "alice_49_340.npz": "val-49-78-2",
+
+  "alice_49_341.npz": "val-49-78-3",
+
+  "alice_49_342.npz": "val-49-78-4",
+
+  "alice_49_343.npz": "val-49-78-5",
+
+  "alice_49_344.npz": "val-49-78-6",
+
+  "alice_49_345.npz": "val-49-79-0",
+
+  "alice_49_346.npz": "val-49-79-1",
+
+  "alice_49_347.npz": "val-49-79-2",
+
+  "alice_49_348.npz": "val-49-79-3",
+
+  "alice_49_349.npz": "val-49-79-4",
+
+  "alice_49_350.npz": "val-49-79-5",
+
+  "alice_49_351.npz": "val-49-79-6",
+
+  "alice_49_352.npz": "val-49-80-0",
+
+  "alice_49_353.npz": "val-49-80-1",
+
+  "alice_49_354.npz": "val-49-80-2",
+
+  "alice_49_355.npz": "val-49-81-0",
+
+  "alice_49_356.npz": "val-49-82-0",
+
+  "alice_49_357.npz": "val-49-82-1",
+
+  "alice_49_358.npz": "val-49-82-2",
+
+  "alice_49_359.npz": "val-49-82-3",
+
+  "alice_49_360.npz": "val-49-82-4",
+
+  "alice_49_361.npz": "val-49-82-5",
+
+  "alice_26_322.npz": "val-26-75-0",
+
+  "alice_26_323.npz": "val-26-75-1",
+
+  "alice_26_324.npz": "val-26-75-2",
+
+  "alice_26_325.npz": "val-26-75-3",
+
+  "alice_26_326.npz": "val-26-75-4",
+
+  "alice_26_327.npz": "val-26-75-5",
+
+  "alice_26_328.npz": "val-26-75-6",
+
+  "alice_26_329.npz": "val-26-75-7",
+
+  "alice_26_330.npz": "val-26-75-8",
+
+  "alice_26_331.npz": "val-26-75-9",
+
+  "alice_26_332.npz": "val-26-75-10",
+
+  "alice_26_333.npz": "val-26-75-11",
+
+  "alice_26_334.npz": "val-26-76-0",
+
+  "alice_26_335.npz": "val-26-76-1",
+
+  "alice_26_336.npz": "val-26-77-0",
+
+  "alice_26_337.npz": "val-26-77-1",
+
+  "alice_26_338.npz": "val-26-78-0",
+
+  "alice_26_339.npz": "val-26-78-1",
+
+  "alice_26_340.npz": "val-26-78-2",
+
+  "alice_26_341.npz": "val-26-78-3",
+
+  "alice_26_342.npz": "val-26-78-4",
+
+  "alice_26_343.npz": "val-26-78-5",
+
+  "alice_26_344.npz": "val-26-78-6",
+
+  "alice_26_345.npz": "val-26-79-0",
+
+  "alice_26_346.npz": "val-26-79-1",
+
+  "alice_26_347.npz": "val-26-79-2",
+
+  "alice_26_348.npz": "val-26-79-3",
+
+  "alice_26_349.npz": "val-26-79-4",
+
+  "alice_26_350.npz": "val-26-79-5",
+
+  "alice_26_351.npz": "val-26-79-6",
+
+  "alice_26_352.npz": "val-26-80-0",
+
+  "alice_26_353.npz": "val-26-80-1",
+
+  "alice_26_354.npz": "val-26-80-2",
+
+  "alice_26_355.npz": "val-26-81-0",
+
+  "alice_26_356.npz": "val-26-82-0",
+
+  "alice_26_357.npz": "val-26-82-1",
+
+  "alice_26_358.npz": "val-26-82-2",
+
+  "alice_26_359.npz": "val-26-82-3",
+
+  "alice_26_360.npz": "val-26-82-4",
+
+  "alice_26_361.npz": "val-26-82-5",
+
+  "alice_22_322.npz": "val-22-75-0",
+
+  "alice_22_323.npz": "val-22-75-1",
+
+  "alice_22_324.npz": "val-22-75-2",
+
+  "alice_22_325.npz": "val-22-75-3",
+
+  "alice_22_326.npz": "val-22-75-4",
+
+  "alice_22_327.npz": "val-22-75-5",
+
+  "alice_22_328.npz": "val-22-75-6",
+
+  "alice_22_329.npz": "val-22-75-7",
+
+  "alice_22_330.npz": "val-22-75-8",
+
+  "alice_22_331.npz": "val-22-75-9",
+
+  "alice_22_332.npz": "val-22-75-10",
+
+  "alice_22_333.npz": "val-22-75-11",
+
+  "alice_22_334.npz": "val-22-76-0",
+
+  "alice_22_335.npz": "val-22-76-1",
+
+  "alice_22_336.npz": "val-22-77-0",
+
+  "alice_22_337.npz": "val-22-77-1",
+
+  "alice_22_338.npz": "val-22-78-0",
+
+  "alice_22_339.npz": "val-22-78-1",
+
+  "alice_22_340.npz": "val-22-78-2",
+
+  "alice_22_341.npz": "val-22-78-3",
+
+  "alice_22_342.npz": "val-22-78-4",
+
+  "alice_22_343.npz": "val-22-78-5",
+
+  "alice_22_344.npz": "val-22-78-6",
+
+  "alice_22_345.npz": "val-22-79-0",
+
+  "alice_22_346.npz": "val-22-79-1",
+
+  "alice_22_347.npz": "val-22-79-2",
+
+  "alice_22_348.npz": "val-22-79-3",
+
+  "alice_22_349.npz": "val-22-79-4",
+
+  "alice_22_350.npz": "val-22-79-5",
+
+  "alice_22_351.npz": "val-22-79-6",
+
+  "alice_22_352.npz": "val-22-80-0",
+
+  "alice_22_353.npz": "val-22-80-1",
+
+  "alice_22_354.npz": "val-22-80-2",
+
+  "alice_22_355.npz": "val-22-81-0",
+
+  "alice_22_356.npz": "val-22-82-0",
+
+  "alice_22_357.npz": "val-22-82-1",
+
+  "alice_22_358.npz": "val-22-82-2",
+
+  "alice_22_359.npz": "val-22-82-3",
+
+  "alice_22_360.npz": "val-22-82-4",
+
+  "alice_22_361.npz": "val-22-82-5",
+
+  "alice_50_322.npz": "val-50-75-0",
+
+  "alice_50_323.npz": "val-50-75-1",
+
+  "alice_50_324.npz": "val-50-75-2",
+
+  "alice_50_325.npz": "val-50-75-3",
+
+  "alice_50_326.npz": "val-50-75-4",
+
+  "alice_50_327.npz": "val-50-75-5",
+
+  "alice_50_328.npz": "val-50-75-6",
+
+  "alice_50_329.npz": "val-50-75-7",
+
+  "alice_50_330.npz": "val-50-75-8",
+
+  "alice_50_331.npz": "val-50-75-9",
+
+  "alice_50_332.npz": "val-50-75-10",
+
+  "alice_50_333.npz": "val-50-75-11",
+
+  "alice_50_334.npz": "val-50-76-0",
+
+  "alice_50_335.npz": "val-50-76-1",
+
+  "alice_50_336.npz": "val-50-77-0",
+
+  "alice_50_337.npz": "val-50-77-1",
+
+  "alice_50_338.npz": "val-50-78-0",
+
+  "alice_50_339.npz": "val-50-78-1",
+
+  "alice_50_340.npz": "val-50-78-2",
+
+  "alice_50_341.npz": "val-50-78-3",
+
+  "alice_50_342.npz": "val-50-78-4",
+
+  "alice_50_343.npz": "val-50-78-5",
+
+  "alice_50_344.npz": "val-50-78-6",
+
+  "alice_50_345.npz": "val-50-79-0",
+
+  "alice_50_346.npz": "val-50-79-1",
+
+  "alice_50_347.npz": "val-50-79-2",
+
+  "alice_50_348.npz": "val-50-79-3",
+
+  "alice_50_349.npz": "val-50-79-4",
+
+  "alice_50_350.npz": "val-50-79-5",
+
+  "alice_50_351.npz": "val-50-79-6",
+
+  "alice_50_352.npz": "val-50-80-0",
+
+  "alice_50_353.npz": "val-50-80-1",
+
+  "alice_50_354.npz": "val-50-80-2",
+
+  "alice_50_355.npz": "val-50-81-0",
+
+  "alice_50_356.npz": "val-50-82-0",
+
+  "alice_50_357.npz": "val-50-82-1",
+
+  "alice_50_358.npz": "val-50-82-2",
+
+  "alice_50_359.npz": "val-50-82-3",
+
+  "alice_50_360.npz": "val-50-82-4",
+
+  "alice_50_361.npz": "val-50-82-5",
+
+  "alice_37_322.npz": "val-37-75-0",
+
+  "alice_37_323.npz": "val-37-75-1",
+
+  "alice_37_324.npz": "val-37-75-2",
+
+  "alice_37_325.npz": "val-37-75-3",
+
+  "alice_37_326.npz": "val-37-75-4",
+
+  "alice_37_327.npz": "val-37-75-5",
+
+  "alice_37_328.npz": "val-37-75-6",
+
+  "alice_37_329.npz": "val-37-75-7",
+
+  "alice_37_330.npz": "val-37-75-8",
+
+  "alice_37_331.npz": "val-37-75-9",
+
+  "alice_37_332.npz": "val-37-75-10",
+
+  "alice_37_333.npz": "val-37-75-11",
+
+  "alice_37_334.npz": "val-37-76-0",
+
+  "alice_37_335.npz": "val-37-76-1",
+
+  "alice_37_336.npz": "val-37-77-0",
+
+  "alice_37_337.npz": "val-37-77-1",
+
+  "alice_37_338.npz": "val-37-78-0",
+
+  "alice_37_339.npz": "val-37-78-1",
+
+  "alice_37_340.npz": "val-37-78-2",
+
+  "alice_37_341.npz": "val-37-78-3",
+
+  "alice_37_342.npz": "val-37-78-4",
+
+  "alice_37_343.npz": "val-37-78-5",
+
+  "alice_37_344.npz": "val-37-78-6",
+
+  "alice_37_345.npz": "val-37-79-0",
+
+  "alice_37_346.npz": "val-37-79-1",
+
+  "alice_37_347.npz": "val-37-79-2",
+
+  "alice_37_348.npz": "val-37-79-3",
+
+  "alice_37_349.npz": "val-37-79-4",
+
+  "alice_37_350.npz": "val-37-79-5",
+
+  "alice_37_351.npz": "val-37-79-6",
+
+  "alice_37_352.npz": "val-37-80-0",
+
+  "alice_37_353.npz": "val-37-80-1",
+
+  "alice_37_354.npz": "val-37-80-2",
+
+  "alice_37_355.npz": "val-37-81-0",
+
+  "alice_37_356.npz": "val-37-82-0",
+
+  "alice_37_357.npz": "val-37-82-1",
+
+  "alice_37_358.npz": "val-37-82-2",
+
+  "alice_37_359.npz": "val-37-82-3",
+
+  "alice_37_360.npz": "val-37-82-4",
+
+  "alice_37_361.npz": "val-37-82-5",
+
+  "alice_18_282.npz": "test-18-67-0",
+
+  "alice_18_283.npz": "test-18-67-1",
+
+  "alice_18_284.npz": "test-18-67-2",
+
+  "alice_18_285.npz": "test-18-67-3",
+
+  "alice_18_286.npz": "test-18-67-4",
+
+  "alice_18_287.npz": "test-18-67-5",
+
+  "alice_18_288.npz": "test-18-68-0",
+
+  "alice_18_289.npz": "test-18-68-1",
+
+  "alice_18_290.npz": "test-18-68-2",
+
+  "alice_18_291.npz": "test-18-68-3",
+
+  "alice_18_292.npz": "test-18-68-4",
+
+  "alice_18_293.npz": "test-18-68-5",
+
+  "alice_18_294.npz": "test-18-68-6",
+
+  "alice_18_295.npz": "test-18-69-0",
+
+  "alice_18_296.npz": "test-18-70-0",
+
+  "alice_18_297.npz": "test-18-70-1",
+
+  "alice_18_298.npz": "test-18-70-2",
+
+  "alice_18_299.npz": "test-18-70-3",
+
+  "alice_18_300.npz": "test-18-70-4",
+
+  "alice_18_301.npz": "test-18-71-0",
+
+  "alice_18_302.npz": "test-18-71-1",
+
+  "alice_18_303.npz": "test-18-71-2",
+
+  "alice_18_304.npz": "test-18-71-3",
+
+  "alice_18_305.npz": "test-18-72-0",
+
+  "alice_18_306.npz": "test-18-72-1",
+
+  "alice_18_307.npz": "test-18-72-2",
+
+  "alice_18_308.npz": "test-18-72-3",
+
+  "alice_18_309.npz": "test-18-72-4",
+
+  "alice_18_310.npz": "test-18-72-5",
+
+  "alice_18_311.npz": "test-18-72-6",
+
+  "alice_18_312.npz": "test-18-72-7",
+
+  "alice_18_313.npz": "test-18-72-8",
+
+  "alice_18_314.npz": "test-18-72-9",
+
+  "alice_18_315.npz": "test-18-72-10",
+
+  "alice_18_316.npz": "test-18-72-11",
+
+  "alice_18_317.npz": "test-18-72-12",
+
+  "alice_18_318.npz": "test-18-73-0",
+
+  "alice_18_319.npz": "test-18-74-0",
+
+  "alice_18_320.npz": "test-18-74-1",
+
+  "alice_18_321.npz": "test-18-74-2",
+
+  "alice_48_282.npz": "test-48-67-0",
+
+  "alice_48_283.npz": "test-48-67-1",
+
+  "alice_48_284.npz": "test-48-67-2",
+
+  "alice_48_285.npz": "test-48-67-3",
+
+  "alice_48_286.npz": "test-48-67-4",
+
+  "alice_48_287.npz": "test-48-67-5",
+
+  "alice_48_288.npz": "test-48-68-0",
+
+  "alice_48_289.npz": "test-48-68-1",
+
+  "alice_48_290.npz": "test-48-68-2",
+
+  "alice_48_291.npz": "test-48-68-3",
+
+  "alice_48_292.npz": "test-48-68-4",
+
+  "alice_48_293.npz": "test-48-68-5",
+
+  "alice_48_294.npz": "test-48-68-6",
+
+  "alice_48_295.npz": "test-48-69-0",
+
+  "alice_48_296.npz": "test-48-70-0",
+
+  "alice_48_297.npz": "test-48-70-1",
+
+  "alice_48_298.npz": "test-48-70-2",
+
+  "alice_48_299.npz": "test-48-70-3",
+
+  "alice_48_300.npz": "test-48-70-4",
+
+  "alice_48_301.npz": "test-48-71-0",
+
+  "alice_48_302.npz": "test-48-71-1",
+
+  "alice_48_303.npz": "test-48-71-2",
+
+  "alice_48_304.npz": "test-48-71-3",
+
+  "alice_48_305.npz": "test-48-72-0",
+
+  "alice_48_306.npz": "test-48-72-1",
+
+  "alice_48_307.npz": "test-48-72-2",
+
+  "alice_48_308.npz": "test-48-72-3",
+
+  "alice_48_309.npz": "test-48-72-4",
+
+  "alice_48_310.npz": "test-48-72-5",
+
+  "alice_48_311.npz": "test-48-72-6",
+
+  "alice_48_312.npz": "test-48-72-7",
+
+  "alice_48_313.npz": "test-48-72-8",
+
+  "alice_48_314.npz": "test-48-72-9",
+
+  "alice_48_315.npz": "test-48-72-10",
+
+  "alice_48_316.npz": "test-48-72-11",
+
+  "alice_48_317.npz": "test-48-72-12",
+
+  "alice_48_318.npz": "test-48-73-0",
+
+  "alice_48_319.npz": "test-48-74-0",
+
+  "alice_48_320.npz": "test-48-74-1",
+
+  "alice_48_321.npz": "test-48-74-2",
+
+  "alice_31_282.npz": "test-31-67-0",
+
+  "alice_31_283.npz": "test-31-67-1",
+
+  "alice_31_284.npz": "test-31-67-2",
+
+  "alice_31_285.npz": "test-31-67-3",
+
+  "alice_31_286.npz": "test-31-67-4",
+
+  "alice_31_287.npz": "test-31-67-5",
+
+  "alice_31_288.npz": "test-31-68-0",
+
+  "alice_31_289.npz": "test-31-68-1",
+
+  "alice_31_290.npz": "test-31-68-2",
+
+  "alice_31_291.npz": "test-31-68-3",
+
+  "alice_31_292.npz": "test-31-68-4",
+
+  "alice_31_293.npz": "test-31-68-5",
+
+  "alice_31_294.npz": "test-31-68-6",
+
+  "alice_31_295.npz": "test-31-69-0",
+
+  "alice_31_296.npz": "test-31-70-0",
+
+  "alice_31_297.npz": "test-31-70-1",
+
+  "alice_31_298.npz": "test-31-70-2",
+
+  "alice_31_299.npz": "test-31-70-3",
+
+  "alice_31_300.npz": "test-31-70-4",
+
+  "alice_31_301.npz": "test-31-71-0",
+
+  "alice_31_302.npz": "test-31-71-1",
+
+  "alice_31_303.npz": "test-31-71-2",
+
+  "alice_31_304.npz": "test-31-71-3",
+
+  "alice_31_305.npz": "test-31-72-0",
+
+  "alice_31_306.npz": "test-31-72-1",
+
+  "alice_31_307.npz": "test-31-72-2",
+
+  "alice_31_308.npz": "test-31-72-3",
+
+  "alice_31_309.npz": "test-31-72-4",
+
+  "alice_31_310.npz": "test-31-72-5",
+
+  "alice_31_311.npz": "test-31-72-6",
+
+  "alice_31_312.npz": "test-31-72-7",
+
+  "alice_31_313.npz": "test-31-72-8",
+
+  "alice_31_314.npz": "test-31-72-9",
+
+  "alice_31_315.npz": "test-31-72-10",
+
+  "alice_31_316.npz": "test-31-72-11",
+
+  "alice_31_317.npz": "test-31-72-12",
+
+  "alice_31_318.npz": "test-31-73-0",
+
+  "alice_31_319.npz": "test-31-74-0",
+
+  "alice_31_320.npz": "test-31-74-1",
+
+  "alice_31_321.npz": "test-31-74-2",
+
+  "alice_47_282.npz": "test-47-67-0",
+
+  "alice_47_283.npz": "test-47-67-1",
+
+  "alice_47_284.npz": "test-47-67-2",
+
+  "alice_47_285.npz": "test-47-67-3",
+
+  "alice_47_286.npz": "test-47-67-4",
+
+  "alice_47_287.npz": "test-47-67-5",
+
+  "alice_47_288.npz": "test-47-68-0",
+
+  "alice_47_289.npz": "test-47-68-1",
+
+  "alice_47_290.npz": "test-47-68-2",
+
+  "alice_47_291.npz": "test-47-68-3",
+
+  "alice_47_292.npz": "test-47-68-4",
+
+  "alice_47_293.npz": "test-47-68-5",
+
+  "alice_47_294.npz": "test-47-68-6",
+
+  "alice_47_295.npz": "test-47-69-0",
+
+  "alice_47_296.npz": "test-47-70-0",
+
+  "alice_47_297.npz": "test-47-70-1",
+
+  "alice_47_298.npz": "test-47-70-2",
+
+  "alice_47_299.npz": "test-47-70-3",
+
+  "alice_47_300.npz": "test-47-70-4",
+
+  "alice_47_301.npz": "test-47-71-0",
+
+  "alice_47_302.npz": "test-47-71-1",
+
+  "alice_47_303.npz": "test-47-71-2",
+
+  "alice_47_304.npz": "test-47-71-3",
+
+  "alice_47_305.npz": "test-47-72-0",
+
+  "alice_47_306.npz": "test-47-72-1",
+
+  "alice_47_307.npz": "test-47-72-2",
+
+  "alice_47_308.npz": "test-47-72-3",
+
+  "alice_47_309.npz": "test-47-72-4",
+
+  "alice_47_310.npz": "test-47-72-5",
+
+  "alice_47_311.npz": "test-47-72-6",
+
+  "alice_47_312.npz": "test-47-72-7",
+
+  "alice_47_313.npz": "test-47-72-8",
+
+  "alice_47_314.npz": "test-47-72-9",
+
+  "alice_47_315.npz": "test-47-72-10",
+
+  "alice_47_316.npz": "test-47-72-11",
+
+  "alice_47_317.npz": "test-47-72-12",
+
+  "alice_47_318.npz": "test-47-73-0",
+
+  "alice_47_319.npz": "test-47-74-0",
+
+  "alice_47_320.npz": "test-47-74-1",
+
+  "alice_47_321.npz": "test-47-74-2",
+
+  "alice_51_282.npz": "test-51-67-0",
+
+  "alice_51_283.npz": "test-51-67-1",
+
+  "alice_51_284.npz": "test-51-67-2",
+
+  "alice_51_285.npz": "test-51-67-3",
+
+  "alice_51_286.npz": "test-51-67-4",
+
+  "alice_51_287.npz": "test-51-67-5",
+
+  "alice_51_288.npz": "test-51-68-0",
+
+  "alice_51_289.npz": "test-51-68-1",
+
+  "alice_51_290.npz": "test-51-68-2",
+
+  "alice_51_291.npz": "test-51-68-3",
+
+  "alice_51_292.npz": "test-51-68-4",
+
+  "alice_51_293.npz": "test-51-68-5",
+
+  "alice_51_294.npz": "test-51-68-6",
+
+  "alice_51_295.npz": "test-51-69-0",
+
+  "alice_51_296.npz": "test-51-70-0",
+
+  "alice_51_297.npz": "test-51-70-1",
+
+  "alice_51_298.npz": "test-51-70-2",
+
+  "alice_51_299.npz": "test-51-70-3",
+
+  "alice_51_300.npz": "test-51-70-4",
+
+  "alice_51_301.npz": "test-51-71-0",
+
+  "alice_51_302.npz": "test-51-71-1",
+
+  "alice_51_303.npz": "test-51-71-2",
+
+  "alice_51_304.npz": "test-51-71-3",
+
+  "alice_51_305.npz": "test-51-72-0",
+
+  "alice_51_306.npz": "test-51-72-1",
+
+  "alice_51_307.npz": "test-51-72-2",
+
+  "alice_51_308.npz": "test-51-72-3",
+
+  "alice_51_309.npz": "test-51-72-4",
+
+  "alice_51_310.npz": "test-51-72-5",
+
+  "alice_51_311.npz": "test-51-72-6",
+
+  "alice_51_312.npz": "test-51-72-7",
+
+  "alice_51_313.npz": "test-51-72-8",
+
+  "alice_51_314.npz": "test-51-72-9",
+
+  "alice_51_315.npz": "test-51-72-10",
+
+  "alice_51_316.npz": "test-51-72-11",
+
+  "alice_51_317.npz": "test-51-72-12",
+
+  "alice_51_318.npz": "test-51-73-0",
+
+  "alice_51_319.npz": "test-51-74-0",
+
+  "alice_51_320.npz": "test-51-74-1",
+
+  "alice_51_321.npz": "test-51-74-2",
+
+  "alice_24_282.npz": "test-24-67-0",
+
+  "alice_24_283.npz": "test-24-67-1",
+
+  "alice_24_284.npz": "test-24-67-2",
+
+  "alice_24_285.npz": "test-24-67-3",
+
+  "alice_24_286.npz": "test-24-67-4",
+
+  "alice_24_287.npz": "test-24-67-5",
+
+  "alice_24_288.npz": "test-24-68-0",
+
+  "alice_24_289.npz": "test-24-68-1",
+
+  "alice_24_290.npz": "test-24-68-2",
+
+  "alice_24_291.npz": "test-24-68-3",
+
+  "alice_24_292.npz": "test-24-68-4",
+
+  "alice_24_293.npz": "test-24-68-5",
+
+  "alice_24_294.npz": "test-24-68-6",
+
+  "alice_24_295.npz": "test-24-69-0",
+
+  "alice_24_296.npz": "test-24-70-0",
+
+  "alice_24_297.npz": "test-24-70-1",
+
+  "alice_24_298.npz": "test-24-70-2",
+
+  "alice_24_299.npz": "test-24-70-3",
+
+  "alice_24_300.npz": "test-24-70-4",
+
+  "alice_24_301.npz": "test-24-71-0",
+
+  "alice_24_302.npz": "test-24-71-1",
+
+  "alice_24_303.npz": "test-24-71-2",
+
+  "alice_24_304.npz": "test-24-71-3",
+
+  "alice_24_305.npz": "test-24-72-0",
+
+  "alice_24_306.npz": "test-24-72-1",
+
+  "alice_24_307.npz": "test-24-72-2",
+
+  "alice_24_308.npz": "test-24-72-3",
+
+  "alice_24_309.npz": "test-24-72-4",
+
+  "alice_24_310.npz": "test-24-72-5",
+
+  "alice_24_311.npz": "test-24-72-6",
+
+  "alice_24_312.npz": "test-24-72-7",
+
+  "alice_24_313.npz": "test-24-72-8",
+
+  "alice_24_314.npz": "test-24-72-9",
+
+  "alice_24_315.npz": "test-24-72-10",
+
+  "alice_24_316.npz": "test-24-72-11",
+
+  "alice_24_317.npz": "test-24-72-12",
+
+  "alice_24_318.npz": "test-24-73-0",
+
+  "alice_24_319.npz": "test-24-74-0",
+
+  "alice_24_320.npz": "test-24-74-1",
+
+  "alice_24_321.npz": "test-24-74-2",
+
+  "alice_35_282.npz": "test-35-67-0",
+
+  "alice_35_283.npz": "test-35-67-1",
+
+  "alice_35_284.npz": "test-35-67-2",
+
+  "alice_35_285.npz": "test-35-67-3",
+
+  "alice_35_286.npz": "test-35-67-4",
+
+  "alice_35_287.npz": "test-35-67-5",
+
+  "alice_35_288.npz": "test-35-68-0",
+
+  "alice_35_289.npz": "test-35-68-1",
+
+  "alice_35_290.npz": "test-35-68-2",
+
+  "alice_35_291.npz": "test-35-68-3",
+
+  "alice_35_292.npz": "test-35-68-4",
+
+  "alice_35_293.npz": "test-35-68-5",
+
+  "alice_35_294.npz": "test-35-68-6",
+
+  "alice_35_295.npz": "test-35-69-0",
+
+  "alice_35_296.npz": "test-35-70-0",
+
+  "alice_35_297.npz": "test-35-70-1",
+
+  "alice_35_298.npz": "test-35-70-2",
+
+  "alice_35_299.npz": "test-35-70-3",
+
+  "alice_35_300.npz": "test-35-70-4",
+
+  "alice_35_301.npz": "test-35-71-0",
+
+  "alice_35_302.npz": "test-35-71-1",
+
+  "alice_35_303.npz": "test-35-71-2",
+
+  "alice_35_304.npz": "test-35-71-3",
+
+  "alice_35_305.npz": "test-35-72-0",
+
+  "alice_35_306.npz": "test-35-72-1",
+
+  "alice_35_307.npz": "test-35-72-2",
+
+  "alice_35_308.npz": "test-35-72-3",
+
+  "alice_35_309.npz": "test-35-72-4",
+
+  "alice_35_310.npz": "test-35-72-5",
+
+  "alice_35_311.npz": "test-35-72-6",
+
+  "alice_35_312.npz": "test-35-72-7",
+
+  "alice_35_313.npz": "test-35-72-8",
+
+  "alice_35_314.npz": "test-35-72-9",
+
+  "alice_35_315.npz": "test-35-72-10",
+
+  "alice_35_316.npz": "test-35-72-11",
+
+  "alice_35_317.npz": "test-35-72-12",
+
+  "alice_35_318.npz": "test-35-73-0",
+
+  "alice_35_319.npz": "test-35-74-0",
+
+  "alice_35_320.npz": "test-35-74-1",
+
+  "alice_35_321.npz": "test-35-74-2",
+
+  "alice_28_282.npz": "test-28-67-0",
+
+  "alice_28_283.npz": "test-28-67-1",
+
+  "alice_28_284.npz": "test-28-67-2",
+
+  "alice_28_285.npz": "test-28-67-3",
+
+  "alice_28_286.npz": "test-28-67-4",
+
+  "alice_28_287.npz": "test-28-67-5",
+
+  "alice_28_288.npz": "test-28-68-0",
+
+  "alice_28_289.npz": "test-28-68-1",
+
+  "alice_28_290.npz": "test-28-68-2",
+
+  "alice_28_291.npz": "test-28-68-3",
+
+  "alice_28_292.npz": "test-28-68-4",
+
+  "alice_28_293.npz": "test-28-68-5",
+
+  "alice_28_294.npz": "test-28-68-6",
+
+  "alice_28_295.npz": "test-28-69-0",
+
+  "alice_28_296.npz": "test-28-70-0",
+
+  "alice_28_297.npz": "test-28-70-1",
+
+  "alice_28_298.npz": "test-28-70-2",
+
+  "alice_28_299.npz": "test-28-70-3",
+
+  "alice_28_300.npz": "test-28-70-4",
+
+  "alice_28_301.npz": "test-28-71-0",
+
+  "alice_28_302.npz": "test-28-71-1",
+
+  "alice_28_303.npz": "test-28-71-2",
+
+  "alice_28_304.npz": "test-28-71-3",
+
+  "alice_28_305.npz": "test-28-72-0",
+
+  "alice_28_306.npz": "test-28-72-1",
+
+  "alice_28_307.npz": "test-28-72-2",
+
+  "alice_28_308.npz": "test-28-72-3",
+
+  "alice_28_309.npz": "test-28-72-4",
+
+  "alice_28_310.npz": "test-28-72-5",
+
+  "alice_28_311.npz": "test-28-72-6",
+
+  "alice_28_312.npz": "test-28-72-7",
+
+  "alice_28_313.npz": "test-28-72-8",
+
+  "alice_28_314.npz": "test-28-72-9",
+
+  "alice_28_315.npz": "test-28-72-10",
+
+  "alice_28_316.npz": "test-28-72-11",
+
+  "alice_28_317.npz": "test-28-72-12",
+
+  "alice_28_318.npz": "test-28-73-0",
+
+  "alice_28_319.npz": "test-28-74-0",
+
+  "alice_28_320.npz": "test-28-74-1",
+
+  "alice_28_321.npz": "test-28-74-2",
+
+  "alice_53_282.npz": "test-53-67-0",
+
+  "alice_53_283.npz": "test-53-67-1",
+
+  "alice_53_284.npz": "test-53-67-2",
+
+  "alice_53_285.npz": "test-53-67-3",
+
+  "alice_53_286.npz": "test-53-67-4",
+
+  "alice_53_287.npz": "test-53-67-5",
+
+  "alice_53_288.npz": "test-53-68-0",
+
+  "alice_53_289.npz": "test-53-68-1",
+
+  "alice_53_290.npz": "test-53-68-2",
+
+  "alice_53_291.npz": "test-53-68-3",
+
+  "alice_53_292.npz": "test-53-68-4",
+
+  "alice_53_293.npz": "test-53-68-5",
+
+  "alice_53_294.npz": "test-53-68-6",
+
+  "alice_53_295.npz": "test-53-69-0",
+
+  "alice_53_296.npz": "test-53-70-0",
+
+  "alice_53_297.npz": "test-53-70-1",
+
+  "alice_53_298.npz": "test-53-70-2",
+
+  "alice_53_299.npz": "test-53-70-3",
+
+  "alice_53_300.npz": "test-53-70-4",
+
+  "alice_53_301.npz": "test-53-71-0",
+
+  "alice_53_302.npz": "test-53-71-1",
+
+  "alice_53_303.npz": "test-53-71-2",
+
+  "alice_53_304.npz": "test-53-71-3",
+
+  "alice_53_305.npz": "test-53-72-0",
+
+  "alice_53_306.npz": "test-53-72-1",
+
+  "alice_53_307.npz": "test-53-72-2",
+
+  "alice_53_308.npz": "test-53-72-3",
+
+  "alice_53_309.npz": "test-53-72-4",
+
+  "alice_53_310.npz": "test-53-72-5",
+
+  "alice_53_311.npz": "test-53-72-6",
+
+  "alice_53_312.npz": "test-53-72-7",
+
+  "alice_53_313.npz": "test-53-72-8",
+
+  "alice_53_314.npz": "test-53-72-9",
+
+  "alice_53_315.npz": "test-53-72-10",
+
+  "alice_53_316.npz": "test-53-72-11",
+
+  "alice_53_317.npz": "test-53-72-12",
+
+  "alice_53_318.npz": "test-53-73-0",
+
+  "alice_53_319.npz": "test-53-74-0",
+
+  "alice_53_320.npz": "test-53-74-1",
+
+  "alice_53_321.npz": "test-53-74-2",
+
+  "alice_23_282.npz": "test-23-67-0",
+
+  "alice_23_283.npz": "test-23-67-1",
+
+  "alice_23_284.npz": "test-23-67-2",
+
+  "alice_23_285.npz": "test-23-67-3",
+
+  "alice_23_286.npz": "test-23-67-4",
+
+  "alice_23_287.npz": "test-23-67-5",
+
+  "alice_23_288.npz": "test-23-68-0",
+
+  "alice_23_289.npz": "test-23-68-1",
+
+  "alice_23_290.npz": "test-23-68-2",
+
+  "alice_23_291.npz": "test-23-68-3",
+
+  "alice_23_292.npz": "test-23-68-4",
+
+  "alice_23_293.npz": "test-23-68-5",
+
+  "alice_23_294.npz": "test-23-68-6",
+
+  "alice_23_295.npz": "test-23-69-0",
+
+  "alice_23_296.npz": "test-23-70-0",
+
+  "alice_23_297.npz": "test-23-70-1",
+
+  "alice_23_298.npz": "test-23-70-2",
+
+  "alice_23_299.npz": "test-23-70-3",
+
+  "alice_23_300.npz": "test-23-70-4",
+
+  "alice_23_301.npz": "test-23-71-0",
+
+  "alice_23_302.npz": "test-23-71-1",
+
+  "alice_23_303.npz": "test-23-71-2",
+
+  "alice_23_304.npz": "test-23-71-3",
+
+  "alice_23_305.npz": "test-23-72-0",
+
+  "alice_23_306.npz": "test-23-72-1",
+
+  "alice_23_307.npz": "test-23-72-2",
+
+  "alice_23_308.npz": "test-23-72-3",
+
+  "alice_23_309.npz": "test-23-72-4",
+
+  "alice_23_310.npz": "test-23-72-5",
+
+  "alice_23_311.npz": "test-23-72-6",
+
+  "alice_23_312.npz": "test-23-72-7",
+
+  "alice_23_313.npz": "test-23-72-8",
+
+  "alice_23_314.npz": "test-23-72-9",
+
+  "alice_23_315.npz": "test-23-72-10",
+
+  "alice_23_316.npz": "test-23-72-11",
+
+  "alice_23_317.npz": "test-23-72-12",
+
+  "alice_23_318.npz": "test-23-73-0",
+
+  "alice_23_319.npz": "test-23-74-0",
+
+  "alice_23_320.npz": "test-23-74-1",
+
+  "alice_23_321.npz": "test-23-74-2",
+
+  "alice_36_282.npz": "test-36-67-0",
+
+  "alice_36_283.npz": "test-36-67-1",
+
+  "alice_36_284.npz": "test-36-67-2",
+
+  "alice_36_285.npz": "test-36-67-3",
+
+  "alice_36_286.npz": "test-36-67-4",
+
+  "alice_36_287.npz": "test-36-67-5",
+
+  "alice_36_288.npz": "test-36-68-0",
+
+  "alice_36_289.npz": "test-36-68-1",
+
+  "alice_36_290.npz": "test-36-68-2",
+
+  "alice_36_291.npz": "test-36-68-3",
+
+  "alice_36_292.npz": "test-36-68-4",
+
+  "alice_36_293.npz": "test-36-68-5",
+
+  "alice_36_294.npz": "test-36-68-6",
+
+  "alice_36_295.npz": "test-36-69-0",
+
+  "alice_36_296.npz": "test-36-70-0",
+
+  "alice_36_297.npz": "test-36-70-1",
+
+  "alice_36_298.npz": "test-36-70-2",
+
+  "alice_36_299.npz": "test-36-70-3",
+
+  "alice_36_300.npz": "test-36-70-4",
+
+  "alice_36_301.npz": "test-36-71-0",
+
+  "alice_36_302.npz": "test-36-71-1",
+
+  "alice_36_303.npz": "test-36-71-2",
+
+  "alice_36_304.npz": "test-36-71-3",
+
+  "alice_36_305.npz": "test-36-72-0",
+
+  "alice_36_306.npz": "test-36-72-1",
+
+  "alice_36_307.npz": "test-36-72-2",
+
+  "alice_36_308.npz": "test-36-72-3",
+
+  "alice_36_309.npz": "test-36-72-4",
+
+  "alice_36_310.npz": "test-36-72-5",
+
+  "alice_36_311.npz": "test-36-72-6",
+
+  "alice_36_312.npz": "test-36-72-7",
+
+  "alice_36_313.npz": "test-36-72-8",
+
+  "alice_36_314.npz": "test-36-72-9",
+
+  "alice_36_315.npz": "test-36-72-10",
+
+  "alice_36_316.npz": "test-36-72-11",
+
+  "alice_36_317.npz": "test-36-72-12",
+
+  "alice_36_318.npz": "test-36-73-0",
+
+  "alice_36_319.npz": "test-36-74-0",
+
+  "alice_36_320.npz": "test-36-74-1",
+
+  "alice_36_321.npz": "test-36-74-2",
+
+  "alice_42_282.npz": "test-42-67-0",
+
+  "alice_42_283.npz": "test-42-67-1",
+
+  "alice_42_284.npz": "test-42-67-2",
+
+  "alice_42_285.npz": "test-42-67-3",
+
+  "alice_42_286.npz": "test-42-67-4",
+
+  "alice_42_287.npz": "test-42-67-5",
+
+  "alice_42_288.npz": "test-42-68-0",
+
+  "alice_42_289.npz": "test-42-68-1",
+
+  "alice_42_290.npz": "test-42-68-2",
+
+  "alice_42_291.npz": "test-42-68-3",
+
+  "alice_42_292.npz": "test-42-68-4",
+
+  "alice_42_293.npz": "test-42-68-5",
+
+  "alice_42_294.npz": "test-42-68-6",
+
+  "alice_42_295.npz": "test-42-69-0",
+
+  "alice_42_296.npz": "test-42-70-0",
+
+  "alice_42_297.npz": "test-42-70-1",
+
+  "alice_42_298.npz": "test-42-70-2",
+
+  "alice_42_299.npz": "test-42-70-3",
+
+  "alice_42_300.npz": "test-42-70-4",
+
+  "alice_42_301.npz": "test-42-71-0",
+
+  "alice_42_302.npz": "test-42-71-1",
+
+  "alice_42_303.npz": "test-42-71-2",
+
+  "alice_42_304.npz": "test-42-71-3",
+
+  "alice_42_305.npz": "test-42-72-0",
+
+  "alice_42_306.npz": "test-42-72-1",
+
+  "alice_42_307.npz": "test-42-72-2",
+
+  "alice_42_308.npz": "test-42-72-3",
+
+  "alice_42_309.npz": "test-42-72-4",
+
+  "alice_42_310.npz": "test-42-72-5",
+
+  "alice_42_311.npz": "test-42-72-6",
+
+  "alice_42_312.npz": "test-42-72-7",
+
+  "alice_42_313.npz": "test-42-72-8",
+
+  "alice_42_314.npz": "test-42-72-9",
+
+  "alice_42_315.npz": "test-42-72-10",
+
+  "alice_42_316.npz": "test-42-72-11",
+
+  "alice_42_317.npz": "test-42-72-12",
+
+  "alice_42_318.npz": "test-42-73-0",
+
+  "alice_42_319.npz": "test-42-74-0",
+
+  "alice_42_320.npz": "test-42-74-1",
+
+  "alice_42_321.npz": "test-42-74-2",
+
+  "alice_44_282.npz": "test-44-67-0",
+
+  "alice_44_283.npz": "test-44-67-1",
+
+  "alice_44_284.npz": "test-44-67-2",
+
+  "alice_44_285.npz": "test-44-67-3",
+
+  "alice_44_286.npz": "test-44-67-4",
+
+  "alice_44_287.npz": "test-44-67-5",
+
+  "alice_44_288.npz": "test-44-68-0",
+
+  "alice_44_289.npz": "test-44-68-1",
+
+  "alice_44_290.npz": "test-44-68-2",
+
+  "alice_44_291.npz": "test-44-68-3",
+
+  "alice_44_292.npz": "test-44-68-4",
+
+  "alice_44_293.npz": "test-44-68-5",
+
+  "alice_44_294.npz": "test-44-68-6",
+
+  "alice_44_295.npz": "test-44-69-0",
+
+  "alice_44_296.npz": "test-44-70-0",
+
+  "alice_44_297.npz": "test-44-70-1",
+
+  "alice_44_298.npz": "test-44-70-2",
+
+  "alice_44_299.npz": "test-44-70-3",
+
+  "alice_44_300.npz": "test-44-70-4",
+
+  "alice_44_301.npz": "test-44-71-0",
+
+  "alice_44_302.npz": "test-44-71-1",
+
+  "alice_44_303.npz": "test-44-71-2",
+
+  "alice_44_304.npz": "test-44-71-3",
+
+  "alice_44_305.npz": "test-44-72-0",
+
+  "alice_44_306.npz": "test-44-72-1",
+
+  "alice_44_307.npz": "test-44-72-2",
+
+  "alice_44_308.npz": "test-44-72-3",
+
+  "alice_44_309.npz": "test-44-72-4",
+
+  "alice_44_310.npz": "test-44-72-5",
+
+  "alice_44_311.npz": "test-44-72-6",
+
+  "alice_44_312.npz": "test-44-72-7",
+
+  "alice_44_313.npz": "test-44-72-8",
+
+  "alice_44_314.npz": "test-44-72-9",
+
+  "alice_44_315.npz": "test-44-72-10",
+
+  "alice_44_316.npz": "test-44-72-11",
+
+  "alice_44_317.npz": "test-44-72-12",
+
+  "alice_44_318.npz": "test-44-73-0",
+
+  "alice_44_319.npz": "test-44-74-0",
+
+  "alice_44_320.npz": "test-44-74-1",
+
+  "alice_44_321.npz": "test-44-74-2",
+
+  "alice_39_282.npz": "test-39-67-0",
+
+  "alice_39_283.npz": "test-39-67-1",
+
+  "alice_39_284.npz": "test-39-67-2",
+
+  "alice_39_285.npz": "test-39-67-3",
+
+  "alice_39_286.npz": "test-39-67-4",
+
+  "alice_39_287.npz": "test-39-67-5",
+
+  "alice_39_288.npz": "test-39-68-0",
+
+  "alice_39_289.npz": "test-39-68-1",
+
+  "alice_39_290.npz": "test-39-68-2",
+
+  "alice_39_291.npz": "test-39-68-3",
+
+  "alice_39_292.npz": "test-39-68-4",
+
+  "alice_39_293.npz": "test-39-68-5",
+
+  "alice_39_294.npz": "test-39-68-6",
+
+  "alice_39_295.npz": "test-39-69-0",
+
+  "alice_39_296.npz": "test-39-70-0",
+
+  "alice_39_297.npz": "test-39-70-1",
+
+  "alice_39_298.npz": "test-39-70-2",
+
+  "alice_39_299.npz": "test-39-70-3",
+
+  "alice_39_300.npz": "test-39-70-4",
+
+  "alice_39_301.npz": "test-39-71-0",
+
+  "alice_39_302.npz": "test-39-71-1",
+
+  "alice_39_303.npz": "test-39-71-2",
+
+  "alice_39_304.npz": "test-39-71-3",
+
+  "alice_39_305.npz": "test-39-72-0",
+
+  "alice_39_306.npz": "test-39-72-1",
+
+  "alice_39_307.npz": "test-39-72-2",
+
+  "alice_39_308.npz": "test-39-72-3",
+
+  "alice_39_309.npz": "test-39-72-4",
+
+  "alice_39_310.npz": "test-39-72-5",
+
+  "alice_39_311.npz": "test-39-72-6",
+
+  "alice_39_312.npz": "test-39-72-7",
+
+  "alice_39_313.npz": "test-39-72-8",
+
+  "alice_39_314.npz": "test-39-72-9",
+
+  "alice_39_315.npz": "test-39-72-10",
+
+  "alice_39_316.npz": "test-39-72-11",
+
+  "alice_39_317.npz": "test-39-72-12",
+
+  "alice_39_318.npz": "test-39-73-0",
+
+  "alice_39_319.npz": "test-39-74-0",
+
+  "alice_39_320.npz": "test-39-74-1",
+
+  "alice_39_321.npz": "test-39-74-2",
+
+  "alice_41_282.npz": "test-41-67-0",
+
+  "alice_41_283.npz": "test-41-67-1",
+
+  "alice_41_284.npz": "test-41-67-2",
+
+  "alice_41_285.npz": "test-41-67-3",
+
+  "alice_41_286.npz": "test-41-67-4",
+
+  "alice_41_287.npz": "test-41-67-5",
+
+  "alice_41_288.npz": "test-41-68-0",
+
+  "alice_41_289.npz": "test-41-68-1",
+
+  "alice_41_290.npz": "test-41-68-2",
+
+  "alice_41_291.npz": "test-41-68-3",
+
+  "alice_41_292.npz": "test-41-68-4",
+
+  "alice_41_293.npz": "test-41-68-5",
+
+  "alice_41_294.npz": "test-41-68-6",
+
+  "alice_41_295.npz": "test-41-69-0",
+
+  "alice_41_296.npz": "test-41-70-0",
+
+  "alice_41_297.npz": "test-41-70-1",
+
+  "alice_41_298.npz": "test-41-70-2",
+
+  "alice_41_299.npz": "test-41-70-3",
+
+  "alice_41_300.npz": "test-41-70-4",
+
+  "alice_41_301.npz": "test-41-71-0",
+
+  "alice_41_302.npz": "test-41-71-1",
+
+  "alice_41_303.npz": "test-41-71-2",
+
+  "alice_41_304.npz": "test-41-71-3",
+
+  "alice_41_305.npz": "test-41-72-0",
+
+  "alice_41_306.npz": "test-41-72-1",
+
+  "alice_41_307.npz": "test-41-72-2",
+
+  "alice_41_308.npz": "test-41-72-3",
+
+  "alice_41_309.npz": "test-41-72-4",
+
+  "alice_41_310.npz": "test-41-72-5",
+
+  "alice_41_311.npz": "test-41-72-6",
+
+  "alice_41_312.npz": "test-41-72-7",
+
+  "alice_41_313.npz": "test-41-72-8",
+
+  "alice_41_314.npz": "test-41-72-9",
+
+  "alice_41_315.npz": "test-41-72-10",
+
+  "alice_41_316.npz": "test-41-72-11",
+
+  "alice_41_317.npz": "test-41-72-12",
+
+  "alice_41_318.npz": "test-41-73-0",
+
+  "alice_41_319.npz": "test-41-74-0",
+
+  "alice_41_320.npz": "test-41-74-1",
+
+  "alice_41_321.npz": "test-41-74-2",
+
+  "alice_30_282.npz": "test-30-67-0",
+
+  "alice_30_283.npz": "test-30-67-1",
+
+  "alice_30_284.npz": "test-30-67-2",
+
+  "alice_30_285.npz": "test-30-67-3",
+
+  "alice_30_286.npz": "test-30-67-4",
+
+  "alice_30_287.npz": "test-30-67-5",
+
+  "alice_30_288.npz": "test-30-68-0",
+
+  "alice_30_289.npz": "test-30-68-1",
+
+  "alice_30_290.npz": "test-30-68-2",
+
+  "alice_30_291.npz": "test-30-68-3",
+
+  "alice_30_292.npz": "test-30-68-4",
+
+  "alice_30_293.npz": "test-30-68-5",
+
+  "alice_30_294.npz": "test-30-68-6",
+
+  "alice_30_295.npz": "test-30-69-0",
+
+  "alice_30_296.npz": "test-30-70-0",
+
+  "alice_30_297.npz": "test-30-70-1",
+
+  "alice_30_298.npz": "test-30-70-2",
+
+  "alice_30_299.npz": "test-30-70-3",
+
+  "alice_30_300.npz": "test-30-70-4",
+
+  "alice_30_301.npz": "test-30-71-0",
+
+  "alice_30_302.npz": "test-30-71-1",
+
+  "alice_30_303.npz": "test-30-71-2",
+
+  "alice_30_304.npz": "test-30-71-3",
+
+  "alice_30_305.npz": "test-30-72-0",
+
+  "alice_30_306.npz": "test-30-72-1",
+
+  "alice_30_307.npz": "test-30-72-2",
+
+  "alice_30_308.npz": "test-30-72-3",
+
+  "alice_30_309.npz": "test-30-72-4",
+
+  "alice_30_310.npz": "test-30-72-5",
+
+  "alice_30_311.npz": "test-30-72-6",
+
+  "alice_30_312.npz": "test-30-72-7",
+
+  "alice_30_313.npz": "test-30-72-8",
+
+  "alice_30_314.npz": "test-30-72-9",
+
+  "alice_30_315.npz": "test-30-72-10",
+
+  "alice_30_316.npz": "test-30-72-11",
+
+  "alice_30_317.npz": "test-30-72-12",
+
+  "alice_30_318.npz": "test-30-73-0",
+
+  "alice_30_319.npz": "test-30-74-0",
+
+  "alice_30_320.npz": "test-30-74-1",
+
+  "alice_30_321.npz": "test-30-74-2",
+
+  "alice_43_282.npz": "test-43-67-0",
+
+  "alice_43_283.npz": "test-43-67-1",
+
+  "alice_43_284.npz": "test-43-67-2",
+
+  "alice_43_285.npz": "test-43-67-3",
+
+  "alice_43_286.npz": "test-43-67-4",
+
+  "alice_43_287.npz": "test-43-67-5",
+
+  "alice_43_288.npz": "test-43-68-0",
+
+  "alice_43_289.npz": "test-43-68-1",
+
+  "alice_43_290.npz": "test-43-68-2",
+
+  "alice_43_291.npz": "test-43-68-3",
+
+  "alice_43_292.npz": "test-43-68-4",
+
+  "alice_43_293.npz": "test-43-68-5",
+
+  "alice_43_294.npz": "test-43-68-6",
+
+  "alice_43_295.npz": "test-43-69-0",
+
+  "alice_43_296.npz": "test-43-70-0",
+
+  "alice_43_297.npz": "test-43-70-1",
+
+  "alice_43_298.npz": "test-43-70-2",
+
+  "alice_43_299.npz": "test-43-70-3",
+
+  "alice_43_300.npz": "test-43-70-4",
+
+  "alice_43_301.npz": "test-43-71-0",
+
+  "alice_43_302.npz": "test-43-71-1",
+
+  "alice_43_303.npz": "test-43-71-2",
+
+  "alice_43_304.npz": "test-43-71-3",
+
+  "alice_43_305.npz": "test-43-72-0",
+
+  "alice_43_306.npz": "test-43-72-1",
+
+  "alice_43_307.npz": "test-43-72-2",
+
+  "alice_43_308.npz": "test-43-72-3",
+
+  "alice_43_309.npz": "test-43-72-4",
+
+  "alice_43_310.npz": "test-43-72-5",
+
+  "alice_43_311.npz": "test-43-72-6",
+
+  "alice_43_312.npz": "test-43-72-7",
+
+  "alice_43_313.npz": "test-43-72-8",
+
+  "alice_43_314.npz": "test-43-72-9",
+
+  "alice_43_315.npz": "test-43-72-10",
+
+  "alice_43_316.npz": "test-43-72-11",
+
+  "alice_43_317.npz": "test-43-72-12",
+
+  "alice_43_318.npz": "test-43-73-0",
+
+  "alice_43_319.npz": "test-43-74-0",
+
+  "alice_43_320.npz": "test-43-74-1",
+
+  "alice_43_321.npz": "test-43-74-2",
+
+  "alice_45_282.npz": "test-45-67-0",
+
+  "alice_45_283.npz": "test-45-67-1",
+
+  "alice_45_284.npz": "test-45-67-2",
+
+  "alice_45_285.npz": "test-45-67-3",
+
+  "alice_45_286.npz": "test-45-67-4",
+
+  "alice_45_287.npz": "test-45-67-5",
+
+  "alice_45_288.npz": "test-45-68-0",
+
+  "alice_45_289.npz": "test-45-68-1",
+
+  "alice_45_290.npz": "test-45-68-2",
+
+  "alice_45_291.npz": "test-45-68-3",
+
+  "alice_45_292.npz": "test-45-68-4",
+
+  "alice_45_293.npz": "test-45-68-5",
+
+  "alice_45_294.npz": "test-45-68-6",
+
+  "alice_45_295.npz": "test-45-69-0",
+
+  "alice_45_296.npz": "test-45-70-0",
+
+  "alice_45_297.npz": "test-45-70-1",
+
+  "alice_45_298.npz": "test-45-70-2",
+
+  "alice_45_299.npz": "test-45-70-3",
+
+  "alice_45_300.npz": "test-45-70-4",
+
+  "alice_45_301.npz": "test-45-71-0",
+
+  "alice_45_302.npz": "test-45-71-1",
+
+  "alice_45_303.npz": "test-45-71-2",
+
+  "alice_45_304.npz": "test-45-71-3",
+
+  "alice_45_305.npz": "test-45-72-0",
+
+  "alice_45_306.npz": "test-45-72-1",
+
+  "alice_45_307.npz": "test-45-72-2",
+
+  "alice_45_308.npz": "test-45-72-3",
+
+  "alice_45_309.npz": "test-45-72-4",
+
+  "alice_45_310.npz": "test-45-72-5",
+
+  "alice_45_311.npz": "test-45-72-6",
+
+  "alice_45_312.npz": "test-45-72-7",
+
+  "alice_45_313.npz": "test-45-72-8",
+
+  "alice_45_314.npz": "test-45-72-9",
+
+  "alice_45_315.npz": "test-45-72-10",
+
+  "alice_45_316.npz": "test-45-72-11",
+
+  "alice_45_317.npz": "test-45-72-12",
+
+  "alice_45_318.npz": "test-45-73-0",
+
+  "alice_45_319.npz": "test-45-74-0",
+
+  "alice_45_320.npz": "test-45-74-1",
+
+  "alice_45_321.npz": "test-45-74-2",
+
+  "alice_49_282.npz": "test-49-67-0",
+
+  "alice_49_283.npz": "test-49-67-1",
+
+  "alice_49_284.npz": "test-49-67-2",
+
+  "alice_49_285.npz": "test-49-67-3",
+
+  "alice_49_286.npz": "test-49-67-4",
+
+  "alice_49_287.npz": "test-49-67-5",
+
+  "alice_49_288.npz": "test-49-68-0",
+
+  "alice_49_289.npz": "test-49-68-1",
+
+  "alice_49_290.npz": "test-49-68-2",
+
+  "alice_49_291.npz": "test-49-68-3",
+
+  "alice_49_292.npz": "test-49-68-4",
+
+  "alice_49_293.npz": "test-49-68-5",
+
+  "alice_49_294.npz": "test-49-68-6",
+
+  "alice_49_295.npz": "test-49-69-0",
+
+  "alice_49_296.npz": "test-49-70-0",
+
+  "alice_49_297.npz": "test-49-70-1",
+
+  "alice_49_298.npz": "test-49-70-2",
+
+  "alice_49_299.npz": "test-49-70-3",
+
+  "alice_49_300.npz": "test-49-70-4",
+
+  "alice_49_301.npz": "test-49-71-0",
+
+  "alice_49_302.npz": "test-49-71-1",
+
+  "alice_49_303.npz": "test-49-71-2",
+
+  "alice_49_304.npz": "test-49-71-3",
+
+  "alice_49_305.npz": "test-49-72-0",
+
+  "alice_49_306.npz": "test-49-72-1",
+
+  "alice_49_307.npz": "test-49-72-2",
+
+  "alice_49_308.npz": "test-49-72-3",
+
+  "alice_49_309.npz": "test-49-72-4",
+
+  "alice_49_310.npz": "test-49-72-5",
+
+  "alice_49_311.npz": "test-49-72-6",
+
+  "alice_49_312.npz": "test-49-72-7",
+
+  "alice_49_313.npz": "test-49-72-8",
+
+  "alice_49_314.npz": "test-49-72-9",
+
+  "alice_49_315.npz": "test-49-72-10",
+
+  "alice_49_316.npz": "test-49-72-11",
+
+  "alice_49_317.npz": "test-49-72-12",
+
+  "alice_49_318.npz": "test-49-73-0",
+
+  "alice_49_319.npz": "test-49-74-0",
+
+  "alice_49_320.npz": "test-49-74-1",
+
+  "alice_49_321.npz": "test-49-74-2",
+
+  "alice_26_282.npz": "test-26-67-0",
+
+  "alice_26_283.npz": "test-26-67-1",
+
+  "alice_26_284.npz": "test-26-67-2",
+
+  "alice_26_285.npz": "test-26-67-3",
+
+  "alice_26_286.npz": "test-26-67-4",
+
+  "alice_26_287.npz": "test-26-67-5",
+
+  "alice_26_288.npz": "test-26-68-0",
+
+  "alice_26_289.npz": "test-26-68-1",
+
+  "alice_26_290.npz": "test-26-68-2",
+
+  "alice_26_291.npz": "test-26-68-3",
+
+  "alice_26_292.npz": "test-26-68-4",
+
+  "alice_26_293.npz": "test-26-68-5",
+
+  "alice_26_294.npz": "test-26-68-6",
+
+  "alice_26_295.npz": "test-26-69-0",
+
+  "alice_26_296.npz": "test-26-70-0",
+
+  "alice_26_297.npz": "test-26-70-1",
+
+  "alice_26_298.npz": "test-26-70-2",
+
+  "alice_26_299.npz": "test-26-70-3",
+
+  "alice_26_300.npz": "test-26-70-4",
+
+  "alice_26_301.npz": "test-26-71-0",
+
+  "alice_26_302.npz": "test-26-71-1",
+
+  "alice_26_303.npz": "test-26-71-2",
+
+  "alice_26_304.npz": "test-26-71-3",
+
+  "alice_26_305.npz": "test-26-72-0",
+
+  "alice_26_306.npz": "test-26-72-1",
+
+  "alice_26_307.npz": "test-26-72-2",
+
+  "alice_26_308.npz": "test-26-72-3",
+
+  "alice_26_309.npz": "test-26-72-4",
+
+  "alice_26_310.npz": "test-26-72-5",
+
+  "alice_26_311.npz": "test-26-72-6",
+
+  "alice_26_312.npz": "test-26-72-7",
+
+  "alice_26_313.npz": "test-26-72-8",
+
+  "alice_26_314.npz": "test-26-72-9",
+
+  "alice_26_315.npz": "test-26-72-10",
+
+  "alice_26_316.npz": "test-26-72-11",
+
+  "alice_26_317.npz": "test-26-72-12",
+
+  "alice_26_318.npz": "test-26-73-0",
+
+  "alice_26_319.npz": "test-26-74-0",
+
+  "alice_26_320.npz": "test-26-74-1",
+
+  "alice_26_321.npz": "test-26-74-2",
+
+  "alice_22_282.npz": "test-22-67-0",
+
+  "alice_22_283.npz": "test-22-67-1",
+
+  "alice_22_284.npz": "test-22-67-2",
+
+  "alice_22_285.npz": "test-22-67-3",
+
+  "alice_22_286.npz": "test-22-67-4",
+
+  "alice_22_287.npz": "test-22-67-5",
+
+  "alice_22_288.npz": "test-22-68-0",
+
+  "alice_22_289.npz": "test-22-68-1",
+
+  "alice_22_290.npz": "test-22-68-2",
+
+  "alice_22_291.npz": "test-22-68-3",
+
+  "alice_22_292.npz": "test-22-68-4",
+
+  "alice_22_293.npz": "test-22-68-5",
+
+  "alice_22_294.npz": "test-22-68-6",
+
+  "alice_22_295.npz": "test-22-69-0",
+
+  "alice_22_296.npz": "test-22-70-0",
+
+  "alice_22_297.npz": "test-22-70-1",
+
+  "alice_22_298.npz": "test-22-70-2",
+
+  "alice_22_299.npz": "test-22-70-3",
+
+  "alice_22_300.npz": "test-22-70-4",
+
+  "alice_22_301.npz": "test-22-71-0",
+
+  "alice_22_302.npz": "test-22-71-1",
+
+  "alice_22_303.npz": "test-22-71-2",
+
+  "alice_22_304.npz": "test-22-71-3",
+
+  "alice_22_305.npz": "test-22-72-0",
+
+  "alice_22_306.npz": "test-22-72-1",
+
+  "alice_22_307.npz": "test-22-72-2",
+
+  "alice_22_308.npz": "test-22-72-3",
+
+  "alice_22_309.npz": "test-22-72-4",
+
+  "alice_22_310.npz": "test-22-72-5",
+
+  "alice_22_311.npz": "test-22-72-6",
+
+  "alice_22_312.npz": "test-22-72-7",
+
+  "alice_22_313.npz": "test-22-72-8",
+
+  "alice_22_314.npz": "test-22-72-9",
+
+  "alice_22_315.npz": "test-22-72-10",
+
+  "alice_22_316.npz": "test-22-72-11",
+
+  "alice_22_317.npz": "test-22-72-12",
+
+  "alice_22_318.npz": "test-22-73-0",
+
+  "alice_22_319.npz": "test-22-74-0",
+
+  "alice_22_320.npz": "test-22-74-1",
+
+  "alice_22_321.npz": "test-22-74-2",
+
+  "alice_50_282.npz": "test-50-67-0",
+
+  "alice_50_283.npz": "test-50-67-1",
+
+  "alice_50_284.npz": "test-50-67-2",
+
+  "alice_50_285.npz": "test-50-67-3",
+
+  "alice_50_286.npz": "test-50-67-4",
+
+  "alice_50_287.npz": "test-50-67-5",
+
+  "alice_50_288.npz": "test-50-68-0",
+
+  "alice_50_289.npz": "test-50-68-1",
+
+  "alice_50_290.npz": "test-50-68-2",
+
+  "alice_50_291.npz": "test-50-68-3",
+
+  "alice_50_292.npz": "test-50-68-4",
+
+  "alice_50_293.npz": "test-50-68-5",
+
+  "alice_50_294.npz": "test-50-68-6",
+
+  "alice_50_295.npz": "test-50-69-0",
+
+  "alice_50_296.npz": "test-50-70-0",
+
+  "alice_50_297.npz": "test-50-70-1",
+
+  "alice_50_298.npz": "test-50-70-2",
+
+  "alice_50_299.npz": "test-50-70-3",
+
+  "alice_50_300.npz": "test-50-70-4",
+
+  "alice_50_301.npz": "test-50-71-0",
+
+  "alice_50_302.npz": "test-50-71-1",
+
+  "alice_50_303.npz": "test-50-71-2",
+
+  "alice_50_304.npz": "test-50-71-3",
+
+  "alice_50_305.npz": "test-50-72-0",
+
+  "alice_50_306.npz": "test-50-72-1",
+
+  "alice_50_307.npz": "test-50-72-2",
+
+  "alice_50_308.npz": "test-50-72-3",
+
+  "alice_50_309.npz": "test-50-72-4",
+
+  "alice_50_310.npz": "test-50-72-5",
+
+  "alice_50_311.npz": "test-50-72-6",
+
+  "alice_50_312.npz": "test-50-72-7",
+
+  "alice_50_313.npz": "test-50-72-8",
+
+  "alice_50_314.npz": "test-50-72-9",
+
+  "alice_50_315.npz": "test-50-72-10",
+
+  "alice_50_316.npz": "test-50-72-11",
+
+  "alice_50_317.npz": "test-50-72-12",
+
+  "alice_50_318.npz": "test-50-73-0",
+
+  "alice_50_319.npz": "test-50-74-0",
+
+  "alice_50_320.npz": "test-50-74-1",
+
+  "alice_50_321.npz": "test-50-74-2",
+
+  "alice_37_282.npz": "test-37-67-0",
+
+  "alice_37_283.npz": "test-37-67-1",
+
+  "alice_37_284.npz": "test-37-67-2",
+
+  "alice_37_285.npz": "test-37-67-3",
+
+  "alice_37_286.npz": "test-37-67-4",
+
+  "alice_37_287.npz": "test-37-67-5",
+
+  "alice_37_288.npz": "test-37-68-0",
+
+  "alice_37_289.npz": "test-37-68-1",
+
+  "alice_37_290.npz": "test-37-68-2",
+
+  "alice_37_291.npz": "test-37-68-3",
+
+  "alice_37_292.npz": "test-37-68-4",
+
+  "alice_37_293.npz": "test-37-68-5",
+
+  "alice_37_294.npz": "test-37-68-6",
+
+  "alice_37_295.npz": "test-37-69-0",
+
+  "alice_37_296.npz": "test-37-70-0",
+
+  "alice_37_297.npz": "test-37-70-1",
+
+  "alice_37_298.npz": "test-37-70-2",
+
+  "alice_37_299.npz": "test-37-70-3",
+
+  "alice_37_300.npz": "test-37-70-4",
+
+  "alice_37_301.npz": "test-37-71-0",
+
+  "alice_37_302.npz": "test-37-71-1",
+
+  "alice_37_303.npz": "test-37-71-2",
+
+  "alice_37_304.npz": "test-37-71-3",
+
+  "alice_37_305.npz": "test-37-72-0",
+
+  "alice_37_306.npz": "test-37-72-1",
+
+  "alice_37_307.npz": "test-37-72-2",
+
+  "alice_37_308.npz": "test-37-72-3",
+
+  "alice_37_309.npz": "test-37-72-4",
+
+  "alice_37_310.npz": "test-37-72-5",
+
+  "alice_37_311.npz": "test-37-72-6",
+
+  "alice_37_312.npz": "test-37-72-7",
+
+  "alice_37_313.npz": "test-37-72-8",
+
+  "alice_37_314.npz": "test-37-72-9",
+
+  "alice_37_315.npz": "test-37-72-10",
+
+  "alice_37_316.npz": "test-37-72-11",
+
+  "alice_37_317.npz": "test-37-72-12",
+
+  "alice_37_318.npz": "test-37-73-0",
+
+  "alice_37_319.npz": "test-37-74-0",
+
+  "alice_37_320.npz": "test-37-74-1",
+
+  "alice_37_321.npz": "test-37-74-2"
+
+}
Index: src/com/model/pereira_feature_extraction.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/com/model/pereira_feature_extraction.py b/src/com/model/pereira_feature_extraction.py
new file mode 100644
--- /dev/null	(date 1672867807000)
+++ b/src/com/model/pereira_feature_extraction.py	(date 1672867807000)
@@ -0,0 +1,221 @@
+import os
+Proj_dir = os.path.abspath(os.path.join(os.getcwd(), "../../../"))#TODO local
+import sys
+
+sys.path.append(Proj_dir)
+# print(sys.path)
+import json
+import torch
+import scipy.io as scio
+import numpy as np
+from src.com.util.data_format import normalization
+from transformers import BertModel, BertTokenizer
+from src.com.model.run_auto_encoder import Autoencoder
+
+tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')
+bert_model = BertModel.from_pretrained('bert-large-uncased', output_hidden_states=True)
+# 这里调整模型
+model_file = Proj_dir + '/benchmark/model_1e-05.bin'
+# sent_to_brain_json = PROJ_DIR + "/text_tmp/alice_sent_to_brain.json"
+dataset_name = "pereira"
+participants = {'P01', 'M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07',
+                'M08', 'M09', 'M10', 'M13', 'M14', 'M15', 'M16', 'M17'}
+
+def get_sentence_embedding(sentence, option):
+    # if YOU NEED [cls] and [seq] PRESENTATION：True
+    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)  # Batch size 1
+    outputs = bert_model(input_ids)
+
+    all_layers_output = outputs[2]
+    # list of torch.FloatTensor (one for the output of each layer + the output of the embeddings) of shape (batch_size, sequence_length, hidden_size): Hidden-states of the model at the output of each layer plus the initial embedding outputs.
+
+    if option == "last_layer":
+        sent_embeddings = all_layers_output[-1]  # last layer
+    elif option == "second_to_last_layer":
+        sent_embeddings = all_layers_output[-2]  # second to last layer
+    else:
+        sent_embeddings = all_layers_output[-1]  # last layer
+
+    sent_embeddings = torch.squeeze(sent_embeddings, dim=0)
+    # print(sent_embeddings.shape)
+
+    # Calculate the average of all token vectors.
+    sentence_embedding_avg = torch.mean(sent_embeddings, dim=0)
+    # print(sentence_embedding_avg.shape)
+
+    return sent_embeddings.detach(), sentence_embedding_avg.detach()
+
+
+def load_brain_data(dataset, user):
+    if dataset == 'pereira':
+        paticipants_1 = ['M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07',
+                         'M08', 'M09', 'M10', 'M13', 'M14', 'M15', 'M16', 'M17', 'P01']
+        paticipants_2 = ['M02', 'M04', 'M07', 'M08', 'M09', 'M14', 'M15', 'P01']
+        paticipants_3 = ['M02', 'M03', 'M04', 'M07', 'M15', 'P01']
+        a = []
+        # dataset_path = "/Storage/ying/resources/pereira2018/'+user+'/data_180concepts_wordclouds.mat"
+        if user in paticipants_1:
+            exp1_path = '/Storage/ying/resources/pereira2018/' + user + '/data_180concepts_wordclouds.mat'
+            exp1_data = scio.loadmat(exp1_path)
+            examples = exp1_data['examples']
+            print(user, examples.shape)
+            ROI_path = '../../../resource/' + user + '_roi.mat'
+            data = scio.loadmat(ROI_path)
+            # read roi index
+            roi = data['index']
+
+            for i in range((examples.shape[0])):
+                # exp1_save_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/' + \
+                #                  'pereira_' + user + '_exp1_' + str(i) + '.npy'
+                b = []
+                for index in roi[0]:
+                    b.append(examples[i][index])
+                # np.save(exp1_save_path, a)
+                a.append(b[:46840])
+            if user in paticipants_2:
+                exp2_path = '/Storage/ying/resources/pereira2018/' + user + '/data_384sentences.mat'
+                exp2_data = scio.loadmat(exp2_path)
+                examples = exp2_data['examples_passagesentences']
+                # b = []
+                for i in range((examples.shape[0])):
+                    # exp2_save_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/' + \
+                    #                  'pereira_' + user + '_exp2_' + str(i) + '.npy'
+                    # print(exp2_save_path)
+                    b = []
+                    for index in roi[0]:
+                        b.append(examples[i][index])
+                    # print(len(a))
+                    # np.save(exp2_save_path, a)
+                    a.append(b[:46840])
+            if user in paticipants_3:
+                exp3_path = '/Storage/ying/resources/pereira2018/' + user + '/data_243sentences.mat'
+                exp3_data = scio.loadmat(exp3_path)
+                # print(exp3_data.keys())
+                examples = exp3_data['examples_passagesentences']
+                for i in range((examples.shape[0])):
+                    # print(i)
+                    # exp3_save_path = '/Storage/ying/resources/BrainBertTorch/brain/pereira/npy/' + \
+                    #                  'pereira_' + user + '_exp3_' + str(i) + '.npy'
+                    # print(exp3_save_path)
+                    b = []
+                    for index in roi[0]:
+                        b.append(examples[i][index])
+                    # print(len(a))
+                    # np.save(exp3_save_path, a)
+                    a.append(b[:46840])
+    return a
+
+
+def create_brain_npz(dataset):
+    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+
+    pre_trained_model = Autoencoder()
+    # pre_trained_model = nn.DataParallel(pre_trained_model, device_ids=[0, 1, 2, 4, 5, 6, 7])  # multi-GPU
+
+    # checkpoint = torch.load(os.path.join(model_file))
+    # pre_trained_model.load_state_dict(checkpoint)
+    pre_trained_model.load_state_dict(
+        {k.replace('module.', ''): v for k, v in torch.load(os.path.join(model_file)).items()})
+
+    pre_trained_model.to(device)
+
+    norm_path = '/Storage/ying/resources/BrainBertTorch/dataset/' + dataset + '/norm/'
+    feature_path = '/Storage/ying/resources/BrainBertTorch/dataset/' + dataset + '/features/'
+    feature_data = {}
+    norm_data = {}
+    # norm_path = '/Storage/ying/resources/BrainBertTorch/brain/' + dataset + '/npy/'
+    # files = os.listdir(norm_path)
+
+    for user in participants:
+        #     file_spilt = file.replace('.npy', '').split('_')
+        brain_data = load_brain_data(dataset, user)
+        #     user = file_spilt[1]
+        #     index = int(file_spilt[3])
+
+        train_X = np.array(brain_data)
+        train_X, _, _ = normalization(train_X)
+        train_X = torch.Tensor(train_X)
+        train_X = train_X.to(device, dtype=torch.float)
+        y, z = pre_trained_model(train_X)
+        # encoded_imgs, _, _ = normalization(encoded_imgs)
+        # z = tf.reshape(encoded_imgs, [-1, 1024])
+        norm_shape = train_X[0].shape
+        feature_shape = z[0].shape[0]
+        for index in range((z.shape[0])):
+            npz_filename = dataset_name + '_' + user + '_' + str(index) + '.npz'
+            norm_data['norm'] = {'data': train_X[index].cpu().data.tolist(),
+                                 'shape': list(norm_shape),
+                                 'type': None,
+                                 'kind': None}
+            feature_data['features'] = {'data': z[index].cpu().data.numpy().tolist(),
+                                        'shape': [feature_shape],
+                                        'type': None,
+                                        'kind': None}
+            np.savez(feature_path + npz_filename, features=feature_data['features'])
+            np.savez(norm_path + npz_filename, features=norm_data['norm'])
+
+            # print(k[1])
+
+
+def calculate_corrcoef(dataset):
+    import pandas as pd
+    device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")
+    sentence1_tsv_path = '../../../resource/text_807.tsv'
+    sentence2_tsv_path = '../../../resource/text_564.tsv'
+    sentence3_tsv_path = '../../../resource/text_423.tsv'
+    sentence4_tsv_path = '../../../resource/text_180.tsv'
+    # join exp1, 2and 3
+    type1_participants = ['P01', 'M02', 'M04', 'M07', 'M15']
+    # join exp1 and 3
+    type2_participants = ['M08', 'M09', 'M14']
+    # join exp1 and 3
+    type3_participants = ['M03']
+    # only join exp1
+    type4_participants = ['M01', 'M05', 'M06', 'M10', 'M13', 'M16', 'M17']
+    pre_trained_model = Autoencoder()
+    pre_trained_model.load_state_dict(
+        {k.replace('module.', ''): v for k, v in torch.load(os.path.join(model_file)).items()})
+
+    pre_trained_model.to(device)
+
+    corr_user = {}
+    for user in participants:
+        brain_data = load_brain_data(dataset, user)
+
+        train_X = np.array(brain_data)
+        train_X, _, _ = normalization(train_X)
+        train_X = torch.Tensor(train_X)
+        train_X = train_X.to(device, dtype=torch.float)
+        y, z = pre_trained_model(train_X)
+        corr_list = []
+        # feature_shape = z[0].shape[0]
+        if user in type1_participants:
+            sentence_df_path = sentence1_tsv_path
+        elif user in type2_participants:
+            sentence_df_path = sentence2_tsv_path
+        elif user in type3_participants:
+            sentence_df_path = sentence3_tsv_path
+        elif user in type4_participants:
+            sentence_df_path = sentence4_tsv_path
+        sentence_df = pd.read_csv(sentence_df_path, sep='\t', header=None)
+        sentence_df.columns = ['text', 'type']
+        for index in range((z.shape[0])):
+            sentence = sentence_df.loc[index]['text']
+            sent_embeddings, t = get_sentence_embedding(sentence, "last_layer")
+            # z[index, :].cpu().detach().numpy(), t.cpu().detach().numpy()
+            corr = np.corrcoef(z[index, :].cpu().detach().numpy(), t.cpu().detach().numpy())[0, 1]
+            corr_list.append(corr)
+        corr_user[user] = corr_list
+    json.dump(corr_user, dataset+f'_corr_user.json')
+
+
+if __name__ == "__main__":
+    # dataset = 'pereira'
+    # feature_path = '/Storage/ying/resources/BrainBertTorch/dataset/' + dataset + '/features/'
+    # user = 'P01'
+    # npz_filename = dataset_name + '_' + user + '_' + str(0) + '.npz'
+    # # participants = {'P01', 'M01', 'M02', 'M03', 'M04', 'M05', 'M06', 'M07',
+    # #                 'M08', 'M09', 'M10', 'M13', 'M14', 'M15', 'M16', 'M17'}
+    # features = np.load(feature_path+npz_filename)
+    # print(features['data'])
+    calculate_corrcoef('pereira')
Index: .idea/.gitignore
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/.gitignore b/.idea/.gitignore
new file mode 100644
--- /dev/null	(date 1672825716000)
+++ b/.idea/.gitignore	(date 1672825716000)
@@ -0,0 +1,8 @@
+# Default ignored files
+/shelf/
+/workspace.xml
+# Editor-based HTTP Client requests
+/httpRequests/
+# Datasource local storage ignored files
+/dataSources/
+/dataSources.local.xml
Index: .idea/deployment.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/deployment.xml b/.idea/deployment.xml
new file mode 100644
--- /dev/null	(date 1695637746000)
+++ b/.idea/deployment.xml	(date 1695637746000)
@@ -0,0 +1,23 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="PublishConfigData" autoUpload="Always" serverName="laplace_local_prince" remoteFilesAllowedToDisappearOnAutoupload="false" confirmBeforeUploading="false" showAutoUploadSettingsWarning="false">
+    <option name="confirmBeforeUploading" value="false" />
+    <serverData>
+      <paths name="laplace_local">
+        <serverdata>
+          <mappings>
+            <mapping deploy="/home/ying/project/brainAE" local="$PROJECT_DIR$" web="/" />
+          </mappings>
+        </serverdata>
+      </paths>
+      <paths name="laplace_local_prince">
+        <serverdata>
+          <mappings>
+            <mapping deploy="/home/ying/project/brainAE" local="$PROJECT_DIR$" web="/" />
+          </mappings>
+        </serverdata>
+      </paths>
+    </serverData>
+    <option name="myAutoUpload" value="ALWAYS" />
+  </component>
+</project>
\ No newline at end of file
Index: .idea/modules.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/modules.xml b/.idea/modules.xml
new file mode 100644
--- /dev/null	(date 1672825716000)
+++ b/.idea/modules.xml	(date 1672825716000)
@@ -0,0 +1,8 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="ProjectModuleManager">
+    <modules>
+      <module fileurl="file://$PROJECT_DIR$/.idea/BrainAE.iml" filepath="$PROJECT_DIR$/.idea/BrainAE.iml" />
+    </modules>
+  </component>
+</project>
\ No newline at end of file
Index: .idea/BrainAE.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/BrainAE.iml b/.idea/BrainAE.iml
new file mode 100644
--- /dev/null	(date 1695637415000)
+++ b/.idea/BrainAE.iml	(date 1695637415000)
@@ -0,0 +1,8 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<module type="PYTHON_MODULE" version="4">
+  <component name="NewModuleRootManager">
+    <content url="file://$MODULE_DIR$" />
+    <orderEntry type="jdk" jdkName="laplace_local" jdkType="Python SDK" />
+    <orderEntry type="sourceFolder" forTests="false" />
+  </component>
+</module>
\ No newline at end of file
diff --git a/alice_cae_corr_user.json b/alice_cae_corr_user.json
new file mode 100644
diff --git a/pereira_feature_extraction.py b/pereira_feature_extraction.py
new file mode 100644
diff --git a/src/__init__.py b/src/__init__.py
new file mode 100644
diff --git a/src/com/__init__.py b/src/com/__init__.py
new file mode 100644
diff --git a/src/com/model/__init__.py b/src/com/model/__init__.py
new file mode 100644
